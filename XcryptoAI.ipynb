{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_FileName='XcryptoAi_model.hdf5'\n",
    "Normalization_File='Normalization_Values.json'\n",
    "import sys\n",
    "sys.path.append('a/UltimeTradingBot/Crypto_backtest_tools')\n",
    "from utilities.get_data import get_historical_from_db\n",
    "from utilities.backtesting import basic_single_asset_backtest, plot_wallet_vs_asset, get_metrics\n",
    "import pandas as pd\n",
    "import ccxt\n",
    "import matplotlib.pyplot as plt\n",
    "import ta\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "from utilities.backtesting import plot_wallet_vs_asset, get_metrics, get_n_columns, basic_multi_asset_backtest, plot_sharpe_evolution, plot_bar_by_month\n",
    "from utilities.custom_indicators import SuperTrend\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense \n",
    "import os\n",
    "import gc\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "PRERR=False\n",
    "def prerr(err):\n",
    "    if PRERR:\n",
    "        print(\"\\033[0;31m Error in \"+str(sys._getframe().f_code.co_name) +\" \\033[0;33m\"+str(err))\n",
    "\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MetaData=get_crypto_metadata(Binance_USDT_HALAL)\n",
    "MetaData = pd.read_csv(\"D:\\+DATA+\\MetaData.csv\")\n",
    "df = pd.read_csv('D:/+DATA+/AICryptoBot/allok_w15_nosell.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df.drop(columns=\"sell\")\n",
    "#df=df.drop(columns=[\"Unnamed: 0\"])\n",
    "#df.to_csv('D:/+DATA+/allok_w15_nosell.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(df)/(1024**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing impoted DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['buy']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1000037][\"buy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "high_weight=3\n",
    "df[\"high\"]=(df[\"open\"]+high_weight*df[\"high\"]+df[\"low\"]+df[\"close\"])/(3+high_weight)\n",
    "df.rename(columns={\"high\":\"price\"},inplace = True)\n",
    "df[\"BTC_high\"]=(df[\"BTC_open\"]+high_weight*df[\"BTC_high\"]+df[\"BTC_low\"]+df[\"BTC_close\"])/(3+high_weight)\n",
    "df.rename(columns={\"BTC_high\":\"BTC_price\"},inplace = True)\n",
    "df2=df.drop(columns=[\"BTC_open\",\"BTC_low\",\"BTC_close\",\"open\",\"low\",\"close\"])\n",
    "del(df)\n",
    "df=df2\n",
    "#del(df2)\n",
    "for key in df.keys():\n",
    "    if key.find(\"BTC\")!=-1 and (key.find(\"open\")!=-1 or\n",
    "    key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "        df[key]=(df[\"BTC_price\"]-df[key])/df[\"BTC_price\"]\n",
    "    if key.find(\"BTC\")==-1 and (key.find(\"open\")!=-1 or\n",
    "    key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "        df[key]=(df[\"price\"]-df[key])/df[\"price\"]\n",
    "\n",
    "df1=df[df[\"buy\"]==1]\n",
    "df0=df[df[\"buy\"]==0].iloc[0:len(df1)]\n",
    "df=pd.concat([df1,df0],axis=0)\n",
    "del(df1)\n",
    "del(df0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VolRemover=[\"volume\",\"volume-1\",\"BTC_volume\",\"BTC_volume-1\"]\n",
    "#VolRemover=[]\n",
    "for key in df.keys():\n",
    "    if key.find(\"volume-1_\") != -1 :\n",
    "        VolRemover.append(key)\n",
    "\n",
    "df=df.drop(columns=VolRemover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"volume-1_1day\" in df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in df.keys():print(k, end=\"  ; \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_w15_50percent_novolume.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     df=pd.concat([df1,df0],axis=0).drop(columns=['volume-1', 'volume-1','close','BTC_volume-1', 'BTC_volume-1','BTC_volume-1'])\n",
    "# except:\n",
    "#     print(\"df may be clean\")\n",
    "    \n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del(df1)\n",
    "#del(df0)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.reindex(np.random.permutation(df.index))\n",
    "gc.collect()\n",
    "df=df.reindex(np.random.permutation(df.index))\n",
    "gc.collect()\n",
    "df=df.reindex(np.random.permutation(df.index))\n",
    "gc.collect()\n",
    "sys.getsizeof(df)/(1024**2)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cheking null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "df[df.isnull().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in df.keys():print(k,end=\"  ;\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# starting numpy process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert Pandas DataFrame to numpy object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt = df.to_numpy()\n",
    "dt\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[142110,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the rows Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(dt)/(1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('np_shuffled_cryptodata_w15.csv', dt ,delimiter=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt=np.genfromtxt('np_shuffled_cryptodata_w15.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_20percent= int(0.3*len(dt[:,0]))\n",
    "print(index_20percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XVALIDATION= dt[:index_20percent, :-1]\n",
    "YVALIDATION= dt[:index_20percent,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRAIN= dt[index_20percent:, 0:-1]\n",
    "YTRAIN= dt[index_20percent:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(XTRAIN[:,0])\n",
    "plt.ylabel(\"open_1min\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(YTRAIN)\n",
    "plt.ylabel(\"Output labels\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(YVALIDATION)\n",
    "plt.ylabel(\"Output labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenderalization (mean normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = XTRAIN.mean(axis=0)\n",
    "XTRAIN -= mean \n",
    "std = XTRAIN.std(axis=0)\n",
    "XTRAIN /= std\n",
    "\n",
    "XVALIDATION -=mean\n",
    "XVALIDATION /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normalization={\"mean\":mean.tolist(),\"std\":std.tolist()}\n",
    "with open(Normalization_File, 'w') as fp:\n",
    "            json.dump(Normalization, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(XTRAIN[:,0])\n",
    "plt.ylabel(\"open column\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XTRAIN.shape)\n",
    "print(YTRAIN.shape)\n",
    "print(XVALIDATION.shape)\n",
    "print(YVALIDATION.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5SKqJygzA6X7"
   },
   "outputs": [],
   "source": [
    "IN_DIM=len(XTRAIN[0,:])\n",
    "\n",
    "#code genrator\n",
    "global All_Hist\n",
    "try:\n",
    "    with open('Results_history.json') as json_file:\n",
    "        All_Hist = json.load(json_file)\n",
    "except:\n",
    "    All_Hist={0.000001:\"code\"}\n",
    "\n",
    "try:\n",
    "    All_Hist.pop('1e-06')\n",
    "except:\n",
    "    print(All_Hist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network architecture:\n",
    "- layer 1 : 764 neurons\n",
    "- layer 2 : 8 neurons\n",
    "- layer 3 : neurons "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(int(IN_DIM/2),input_dim=IN_DIM,activation='softplus'))\n",
    "model.add(Dense(int(IN_DIM/2),activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(int(IN_DIM/5),activation='softplus'))\n",
    "model.add(Dense(int(IN_DIM/4),activation='softmax'))\n",
    "model.add(Dense(int(IN_DIM/1),activation='softplus'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "print(model.summary())\n",
    "#model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "callbacks_a = ModelCheckpoint(filepath = Model_FileName,monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "callbacks_b = EarlyStopping(monitor ='val_accuracy',mode='auto',patience=20,verbose=1)\n",
    "history = model.fit(XTRAIN,\n",
    "                YTRAIN,\n",
    "                validation_data=(XVALIDATION,YVALIDATION),\n",
    "                epochs=1200,\n",
    "                batch_size=5000,\n",
    "                callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "print('##########################################################################')\n",
    "print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(IN_DIM/2),input_dim=IN_DIM,activation='softplus'))\n",
    "    model.add(Dense(int(IN_DIM/2),activation='relu'))\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(Dense(int(IN_DIM/5),activation='softplus'))\n",
    "    model.add(Dense(int(IN_DIM/4),activation='softmax'))\n",
    "    model.add(Dense(int(IN_DIM/1),activation='softplus'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    print(model.summary())\n",
    "    #model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    callbacks_a = ModelCheckpoint(filepath = Model_FileName,monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "    callbacks_b = EarlyStopping(monitor ='val_accuracy',mode='auto',patience=20,verbose=1)\n",
    "    history = model.fit(XTRAIN,\n",
    "                    YTRAIN,\n",
    "                    validation_data=(XVALIDATION,YVALIDATION),\n",
    "                    epochs=1200,\n",
    "                    batch_size=5000,\n",
    "                    callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "    print('##########################################################################')\n",
    "    print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('##########################################################################')\n",
    "print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[0,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.evaluate(XVALIDATION, YVALIDATION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[0:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make probability predictions with the model\n",
    "predictions = model.predict(XVALIDATION)\n",
    "# round predictions \n",
    "rounded = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded[1201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YVALIDATION[1201]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "875f36f95367728e9e1ed7321fa85119a0c86f1195820c7e047475fcf301cc07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

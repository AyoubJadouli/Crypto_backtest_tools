{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/UltimeTradingBot/Crypto_backtest_tools'\n",
    "Normalization_File='/UltimeTradingBot/Data/005_w20_Norm_v2.json'\n",
    "Model_FileName='/UltimeTradingBot/Data/005_w20_Model_v2.hdf5'\n",
    "#Normalization_File='w15_NoVol_Normalization.json'\n",
    "#Model_FileName='w15_NoVol_XcryptoAi_model.hdf5'\n",
    "WINDOW_SIZE=20\n",
    "window=WINDOW_SIZE\n",
    "MAX_FORCAST_SIZE=10\n",
    "BUY_PERCENT=0.5\n",
    "SELL_PERCENT=0.3\n",
    "NORM_FILE=Normalization_File\n",
    "MODEL_FILE=Model_FileName\n",
    "ALLHIST_FILE='Results_history.json'\n",
    "DATA_DIR='/UltimeTradingBot/Data/'\n",
    "DATA_FILE=DATA_DIR+'w'+str(WINDOW_SIZE)+'_CryIn_NoVol.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('/UltimeTradingBot/Crypto_backtest_tools')\n",
    "\n",
    "from utilities.get_data import get_historical_from_db\n",
    "from utilities.backtesting import basic_single_asset_backtest, plot_wallet_vs_asset, get_metrics\n",
    "import pandas as pd\n",
    "import ccxt\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense \n",
    "import os\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import os\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()    \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "PRERR=False\n",
    "def prerr(err):\n",
    "    if PRERR:\n",
    "        print(\"\\033[0;31m Error in \"+str(sys._getframe().f_code.co_name) +\" \\033[0;33m\"+str(err))\n",
    "\n",
    "PDEBUG=True\n",
    "def pdebug(err):\n",
    "    if PDEBUG:\n",
    "        print(\"\\033[0;31m Error in \"+str(sys._getframe().f_code.co_name) +\" \\033[0;33m\"+str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetaData = pd.read_csv(\"../Data/Metadata.csv\",index_col=0)\n",
    "MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MetaData=get_crypto_metadata(Binance_USDT_HALAL)\n",
    "#MetaData = pd.read_csv(\"../Data/MetaData.csv\")\n",
    "#df = pd.read_csv(DATA_FILE,index_col=0,nrows=1000000)\n",
    "df = pd.read_csv(DATA_FILE,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df.drop(columns=\"sell\")\n",
    "#df=df.drop(columns=[\"Unnamed: 0\"])\n",
    "#df.to_csv('D:/+DATA+/allok_w15_nosell.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(df)/(1024**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing impoted DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=[\"sell\",'bs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VolRemover=[\"volume\",\"volume-1\",\"BTC_volume-1\"]\n",
    "# for key in df.keys():\n",
    "#     if key.find(\"volume-1_\") != -1 :\n",
    "#         VolRemover.append(key)\n",
    "\n",
    "#     df=pd.concat([df1,df0],axis=0).drop(columns=VolRemover)\n",
    "\n",
    "# high_weight=3\n",
    "# df[\"high\"]=(df[\"open\"]+high_weight*df[\"high\"]+df[\"low\"]+df[\"close\"])/(3+high_weight)\n",
    "# df.rename(columns={\"high\":\"price\"},inplace = True)\n",
    "# df[\"BTC_high\"]=(df[\"BTC_open\"]+high_weight*df[\"BTC_high\"]+df[\"BTC_low\"]+df[\"BTC_close\"])/(3+high_weight)\n",
    "# df.rename(columns={\"BTC_high\":\"BTC_price\"},inplace = True)\n",
    "# df2=df.drop(columns=[\"BTC_open\",\"BTC_low\",\"BTC_close\",\"open\",\"low\",\"close\"])\n",
    "# del(df)\n",
    "# df=df2\n",
    "# #del(df2)\n",
    "# for key in df.keys():\n",
    "#     if key.find(\"BTC\")!=-1 and (key.find(\"open\")!=-1 or\n",
    "#     key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "#         df[key]=(df[\"BTC_price\"]-df[key])/df[\"BTC_price\"]\n",
    "#     if key.find(\"BTC\")==-1 and (key.find(\"open\")!=-1 or\n",
    "#     key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "#         df[key]=(df[\"price\"]-df[key])/df[\"price\"]\n",
    "\n",
    "# df1=df[df[\"buy\"]==1]\n",
    "# df0=df[df[\"buy\"]==0].iloc[0:len(df1)]\n",
    "# #del(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gc\n",
    "#df=df.iloc[0:int(len(df)/3)]\n",
    "gc.collect()\n",
    "# df=df.reindex(np.random.permutation(df.index))\n",
    "# df=df.reindex(np.random.permutation(df.index))\n",
    "# sys.getsizeof(df)/(1024**2)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     VolRemover=[\"volume\",\"volume-1\",\"BTC_volume-1\",\"BTC_volume\"]\n",
    "#     for key in df.keys():\n",
    "#         if key.find(\"volume-1_\") != -1 :\n",
    "#             VolRemover.append(key)\n",
    "\n",
    "#         df=df.drop(columns=VolRemover)\n",
    "# except:\n",
    "#     try:\n",
    "#         df=df.drop(columns=[\"BTC_volume\"])\n",
    "#     except:\n",
    "\n",
    "#         print(\"no veol\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cheking null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df[df.isnull().any(axis=1)])\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in df.keys():\n",
    "    if k.find(\"volume\") != -1 :print(k ,end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# starting numpy process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert Pandas DataFrame to numpy object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt = df.to_numpy()\n",
    "dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[3927,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the rows Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.shuffle(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.getsizeof(dt)/(1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('np_shuffled_cryptodata_w15.csv', dt ,delimiter=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt=np.genfromtxt('np_shuffled_cryptodata_w15.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_20percent= int(0.4*len(dt[:,0]))\n",
    "print(index_20percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XVALIDATION= dt[:index_20percent, :-1]\n",
    "YVALIDATION= dt[:index_20percent,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRAIN= dt[index_20percent:, 0:-1]\n",
    "YTRAIN= dt[index_20percent:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(XTRAIN[:,0])\n",
    "plt.ylabel(\"open_1min\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(YTRAIN)\n",
    "plt.ylabel(\"Output labels\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(YVALIDATION)\n",
    "plt.ylabel(\"Output labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenderalization (mean normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normalization=None\n",
    "def normalize(dataset,file=Normalization_File):\n",
    "    global Normalization\n",
    "    try:\n",
    "        N=Normalization\n",
    "    except:\n",
    "        Normalization=None\n",
    "    if(Normalization==None):\n",
    "        #print('Loading normalization from file')\n",
    "        with open(file) as json_file:\n",
    "            Normalization = json.load(json_file)\n",
    "    else:\n",
    "        #print('normalization is loaded')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "# with open('w15_NoVol_Normalization.json') as json_file:\n",
    "#             Normalization = json.load(json_file)\n",
    "# np.array(Normalization[\"mean\"])\n",
    "# mean=np.array(Normalization[\"mean\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean=np.array(Normalization[\"mean\"])\n",
    "# std=np.array(Normalization[\"std\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df)\n",
    "gc.collect()\n",
    "\n",
    "mean = XTRAIN.mean(axis=0)\n",
    "std = XTRAIN.std(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "XTRAIN -= mean \n",
    "XTRAIN /= std\n",
    "\n",
    "XVALIDATION -=mean\n",
    "XVALIDATION /= std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    Normalization={\"mean\":mean.tolist(),\"std\":std.tolist()}\n",
    "    with open(Normalization_File, 'w+') as fp:\n",
    "                json.dump(Normalization, fp,  indent=4)\n",
    "except:\n",
    "    print(\"error juppiter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(XTRAIN[:,0])\n",
    "plt.ylabel(\"open column\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XTRAIN.shape)\n",
    "print(YTRAIN.shape)\n",
    "print(XVALIDATION.shape)\n",
    "print(YVALIDATION.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5SKqJygzA6X7"
   },
   "outputs": [],
   "source": [
    "IN_DIM=len(XTRAIN[0,:])\n",
    "\n",
    "#code genrator\n",
    "global All_Hist\n",
    "try:\n",
    "    with open('Results_history.json') as json_file:\n",
    "        All_Hist = json.load(json_file)\n",
    "except:\n",
    "    All_Hist={}\n",
    "\n",
    "try:\n",
    "    All_Hist.pop('1e-06')\n",
    "except:\n",
    "    print(All_Hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def auto_code_gen():\n",
    "    NumLayer=random.randint(1, 5)\n",
    "    InpLay=int(random.randint(1, max(2,int(NumLayer/random.randint(3,NumLayer+4)+4))))\n",
    "    act_func=['tanh','relu','sigmoid','softmax','softplus']\n",
    "    dropout_val=[0.2,0.3,0.4,0.5,0.6,0.7]\n",
    "    decreaser=1\n",
    "    IN_DIM=len(XTRAIN[0,:])\n",
    "    code=\"model.add(Dense(int(IN_DIM/\"+str(InpLay)+\"),input_dim=IN_DIM,activation=\\'\"+random.choice(act_func)+\"\\'))\\n\"\n",
    "    for i in range(0,NumLayer):\n",
    "        code+='model.add(Dense(int(IN_DIM/'+str(random.randint(1,max(2,(i+1)*2)+1))+'),activation=\\''+random.choice(act_func)+'\\'))\\n'\n",
    "        if random.choice([True,False]):\n",
    "            code+='model.add(Dropout('+str(random.choice(dropout_val))+'))\\n'\n",
    "    code+='model.add(Dense(1,activation=\\'sigmoid\\'))'\n",
    "    return code\n",
    "\n",
    "def model_tester(max_tests=500): \n",
    "    code=\"\"\n",
    "    for c in range(1,max_tests+1):\n",
    "        model = Sequential()\n",
    "        if code  in All_Hist.values(): break\n",
    "        code=auto_code_gen()\n",
    "        exec(code)\n",
    "        print(model.summary())\n",
    "        #model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "        model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        callbacks_a = ModelCheckpoint(filepath ='X004_w15_cryptoAi_model.hdf5',monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "        callbacks_b = EarlyStopping(monitor ='val_accuracy',mode='auto',patience=20,verbose=1)\n",
    "        history = model.fit(XTRAIN,\n",
    "                        YTRAIN,\n",
    "                        validation_data=(XVALIDATION,YVALIDATION),\n",
    "                        epochs=1200,\n",
    "                        batch_size=5000,\n",
    "                        callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "        print('##########################################################################')\n",
    "        print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "        All_Hist[max(history.history['val_accuracy'])]=code\n",
    "        with open('Results_history.json', 'w') as fp:\n",
    "            json.dump(All_Hist, fp,  indent=4)\n",
    "\n",
    "\n",
    "#model_tester(max_tests=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network architecture:\n",
    "- layer 1 : 764 neurons\n",
    "- layer 2 : 8 neurons\n",
    "- layer 3 : neurons "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model = Sequential()\n",
    "model.add(Dense(int(IN_DIM/2),input_dim=IN_DIM,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(int(IN_DIM/6),activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(int(IN_DIM/12),activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "print(model.summary())\n",
    "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "callbacks_a = ModelCheckpoint(filepath=Model_FileName,monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "callbacks_b = EarlyStopping(monitor ='val_accuracy',mode='auto',patience=20,verbose=1)\n",
    "history = model.fit(XTRAIN,\n",
    "                YTRAIN,\n",
    "                validation_data=(XVALIDATION,YVALIDATION),\n",
    "                epochs=1200,\n",
    "                batch_size=5000,\n",
    "                callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "print('##########################################################################')\n",
    "print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.evaluate(dt[:,:-1], dt[:,-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make probability predictions with the model\n",
    "predictions = model.predict(XVALIDATION)\n",
    "# round predictions \n",
    "rounded = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded[1002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YVALIDATION[1002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Buy_Dessision(input):\n",
    "    predictions = model.predict(XVALIDATION)\n",
    "    rounded = [round(x[0]) for x in predictions]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "||||||||||||||||||||||     AI Crypto Bot by ABJ vMultiMod  |||||||||||||||||||||||\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "/UltimeTradingBot/Binance-Fast-Trade-Bot\n"
     ]
    }
   ],
   "source": [
    "# ABJ AI MOD\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "print(\"||||||||||||||||||||||     AI Crypto Bot by ABJ vMultiMod  |||||||||||||||||||||||\")\n",
    "print(\"|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "sys.path.append('/UltimeTradingBot/Binance-Fast-Trade-Bot')\n",
    "%cd '/UltimeTradingBot/Binance-Fast-Trade-Bot'\n",
    "from helpers.parameters import parse_args, load_config\n",
    "# Settings\n",
    "DEFAULT_CONFIG_FILE = 'config.yml'\n",
    "DEFAULT_CREDS_FILE = 'creds.yml'\n",
    "config_file =  DEFAULT_CONFIG_FILE\n",
    "parsed_config = load_config(config_file)\n",
    "\n",
    "PAIR_WITH = parsed_config['trading_options']['PAIR_WITH']\n",
    "EX_PAIRS = parsed_config['trading_options']['EX_PAIRS']\n",
    "\n",
    "\n",
    "# Acc:97% w21 tp:0028 T4 ->  Running for: 4:46:34 - 60/48 WIN %: 55.56% - 7.40 USDT | PROFIT %: 0.74%\n",
    "Normalization_File= parsed_config['ai_options']['Normalization_File']\n",
    "Model_FileName= parsed_config['ai_options']['Model_FileName']\n",
    "WINDOW_SIZE= int( parsed_config['ai_options']['WINDOW_SIZE'])\n",
    "PRESSISION=float( parsed_config['ai_options']['PRESSISION'])\n",
    "\n",
    "\n",
    "# Load trading vars\n",
    "PAIR_WITH = parsed_config['trading_options']['PAIR_WITH']\n",
    "EX_PAIRS = parsed_config['trading_options']['EX_PAIRS']\n",
    "TEST_MODE = parsed_config['script_options']['TEST_MODE']\n",
    "#TICKERS = parsed_config['trading_options']['TICKERS_LIST']\n",
    "USE_MOST_VOLUME_COINS = parsed_config['trading_options']['USE_MOST_VOLUME_COINS']\n",
    "\n",
    "ANNOYED_MOD= parsed_config['trading_options']['ANNOYED_MOD']\n",
    "WISE_ANNOYED_MOD= parsed_config['trading_options']['WISE_ANNOYED_MOD']\n",
    "RSI_MIN=  float(parsed_config['trading_options']['RSI_MIN'])\n",
    "RSI_BUY=  float(parsed_config['trading_options']['RSI_BUY'])\n",
    "BTC_CHECK_LEVEL=  int(parsed_config['trading_options']['BTC_CHECK_LEVEL'])\n",
    "CHOOSEN_INTERVAL=  parsed_config['trading_options']['CHOOSEN_INTERVAL']\n",
    "\n",
    "window=WINDOW_SIZE\n",
    "MAX_FORCAST_SIZE=1\n",
    "BUY_PERCENT=0.29\n",
    "SELL_PERCENT=0.2\n",
    "DATA_DIR='/UltimeTradingBot/Data/'\n",
    "hard_prediction_value=0.0e-01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import timeit\n",
    "import numpy as np\n",
    "import urllib\n",
    "#import ccxt\n",
    "import  ccxt  \n",
    "import random\n",
    "from keras.models import load_model\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "import asyncio\n",
    "import timeit\n",
    "import tensorflow as tf\n",
    "from pyparsing import anyOpenTag\n",
    "TIME_TO_WAIT = 0.65 # Minutes to wait between analysis\n",
    "ANNOYED_MOD=False\n",
    "import gc\n",
    "gc.collect()  \n",
    "# used for directory handling\n",
    "import glob\n",
    "import threading\n",
    "import time\n",
    "from datetime import date, datetime, timedelta\n",
    "#IMPORT and basic fonctions\n",
    "# use for environment variables\n",
    "import os\n",
    "import datetime as dt\n",
    "import asyncio\n",
    "# use if needed to pass args to external modules\n",
    "import sys\n",
    "import pandas as pd\n",
    "import urllib\n",
    "\n",
    "#for clear screen console\n",
    "from os import system, name\n",
    "\n",
    "# used for math functions\n",
    "import math\n",
    "\n",
    "# used to create threads & dynamic loading of modules\n",
    "import threading\n",
    "import multiprocessing\n",
    "import importlib\n",
    "import subprocess\n",
    "\n",
    "# used for directory handling\n",
    "import glob\n",
    "\n",
    "#discord needs import request\n",
    "import requests\n",
    "\n",
    "# Needed for colorful console output Install with: python3 -m pip install colorama (Mac/Linux) or pip install colorama (PC)\n",
    "from colorama import init\n",
    "init()\n",
    "\n",
    "# needed for the binance API / websockets / Exception handling\n",
    "from binance.client import Client\n",
    "from binance.client import AsyncClient\n",
    "\n",
    "from binance.exceptions import BinanceAPIException\n",
    "from binance.helpers import round_step_size\n",
    "from requests.exceptions import ReadTimeout, ConnectionError\n",
    "\n",
    "# used for dates\n",
    "from datetime import date, datetime, timedelta\n",
    "import time\n",
    "\n",
    "# used to repeatedly execute the code\n",
    "from itertools import count\n",
    "\n",
    "# used to store trades and sell assets\n",
    "import json\n",
    "\n",
    "#print output tables\n",
    "from prettytable import PrettyTable, from_html_one\n",
    "#from pretty_html_table import build_table\n",
    "\n",
    "#for regex\n",
    "import re\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load helper modules\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load creds modules\n",
    "from helpers.handle_creds import (\n",
    "    load_correct_creds\n",
    ")\n",
    "global graph,model\n",
    "\n",
    "#graph = tf.get_default_graph()\n",
    "\n",
    "\n",
    "\n",
    "creds_file =  DEFAULT_CREDS_FILE\n",
    "parsed_creds = load_config(creds_file)\n",
    "\n",
    "\n",
    "access_key= parsed_creds[\"prod\"][\"access_key\"]\n",
    "secret_key= parsed_creds[\"prod\"][\"secret_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if USE_MOST_VOLUME_COINS == True:\n",
    "        #if ABOVE_COINS_VOLUME == True:\n",
    "    TICKERS = \"volatile_volume_\" + str(date.today()) + \".txt\"\n",
    "else:\n",
    "    TICKERS = 'tickers.txt' #'signalsample.txt'\n",
    "    \n",
    "    \n",
    "    \n",
    "MY_EXCHANGE = 'BINANCE'\n",
    "MY_SCREENER = 'CRYPTO'\n",
    "\n",
    "\n",
    "FULL_LOG = False # List anylysis result to console\n",
    "\n",
    "\n",
    "SIGNAL_NAME = 'abj_ai_buy_signal_vMultiMod'\n",
    "SIGNAL_FILE = 'signals/' + SIGNAL_NAME + '.buy'\n",
    "\n",
    "X_AI_EX_FILE = 'AI_EXBUY'\n",
    "\n",
    "Exchange=ccxt.binance()\n",
    "ex=Exchange\n",
    "exchange=Exchange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pairs=[line.strip() for line in open(TICKERS)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LTC/USDT', 'FIDA/USDT', 'AXS/USDT', 'XMR/USDT', 'DOGE/USDT', 'SOL/USDT', 'AVAX/USDT', 'SHIB/USDT', 'NEAR/USDT', 'APE/USDT', 'GMT/USDT', 'GALA/USDT', 'XRP/USDT', 'ETH/USDT', 'ADA/USDT', 'ETC/USDT', 'DOT/USDT', 'TRX/USDT', 'ALGO/USDT', 'AR/USDT', 'SRM/USDT']\n"
     ]
    }
   ],
   "source": [
    "pusdt=pairs.copy()\n",
    "for i in range(len(pusdt)):\n",
    "    pusdt[i]=pusdt[i]+'/USDT'\n",
    "print(pusdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ loading the model for : LTC\n",
      "--- Error while processing the model of LTC\n",
      "--- LTC will be removed from the list.\n",
      "+++ loading the model for : AXS\n",
      "--- Error while processing the model of AXS\n",
      "--- AXS will be removed from the list.\n",
      "+++ loading the model for : DOGE\n",
      "--- Error while processing the model of DOGE\n",
      "--- DOGE will be removed from the list.\n",
      "+++ loading the model for : AVAX\n",
      "--- Error while processing the model of AVAX\n",
      "--- AVAX will be removed from the list.\n",
      "+++ loading the model for : NEAR\n",
      "--- Error while processing the model of NEAR\n",
      "--- NEAR will be removed from the list.\n",
      "+++ loading the model for : GMT\n",
      "--- Error while processing the model of GMT\n",
      "--- GMT will be removed from the list.\n",
      "+++ loading the model for : XRP\n",
      "--- Error while processing the model of XRP\n",
      "--- XRP will be removed from the list.\n",
      "+++ loading the model for : ADA\n",
      "--- Error while processing the model of ADA\n",
      "--- ADA will be removed from the list.\n",
      "+++ loading the model for : DOT\n",
      "--- Error while processing the model of DOT\n",
      "--- DOT will be removed from the list.\n",
      "+++ loading the model for : ALGO\n",
      "--- Error while processing the model of ALGO\n",
      "--- ALGO will be removed from the list.\n",
      "+++ loading the model for : SRM\n",
      "--- Error while processing the model of SRM\n",
      "--- SRM will be removed from the list.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ModelList={}\n",
    "NormList={}\n",
    "\n",
    "for pp in pairs:\n",
    "    try:\n",
    "        print(f\"+++ loading the model for : {pp}\")\n",
    "        ModelList[pp]=load_model(f'{DATA_DIR}/{pp+\"-USDT\"}-tp{int(BUY_PERCENT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model_v{VERSION}.hdf5')\n",
    "        print(f\"+++ loading the normalization parameters for : {pp}\")\n",
    "        NormList[pp]=f'{DATA_DIR}/{pp+\"-USDT\"}-tp{int(BUY_PERCENT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Norm_v{VERSION}.json'\n",
    "    except:\n",
    "        print(f\"--- Error while processing the model of {pp}\")\n",
    "        print(f\"--- {pp} will be removed from the list.\")\n",
    "        pairs.remove(pp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FIDA', 'XMR', 'SOL', 'SHIB', 'APE', 'GALA', 'ETH', 'ETC', 'TRX', 'AR']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7fdf743fcac0>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>Pair</th>\n",
       "      <th>launch_week_stamp</th>\n",
       "      <th>launch_day_stamp</th>\n",
       "      <th>launch_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>1502668800000</td>\n",
       "      <td>1502928000000</td>\n",
       "      <td>2017-08-17 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LUNAUSDT</td>\n",
       "      <td>LUNA/USDT</td>\n",
       "      <td>1597622400000</td>\n",
       "      <td>1597968000000</td>\n",
       "      <td>2020-08-21 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>ETH/USDT</td>\n",
       "      <td>1502668800000</td>\n",
       "      <td>1502928000000</td>\n",
       "      <td>2017-08-17 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GMTUSDT</td>\n",
       "      <td>GMT/USDT</td>\n",
       "      <td>1646611200000</td>\n",
       "      <td>1646784000000</td>\n",
       "      <td>2022-03-09 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>USTUSDT</td>\n",
       "      <td>UST/USDT</td>\n",
       "      <td>1639958400000</td>\n",
       "      <td>1640304000000</td>\n",
       "      <td>2021-12-24 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>FIDAUSDT</td>\n",
       "      <td>FIDA/USDT</td>\n",
       "      <td>1632700800000</td>\n",
       "      <td>1632960000000</td>\n",
       "      <td>2021-09-30 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107</td>\n",
       "      <td>XNOUSDT</td>\n",
       "      <td>XNO/USDT</td>\n",
       "      <td>1642982400000</td>\n",
       "      <td>1643328000000</td>\n",
       "      <td>2022-01-28 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>108</td>\n",
       "      <td>BTGUSDT</td>\n",
       "      <td>BTG/USDT</td>\n",
       "      <td>1618185600000</td>\n",
       "      <td>1618531200000</td>\n",
       "      <td>2021-04-16 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>109</td>\n",
       "      <td>GHSTUSDT</td>\n",
       "      <td>GHST/USDT</td>\n",
       "      <td>1629072000000</td>\n",
       "      <td>1629417600000</td>\n",
       "      <td>2021-08-20 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>110</td>\n",
       "      <td>EPSUSDT</td>\n",
       "      <td>EPS/USDT</td>\n",
       "      <td>1616976000000</td>\n",
       "      <td>1617321600000</td>\n",
       "      <td>2021-04-02 09:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0         0       Pair  launch_week_stamp  launch_day_stamp  \\\n",
       "0             0   BTCUSDT   BTC/USDT      1502668800000     1502928000000   \n",
       "1             1  LUNAUSDT  LUNA/USDT      1597622400000     1597968000000   \n",
       "2             2   ETHUSDT   ETH/USDT      1502668800000     1502928000000   \n",
       "3             3   GMTUSDT   GMT/USDT      1646611200000     1646784000000   \n",
       "4             4   USTUSDT   UST/USDT      1639958400000     1640304000000   \n",
       "..          ...       ...        ...                ...               ...   \n",
       "106         106  FIDAUSDT  FIDA/USDT      1632700800000     1632960000000   \n",
       "107         107   XNOUSDT   XNO/USDT      1642982400000     1643328000000   \n",
       "108         108   BTGUSDT   BTG/USDT      1618185600000     1618531200000   \n",
       "109         109  GHSTUSDT  GHST/USDT      1629072000000     1629417600000   \n",
       "110         110   EPSUSDT   EPS/USDT      1616976000000     1617321600000   \n",
       "\n",
       "           launch_minute  \n",
       "0    2017-08-17 04:00:00  \n",
       "1    2020-08-21 10:00:00  \n",
       "2    2017-08-17 04:00:00  \n",
       "3    2022-03-09 12:00:00  \n",
       "4    2021-12-24 08:00:00  \n",
       "..                   ...  \n",
       "106  2021-09-30 12:00:00  \n",
       "107  2022-01-28 08:00:00  \n",
       "108  2021-04-16 07:00:00  \n",
       "109  2021-08-20 10:00:00  \n",
       "110  2021-04-02 09:00:00  \n",
       "\n",
       "[111 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "        \n",
    "GoodDeal=[]\n",
    "BadDeal=[]\n",
    "pair=\"ETH/USDT\"\n",
    "min_win_percent=BUY_PERCENT\n",
    "max_time_window=MAX_FORCAST_SIZE\n",
    "window=WINDOW_SIZE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "PRERR=True\n",
    "def prerr(err):\n",
    "    if PRERR:\n",
    "        print(\"\\033[0;31m Error in \"+str(sys._getframe().f_code.co_name) +\" \\033[0;33m\"+str(err))\n",
    "\n",
    "PDEBUG=True\n",
    "def pdebug(err):\n",
    "    if PDEBUG:\n",
    "        print(\"\\033[0;31m Error in \"+str(sys._getframe().f_code.co_name) +\" \\033[0;33m\"+str(err))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def obj_size_fmt(num):\n",
    "    if num<10**3:\n",
    "        return \"{:.2f}{}\".format(num,\"B\")\n",
    "    elif ((num>=10**3)&(num<10**6)):\n",
    "        return \"{:.2f}{}\".format(num/(1.024*10**3),\"KB\")\n",
    "    elif ((num>=10**6)&(num<10**9)):\n",
    "        return \"{:.2f}{}\".format(num/(1.024*10**6),\"MB\")\n",
    "    else:\n",
    "        return \"{:.2f}{}\".format(num/(1.024*10**9),\"GB\")\n",
    "def memory_usage():\n",
    "    memory_usage_by_variable=pd.DataFrame({k:sys.getsizeof(v)\\\n",
    "    for (k,v) in globals().items()},index=['Size'])\n",
    "    memory_usage_by_variable=memory_usage_by_variable.T\n",
    "    memory_usage_by_variable=memory_usage_by_variable.sort_values(by='Size',ascending=False).head(10)\n",
    "    memory_usage_by_variable['Size']=memory_usage_by_variable['Size'].apply(lambda x: obj_size_fmt(x))\n",
    "    return memory_usage_by_variable\n",
    "\n",
    "# Load creds modules\n",
    "from helpers.handle_creds import (\n",
    "    load_correct_creds, test_api_key,\n",
    "    load_discord_creds\n",
    ")\n",
    "\n",
    "access_key, secret_key = load_correct_creds(parsed_creds)\n",
    "acl= AsyncClient(access_key, secret_key,testnet=False)\n",
    "\n",
    "def give_first_kline_open_stamp(interval, symbol, start_ts=1499990400000):\n",
    "        '''\n",
    "        Returns the first kline from an interval and start timestamp and symbol\n",
    "        :param interval:  1w, 1d, 1m etc - the bar length to query\n",
    "        :param symbol:    BTCUSDT or LTCBTC etc\n",
    "        :param start_ts:  Timestamp in miliseconds to start the query from\n",
    "        :return:          The first open candle timestamp\n",
    "        '''\n",
    "\n",
    "        url_stub = \"http://api.binance.com/api/v1/klines?interval=\"\n",
    "\n",
    "        #/api/v1/klines?interval=1m&startTime=1536349500000&symbol=ETCBNB\n",
    "        addInterval   = url_stub     + str(interval) + \"&\"\n",
    "        addStarttime  = addInterval   + \"startTime=\"  + str(start_ts) + \"&\"\n",
    "        addSymbol     = addStarttime + \"symbol=\"     + str(symbol)\n",
    "        url_to_get = addSymbol\n",
    "\n",
    "        kline_data = urllib.request.urlopen(url_to_get).read().decode(\"utf-8\")\n",
    "        kline_data = json.loads(kline_data)\n",
    "\n",
    "        return kline_data[0][0]\n",
    "\n",
    "def get_crypto_metadata(pair_list):\n",
    "    pairs=pair_list\n",
    "    ids = []\n",
    "    #ids = all_ids()\n",
    "    for halalpair in pairs:\n",
    "    #    print( halalpair.replace('/',''))\n",
    "        ids.append(halalpair.replace('/',''))\n",
    "    #print(ids)\n",
    "    MetaData=pd.DataFrame(ids)\n",
    "    MetaData[\"Pair\"]=pairs\n",
    "    counters=0\n",
    "    for this_id in ids:\n",
    "        '''\n",
    "        Find launch Week of symbol, start at Binance launch date 2017-07-14 (1499990400000)\n",
    "        Find launch Day of symbol in week\n",
    "        Find launch minute of symbol in day\n",
    "        '''\n",
    "\n",
    "        symbol_launch_week_stamp   = give_first_kline_open_stamp('1w', this_id, 1499990400000 )\n",
    "        symbol_launch_day_stamp    = give_first_kline_open_stamp('1d', this_id, symbol_launch_week_stamp)\n",
    "        symbol_launch_minute_stamp = give_first_kline_open_stamp('1m', this_id, symbol_launch_day_stamp)\n",
    "        MetaData.loc[counters,\"launch_week_stamp\"]=str(symbol_launch_week_stamp)\n",
    "        MetaData.loc[counters,\"launch_day_stamp\"]=str(symbol_launch_day_stamp)\n",
    "        MetaData.loc[counters,\"launch_minute\"]=pd.to_datetime(symbol_launch_minute_stamp, unit='ms')\n",
    "\n",
    "        counters += 1\n",
    "\n",
    "        #print(\"Week stamp\", symbol_launch_week_stamp)\n",
    "        #print(\"Day  stamp\", symbol_launch_day_stamp)\n",
    "        #print(\"Min  stamp\", symbol_launch_minute_stamp)\n",
    "        #print(counters,end=\" \")\n",
    "        #print(this_id, \"launched\", symbol_launch_minute_stamp )\n",
    "    return MetaData\n",
    "    #print(\"\")\n",
    "\n",
    "# memory_usage()\n",
    "\n",
    "\n",
    "try:\n",
    "    MetaData=pd.read_csv(\"../Data/MetaData.csv\")\n",
    "except:\n",
    "    MetaData=get_crypto_metadata(pairs)\n",
    "# try:\n",
    "#     model = load_model(Model_FileName)\n",
    "#     print(Model_FileName+' Loaded')\n",
    "# except:\n",
    "#     prerr('AI Module not Loaded')\n",
    "MetaData\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################################################\n",
    "##############################################################################################################################################\n",
    "#####################################################   AI FUNCTIONS          ################################################################\n",
    "##############################################################################################################################################\n",
    "##############################################################################################################################################\n",
    "# # Get list of all IDs on binance\n",
    "def give_first_kline_open_stamp(interval, symbol, start_ts=1499990400000):\n",
    "        '''\n",
    "        Returns the first kline from an interval and start timestamp and symbol\n",
    "        :param interval:  1w, 1d, 1m etc - the bar length to query\n",
    "        :param symbol:    BTCUSDT or LTCBTC etc\n",
    "        :param start_ts:  Timestamp in miliseconds to start the query from\n",
    "        :return:          The first open candle timestamp\n",
    "        '''\n",
    "\n",
    "        url_stub = \"http://api.binance.com/api/v1/klines?interval=\"\n",
    "\n",
    "        #/api/v1/klines?interval=1m&startTime=1536349500000&symbol=ETCBNB\n",
    "        addInterval   = url_stub     + str(interval) + \"&\"\n",
    "        addStarttime  = addInterval   + \"startTime=\"  + str(start_ts) + \"&\"\n",
    "        addSymbol     = addStarttime + \"symbol=\"     + str(symbol)\n",
    "        url_to_get = addSymbol\n",
    "\n",
    "        kline_data = urllib.request.urlopen(url_to_get).read().decode(\"utf-8\")\n",
    "        kline_data = json.loads(kline_data)\n",
    "\n",
    "        return kline_data[0][0]\n",
    "\n",
    "def get_crypto_metadata(pair_list):\n",
    "    pairs=pair_list\n",
    "    ids = []\n",
    "    #ids = all_ids()\n",
    "    for halalpair in pairs:\n",
    "    #    print( halalpair.replace('/',''))\n",
    "        ids.append(halalpair.replace('/',''))\n",
    "    #print(ids)\n",
    "    MetaData=pd.DataFrame(ids)\n",
    "    MetaData[\"Pair\"]=pairs\n",
    "    counters=0\n",
    "    for this_id in ids:\n",
    "        '''\n",
    "        Find launch Week of symbol, start at Binance launch date 2017-07-14 (1499990400000)\n",
    "        Find launch Day of symbol in week\n",
    "        Find launch minute of symbol in day\n",
    "        '''\n",
    "\n",
    "        symbol_launch_week_stamp   = give_first_kline_open_stamp('1w', this_id, 1499990400000 )\n",
    "        symbol_launch_day_stamp    = give_first_kline_open_stamp('1d', this_id, symbol_launch_week_stamp)\n",
    "        symbol_launch_minute_stamp = give_first_kline_open_stamp('1m', this_id, symbol_launch_day_stamp)\n",
    "        MetaData.loc[counters,\"launch_week_stamp\"]=str(symbol_launch_week_stamp)\n",
    "        MetaData.loc[counters,\"launch_day_stamp\"]=str(symbol_launch_day_stamp)\n",
    "        MetaData.loc[counters,\"launch_minute\"]=pd.to_datetime(symbol_launch_minute_stamp, unit='ms')\n",
    "\n",
    "        counters += 1\n",
    "\n",
    "        #print(\"Week stamp\", symbol_launch_week_stamp)\n",
    "        #print(\"Day  stamp\", symbol_launch_day_stamp)\n",
    "        #print(\"Min  stamp\", symbol_launch_minute_stamp)\n",
    "        print(counters,end=\" \")\n",
    "        #print(this_id, \"launched\", symbol_launch_minute_stamp )\n",
    "    return MetaData\n",
    "    #print(\"\")\n",
    "    \n",
    "def normalize(dataset,file=Normalization_File):\n",
    "    global Normalization\n",
    "    if True:\n",
    "        print('Loading normalization from file :')\n",
    "        print(Normalization_File)\n",
    "        with open(file) as json_file:\n",
    "            Normalization = json.load(json_file)\n",
    "            NorShape=len(Normalization[\"mean\"])\n",
    "            print(f\"Nomalization shape: {NorShape}\")\n",
    "    else:\n",
    "        #print('normalization is loaded')\n",
    "        pass\n",
    "\n",
    "    mean=np.array(Normalization[\"mean\"])\n",
    "    std=np.array(Normalization[\"std\"])\n",
    "    dataset -= mean \n",
    "    dataset /= std\n",
    "    dataset=np.nan_to_num(dataset,nan=0)\n",
    "    dataset=np.nan_to_num(dataset, neginf=0) \n",
    "    dataset=np.nan_to_num(dataset, posinf=0) \n",
    "    return(dataset)\n",
    "\n",
    "def normalize_org(dataset,file=Normalization_File):\n",
    "    global Normalization\n",
    "    try:\n",
    "        N=Normalization\n",
    "    except:\n",
    "        Normalization=None\n",
    "    if(Normalization==None):\n",
    "        print('Loading normalization from file')\n",
    "        with open(file) as json_file:\n",
    "            Normalization = json.load(json_file)\n",
    "            NorShape=len(Normalization[\"mean\"])\n",
    "            print(f\"Nomalization shape: {NorShape}\")\n",
    "    else:\n",
    "        #print('normalization is loaded')\n",
    "        pass\n",
    "\n",
    "    mean=np.array(Normalization[\"mean\"])\n",
    "    std=np.array(Normalization[\"std\"])\n",
    "    dataset -= mean \n",
    "    dataset /= std\n",
    "    return(dataset)\n",
    "\n",
    "def Buy_Dessision(input):\n",
    "    print(\"making prediction step0\")\n",
    "    A=np.array(input)\n",
    "    A = A.reshape(1,A.shape[0])\n",
    "    print(\"making prediction step1\")\n",
    "    # with tf.compat.v1.get_default_graph():\n",
    "    predictions = model.predict(normalize(A))\n",
    "    print(\"making prediction step2\")\n",
    "    rounded = [round(x[0]) for x in (predictions-hard_prediction_value)]\n",
    "    print(\"making prediction step3\")\n",
    "    return(rounded[0])\n",
    "\n",
    "def Buy_Solo(input,pair):\n",
    "    print(\"making prediction step0\")\n",
    "    A=np.array(input)\n",
    "    A = A.reshape(1,A.shape[0])\n",
    "    print(\"making prediction step1\")\n",
    "    # with tf.compat.v1.get_default_graph():\n",
    "    predictions = ModelList[pair].predict(normalize(A,NormList[pair]))\n",
    "    print(\"making prediction step2\")\n",
    "    rounded = [round(x[0]) for x in (predictions-hard_prediction_value)]\n",
    "    print(\"making prediction step3\")\n",
    "    return(rounded[0])\n",
    "\n",
    "\n",
    "def Buy_Dessision_Org(input):\n",
    "    print(\"making prediction step0\")\n",
    "    A=np.array(input)\n",
    "    A = A.reshape(1,A.shape[0])\n",
    "    print(\"making prediction step1\")\n",
    "    # with tf.compat.v1.get_default_graph():\n",
    "    predictions = model.predict(normalize(A))\n",
    "    print(\"making prediction step2\")\n",
    "    rounded = [round(x[0]) for x in (predictions)]\n",
    "    print(\"making prediction step3\")\n",
    "    return(rounded[0])\n",
    "\n",
    "def Buy_Dessision_Normalized(input):\n",
    "    A=np.array(input)\n",
    "    A = A.reshape(1,A.shape[0])\n",
    "    predictions = model.predict(A)\n",
    "    rounded = [round(x[0]) for x in predictions]\n",
    "    return(rounded[0])\n",
    "\n",
    "def Buy_Dessision_Multi_In_Out(input):\n",
    "    A=np.array(input)\n",
    "    predictions = model.predict(normalize(A))\n",
    "    rounded = [round(x[0]) for x in predictions]\n",
    "    return(rounded)\n",
    "\n",
    "def Buy_Dessision_Multi_In_Out_Normalized(input):\n",
    "    A=np.array(input)\n",
    "    predictions = model.predict(A)\n",
    "    rounded = [round(x[0]) for x in predictions]\n",
    "    return(rounded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################### V2.0 ################################################################################\n",
    "\n",
    "def instant_pair_data(pair=\"GMT/BUSD\",exchange=ccxt.binance(),window=WINDOW_SIZE):\n",
    "    ex=exchange\n",
    "    ticker = ex.fetch_ticker(pair)\n",
    "    pair_current_price=ticker['info']['askPrice']\n",
    "    #print(pair_current_price)\n",
    "\n",
    "    ohlcv1m = ex.fetch_ohlcv(pair, '1m', limit=window+1)\n",
    "    ohlcv5m = ex.fetch_ohlcv(pair, '5m', limit=window+1)\n",
    "    ohlcv15m = ex.fetch_ohlcv(pair, '15m', limit=window+1)\n",
    "    ohlcv1h = ex.fetch_ohlcv(pair, '1h', limit=window+1)\n",
    "    ohlcv1d = ex.fetch_ohlcv(pair, '1d', limit=window+1)\n",
    "\n",
    "    pair_data=pd.DataFrame()\n",
    "    pair_data.loc[0,\"price\"]=float(pair_current_price)\n",
    "    #minute\n",
    "    for window_i in range(1,window+1):\n",
    "        pair_data.loc[0,\"high-\"+str(window_i)]=ohlcv1m[-window_i-1][2]\n",
    "        pair_data.loc[0,\"low-\"+str(window_i)]=ohlcv1m[-window_i-1][3]\n",
    "        #pair_data.loc[0,\"open-\"+str(window_i)]=ohlcv1m[-window_i-1][1]\n",
    "        pair_data.loc[0,\"close-\"+str(window_i)]=ohlcv1m[-window_i-1][4]\n",
    "        #if(window_i!=1):\n",
    "        pair_data.loc[0,\"volume-\"+str(window_i)]=ohlcv1m[-window_i-1][5]\n",
    "\n",
    "    for window_i in range(1,window+1):\n",
    "        pair_data.loc[0,\"high-\"+str(window_i)+\"_day\"]=ohlcv1d[-window_i-1][2]\n",
    "        pair_data.loc[0,\"low-\"+str(window_i)+\"_day\"]=ohlcv1d[-window_i-1][3]\n",
    "        #pair_data.loc[0,\"open-\"+str(window_i)+\"_day\"]=ohlcv1d[-window_i-1][1]\n",
    "        pair_data.loc[0,\"close-\"+str(window_i)+\"_day\"]=ohlcv1d[-window_i-1][4]\n",
    "        #if(window_i!=1):\n",
    "        pair_data.loc[0,\"volume-\"+str(window_i)+\"_day\"]=ohlcv1d[-window_i-1][5]  \n",
    "\n",
    "    for window_i in range(1,window+1):\n",
    "        pair_data.loc[0,\"high-\"+str(window_i)+\"_hour\"]=ohlcv1h[-window_i-1][2]\n",
    "        pair_data.loc[0,\"low-\"+str(window_i)+\"_hour\"]=ohlcv1h[-window_i-1][3]\n",
    "        #pair_data.loc[0,\"open-\"+str(window_i)+\"_hour\"]=ohlcv1h[-window_i-1][1]\n",
    "        pair_data.loc[0,\"close-\"+str(window_i)+\"_hour\"]=ohlcv1h[-window_i-1][4]\n",
    "        #if(window_i!=1):\n",
    "        pair_data.loc[0,\"volume-\"+str(window_i)+\"_hour\"]=ohlcv1h[-window_i-1][5]  \n",
    "\n",
    "    for window_i in range(1,window+1):\n",
    "        pair_data.loc[0,\"high-\"+str(window_i)+\"_15min\"]=ohlcv15m[-window_i-1][2]\n",
    "        pair_data.loc[0,\"low-\"+str(window_i)+\"_15min\"]=ohlcv15m[-window_i-1][3]\n",
    "        #pair_data.loc[0,\"open-\"+str(window_i)+\"_15min\"]=ohlcv15m[-window_i-1][1]\n",
    "        pair_data.loc[0,\"close-\"+str(window_i)+\"_15min\"]=ohlcv15m[-window_i-1][4]\n",
    "        #if(window_i!=1):\n",
    "        pair_data.loc[0,\"volume-\"+str(window_i)+\"_15min\"]=ohlcv5m[-window_i-1][5]  \n",
    "\n",
    "    for window_i in range(1,window+1):\n",
    "        pair_data.loc[0,\"high-\"+str(window_i)+\"_5min\"]=ohlcv5m[-window_i-1][2]\n",
    "        pair_data.loc[0,\"low-\"+str(window_i)+\"_5min\"]=ohlcv5m[-window_i-1][3]\n",
    "        #pair_data.loc[0,\"open-\"+str(window_i)+\"_5min\"]=ohlcv5m[-window_i-1][1]\n",
    "        pair_data.loc[0,\"close-\"+str(window_i)+\"_5min\"]=ohlcv5m[-window_i-1][4]\n",
    "        #if(window_i!=1):\n",
    "        pair_data.loc[0,\"volume-\"+str(window_i)+\"_5min\"]=ohlcv5m[-window_i-1][5]\n",
    "\n",
    "    return  pair_data\n",
    "\n",
    "def instant_full_data(pair,exchange=ex,window=WINDOW_SIZE):\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    pdata=instant_pair_data(pair,exchange=exchange,window=WINDOW_SIZE)\n",
    "    btcdata=instant_pair_data(\"BTC/USDT\",exchange=exchange,window=WINDOW_SIZE).add_prefix(\"BTC_\")\n",
    "    Timestamp=pd.to_datetime(ex.fetchTime(),unit='ms')\n",
    "    pdata=pd.concat([pdata,btcdata],axis=1)\n",
    "    pdata.loc[0,\"day\"]=Timestamp.dayofweek+1\n",
    "    pdata.loc[0,\"hour\"]=Timestamp.hour\n",
    "    pdata.loc[0,\"minute\"]=Timestamp.minute\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"synctime for \"+str(pair)+\" :\"+str(stop-start))\n",
    "    try:\n",
    "        pdata.loc[0,\"lunch_day\"]=int(-(pd.to_datetime(MetaData[MetaData[\"Pair\"] == (pair.split(\"/\")[0]+\"/USDT\")][\"launch_minute\"])-pd.Timestamp('2020-01-01 00:00:00.000000')).dt.days)\n",
    "    except:\n",
    "        MData=get_crypto_metadata([pair.split(\"/\")[0]+\"/USDT\"])\n",
    "        pdata.loc[0,\"lunch_day\"]=int(-(pd.to_datetime(MData[MData[\"Pair\"] == (pair.split(\"/\")[0]+\"/USDT\")][\"launch_minute\"])-pd.Timestamp('2020-01-01 00:00:00.000000')).dt.days)\n",
    "    for key in pdata.keys():\n",
    "        if key.find(\"BTC\")!=-1 and (key.find(\"open\")!=-1 or\n",
    "        key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "            pdata[key]=(pdata[\"BTC_price\"]-pdata[key])/pdata[\"BTC_price\"]\n",
    "        if key.find(\"BTC\")==-1 and (key.find(\"open\")!=-1 or\n",
    "        key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "            pdata[key]=(pdata[\"price\"]-pdata[key])/pdata[\"price\"]\n",
    "    return pdata\n",
    "\n",
    "\n",
    "import asyncio\n",
    "PRERR=False\n",
    "\n",
    "\n",
    "import timeit\n",
    "\n",
    "window=WINDOW_SIZE\n",
    "\n",
    "async def do_get_ask_price(pair,price):\n",
    "    # prerr(\"Preparing 1 day candelstics\")\n",
    "    await asyncio.sleep(0)\n",
    "    ticker = ex.fetch_ticker(pair)\n",
    "    price[0]+=float(ticker['info']['askPrice'])\n",
    "    # prerr(\"-->  1 day candelstics is ok <--\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async def do_pdata(pair,exchange,window=WINDOW_SIZE,pdata=pd.DataFrame()):\n",
    "    # prerr(\"Preparing 1 day candelstics\")\n",
    "    await async_instant_pair_data(pair=pair,exchange=exchange,window=window,pdata=pdata)\n",
    "    # prerr(\"-->  1 day candelstics is ok <--\")\n",
    "async def do_whattime(TimestampAll):\n",
    "    TimestampAll.append(pd.to_datetime(ex.fetchTime(),unit='ms'))\n",
    "    \n",
    "async def async_instant_full_data(pair,exchange=ex,window=WINDOW_SIZE):\n",
    "    start = timeit.default_timer()\n",
    "    pdata=pd.DataFrame()\n",
    "    btcdata=pd.DataFrame()\n",
    "    #async tascs\n",
    "    TimestampAll=[]\n",
    "    task_pdata=asyncio.create_task(do_pdata(pair=pair,exchange=exchange,window=window,pdata=pdata))\n",
    "    task_btcdata=asyncio.create_task(do_pdata(pair=\"BTC/USDT\",exchange=exchange,window=window,pdata=btcdata))\n",
    "    task_whattime=asyncio.create_task(do_whattime(TimestampAll)) \n",
    "    #Timestamp=pd.to_datetime(ex.fetchTime(),unit='ms')\n",
    "    await asyncio.wait([task_pdata, task_btcdata, task_whattime])\n",
    "    Timestamp=TimestampAll[0]\n",
    "    btcdata=btcdata.add_prefix(\"BTC_\")\n",
    "    pdata=pd.concat([pdata,btcdata],axis=1)\n",
    "    pdata.loc[0,\"day\"]=Timestamp.dayofweek+1\n",
    "    pdata.loc[0,\"hour\"]=Timestamp.hour\n",
    "    pdata.loc[0,\"minute\"]=Timestamp.minute\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"async time for \"+str(pair)+\" :\"+str(stop-start))\n",
    "    try:\n",
    "        pdata.loc[0,\"lunch_day\"]=int(-(pd.to_datetime(MetaData[MetaData[\"Pair\"] == (pair.split(\"/\")[0]+\"/USDT\")][\"launch_minute\"])-pd.Timestamp('2020-01-01 00:00:00.000000')).dt.days)\n",
    "    except:\n",
    "        MData=get_crypto_metadata([pair.split(\"/\")[0]+\"/USDT\"])\n",
    "        pdata.loc[0,\"lunch_day\"]=int(-(pd.to_datetime(MData[MData[\"Pair\"] == (pair.split(\"/\")[0]+\"/USDT\")][\"launch_minute\"])-pd.Timestamp('2020-01-01 00:00:00.000000')).dt.days)\n",
    "    for key in pdata.keys():\n",
    "        if key.find(\"BTC\")!=-1 and (key.find(\"open\")!=-1 or\n",
    "        key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "            pdata[key]=(pdata[\"BTC_price\"]-pdata[key])/pdata[\"BTC_price\"]\n",
    "        if key.find(\"BTC\")==-1 and (key.find(\"open\")!=-1 or\n",
    "        key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "            pdata[key]=(pdata[\"price\"]-pdata[key])/pdata[\"price\"]\n",
    "    return pdata\n",
    "\n",
    "async def do_async_instant_full_data(pdata,pair,exchange=ex,window=WINDOW_SIZE):\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    #pdata=pd.DataFrame()\n",
    "    btcdata=pd.DataFrame()\n",
    "    #async tascs\n",
    "    TimestampAll=[] \n",
    "    task_pdata=asyncio.create_task(do_pdata(pair=pair,exchange=exchange,window=window,pdata=pdata))\n",
    "    task_btcdata=asyncio.create_task(do_pdata(pair=\"BTC/USDT\",exchange=exchange,window=window,pdata=btcdata))\n",
    "    task_whattime=asyncio.create_task(do_whattime(TimestampAll)) \n",
    "    #Timestamp=pd.to_datetime(ex.fetchTime(),unit='ms')\n",
    "    await asyncio.wait([task_pdata, task_btcdata, task_whattime])\n",
    "    Timestamp=TimestampAll[0]\n",
    "    btcdata=btcdata.add_prefix(\"BTC_\")\n",
    "    #pdata=pd.concat([pdata,btcdata],axis=1,copy=False)\n",
    "    #pdata.join(btcdata)\n",
    "    for k in btcdata.keys():\n",
    "        pdata.loc[0,str(k)]=btcdata[str(k)][0]\n",
    "    pdata.loc[0,\"day\"]=Timestamp.dayofweek+1\n",
    "    pdata.loc[0,\"hour\"]=Timestamp.hour\n",
    "    pdata.loc[0,\"minute\"]=Timestamp.minute\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"async time for \"+str(pair)+\" :\"+str(stop-start))\n",
    "    try:\n",
    "        pdata.loc[0,\"lunch_day\"]=int(-(pd.to_datetime(MetaData[MetaData[\"Pair\"] == (pair.split(\"/\")[0]+\"/USDT\")][\"launch_minute\"])-pd.Timestamp('2020-01-01 00:00:00.000000')).dt.days)\n",
    "    except:\n",
    "        MData=get_crypto_metadata([pair.split(\"/\")[0]+\"/USDT\"])\n",
    "        pdata.loc[0,\"lunch_day\"]=int(-(pd.to_datetime(MData[MData[\"Pair\"] == (pair.split(\"/\")[0]+\"/USDT\")][\"launch_minute\"])-pd.Timestamp('2020-01-01 00:00:00.000000')).dt.days)\n",
    "    for key in pdata.keys():\n",
    "        if key.find(\"BTC\")!=-1 and (key.find(\"open\")!=-1 or\n",
    "        key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "            pdata[key]=(pdata[\"BTC_price\"]-pdata[key])/pdata[\"BTC_price\"]\n",
    "        if key.find(\"BTC\")==-1 and (key.find(\"open\")!=-1 or\n",
    "        key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "            pdata[key]=(pdata[\"price\"]-pdata[key])/pdata[\"price\"]\n",
    "\n",
    "async def get_all_data_for(list_pair=pairs,exchange=ex,window=WINDOW_SIZE):\n",
    "    #loop init data dic\n",
    "    data_dic={}\n",
    "    for pair in list_pair:\n",
    "        data_dic[pair]=pd.DataFrame()\n",
    "    \n",
    "    ###loop tasklist\n",
    "    task_list=[]\n",
    "    for pair in list_pair:\n",
    "        task_list.append(   asyncio.create_task(do_async_instant_full_data(pair=pair,exchange=exchange,window=window,pdata=data_dic[pair]))   )\n",
    "    await asyncio.wait(task_list)\n",
    "\n",
    "    return(data_dic)\n",
    "\n",
    "###################################################################### V Binance ###################################################\n",
    "def Buy_PLUS(input):\n",
    "    dt=np.array(input)\n",
    "    dt=np.nan_to_num(dt,nan=0)\n",
    "    dt=np.nan_to_num(dt, neginf=0) \n",
    "    dt=np.nan_to_num(dt, posinf=0) \n",
    "    A=dt\n",
    "    predictions = model.predict(normalize(A))\n",
    "    #rounded = [round(x[0]) for x in predictions]\n",
    "    return predictions\n",
    "\n",
    "async def do_ohlcv(pair,Dlist=[],window=10,interval='1m'):\n",
    "    #print(f\"Preparing {interval} candelstics\",end=' ->')\n",
    "    start_str=str((pd.to_datetime('today')-(pd.Timedelta(interval)*window)))\n",
    "    #await asyncio.sleep(0)\n",
    "    try:\n",
    "        df=await acl.get_historical_klines(symbol=pair,start_str=start_str,interval=interval)\n",
    "        #D.columns=['open_time','open', 'high', 'low', 'close', 'volume', 'close_time', 'qav', 'num_trades', 'taker_base_vol', 'taker_quote_vol','is_best_match']\n",
    "        Dlist.extend(df)\n",
    "        #print(\"Done\")\n",
    "    except Exception as e:\n",
    "        print(\"Error do_ohlcv\")\n",
    "        print('######################################################################################################################')\n",
    "        print(e)\n",
    "        print('######################################################################################################################')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst\n",
    "\n",
    "async def get_pdata_data(symbol,RLIST={},window=10,pair_with='USDT'):\n",
    "    \n",
    "    print(\"working on: \"+symbol)\n",
    "    try:\n",
    "        pair=symbol.split(pair_with)[0].split(\"/\")[0]+\"/USDT\"\n",
    "        try:\n",
    "            symbol=symbol.split(pair_with)[0].split(\"/\")[0]+\"USDT\"\n",
    "        except:\n",
    "            symbol=symbol\n",
    "        window+=1\n",
    "        D1m=[]\n",
    "        D5m=[]\n",
    "        D15m=[]\n",
    "        D1h=[]\n",
    "        D1d=[]\n",
    "\n",
    "        BTC1m=[]\n",
    "        BTC5m=[]\n",
    "        BTC15m=[]\n",
    "        BTC1h=[]\n",
    "        BTC1d=[]\n",
    "\n",
    "        # tasks = [do_ohlcv(pair=symbol,window=window,Dlist=D1m,interval='1m'),\n",
    "        #             do_ohlcv(pair=symbol,window=window,Dlist=D5m,interval='5m'),\n",
    "        #             do_ohlcv(pair=symbol,window=window,Dlist=D15m,interval='15m'),\n",
    "        #             do_ohlcv(pair=symbol,window=window,Dlist=D1h,interval='1h'),\n",
    "        #             do_ohlcv(pair=symbol,window=window,Dlist=D1d,interval='1d'),\n",
    "        #             #BTC\n",
    "        #             do_ohlcv(pair=\"BTCUSDT\",window=window,Dlist=BTC1m,interval='1m'),\n",
    "        #             do_ohlcv(pair=\"BTCUSDT\",window=window,Dlist=BTC5m,interval='5m'),\n",
    "        #             do_ohlcv(pair=\"BTCUSDT\",window=window,Dlist=BTC15m,interval='15m'),\n",
    "        #             do_ohlcv(pair=\"BTCUSDT\",window=window,Dlist=BTC1h,interval='1h'),\n",
    "        #             do_ohlcv(pair=\"BTCUSDT\",window=window,Dlist=BTC1d,interval='1d'),\n",
    "\n",
    "        #             ]\n",
    "        \n",
    "        tasks = [asyncio.create_task(do_ohlcv(pair=symbol,window=window,Dlist=D1m,interval='1m')),\n",
    "                    asyncio.create_task(do_ohlcv(pair=symbol,window=window,Dlist=D5m,interval='5m')),\n",
    "                    asyncio.create_task(do_ohlcv(pair=symbol,window=window,Dlist=D15m,interval='15m')),\n",
    "                    asyncio.create_task(do_ohlcv(pair=symbol,window=window,Dlist=D1h,interval='1h')),\n",
    "                    asyncio.create_task(do_ohlcv(pair=symbol,window=window,Dlist=D1d,interval='1d')),\n",
    "                    #BTC\n",
    "                    asyncio.create_task(do_ohlcv(pair=\"BTCUSDT\",window=window,Dlist=BTC1m,interval='1m')),\n",
    "                    asyncio.create_task(do_ohlcv(pair=\"BTCUSDT\",window=window,Dlist=BTC5m,interval='5m')),\n",
    "                    asyncio.create_task(do_ohlcv(pair=\"BTCUSDT\",window=window,Dlist=BTC15m,interval='15m')),\n",
    "                    asyncio.create_task(do_ohlcv(pair=\"BTCUSDT\",window=window,Dlist=BTC1h,interval='1h')),\n",
    "                    asyncio.create_task(do_ohlcv(pair=\"BTCUSDT\",window=window,Dlist=BTC1d,interval='1d'))\n",
    "                    ]\n",
    "        \n",
    "        result = await asyncio.wait(tasks) \n",
    "        #print(len(D1m))\n",
    "        DF1m=pd.DataFrame(D1m,columns=['open_time','open', 'high', 'low', 'close', 'volume', 'close_time', 'qav', 'num_trades', 'taker_base_vol', 'taker_quote_vol','is_best_match']).astype(np.float64)\n",
    "        DF5m=pd.DataFrame(D5m,columns=['open_time','open', 'high', 'low', 'close', 'volume', 'close_time', 'qav', 'num_trades', 'taker_base_vol', 'taker_quote_vol','is_best_match']).astype(np.float64)\n",
    "        DF15m=pd.DataFrame(D15m,columns=['open_time','open', 'high', 'low', 'close', 'volume', 'close_time', 'qav', 'num_trades', 'taker_base_vol', 'taker_quote_vol','is_best_match']).astype(np.float64)\n",
    "        DF1h=pd.DataFrame(D1h,columns=['open_time','open', 'high', 'low', 'close', 'volume', 'close_time', 'qav', 'num_trades', 'taker_base_vol', 'taker_quote_vol','is_best_match']).astype(np.float64)\n",
    "        DF1d=pd.DataFrame(D1d,columns=['open_time','open', 'high', 'low', 'close', 'volume', 'close_time', 'qav', 'num_trades', 'taker_base_vol', 'taker_quote_vol','is_best_match']).astype(np.float64)\n",
    "        price=DF1m[\"close\"].iloc[-1].astype(np.float64)\n",
    "        #D['open_date_time']=[dt.datetime.fromtimestamp(x/1000) for x in D[\"open_time\"].to_list()]\n",
    "\n",
    "    ####### BTC\n",
    "        BTC_DF1m=pd.DataFrame(BTC1m,columns=['open_time','open', 'high', 'low', 'close', 'volume', 'close_time', 'qav', 'num_trades', 'taker_base_vol', 'taker_quote_vol','is_best_match']).astype(np.float64)\n",
    "        BTC_DF5m=pd.DataFrame(BTC5m,columns=['open_time','open', 'high', 'low', 'close', 'volume', 'close_time', 'qav', 'num_trades', 'taker_base_vol', 'taker_quote_vol','is_best_match']).astype(np.float64)\n",
    "        BTC_DF15m=pd.DataFrame(BTC15m,columns=['open_time','open', 'high', 'low', 'close', 'volume', 'close_time', 'qav', 'num_trades', 'taker_base_vol', 'taker_quote_vol','is_best_match']).astype(np.float64)\n",
    "        BTC_DF1h=pd.DataFrame(BTC1h,columns=['open_time','open', 'high', 'low', 'close', 'volume', 'close_time', 'qav', 'num_trades', 'taker_base_vol', 'taker_quote_vol','is_best_match']).astype(np.float64)\n",
    "        BTC_DF1d=pd.DataFrame(BTC1d,columns=['open_time','open', 'high', 'low', 'close', 'volume', 'close_time', 'qav', 'num_trades', 'taker_base_vol', 'taker_quote_vol','is_best_match']).astype(np.float64)\n",
    "        BTC_price=BTC_DF1m[\"close\"].iloc[-1].astype(np.float64)\n",
    "\n",
    "        pair_data=pd.DataFrame()\n",
    "\n",
    "        #############################################################  Pair_data population  ######################################################################################\n",
    "        pair_data.loc[0,\"price\"]=DF1m.iloc[-1][\"close\"]\n",
    "        #minute\n",
    "        for window_i in range(1,window):\n",
    "            pair_data.loc[0,\"high-\"+str(window_i)]=DF1m.iloc[-window_i-1][2]\n",
    "            pair_data.loc[0,\"low-\"+str(window_i)]=DF1m.iloc[-window_i-1][3]\n",
    "            #pair_data.loc[0,\"open-\"+str(window_i)]=DF1m.iloc[-window_i-1][1]\n",
    "            pair_data.loc[0,\"close-\"+str(window_i)]=DF1m.iloc[-window_i-1][4]\n",
    "            pair_data.loc[0,\"volume-\"+str(window_i)]=DF1m.iloc[-window_i-1][5]\n",
    "\n",
    "        for window_i in range(1,window):\n",
    "            pair_data.loc[0,\"high-\"+str(window_i)+\"_day\"]=DF1d.iloc[-window_i-1][2]\n",
    "            pair_data.loc[0,\"low-\"+str(window_i)+\"_day\"]=DF1d.iloc[-window_i-1][3]\n",
    "            #pair_data.loc[0,\"open-\"+str(window_i)+\"_day\"]=DF1d.iloc[-window_i-1][1]\n",
    "            pair_data.loc[0,\"close-\"+str(window_i)+\"_day\"]=DF1d.iloc[-window_i-1][4]\n",
    "            #if(window_i!=1):\n",
    "            pair_data.loc[0,\"volume-\"+str(window_i)+\"_day\"]=DF1d.iloc[-window_i-1][5]  \n",
    "\n",
    "        for window_i in range(1,window):\n",
    "            pair_data.loc[0,\"high-\"+str(window_i)+\"_hour\"]=DF1h.iloc[-window_i-1][2]\n",
    "            pair_data.loc[0,\"low-\"+str(window_i)+\"_hour\"]=DF1h.iloc[-window_i-1][3]\n",
    "            #pair_data.loc[0,\"open-\"+str(window_i)+\"_hour\"]=DF1h.iloc[-window_i-1][1]\n",
    "            pair_data.loc[0,\"close-\"+str(window_i)+\"_hour\"]=DF1h.iloc[-window_i-1][4]\n",
    "            #if(window_i!=1):\n",
    "            pair_data.loc[0,\"volume-\"+str(window_i)+\"_hour\"]=DF1h.iloc[-window_i-1][5]  \n",
    "\n",
    "        for window_i in range(1,window):\n",
    "            pair_data.loc[0,\"high-\"+str(window_i)+\"_15min\"]=DF15m.iloc[-window_i-1][2]\n",
    "            pair_data.loc[0,\"low-\"+str(window_i)+\"_15min\"]=DF15m.iloc[-window_i-1][3]\n",
    "            #pair_data.loc[0,\"open-\"+str(window_i)+\"_15min\"]=DF15m.iloc[-window_i-1][1]\n",
    "            pair_data.loc[0,\"close-\"+str(window_i)+\"_15min\"]=DF15m.iloc[-window_i-1][4]\n",
    "            #if(window_i!=1):\n",
    "            pair_data.loc[0,\"volume-\"+str(window_i)+\"_15min\"]=DF15m.iloc[-window_i-1][5]  \n",
    "\n",
    "        for window_i in range(1,window):\n",
    "            pair_data.loc[0,\"high-\"+str(window_i)+\"_5min\"]=DF5m.iloc[-window_i-1][2]\n",
    "            pair_data.loc[0,\"low-\"+str(window_i)+\"_5min\"]=DF5m.iloc[-window_i-1][3]\n",
    "            #pair_data.loc[0,\"open-\"+str(window_i)+\"_5min\"]=DF5m.iloc[-window_i-1][1]\n",
    "            pair_data.loc[0,\"close-\"+str(window_i)+\"_5min\"]=DF5m.iloc[-window_i-1][4]\n",
    "            #if(window_i!=1):\n",
    "            pair_data.loc[0,\"volume-\"+str(window_i)+\"_5min\"]=DF5m.iloc[-window_i-1][5]\n",
    "\n",
    "        ################## BTC PART ###################\n",
    "        pair_data.loc[0,\"BTC_price\"]=BTC_DF1m.iloc[-1][\"close\"]\n",
    "        #minute\n",
    "        for window_i in range(1,window):\n",
    "            pair_data.loc[0,\"BTC_high-\"+str(window_i)]=BTC_DF1m.iloc[-window_i-1][2]\n",
    "            pair_data.loc[0,\"BTC_low-\"+str(window_i)]=BTC_DF1m.iloc[-window_i-1][3]\n",
    "            #pair_data.loc[0,\"open-\"+str(window_i)]=BTC_DF1m.iloc[-window_i-1][1]\n",
    "            pair_data.loc[0,\"BTC_close-\"+str(window_i)]=BTC_DF1m.iloc[-window_i-1][4]\n",
    "            pair_data.loc[0,\"BTC_volume-\"+str(window_i)]=BTC_DF1m.iloc[-window_i-1][5]\n",
    "\n",
    "        for window_i in range(1,window):\n",
    "            pair_data.loc[0,\"BTC_high-\"+str(window_i)+\"_day\"]=BTC_DF1d.iloc[-window_i-1][2]\n",
    "            pair_data.loc[0,\"BTC_low-\"+str(window_i)+\"_day\"]=BTC_DF1d.iloc[-window_i-1][3]\n",
    "            #pair_data.loc[0,\"BTC_open-\"+str(window_i)+\"_day\"]=BTC_DF1d.iloc[-window_i-1][1]\n",
    "            pair_data.loc[0,\"BTC_close-\"+str(window_i)+\"_day\"]=BTC_DF1d.iloc[-window_i-1][4]\n",
    "            #if(window_i!=1):\n",
    "            pair_data.loc[0,\"BTC_volume-\"+str(window_i)+\"_day\"]=BTC_DF1d.iloc[-window_i-1][5]  \n",
    "\n",
    "        for window_i in range(1,window):\n",
    "            pair_data.loc[0,\"BTC_high-\"+str(window_i)+\"_hour\"]=BTC_DF1h.iloc[-window_i-1][2]\n",
    "            pair_data.loc[0,\"BTC_low-\"+str(window_i)+\"_hour\"]=BTC_DF1h.iloc[-window_i-1][3]\n",
    "            #pair_data.loc[0,\"BTC_open-\"+str(window_i)+\"_hour\"]=BTC_DF1h.iloc[-window_i-1][1]\n",
    "            pair_data.loc[0,\"BTC_close-\"+str(window_i)+\"_hour\"]=BTC_DF1h.iloc[-window_i-1][4]\n",
    "            #if(window_i!=1):\n",
    "            pair_data.loc[0,\"BTC_volume-\"+str(window_i)+\"_hour\"]=BTC_DF1h.iloc[-window_i-1][5]  \n",
    "\n",
    "        for window_i in range(1,window):\n",
    "            pair_data.loc[0,\"BTC_high-\"+str(window_i)+\"_15min\"]=BTC_DF15m.iloc[-window_i-1][2]\n",
    "            pair_data.loc[0,\"BTC_low-\"+str(window_i)+\"_15min\"]=BTC_DF15m.iloc[-window_i-1][3]\n",
    "            #pair_data.loc[0,\"BTC_open-\"+str(window_i)+\"_15min\"]=BTC_DF15m.iloc[-window_i-1][1]\n",
    "            pair_data.loc[0,\"BTC_close-\"+str(window_i)+\"_15min\"]=BTC_DF15m.iloc[-window_i-1][4]\n",
    "            #if(window_i!=1):\n",
    "            pair_data.loc[0,\"BTC_volume-\"+str(window_i)+\"_15min\"]=BTC_DF15m.iloc[-window_i-1][5]  \n",
    "\n",
    "        for window_i in range(1,window):\n",
    "            pair_data.loc[0,\"BTC_high-\"+str(window_i)+\"_5min\"]=BTC_DF5m.iloc[-window_i-1][2]\n",
    "            pair_data.loc[0,\"BTC_low-\"+str(window_i)+\"_5min\"]=BTC_DF5m.iloc[-window_i-1][3]\n",
    "            #pair_data.loc[0,\"BTC_open-\"+str(window_i)+\"_5min\"]=BTC_DF5m.iloc[-window_i-1][1]\n",
    "            pair_data.loc[0,\"BTC_close-\"+str(window_i)+\"_5min\"]=BTC_DF5m.iloc[-window_i-1][4]\n",
    "            #if(window_i!=1):\n",
    "            pair_data.loc[0,\"BTC_volume-\"+str(window_i)+\"_5min\"]=BTC_DF5m.iloc[-window_i-1][5]\n",
    "        Timestamp=pd.to_datetime(D1m[-1][0]+29000,unit='ms')\n",
    "        pair_data.loc[0,\"day\"]=Timestamp.dayofweek+1\n",
    "        pair_data.loc[0,\"hour\"]=Timestamp.hour\n",
    "        pair_data.loc[0,\"minute\"]=Timestamp.minute\n",
    "        try:\n",
    "            pair_data.loc[0,\"lunch_day\"]=int(-(pd.to_datetime(MetaData[MetaData[\"Pair\"] == pair][\"launch_minute\"])-pd.Timestamp('2020-01-01 00:00:00.000000')).dt.days)\n",
    "        except:\n",
    "            MData=get_crypto_metadata([pair])\n",
    "            pair_data.loc[0,\"lunch_day\"]=int(-(pd.to_datetime(MData[MData[\"Pair\"] == pair][\"launch_minute\"])-pd.Timestamp('2020-01-01 00:00:00.000000')).dt.days)\n",
    "        for key in pair_data.keys():\n",
    "            if key.find(\"BTC\")!=-1 and (key.find(\"open\")!=-1 or\n",
    "            key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "                pair_data[key]=(pair_data[\"BTC_price\"]-pair_data[key])/pair_data[\"BTC_price\"]\n",
    "            if key.find(\"BTC\")==-1 and (key.find(\"open\")!=-1 or\n",
    "            key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "                pair_data[key]=(pair_data[\"price\"]-pair_data[key])/pair_data[\"price\"]\n",
    "\n",
    "        RLIST[symbol]=pair_data\n",
    "        print(\"finshing work of: \"+symbol)\n",
    "    except Exception as e:\n",
    "        print(\"Error while working on: \"+symbol)\n",
    "        #sys.stderr.write(e)\n",
    "        print(e)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async def pair_loop(Symbollist,window,pair_with='USDT'):\n",
    "    tasks=[]\n",
    "    RLIST={}\n",
    "    for t in Symbollist:\n",
    "        tasks.append(get_pdata_data(symbol=t,RLIST=RLIST,window=window,pair_with=pair_with))\n",
    "    result = await asyncio.wait(tasks)\n",
    "    return RLIST\n",
    "\n",
    "async def get_df_from_pair_loop(pair_list=[],window=10,pair_with='USDT'):\n",
    "    LL=await pair_loop(pair_list,window=window,pair_with=pair_with)\n",
    "    DF=pd.DataFrame()\n",
    "    PL=pd.DataFrame(LL.keys(),columns=[\"pair\"])\n",
    "    for k,v in LL.items():\n",
    "        DF=pd.concat([DF,v])\n",
    "    DF=DF.reset_index().drop(columns=\"index\")\n",
    "    return PL,DF\n",
    "\n",
    "\n",
    "\n",
    "async def get_df_from_pair_loop2(pair_list=[],window=10,pair_with='USDT'):\n",
    "    LL=await pair_loop(pair_list,window=window,pair_with=pair_with)\n",
    "    DF=pd.DataFrame()\n",
    "    PL=pd.DataFrame(LL.keys(),columns=[\"pair\"])\n",
    "    for k,v in LL.items():\n",
    "        DF=pd.concat([DF,v])\n",
    "    DF=DF.reset_index().drop(columns=\"index\")\n",
    "    return PL,DF\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from binance import ThreadedWebsocketManager\n",
    "\n",
    "api_key = access_key\n",
    "api_secret = secret_key\n",
    "\n",
    "def mm():\n",
    "\n",
    "    symbol = 'BNBBTC'\n",
    "\n",
    "    twm = ThreadedWebsocketManager(api_key=api_key, api_secret=api_secret)\n",
    "    # start is required to initialise its internal loop\n",
    "    twm.start()\n",
    "\n",
    "    def handle_socket_message(msg):\n",
    "        print(f\"message type: {msg['e']}\")\n",
    "        print(msg)\n",
    "\n",
    "    twm.start_kline_socket(callback=handle_socket_message, symbol=symbol)\n",
    "\n",
    "    # multiple sockets can be started\n",
    "    twm.start_depth_socket(callback=handle_socket_message, symbol=symbol)\n",
    "\n",
    "    # or a multiplex socket can be started like this\n",
    "    # see Binance docs for stream names\n",
    "    streams = ['bnbbtc@miniTicker', 'bnbbtc@bookTicker']\n",
    "    twm.start_multiplex_socket(callback=handle_socket_message, streams=streams)\n",
    "\n",
    "    twm.join()\n",
    "\n",
    "\n",
    "mm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_df_from_pair_loop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m PL,DF\u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m get_df_from_pair_loop(pair_list\u001b[39m=\u001b[39mpairs,window\u001b[39m=\u001b[39mWINDOW_SIZE,pair_with\u001b[39m=\u001b[39mPAIR_WITH)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_df_from_pair_loop' is not defined"
     ]
    }
   ],
   "source": [
    "PL,DF= await get_df_from_pair_loop(pair_list=pairs,window=WINDOW_SIZE,pair_with=PAIR_WITH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m DF\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DF' is not defined"
     ]
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "PDEBUG=True\n",
    "\n",
    "\n",
    "def analyze(pairs):\n",
    "    signal_coins = {}\n",
    "    print('########################################### Start Analyser ###################################################')\n",
    "    if os.path.exists(SIGNAL_FILE):\n",
    "        os.remove(SIGNAL_FILE)\n",
    "\n",
    "    if os.path.exists(X_AI_EX_FILE):\n",
    "        os.remove(X_AI_EX_FILE)\n",
    "    #BTC_OK=btc_check(BTC_CHECK_LEVEL)\n",
    "    break_out_flag = False\n",
    "    iii=0\n",
    "    for pair in pairs:\n",
    "        print(f\"-------> working on : {pair} <------------\")\n",
    "        pair_usdt=pair.split(PAIR_WITH)[0]+\"/USDT\"\n",
    "        pair_usdt=pair_usdt.split('/USDT')[0]+\"/USDT\"\n",
    "        print(f\"-------> pair_usdt : {pair_usdt} <------------\")\n",
    "        try:\n",
    "            pdata=instant_full_data(pair_usdt,exchange=ex,window=WINDOW_SIZE)\n",
    "            print(f\"{pdata}\")\n",
    "            BuyD=Buy_Dessision(pdata.iloc[0])\n",
    "            print(f\"XXXXXX=================  buy dession for :{pair} is {BuyD} ==================XXXXXXX\")\n",
    "            if int(BuyD) == 1:\n",
    "                print(\"Good : \" +pair)\n",
    "                print(\"buying at\"+str(pdata[\"price\"].iloc[0]))\n",
    "                bt=pd.to_datetime(ex.fetchTime(),unit='ms')\n",
    "                pp=ex.fetch_ticker(pair_usdt)['info']['askPrice']\n",
    "                GoodDeal.append({\"pair\":pair_usdt,\n",
    "                            \"buying_time\":bt,\n",
    "                            \"buying_price\":float(pdata[\"price\"].iloc[0]),\n",
    "                            \"Selling_time\":bt,\n",
    "                            \"selling_price\":float(pp)})\n",
    "                signal_coins[pair] = pair          \n",
    "                with open(SIGNAL_FILE,'a+') as f: f.write(pair + '\\n')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'{SIGNAL_NAME}')\n",
    "            print(\"Exception:\")\n",
    "            print(e)\n",
    "            print (f'Coin: {pair}')\n",
    "            #print (f'The handler interval: {interval}')\n",
    "            #print (f'The handler pair: {the_handler}')\n",
    "            with open(X_AI_EX_FILE,'a+') as f:\n",
    "                    f.write(pair.removesuffix(PAIR_WITH) + '\\n')\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        if FULL_LOG:\n",
    "                \n",
    "                print(f'{SIGNAL_NAME}: {pair} \\n'+\n",
    "                    f'Seem Good deals {GoodDeal[iii][\"pair\"]} detection_price {GoodDeal[iii][\"buying_price\"]}\\n'+\n",
    "                    f'Recheck time {GoodDeal[iii][\"Selling_time\"]} recheck price {GoodDeal[iii][\"selling_price\"]}\\n'\n",
    "\n",
    "                    )\n",
    "        iii+=1\n",
    "\n",
    "            # for i in range(max_time_window*2):\n",
    "            #     time.sleep(30)\n",
    "            #     pp=ex.fetch_ticker(pair)['info']['askPrice']\n",
    "            #     if((float(pdata.loc[0,\"price\"])*0.01*min_win_percent+float(pdata.loc[0,\"price\"])) <= float(pp)):\n",
    "            #         GoodDeal.append({\"pair\":pair,\n",
    "            #                          \"buying_time\":bt,\n",
    "            #                          \"buying_price\":float(pdata[\"price\"].iloc[0]),\n",
    "            #                          \"Selling_time\":pd.to_datetime(ex.fetchTime(),unit='ms'),\n",
    "            #                          \"selling_price\":float(pp)})\n",
    "            #         print(\"+++ wining bought at:\"+str(pdata.loc[0,\"price\"]) +\" sold at: \"+str(pp) )\n",
    "            #         break_out_flag = True\n",
    "            #         break     \n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "    return signal_coins\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "async def analyze2(pairs):\n",
    "    signal_coins = {}\n",
    "    print('########################################### Start Analyser ###################################################')\n",
    "    if os.path.exists(SIGNAL_FILE):\n",
    "        os.remove(SIGNAL_FILE)\n",
    "\n",
    "    if os.path.exists(X_AI_EX_FILE):\n",
    "        os.remove(X_AI_EX_FILE)\n",
    "    #BTC_OK=btc_check(BTC_CHECK_LEVEL)\n",
    "    break_out_flag = False\n",
    "    iii=0\n",
    "#################################### New ##############################3\n",
    "    try:\n",
    "        \n",
    "        PL,DF= await get_df_from_pair_loop(pair_list=pairs,window=WINDOW_SIZE,pair_with=PAIR_WITH)\n",
    "        DF['Note']= np.float64(Buy_PLUS(DF))+np.float64(PRESSISION)\n",
    "        DF['Buy']=np.rint(DF['Note'])\n",
    "        DF['Pair']=PL\n",
    "        print(DF[['Pair','Buy','Note']])\n",
    "        try:\n",
    "            Dtobuy=DF[DF[\"Buy\"]==1]\n",
    "            Dtobuy=Dtobuy.sort_values(\"Note\",ascending=False)   \n",
    "            print(Dtobuy[['Pair','Note']])\n",
    "\n",
    "            buy_pairs=Dtobuy[\"Pair\"].to_list()\n",
    "        except Exception as ee:\n",
    "            buy_pairs=[]\n",
    "            print(ee)\n",
    "    \n",
    "\n",
    "########################################################################\n",
    "        for pair in buy_pairs:\n",
    "            print(f\"-------> working on : {pair} <------------\")\n",
    "            pair_usdt=pair.split(PAIR_WITH)[0]+\"/USDT\"\n",
    "            pair_usdt=pair_usdt.split('/USDT')[0]+\"/USDT\"\n",
    "            print(f\"-------> pair_usdt : {pair_usdt} <------------\")\n",
    "            try:\n",
    "                print(f\"XXXXXX=================  buy dession for :{pair} ==================XXXXXXX\")\n",
    "                pairok=pair.split(\"USDT\")[0]+PAIR_WITH\n",
    "                if pairok.find('/')!=-1:\n",
    "                    pairok=pair.split(\"/\")[0]+PAIR_WITH\n",
    "                with open(SIGNAL_FILE,'a+') as f: \n",
    "                    f.write(pairok + '\\n')\n",
    "                    signal_coins[pairok] = pair\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f'{SIGNAL_NAME}')\n",
    "                print(\"Exception:\")\n",
    "                print(e)\n",
    "                print (f'Coin: {pair}')\n",
    "                #print (f'The handler interval: {interval}')\n",
    "                #print (f'The handler pair: {the_handler}')\n",
    "                with open(X_AI_EX_FILE,'a+') as f:\n",
    "                        f.write(pair.removesuffix(PAIR_WITH) + '\\n')\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            if FULL_LOG:\n",
    "                    \n",
    "                    print(f'{SIGNAL_NAME}: {pair} \\n'+\n",
    "                        f'Seem Good deals {GoodDeal[iii][\"pair\"]} detection_price {GoodDeal[iii][\"buying_price\"]}\\n'+\n",
    "                        f'Recheck time {GoodDeal[iii][\"Selling_time\"]} recheck price {GoodDeal[iii][\"selling_price\"]}\\n'\n",
    "\n",
    "                        )\n",
    "            iii+=1\n",
    "    except Exception as e:\n",
    "        print(\"error new part at analyse()\")\n",
    "        print(\"exception : \"+str(e))\n",
    "            # for i in range(max_time_window*2):\n",
    "            #     time.sleep(30)\n",
    "            #     pp=ex.fetch_ticker(pair)['info']['askPrice']\n",
    "            #     if((float(pdata.loc[0,\"price\"])*0.01*min_win_percent+float(pdata.loc[0,\"price\"])) <= float(pp)):\n",
    "            #         GoodDeal.append({\"pair\":pair,\n",
    "            #                          \"buying_time\":bt,\n",
    "            #                          \"buying_price\":float(pdata[\"price\"].iloc[0]),\n",
    "            #                          \"Selling_time\":pd.to_datetime(ex.fetchTime(),unit='ms'),\n",
    "            #                          \"selling_price\":float(pp)})\n",
    "            #         print(\"+++ wining bought at:\"+str(pdata.loc[0,\"price\"]) +\" sold at: \"+str(pp) )\n",
    "            #         break_out_flag = True\n",
    "            #         break     \n",
    "\n",
    "    return signal_coins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "DIVIDE_ANALYSE=True\n",
    "ANALYZE_RELAX_TIME=40\n",
    "async def do_work1():\n",
    "    print(f'{SIGNAL_NAME} - Starting')\n",
    "    while True:\n",
    "        time.sleep(ANALYZE_RELAX_TIME)\n",
    "        try:\n",
    "            if not os.path.exists(TICKERS):\n",
    "                time.sleep((TIME_TO_WAIT*60))\n",
    "                continue\n",
    "\n",
    "            signal_coins = {}\n",
    "            pairs = {}\n",
    "\n",
    "            pairs=[line.strip() for line in open(TICKERS)]\n",
    "            for line in open(TICKERS):\n",
    "                pairs=[line.strip() + PAIR_WITH for line in open(TICKERS)] \n",
    "            print(\"abj_ai_buy_signal_vBinance.py\")\n",
    "            if not threading.main_thread().is_alive(): exit()\n",
    "            print(f'{SIGNAL_NAME}: Analyzing {len(pairs)} coins')\n",
    "            if DIVIDE_ANALYSE:\n",
    "                print(\"->Double anlayse mode\")\n",
    "                print(\"->Analysing the fist part\")\n",
    "                signal_coins =await analyze(pairs[:int(len(pairs)/2)])\n",
    "                time.sleep(ANALYZE_RELAX_TIME)\n",
    "                print(\"->Analysing the sconde part\")\n",
    "                signal_coins.update(await analyze(pairs[int(len(pairs)/2):])) \n",
    "\n",
    "            else:\n",
    "                signal_coins =await analyze(pairs)\n",
    "\n",
    "            print(f'{SIGNAL_NAME}: {len(signal_coins)} coins with Buy Signals. Waiting {TIME_TO_WAIT} minutes for next analysis.')\n",
    "\n",
    "            #time.sleep((TIME_TO_WAIT*60))\n",
    "        except Exception as e:\n",
    "            print(f'{SIGNAL_NAME}: Exception do_work() 1: {e}')\n",
    "            continue\n",
    "        except KeyboardInterrupt as ki:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def do_work():\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(do_work1())\n",
    "    #asyncio.run(do_work1())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

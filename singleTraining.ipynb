{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single AI crypto concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xdata_config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Imports and fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/pandas/core/arrays/masked.py:59: UserWarning: Pandas requires version '1.3.2' or newer of 'bottleneck' (version '1.2.1' currently installed).\n",
      "  from pandas.core import (\n",
      "2023-01-06 13:46:51.975589: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-06 13:46:51.975678: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-06 13:46:52.296361: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-06 13:46:55.429624: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-06 13:46:55.430201: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-06 13:46:55.430247: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from functions_module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Binance_USDT_HALAL.index(\"ROSE/USDT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "TICKERS = \"../Binance-Fast-Trade-Bot/volatile_volume_\" + str(date.today()) + \".txt\"\n",
    "VOLATILE_COINS=[line.strip() for line in open(TICKERS)]\n",
    "PAIR_WITH=\"BUSD\"\n",
    "VOLATILE_USDT_PAIRS=[coin+\"/USDT\" for coin in VOLATILE_COINS]\n",
    "VOLATILE_BUSD_PAIRS=[coin+\"/BUSD\" for coin in VOLATILE_COINS]\n",
    "VOLATILE_BUSD_PAIRS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins_to_download=''\n",
    "for coin in VOLATILE_COINS:\n",
    "    coins_to_download=coins_to_download+\" \"+coin\n",
    "os.system(f\"node database/ddargs.js {coins_to_download} {PAIR_WITH}\")#node database/ddargs.js ORN BUSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_list = VOLATILE_BUSD_PAIRS\n",
    "#tf = '1m'\n",
    "oldest_pair = \"BTC/USDT\"\n",
    "if oldest_pair not in pair_list: pair_list.append(oldest_pair)\n",
    "df_list1m = {}\n",
    "df_list1d = {}\n",
    "df_list1h = {}\n",
    "df_list5m = {}\n",
    "df_list15m = {}\n",
    "\n",
    "\n",
    "for pair in pair_list:\n",
    "    df = get_historical_from_db(ccxt.binance(), pair, '1m', path=\"./database/\")\n",
    "    df_list1m[pair] = df.loc[:]\n",
    "\n",
    "for pair in pair_list:\n",
    "    df = get_historical_from_db(ccxt.binance(), pair, '1d', path=\"./database/\")\n",
    "    df_list1d[pair] = df.loc[:]\n",
    "\n",
    "for pair in pair_list:\n",
    "    df = get_historical_from_db(ccxt.binance(), pair, '1h', path=\"./database/\")\n",
    "    df_list1h[pair] = df.loc[:]\n",
    "\n",
    "for pair in pair_list:\n",
    "    df = get_historical_from_db(ccxt.binance(), pair, '5m', path=\"./database/\")\n",
    "    df_list5m[pair] = df.loc[:]\n",
    "\n",
    "for pair in pair_list:\n",
    "    df = get_historical_from_db(\n",
    "        ccxt.binance(), pair, '15m', path=\"./database/\")\n",
    "    df_list15m[pair] = df.loc[:]\n",
    "del(df)\n",
    "df_list = df_list1m\n",
    "prerr(\"Data load 100% use df_list1d[\\\"BTC/USDT\\\"] for exemple to access\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.constraints import MaxNorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Pair</th>\n",
       "      <th>launch_week_stamp</th>\n",
       "      <th>launch_day_stamp</th>\n",
       "      <th>launch_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SNMBUSD</td>\n",
       "      <td>SNM/BUSD</td>\n",
       "      <td>1661126400000</td>\n",
       "      <td>1661472000000</td>\n",
       "      <td>2022-08-26 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>1502668800000</td>\n",
       "      <td>1502928000000</td>\n",
       "      <td>2017-08-17 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LUNAUSDT</td>\n",
       "      <td>LUNA/USDT</td>\n",
       "      <td>1597622400000</td>\n",
       "      <td>1597968000000</td>\n",
       "      <td>2020-08-21 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>ETH/USDT</td>\n",
       "      <td>1502668800000</td>\n",
       "      <td>1502928000000</td>\n",
       "      <td>2017-08-17 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GMTUSDT</td>\n",
       "      <td>GMT/USDT</td>\n",
       "      <td>1646611200000</td>\n",
       "      <td>1646784000000</td>\n",
       "      <td>2022-03-09 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>FIDAUSDT</td>\n",
       "      <td>FIDA/USDT</td>\n",
       "      <td>1632700800000</td>\n",
       "      <td>1632960000000</td>\n",
       "      <td>2021-09-30 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>XNOUSDT</td>\n",
       "      <td>XNO/USDT</td>\n",
       "      <td>1642982400000</td>\n",
       "      <td>1643328000000</td>\n",
       "      <td>2022-01-28 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>BTGUSDT</td>\n",
       "      <td>BTG/USDT</td>\n",
       "      <td>1618185600000</td>\n",
       "      <td>1618531200000</td>\n",
       "      <td>2021-04-16 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>GHSTUSDT</td>\n",
       "      <td>GHST/USDT</td>\n",
       "      <td>1629072000000</td>\n",
       "      <td>1629417600000</td>\n",
       "      <td>2021-08-20 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>EPSUSDT</td>\n",
       "      <td>EPS/USDT</td>\n",
       "      <td>1616976000000</td>\n",
       "      <td>1617321600000</td>\n",
       "      <td>2021-04-02 09:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       Pair  launch_week_stamp  launch_day_stamp  \\\n",
       "0     SNMBUSD   SNM/BUSD      1661126400000     1661472000000   \n",
       "1     BTCUSDT   BTC/USDT      1502668800000     1502928000000   \n",
       "2    LUNAUSDT  LUNA/USDT      1597622400000     1597968000000   \n",
       "3     ETHUSDT   ETH/USDT      1502668800000     1502928000000   \n",
       "4     GMTUSDT   GMT/USDT      1646611200000     1646784000000   \n",
       "..        ...        ...                ...               ...   \n",
       "107  FIDAUSDT  FIDA/USDT      1632700800000     1632960000000   \n",
       "108   XNOUSDT   XNO/USDT      1642982400000     1643328000000   \n",
       "109   BTGUSDT   BTG/USDT      1618185600000     1618531200000   \n",
       "110  GHSTUSDT  GHST/USDT      1629072000000     1629417600000   \n",
       "111   EPSUSDT   EPS/USDT      1616976000000     1617321600000   \n",
       "\n",
       "           launch_minute  \n",
       "0    2022-08-26 08:00:00  \n",
       "1    2017-08-17 04:00:00  \n",
       "2    2020-08-21 10:00:00  \n",
       "3    2017-08-17 04:00:00  \n",
       "4    2022-03-09 12:00:00  \n",
       "..                   ...  \n",
       "107  2021-09-30 12:00:00  \n",
       "108  2022-01-28 08:00:00  \n",
       "109  2021-04-16 07:00:00  \n",
       "110  2021-08-20 10:00:00  \n",
       "111  2021-04-02 09:00:00  \n",
       "\n",
       "[112 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chking import\n",
    "MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '/UltimeTradingBot/Data/BUY_UP_CLOSE'\n",
      "Results dir: /UltimeTradingBot/Data/BUY_UP_CLOSE\n"
     ]
    }
   ],
   "source": [
    "if BUY_MODE==\"BUY_ONLY\":\n",
    "    buy_function=buy_up_only\n",
    "elif BUY_MODE==\"BUY_UP\":\n",
    "    buy_function=buy_up\n",
    "elif  BUY_MODE==\"BUY_DIP\":\n",
    "    buy_function=buy_min_up\n",
    "elif  BUY_MODE==\"AFTER_DEPTH\":\n",
    "    buy_function=buy_after_depth\n",
    "elif  BUY_MODE==\"BUY_UP_CLOSE\":\n",
    "    buy_function=buy_up_close\n",
    "\n",
    "    \n",
    "\n",
    "try:\n",
    "    os.mkdir(DATA_DIR, mode = 0o777)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "print(f\"Results dir: {DATA_DIR}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def One_pair_AI_Gen(pair=\"ETH/USDT\",row_numbers=500000):\n",
    "    ResJS={}\n",
    "    mfile=f'{DATA_DIR}/{pair.replace(\"/\", \"-\")}-tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model_v{VERSION}.hdf5'\n",
    "    nfile=f'{DATA_DIR}/{pair.replace(\"/\", \"-\")}-tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Norm_v{VERSION}.json'\n",
    "    print(f\"One_pair_AI_Gen : {pair}\")\n",
    "    price_volatility_15m=round((100*(df_list15m[pair][\"high\"]-df_list15m[pair][\"low\"])/df_list15m[pair][\"high\"]).mean()*0.51,2)\n",
    "    print(f\"price_volatility_15m:{price_volatility_15m}%\")\n",
    "    df=mini_expand4(pair=pair,i=0,j=len(df_list1m[pair]),window=WINDOW_SIZE,metadata=MetaData,BUY_PCT=max(price_volatility_15m,BUY_PCT),SELL_PCT=SELL_PCT,buy_function=buy_function)\n",
    "    print(\"df original shape \"+str(df.shape))\n",
    "    print(f\"df original shape buy mean : {df.buy.mean()*100}\")\n",
    "    df=df.reset_index()\n",
    "    try:df.pop(\"num_index\")\n",
    "    except: pass\n",
    "    try:df.pop(\"index\")\n",
    "    except: pass\n",
    "    try:df.pop(\"date\")\n",
    "    except: pass\n",
    "    df=data_shufler(df)            \n",
    "    #df=data_chooser(df,weight=50,row_numbers=df.buy.sum()*2)\n",
    "    df=data_chooser50(df,row_numbers=row_numbers)\n",
    "    gc.collect()\n",
    "    df=data_cleanup(df)\n",
    "    df=df.dropna()\n",
    "    print(\"df choosen data shape\"+str(df.shape))\n",
    "    print(f\"pair: {(df.shape[0]/2)==df.buy.sum()}\")\n",
    "    dt=df.to_numpy(dtype=np.float32)\n",
    "    #dt=df.to_numpy()\n",
    "    dt=np.nan_to_num(dt,nan=0)\n",
    "    #dt=dt.astype(np.float32)\n",
    "    dt=np.nan_to_num(dt, neginf=0) \n",
    "    dt=np.nan_to_num(dt, posinf=0) \n",
    "\n",
    "    ## normalisation\n",
    "    index_20pct= int(0.2*len(dt[:,0]))\n",
    "    print(index_20pct)\n",
    "    if True:\n",
    "        if True:\n",
    "        #if True:\n",
    "            print(\"normalizing ...\")\n",
    "            mean = dt[index_20pct:, 0:-1].mean(axis=0)\n",
    "            std = dt[index_20pct:, 0:-1].std(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "            dt[index_20pct:, 0:-1] -= mean \n",
    "            dt[index_20pct:, 0:-1] /= std\n",
    "\n",
    "            dt[:index_20pct, :-1] -=mean\n",
    "            dt[:index_20pct, :-1] /= std\n",
    "            FIRST_NORM_FLAG=False\n",
    "            ######################### SAVIN NORM ################\n",
    "            try:\n",
    "                Normalization={\"mean\":mean.tolist(),\"std\":std.tolist()}\n",
    "                with open(nfile, 'w+') as fp:\n",
    "                            json.dump(Normalization, fp,  indent=4)\n",
    "                            print(fp.name)\n",
    "            except Exception as e:\n",
    "                print(\"error Normalization in juppiter\")\n",
    "                print(e)\n",
    "        else:print(\"already normalized\")\n",
    "        \n",
    "    dt=np.nan_to_num(dt,nan=0)\n",
    "    dt=np.nan_to_num(dt, neginf=0) \n",
    "    dt=np.nan_to_num(dt, posinf=0) \n",
    "    dt=dt.astype(np.float32)\n",
    "    ## Model\n",
    "    IN_DIM=dt.shape[1]-1\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(250),input_dim=IN_DIM,activation='relu')) #( 100=>66.23)\n",
    "    # resultus withe 250 d0.3 50 d 20 d 8 = 65.6% vs  65.49 no droppout vs 65.78 d0.5 vs 65.68 d0.4 # 65.48 # one dropout of   0.5 = 66.11   #tanh 66.33 accuracy #softmax 66.12 #softplus 66.5 # sigmoid 66.21 / \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(int(20),activation='relu')) # best softplus 66.26(69) vs relu 66.65(70)  / -20 => 66.25 /250 ->65.78\n",
    "    #model2.add(Dropout(0.1)) #5=> 66.00  66.21 vs no dopout 66.28\n",
    "    #model2.add(Dense(int(20),activation='relu')) # disabled 6.24\n",
    "    model.add(Dense(int(50),activation='relu')) # -4 -> -> 66.24\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    print(model.summary())\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    callbacks_a = ModelCheckpoint(filepath =mfile,monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "    callbacks_b = EarlyStopping(monitor ='val_accuracy',mode='auto',patience=15,verbose=1)\n",
    "    print(\"saving file in: \"+mfile)\n",
    "    history = model.fit(dt[index_20pct:, 0:-1],\n",
    "                    dt[index_20pct:,-1],\n",
    "                    validation_data=(dt[:index_20pct, :-1],dt[:index_20pct,-1]),\n",
    "                    epochs=6000,\n",
    "                    batch_size=256*10,\n",
    "                    callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "    print('##########################################################################')\n",
    "    print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "    print(nfile)\n",
    "    print(mfile)\n",
    "    ResJS[pair]='{0:.4g}'.format(max(history.history['val_accuracy'])*100)\n",
    "    return( model , ResJS)\n",
    "    #94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalDataTest(pair=\"ETH/USDT\"):\n",
    "    price_volatility_15m=round((100*(df_list15m[pair][\"high\"]-df_list15m[pair][\"low\"])/df_list15m[pair][\"high\"]).mean()*0.51,2)\n",
    "    print(f\"price_volatility_15m:{price_volatility_15m}%\")\n",
    "    df=mini_expand4(pair=pair,i=0,j=len(df_list1m[pair]),window=WINDOW_SIZE,metadata=MetaData,BUY_PCT=max(price_volatility_15m,BUY_PCT),SELL_PCT=SELL_PCT,buy_function=buy_function)\n",
    "    print(\"df original shape \"+str(df.shape))\n",
    "    print(f\"df original shape buy mean : {df.buy.mean()*100}\")\n",
    "    df=df.reset_index()\n",
    "    try:df.pop(\"num_index\")\n",
    "    except: pass\n",
    "    try:df.pop(\"index\")\n",
    "    except: pass\n",
    "    try:df.pop(\"date\")\n",
    "    except: pass\n",
    "    # df=data_shufler(df)            \n",
    "    # #df=data_chooser(df,weight=50,row_numbers=df.buy.sum()*2)\n",
    "    # df=data_chooser50(df,row_numbers=500000)\n",
    "    # gc.collect()\n",
    "    df=data_cleanup(df)\n",
    "    df=df.dropna()\n",
    "    print(\"df choosen data shape\"+str(df.shape))\n",
    "    print(f\"pair: {(df.shape[0]/2)==df.buy.sum()}\")\n",
    "    dt=df.to_numpy(dtype=np.float32)\n",
    "    #dt=df.to_numpy()\n",
    "    dt=np.nan_to_num(dt,nan=0)\n",
    "    #dt=dt.astype(np.float32)\n",
    "    dt=np.nan_to_num(dt, neginf=0) \n",
    "    dt=np.nan_to_num(dt, posinf=0) \n",
    "\n",
    "    ## normalisation\n",
    "    #index_20pct= int(0.2*len(dt[:,0]))\n",
    "    #print(index_20pct)\n",
    "    Y=dt[:,-1].copy()\n",
    "    dt[:,:-1]=normalize(dt[:,:-1],f'{DATA_DIR}/{pair.replace(\"/\", \"-\")}-tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Norm_v{VERSION}.json')\n",
    "    dt=np.nan_to_num(dt,nan=0)\n",
    "    dt=np.nan_to_num(dt, neginf=0) \n",
    "    dt=np.nan_to_num(dt, posinf=0) \n",
    "    dt=dt.astype(np.float32)\n",
    "    ## Model\n",
    "    return dt\n",
    "    #94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair=\"ROSE/USDT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/ROSE-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/ROSE-USDT-tp50_w40_max10min_Norm_v1.json\n"
     ]
    }
   ],
   "source": [
    "mfile=f'{DATA_DIR}/{pair.replace(\"/\", \"-\")}-tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model_v{VERSION}.hdf5'\n",
    "nfile=f'{DATA_DIR}/{pair.replace(\"/\", \"-\")}-tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Norm_v{VERSION}.json'\n",
    "print(mfile)\n",
    "print(nfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Garbage Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m,h=One_pair_AI_Gen(pair=\"ETH/USDT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair=\"ETH/USDT\"\n",
    "# model = load_model(MODEL_FILE.replace(\"/UltimeTradingBot/Data/\", \"/UltimeTradingBot/Data/\"+pair.replace(\"/\", \"-\")+\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mini_expand4(pair=\"GMT/USDT\",i=0,j=10000,window=2,metadata=MetaData,high_weight=1,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,buy_function=buy_min_up):\n",
    "    print(f\"mini_expand : {pair}\")\n",
    "    Pair_Full=full_expand(df_list1m[pair].iloc[i:j],df_list5m[pair],df_list15m[pair],df_list1h[pair],df_list1d[pair],window)\n",
    "    BTC_Full=full_expand(\n",
    "        df_list1m[\"BTC/USDT\"].loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" d\")).round(freq='1 min'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        df_list5m[\"BTC/USDT\"],#.loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" d\")).round(freq='5 min'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        df_list15m[\"BTC/USDT\"],#.loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" day\")).round(freq='15 min'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        df_list1h[\"BTC/USDT\"],#.loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" day\")).round(freq='1 H'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        df_list1d[\"BTC/USDT\"],#.loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" day\")).round(freq='1 d'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        window)   \n",
    "    BTC_Full=BTC_Full.add_prefix(\"BTC_\")\n",
    "    # Merged=pd.merge(Pair_Full, BTC_Full, left_index=True, how='left',\n",
    "    #         right_index=True, suffixes=('', ''))\n",
    "    Merged=pd.merge(Pair_Full, BTC_Full, left_index=True, how='inner',\n",
    "            right_index=True, suffixes=('', ''))\n",
    "    day_expand(Merged)\n",
    "    Meta_expand(Merged,metadata,pair)\n",
    "    #buy_sell(Merged,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=MAX_FORCAST_SIZE)\n",
    "    buy_function(Merged,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=MAX_FORCAST_SIZE)\n",
    "    Merged[\"high\"]=(Merged[\"open\"]+high_weight*Merged[\"high\"]+Merged[\"low\"]+Merged[\"close\"])/(3+high_weight)\n",
    "    Merged.rename(columns={\"high\":\"price\"},inplace = True)\n",
    "    Merged[\"BTC_high\"]=(Merged[\"BTC_open\"]+high_weight*Merged[\"BTC_high\"]+Merged[\"BTC_low\"]+Merged[\"BTC_close\"])/(3+high_weight)\n",
    "    Merged.rename(columns={\"BTC_high\":\"BTC_price\"},inplace = True)\n",
    "    Merged=Merged.drop(columns=[\"BTC_open\",\"BTC_low\",\"BTC_close\",\"open\",\"low\",\"close\"])\n",
    "    # Merged=justlast_remover(Merged)\n",
    "    for key in Merged.keys():\n",
    "        if key.find(\"BTC\")!=-1 and (key.find(\"open\")!=-1 or\n",
    "        key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "            Merged[key]=(Merged[\"BTC_price\"]-Merged[key])/Merged[\"BTC_price\"]\n",
    "        if key.find(\"BTC\")==-1 and (key.find(\"open\")!=-1 or\n",
    "        key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "            Merged[key]=(Merged[\"price\"]-Merged[key])/Merged[\"price\"]\n",
    "    Merged=Merged.dropna()\n",
    "    return Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on pair: SNM/BUSD\n",
      "One_pair_AI_Gen : SNM/BUSD\n",
      "price_volatility_15m:0.93%\n",
      "mini_expand : SNM/BUSD\n",
      "---buy_after_depth--- Buy pct: 0.93%\n",
      "---buy_after_depth--- no b\n"
     ]
    }
   ],
   "source": [
    "### sigle Train sample\n",
    "pair=\"SNM/BUSD\"\n",
    "print(f\"working on pair: {pair}\")\n",
    "buy_function=buy_after_depth\n",
    "m,h=One_pair_AI_Gen(pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price_volatility_15m=round((100*(df_list15m[pair][\"high\"]-df_list15m[pair][\"low\"])/df_list15m[pair][\"high\"]).mean()*0.51,2)\n",
    "# print(f\"price_volatility_15m:{price_volatility_15m}%\")\n",
    "# df=mini_expand3(pair=pair,i=0,j=len(df_list1m[pair]),window=WINDOW_SIZE,metadata=MetaData,BUY_PCT=max(price_volatility_15m,BUY_PCT),SELL_PCT=SELL_PCT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MetaData=get_crypto_metadata(Binance_USDT_HALAL)\n",
    "# MetaData.to_csv(\"../Data/MetaData.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair=\"ORN/BUSD\"\n",
    "buy_function=buy_after_depth\n",
    "m,h=One_pair_AI_Gen(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Binance_USDT_HALAL.index(\"LOKA/USDT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---buy_simple_up--- Buy pct: 0.5%\n",
      "---buy_only--- Max time window: 10%\n",
      "---buy_only--- no b\n",
      "---buy_only--- no sell\n",
      "df original shape (407576, 1607)\n",
      "df original shape buy mean : 12.684996172492982\n",
      "df choosen data shape(407576, 1607)\n",
      "pair: True\n",
      "81515\n",
      "normalizing ...\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/GALA-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_72 (Dense)            (None, 250)               401750    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 250)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 20)                5020      \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,871\n",
      "Trainable params: 407,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_UP_CLOSE/GALA-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "Epoch 1/6000\n",
      "128/128 [==============================] - 27s 170ms/step - loss: 0.5916 - accuracy: 0.6807 - val_loss: 0.5676 - val_accuracy: 0.7000\n",
      "Epoch 2/6000\n",
      "128/128 [==============================] - 17s 131ms/step - loss: 0.5566 - accuracy: 0.7097 - val_loss: 0.5363 - val_accuracy: 0.7246\n",
      "Epoch 3/6000\n",
      "128/128 [==============================] - 16s 126ms/step - loss: 0.5300 - accuracy: 0.7302 - val_loss: 0.5081 - val_accuracy: 0.7488\n",
      "Epoch 4/6000\n",
      "128/128 [==============================] - 16s 124ms/step - loss: 0.5049 - accuracy: 0.7492 - val_loss: 0.4874 - val_accuracy: 0.7638\n",
      "Epoch 5/6000\n",
      "128/128 [==============================] - 16s 125ms/step - loss: 0.4800 - accuracy: 0.7660 - val_loss: 0.4536 - val_accuracy: 0.7858\n",
      "Epoch 6/6000\n",
      "128/128 [==============================] - 16s 126ms/step - loss: 0.4597 - accuracy: 0.7797 - val_loss: 0.4309 - val_accuracy: 0.7995\n",
      "Epoch 7/6000\n",
      "128/128 [==============================] - 16s 123ms/step - loss: 0.4417 - accuracy: 0.7908 - val_loss: 0.4188 - val_accuracy: 0.8081\n",
      "Epoch 8/6000\n",
      "128/128 [==============================] - 16s 123ms/step - loss: 0.4259 - accuracy: 0.8007 - val_loss: 0.4067 - val_accuracy: 0.8161\n",
      "Epoch 9/6000\n",
      "128/128 [==============================] - 20s 158ms/step - loss: 0.4123 - accuracy: 0.8088 - val_loss: 0.3877 - val_accuracy: 0.8257\n",
      "Epoch 10/6000\n",
      "128/128 [==============================] - 16s 124ms/step - loss: 0.3993 - accuracy: 0.8160 - val_loss: 0.3787 - val_accuracy: 0.8298\n",
      "Epoch 11/6000\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 0.3896 - accuracy: 0.8217 - val_loss: 0.3692 - val_accuracy: 0.8349\n",
      "Epoch 12/6000\n",
      "128/128 [==============================] - 16s 127ms/step - loss: 0.3779 - accuracy: 0.8282 - val_loss: 0.3576 - val_accuracy: 0.8427\n",
      "Epoch 13/6000\n",
      "128/128 [==============================] - 20s 153ms/step - loss: 0.3692 - accuracy: 0.8337 - val_loss: 0.3487 - val_accuracy: 0.8481\n",
      "Epoch 14/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.3585 - accuracy: 0.8394 - val_loss: 0.3402 - val_accuracy: 0.8515\n",
      "Epoch 15/6000\n",
      "128/128 [==============================] - 17s 130ms/step - loss: 0.3533 - accuracy: 0.8419 - val_loss: 0.3393 - val_accuracy: 0.8514\n",
      "Epoch 16/6000\n",
      "128/128 [==============================] - 20s 158ms/step - loss: 0.3452 - accuracy: 0.8467 - val_loss: 0.3303 - val_accuracy: 0.8573\n",
      "Epoch 17/6000\n",
      "128/128 [==============================] - 20s 158ms/step - loss: 0.3386 - accuracy: 0.8504 - val_loss: 0.3204 - val_accuracy: 0.8613\n",
      "Epoch 18/6000\n",
      "128/128 [==============================] - 16s 124ms/step - loss: 0.3332 - accuracy: 0.8538 - val_loss: 0.3144 - val_accuracy: 0.8653\n",
      "Epoch 19/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.3285 - accuracy: 0.8557 - val_loss: 0.3066 - val_accuracy: 0.8679\n",
      "Epoch 20/6000\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 0.3231 - accuracy: 0.8589 - val_loss: 0.3048 - val_accuracy: 0.8694\n",
      "Epoch 21/6000\n",
      "128/128 [==============================] - 16s 128ms/step - loss: 0.3176 - accuracy: 0.8611 - val_loss: 0.3001 - val_accuracy: 0.8744\n",
      "Epoch 22/6000\n",
      "128/128 [==============================] - 21s 162ms/step - loss: 0.3131 - accuracy: 0.8635 - val_loss: 0.3041 - val_accuracy: 0.8685\n",
      "Epoch 23/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.3086 - accuracy: 0.8668 - val_loss: 0.2945 - val_accuracy: 0.8750\n",
      "Epoch 24/6000\n",
      "128/128 [==============================] - 16s 126ms/step - loss: 0.3035 - accuracy: 0.8689 - val_loss: 0.2887 - val_accuracy: 0.8780\n",
      "Epoch 25/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.2995 - accuracy: 0.8706 - val_loss: 0.2812 - val_accuracy: 0.8819\n",
      "Epoch 26/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.2959 - accuracy: 0.8730 - val_loss: 0.2800 - val_accuracy: 0.8819\n",
      "Epoch 27/6000\n",
      "128/128 [==============================] - 16s 122ms/step - loss: 0.2916 - accuracy: 0.8745 - val_loss: 0.2780 - val_accuracy: 0.8832\n",
      "Epoch 28/6000\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 0.2885 - accuracy: 0.8764 - val_loss: 0.2707 - val_accuracy: 0.8866\n",
      "Epoch 29/6000\n",
      "128/128 [==============================] - 21s 165ms/step - loss: 0.2848 - accuracy: 0.8783 - val_loss: 0.2681 - val_accuracy: 0.8892\n",
      "Epoch 30/6000\n",
      "128/128 [==============================] - 17s 131ms/step - loss: 0.2812 - accuracy: 0.8802 - val_loss: 0.2685 - val_accuracy: 0.8890\n",
      "Epoch 31/6000\n",
      "128/128 [==============================] - 21s 162ms/step - loss: 0.2780 - accuracy: 0.8817 - val_loss: 0.2647 - val_accuracy: 0.8909\n",
      "Epoch 32/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.2752 - accuracy: 0.8834 - val_loss: 0.2571 - val_accuracy: 0.8955\n",
      "Epoch 33/6000\n",
      "128/128 [==============================] - 16s 122ms/step - loss: 0.2722 - accuracy: 0.8850 - val_loss: 0.2578 - val_accuracy: 0.8937\n",
      "Epoch 34/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.2681 - accuracy: 0.8862 - val_loss: 0.2556 - val_accuracy: 0.8948\n",
      "Epoch 35/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.2665 - accuracy: 0.8876 - val_loss: 0.2541 - val_accuracy: 0.8967\n",
      "Epoch 36/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.2636 - accuracy: 0.8890 - val_loss: 0.2510 - val_accuracy: 0.8989\n",
      "Epoch 37/6000\n",
      "128/128 [==============================] - 16s 127ms/step - loss: 0.2595 - accuracy: 0.8908 - val_loss: 0.2493 - val_accuracy: 0.8985\n",
      "Epoch 38/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.2588 - accuracy: 0.8914 - val_loss: 0.2485 - val_accuracy: 0.9003\n",
      "Epoch 39/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.2571 - accuracy: 0.8924 - val_loss: 0.2448 - val_accuracy: 0.9007\n",
      "Epoch 40/6000\n",
      "128/128 [==============================] - 15s 121ms/step - loss: 0.2559 - accuracy: 0.8928 - val_loss: 0.2464 - val_accuracy: 0.8997\n",
      "Epoch 41/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.2524 - accuracy: 0.8951 - val_loss: 0.2438 - val_accuracy: 0.9024\n",
      "Epoch 42/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.2484 - accuracy: 0.8963 - val_loss: 0.2416 - val_accuracy: 0.9017\n",
      "Epoch 43/6000\n",
      "128/128 [==============================] - 21s 167ms/step - loss: 0.2469 - accuracy: 0.8974 - val_loss: 0.2389 - val_accuracy: 0.9047\n",
      "Epoch 44/6000\n",
      "128/128 [==============================] - 18s 137ms/step - loss: 0.2458 - accuracy: 0.8980 - val_loss: 0.2365 - val_accuracy: 0.9062\n",
      "Epoch 45/6000\n",
      "128/128 [==============================] - 20s 153ms/step - loss: 0.2446 - accuracy: 0.8986 - val_loss: 0.2358 - val_accuracy: 0.9066\n",
      "Epoch 46/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.2415 - accuracy: 0.9000 - val_loss: 0.2345 - val_accuracy: 0.9074\n",
      "Epoch 47/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.2390 - accuracy: 0.9008 - val_loss: 0.2326 - val_accuracy: 0.9087\n",
      "Epoch 48/6000\n",
      "128/128 [==============================] - 17s 132ms/step - loss: 0.2379 - accuracy: 0.9014 - val_loss: 0.2305 - val_accuracy: 0.9091\n",
      "Epoch 49/6000\n",
      "128/128 [==============================] - 20s 153ms/step - loss: 0.2370 - accuracy: 0.9016 - val_loss: 0.2294 - val_accuracy: 0.9099\n",
      "Epoch 50/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.2337 - accuracy: 0.9036 - val_loss: 0.2279 - val_accuracy: 0.9100\n",
      "Epoch 51/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.2322 - accuracy: 0.9042 - val_loss: 0.2304 - val_accuracy: 0.9086\n",
      "Epoch 52/6000\n",
      "128/128 [==============================] - 17s 133ms/step - loss: 0.2302 - accuracy: 0.9052 - val_loss: 0.2337 - val_accuracy: 0.9084\n",
      "Epoch 53/6000\n",
      "128/128 [==============================] - 21s 160ms/step - loss: 0.2294 - accuracy: 0.9057 - val_loss: 0.2251 - val_accuracy: 0.9119\n",
      "Epoch 54/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.2256 - accuracy: 0.9076 - val_loss: 0.2232 - val_accuracy: 0.9129\n",
      "Epoch 55/6000\n",
      "128/128 [==============================] - 20s 157ms/step - loss: 0.2245 - accuracy: 0.9081 - val_loss: 0.2274 - val_accuracy: 0.9121\n",
      "Epoch 56/6000\n",
      "128/128 [==============================] - 19s 150ms/step - loss: 0.2250 - accuracy: 0.9080 - val_loss: 0.2211 - val_accuracy: 0.9140\n",
      "Epoch 57/6000\n",
      "128/128 [==============================] - 18s 137ms/step - loss: 0.2222 - accuracy: 0.9089 - val_loss: 0.2184 - val_accuracy: 0.9144\n",
      "Epoch 58/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.2201 - accuracy: 0.9102 - val_loss: 0.2186 - val_accuracy: 0.9132\n",
      "Epoch 59/6000\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 0.2173 - accuracy: 0.9110 - val_loss: 0.2216 - val_accuracy: 0.9130\n",
      "Epoch 60/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.2178 - accuracy: 0.9109 - val_loss: 0.2184 - val_accuracy: 0.9162\n",
      "Epoch 61/6000\n",
      "128/128 [==============================] - 19s 150ms/step - loss: 0.2161 - accuracy: 0.9119 - val_loss: 0.2146 - val_accuracy: 0.9172\n",
      "Epoch 62/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.2156 - accuracy: 0.9120 - val_loss: 0.2139 - val_accuracy: 0.9169\n",
      "Epoch 63/6000\n",
      "128/128 [==============================] - 21s 167ms/step - loss: 0.2148 - accuracy: 0.9130 - val_loss: 0.2128 - val_accuracy: 0.9172\n",
      "Epoch 64/6000\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 0.2110 - accuracy: 0.9143 - val_loss: 0.2119 - val_accuracy: 0.9184\n",
      "Epoch 65/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.2111 - accuracy: 0.9145 - val_loss: 0.2123 - val_accuracy: 0.9186\n",
      "Epoch 66/6000\n",
      "128/128 [==============================] - 16s 122ms/step - loss: 0.2102 - accuracy: 0.9147 - val_loss: 0.2072 - val_accuracy: 0.9210\n",
      "Epoch 67/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.2090 - accuracy: 0.9159 - val_loss: 0.2063 - val_accuracy: 0.9207\n",
      "Epoch 68/6000\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 0.2081 - accuracy: 0.9157 - val_loss: 0.2078 - val_accuracy: 0.9202\n",
      "Epoch 69/6000\n",
      "128/128 [==============================] - 16s 122ms/step - loss: 0.2038 - accuracy: 0.9178 - val_loss: 0.2114 - val_accuracy: 0.9191\n",
      "Epoch 70/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.2051 - accuracy: 0.9171 - val_loss: 0.2083 - val_accuracy: 0.9203\n",
      "Epoch 71/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.2029 - accuracy: 0.9177 - val_loss: 0.2079 - val_accuracy: 0.9212\n",
      "Epoch 72/6000\n",
      "128/128 [==============================] - 16s 122ms/step - loss: 0.2004 - accuracy: 0.9193 - val_loss: 0.2030 - val_accuracy: 0.9231\n",
      "Epoch 73/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.2007 - accuracy: 0.9194 - val_loss: 0.2030 - val_accuracy: 0.9239\n",
      "Epoch 74/6000\n",
      "128/128 [==============================] - 21s 167ms/step - loss: 0.1990 - accuracy: 0.9202 - val_loss: 0.2019 - val_accuracy: 0.9250\n",
      "Epoch 75/6000\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 0.1988 - accuracy: 0.9198 - val_loss: 0.2078 - val_accuracy: 0.9195\n",
      "Epoch 76/6000\n",
      "128/128 [==============================] - 19s 147ms/step - loss: 0.1967 - accuracy: 0.9209 - val_loss: 0.2006 - val_accuracy: 0.9239\n",
      "Epoch 77/6000\n",
      "128/128 [==============================] - 19s 146ms/step - loss: 0.1984 - accuracy: 0.9204 - val_loss: 0.2000 - val_accuracy: 0.9240\n",
      "Epoch 78/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1957 - accuracy: 0.9216 - val_loss: 0.2010 - val_accuracy: 0.9241\n",
      "Epoch 79/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1941 - accuracy: 0.9226 - val_loss: 0.1957 - val_accuracy: 0.9275\n",
      "Epoch 80/6000\n",
      "128/128 [==============================] - 16s 124ms/step - loss: 0.1919 - accuracy: 0.9238 - val_loss: 0.1972 - val_accuracy: 0.9243\n",
      "Epoch 81/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1917 - accuracy: 0.9228 - val_loss: 0.1969 - val_accuracy: 0.9257\n",
      "Epoch 82/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1916 - accuracy: 0.9232 - val_loss: 0.1980 - val_accuracy: 0.9261\n",
      "Epoch 83/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.1904 - accuracy: 0.9241 - val_loss: 0.1947 - val_accuracy: 0.9275\n",
      "Epoch 84/6000\n",
      "128/128 [==============================] - 17s 135ms/step - loss: 0.1889 - accuracy: 0.9242 - val_loss: 0.1965 - val_accuracy: 0.9269\n",
      "Epoch 85/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1898 - accuracy: 0.9244 - val_loss: 0.1919 - val_accuracy: 0.9282\n",
      "Epoch 86/6000\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 0.1877 - accuracy: 0.9251 - val_loss: 0.1994 - val_accuracy: 0.9270\n",
      "Epoch 87/6000\n",
      "128/128 [==============================] - 17s 130ms/step - loss: 0.1864 - accuracy: 0.9259 - val_loss: 0.1917 - val_accuracy: 0.9287\n",
      "Epoch 88/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1856 - accuracy: 0.9265 - val_loss: 0.1950 - val_accuracy: 0.9284\n",
      "Epoch 89/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.1826 - accuracy: 0.9279 - val_loss: 0.1952 - val_accuracy: 0.9287\n",
      "Epoch 90/6000\n",
      "128/128 [==============================] - 17s 136ms/step - loss: 0.1824 - accuracy: 0.9277 - val_loss: 0.1884 - val_accuracy: 0.9306\n",
      "Epoch 91/6000\n",
      "128/128 [==============================] - 20s 156ms/step - loss: 0.1819 - accuracy: 0.9279 - val_loss: 0.1909 - val_accuracy: 0.9294\n",
      "Epoch 92/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1824 - accuracy: 0.9277 - val_loss: 0.1921 - val_accuracy: 0.9290\n",
      "Epoch 93/6000\n",
      "128/128 [==============================] - 20s 156ms/step - loss: 0.1796 - accuracy: 0.9286 - val_loss: 0.1935 - val_accuracy: 0.9281\n",
      "Epoch 94/6000\n",
      "128/128 [==============================] - 21s 165ms/step - loss: 0.1794 - accuracy: 0.9289 - val_loss: 0.1900 - val_accuracy: 0.9299\n",
      "Epoch 95/6000\n",
      "128/128 [==============================] - 17s 131ms/step - loss: 0.1792 - accuracy: 0.9293 - val_loss: 0.1929 - val_accuracy: 0.9299\n",
      "Epoch 96/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1782 - accuracy: 0.9293 - val_loss: 0.1848 - val_accuracy: 0.9329\n",
      "Epoch 97/6000\n",
      "128/128 [==============================] - 21s 165ms/step - loss: 0.1770 - accuracy: 0.9303 - val_loss: 0.1934 - val_accuracy: 0.9290\n",
      "Epoch 98/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1751 - accuracy: 0.9312 - val_loss: 0.1851 - val_accuracy: 0.9318\n",
      "Epoch 99/6000\n",
      "128/128 [==============================] - 19s 152ms/step - loss: 0.1756 - accuracy: 0.9307 - val_loss: 0.1866 - val_accuracy: 0.9308\n",
      "Epoch 100/6000\n",
      "128/128 [==============================] - 19s 150ms/step - loss: 0.1757 - accuracy: 0.9306 - val_loss: 0.1820 - val_accuracy: 0.9343\n",
      "Epoch 101/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1727 - accuracy: 0.9320 - val_loss: 0.1832 - val_accuracy: 0.9333\n",
      "Epoch 102/6000\n",
      "128/128 [==============================] - 21s 165ms/step - loss: 0.1727 - accuracy: 0.9320 - val_loss: 0.1853 - val_accuracy: 0.9329\n",
      "Epoch 103/6000\n",
      "128/128 [==============================] - 17s 132ms/step - loss: 0.1719 - accuracy: 0.9329 - val_loss: 0.1798 - val_accuracy: 0.9359\n",
      "Epoch 104/6000\n",
      "128/128 [==============================] - 22s 167ms/step - loss: 0.1705 - accuracy: 0.9332 - val_loss: 0.1879 - val_accuracy: 0.9320\n",
      "Epoch 105/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.1712 - accuracy: 0.9325 - val_loss: 0.1854 - val_accuracy: 0.9331\n",
      "Epoch 106/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1692 - accuracy: 0.9335 - val_loss: 0.1812 - val_accuracy: 0.9360\n",
      "Epoch 107/6000\n",
      "128/128 [==============================] - 17s 134ms/step - loss: 0.1684 - accuracy: 0.9336 - val_loss: 0.1765 - val_accuracy: 0.9371\n",
      "Epoch 108/6000\n",
      "128/128 [==============================] - 20s 159ms/step - loss: 0.1685 - accuracy: 0.9339 - val_loss: 0.1805 - val_accuracy: 0.9347\n",
      "Epoch 109/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1674 - accuracy: 0.9342 - val_loss: 0.1777 - val_accuracy: 0.9363\n",
      "Epoch 110/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1650 - accuracy: 0.9350 - val_loss: 0.1788 - val_accuracy: 0.9347\n",
      "Epoch 111/6000\n",
      "128/128 [==============================] - 17s 130ms/step - loss: 0.1671 - accuracy: 0.9344 - val_loss: 0.1843 - val_accuracy: 0.9337\n",
      "Epoch 112/6000\n",
      "128/128 [==============================] - 21s 167ms/step - loss: 0.1662 - accuracy: 0.9350 - val_loss: 0.1831 - val_accuracy: 0.9353\n",
      "Epoch 113/6000\n",
      "128/128 [==============================] - 20s 155ms/step - loss: 0.1635 - accuracy: 0.9359 - val_loss: 0.1781 - val_accuracy: 0.9368\n",
      "Epoch 114/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.1632 - accuracy: 0.9361 - val_loss: 0.1807 - val_accuracy: 0.9357\n",
      "Epoch 115/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.1623 - accuracy: 0.9365 - val_loss: 0.1812 - val_accuracy: 0.9353\n",
      "Epoch 116/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.1623 - accuracy: 0.9368 - val_loss: 0.1729 - val_accuracy: 0.9384\n",
      "Epoch 117/6000\n",
      "128/128 [==============================] - 43s 335ms/step - loss: 0.1607 - accuracy: 0.9377 - val_loss: 0.1735 - val_accuracy: 0.9372\n",
      "Epoch 118/6000\n",
      "128/128 [==============================] - 33s 257ms/step - loss: 0.1608 - accuracy: 0.9377 - val_loss: 0.1749 - val_accuracy: 0.9381\n",
      "Epoch 119/6000\n",
      "128/128 [==============================] - 47s 365ms/step - loss: 0.1589 - accuracy: 0.9382 - val_loss: 0.1783 - val_accuracy: 0.9369\n",
      "Epoch 120/6000\n",
      "128/128 [==============================] - 33s 261ms/step - loss: 0.1582 - accuracy: 0.9381 - val_loss: 0.1753 - val_accuracy: 0.9385\n",
      "Epoch 121/6000\n",
      "128/128 [==============================] - 48s 371ms/step - loss: 0.1597 - accuracy: 0.9373 - val_loss: 0.1771 - val_accuracy: 0.9374\n",
      "Epoch 122/6000\n",
      "128/128 [==============================] - 48s 372ms/step - loss: 0.1562 - accuracy: 0.9395 - val_loss: 0.1707 - val_accuracy: 0.9402\n",
      "Epoch 123/6000\n",
      "128/128 [==============================] - 47s 369ms/step - loss: 0.1571 - accuracy: 0.9386 - val_loss: 0.1743 - val_accuracy: 0.9390\n",
      "Epoch 124/6000\n",
      "128/128 [==============================] - 47s 368ms/step - loss: 0.1560 - accuracy: 0.9396 - val_loss: 0.1947 - val_accuracy: 0.9314\n",
      "Epoch 125/6000\n",
      "128/128 [==============================] - 46s 363ms/step - loss: 0.1579 - accuracy: 0.9386 - val_loss: 0.1782 - val_accuracy: 0.9375\n",
      "Epoch 126/6000\n",
      "128/128 [==============================] - 47s 369ms/step - loss: 0.1553 - accuracy: 0.9403 - val_loss: 0.1665 - val_accuracy: 0.9410\n",
      "Epoch 127/6000\n",
      "128/128 [==============================] - 48s 375ms/step - loss: 0.1535 - accuracy: 0.9407 - val_loss: 0.1724 - val_accuracy: 0.9390\n",
      "Epoch 128/6000\n",
      "128/128 [==============================] - 47s 368ms/step - loss: 0.1538 - accuracy: 0.9409 - val_loss: 0.1704 - val_accuracy: 0.9411\n",
      "Epoch 129/6000\n",
      "128/128 [==============================] - 47s 370ms/step - loss: 0.1540 - accuracy: 0.9403 - val_loss: 0.1722 - val_accuracy: 0.9401\n",
      "Epoch 130/6000\n",
      "128/128 [==============================] - 48s 373ms/step - loss: 0.1528 - accuracy: 0.9409 - val_loss: 0.1670 - val_accuracy: 0.9408\n",
      "Epoch 131/6000\n",
      "128/128 [==============================] - 47s 366ms/step - loss: 0.1535 - accuracy: 0.9408 - val_loss: 0.1672 - val_accuracy: 0.9422\n",
      "Epoch 132/6000\n",
      "128/128 [==============================] - 47s 369ms/step - loss: 0.1511 - accuracy: 0.9418 - val_loss: 0.1729 - val_accuracy: 0.9406\n",
      "Epoch 133/6000\n",
      "128/128 [==============================] - 47s 371ms/step - loss: 0.1505 - accuracy: 0.9415 - val_loss: 0.1702 - val_accuracy: 0.9410\n",
      "Epoch 134/6000\n",
      "128/128 [==============================] - 50s 388ms/step - loss: 0.1520 - accuracy: 0.9413 - val_loss: 0.1661 - val_accuracy: 0.9429\n",
      "Epoch 135/6000\n",
      "128/128 [==============================] - 47s 368ms/step - loss: 0.1489 - accuracy: 0.9428 - val_loss: 0.1754 - val_accuracy: 0.9387\n",
      "Epoch 136/6000\n",
      "128/128 [==============================] - 47s 365ms/step - loss: 0.1488 - accuracy: 0.9422 - val_loss: 0.1695 - val_accuracy: 0.9415\n",
      "Epoch 137/6000\n",
      "128/128 [==============================] - 48s 373ms/step - loss: 0.1482 - accuracy: 0.9429 - val_loss: 0.1726 - val_accuracy: 0.9416\n",
      "Epoch 138/6000\n",
      "128/128 [==============================] - 47s 365ms/step - loss: 0.1471 - accuracy: 0.9433 - val_loss: 0.1735 - val_accuracy: 0.9399\n",
      "Epoch 139/6000\n",
      "128/128 [==============================] - 47s 367ms/step - loss: 0.1466 - accuracy: 0.9430 - val_loss: 0.1675 - val_accuracy: 0.9421\n",
      "Epoch 140/6000\n",
      "128/128 [==============================] - 47s 370ms/step - loss: 0.1477 - accuracy: 0.9429 - val_loss: 0.1645 - val_accuracy: 0.9440\n",
      "Epoch 141/6000\n",
      "128/128 [==============================] - 47s 368ms/step - loss: 0.1462 - accuracy: 0.9434 - val_loss: 0.1638 - val_accuracy: 0.9432\n",
      "Epoch 142/6000\n",
      "128/128 [==============================] - 47s 366ms/step - loss: 0.1455 - accuracy: 0.9443 - val_loss: 0.1657 - val_accuracy: 0.9433\n",
      "Epoch 143/6000\n",
      "128/128 [==============================] - 46s 362ms/step - loss: 0.1450 - accuracy: 0.9439 - val_loss: 0.1660 - val_accuracy: 0.9426\n",
      "Epoch 144/6000\n",
      "128/128 [==============================] - 47s 368ms/step - loss: 0.1459 - accuracy: 0.9443 - val_loss: 0.1683 - val_accuracy: 0.9420\n",
      "Epoch 145/6000\n",
      "128/128 [==============================] - 47s 370ms/step - loss: 0.1439 - accuracy: 0.9447 - val_loss: 0.1651 - val_accuracy: 0.9441\n",
      "Epoch 146/6000\n",
      "128/128 [==============================] - 48s 375ms/step - loss: 0.1435 - accuracy: 0.9449 - val_loss: 0.1687 - val_accuracy: 0.9415\n",
      "Epoch 147/6000\n",
      "128/128 [==============================] - 47s 366ms/step - loss: 0.1427 - accuracy: 0.9450 - val_loss: 0.1634 - val_accuracy: 0.9438\n",
      "Epoch 148/6000\n",
      "128/128 [==============================] - 47s 368ms/step - loss: 0.1420 - accuracy: 0.9456 - val_loss: 0.1653 - val_accuracy: 0.9433\n",
      "Epoch 149/6000\n",
      "128/128 [==============================] - 46s 363ms/step - loss: 0.1419 - accuracy: 0.9456 - val_loss: 0.1688 - val_accuracy: 0.9412\n",
      "Epoch 150/6000\n",
      "128/128 [==============================] - 48s 375ms/step - loss: 0.1414 - accuracy: 0.9458 - val_loss: 0.1693 - val_accuracy: 0.9414\n",
      "Epoch 151/6000\n",
      "128/128 [==============================] - 47s 370ms/step - loss: 0.1418 - accuracy: 0.9449 - val_loss: 0.1680 - val_accuracy: 0.9433\n",
      "Epoch 152/6000\n",
      "128/128 [==============================] - 47s 371ms/step - loss: 0.1381 - accuracy: 0.9470 - val_loss: 0.1665 - val_accuracy: 0.9439\n",
      "Epoch 153/6000\n",
      "128/128 [==============================] - 47s 369ms/step - loss: 0.1395 - accuracy: 0.9465 - val_loss: 0.1793 - val_accuracy: 0.9395\n",
      "Epoch 154/6000\n",
      "128/128 [==============================] - 47s 367ms/step - loss: 0.1430 - accuracy: 0.9455 - val_loss: 0.1636 - val_accuracy: 0.9446\n",
      "Epoch 155/6000\n",
      "128/128 [==============================] - 48s 372ms/step - loss: 0.1393 - accuracy: 0.9466 - val_loss: 0.1726 - val_accuracy: 0.9412\n",
      "Epoch 156/6000\n",
      "128/128 [==============================] - 47s 364ms/step - loss: 0.1380 - accuracy: 0.9472 - val_loss: 0.1661 - val_accuracy: 0.9435\n",
      "Epoch 157/6000\n",
      "128/128 [==============================] - 48s 376ms/step - loss: 0.1378 - accuracy: 0.9472 - val_loss: 0.1637 - val_accuracy: 0.9453\n",
      "Epoch 158/6000\n",
      "128/128 [==============================] - 47s 368ms/step - loss: 0.1380 - accuracy: 0.9479 - val_loss: 0.1594 - val_accuracy: 0.9455\n",
      "Epoch 159/6000\n",
      "128/128 [==============================] - 49s 383ms/step - loss: 0.1362 - accuracy: 0.9481 - val_loss: 0.1577 - val_accuracy: 0.9461\n",
      "Epoch 160/6000\n",
      "128/128 [==============================] - 47s 365ms/step - loss: 0.1357 - accuracy: 0.9480 - val_loss: 0.1630 - val_accuracy: 0.9452\n",
      "Epoch 161/6000\n",
      "128/128 [==============================] - 47s 368ms/step - loss: 0.1352 - accuracy: 0.9484 - val_loss: 0.1675 - val_accuracy: 0.9433\n",
      "Epoch 162/6000\n",
      "128/128 [==============================] - 47s 365ms/step - loss: 0.1378 - accuracy: 0.9472 - val_loss: 0.1637 - val_accuracy: 0.9452\n",
      "Epoch 163/6000\n",
      "128/128 [==============================] - 47s 367ms/step - loss: 0.1355 - accuracy: 0.9479 - val_loss: 0.1656 - val_accuracy: 0.9433\n",
      "Epoch 164/6000\n",
      "128/128 [==============================] - 47s 370ms/step - loss: 0.1348 - accuracy: 0.9482 - val_loss: 0.1592 - val_accuracy: 0.9468\n",
      "Epoch 165/6000\n",
      "128/128 [==============================] - 47s 370ms/step - loss: 0.1358 - accuracy: 0.9482 - val_loss: 0.1638 - val_accuracy: 0.9444\n",
      "Epoch 166/6000\n",
      "128/128 [==============================] - 47s 371ms/step - loss: 0.1334 - accuracy: 0.9492 - val_loss: 0.1649 - val_accuracy: 0.9441\n",
      "Epoch 167/6000\n",
      "128/128 [==============================] - 47s 365ms/step - loss: 0.1323 - accuracy: 0.9495 - val_loss: 0.1529 - val_accuracy: 0.9485\n",
      "Epoch 168/6000\n",
      "128/128 [==============================] - 48s 377ms/step - loss: 0.1338 - accuracy: 0.9489 - val_loss: 0.1596 - val_accuracy: 0.9465\n",
      "Epoch 169/6000\n",
      "128/128 [==============================] - 47s 366ms/step - loss: 0.1359 - accuracy: 0.9482 - val_loss: 0.1592 - val_accuracy: 0.9461\n",
      "Epoch 170/6000\n",
      "128/128 [==============================] - 47s 371ms/step - loss: 0.1316 - accuracy: 0.9499 - val_loss: 0.1588 - val_accuracy: 0.9463\n",
      "Epoch 171/6000\n",
      "128/128 [==============================] - 47s 365ms/step - loss: 0.1317 - accuracy: 0.9501 - val_loss: 0.1651 - val_accuracy: 0.9445\n",
      "Epoch 172/6000\n",
      "128/128 [==============================] - 51s 397ms/step - loss: 0.1329 - accuracy: 0.9491 - val_loss: 0.1670 - val_accuracy: 0.9444\n",
      "Epoch 173/6000\n",
      "128/128 [==============================] - 48s 372ms/step - loss: 0.1296 - accuracy: 0.9506 - val_loss: 0.1610 - val_accuracy: 0.9468\n",
      "Epoch 174/6000\n",
      "128/128 [==============================] - 47s 366ms/step - loss: 0.1317 - accuracy: 0.9497 - val_loss: 0.1613 - val_accuracy: 0.9462\n",
      "Epoch 175/6000\n",
      "128/128 [==============================] - 48s 372ms/step - loss: 0.1296 - accuracy: 0.9509 - val_loss: 0.1629 - val_accuracy: 0.9451\n",
      "Epoch 176/6000\n",
      "128/128 [==============================] - 48s 371ms/step - loss: 0.1301 - accuracy: 0.9502 - val_loss: 0.1648 - val_accuracy: 0.9452\n",
      "Epoch 177/6000\n",
      "128/128 [==============================] - 47s 369ms/step - loss: 0.1290 - accuracy: 0.9511 - val_loss: 0.1562 - val_accuracy: 0.9483\n",
      "Epoch 178/6000\n",
      "128/128 [==============================] - 47s 368ms/step - loss: 0.1294 - accuracy: 0.9504 - val_loss: 0.1622 - val_accuracy: 0.9456\n",
      "Epoch 179/6000\n",
      "128/128 [==============================] - 47s 371ms/step - loss: 0.1282 - accuracy: 0.9513 - val_loss: 0.1582 - val_accuracy: 0.9476\n",
      "Epoch 180/6000\n",
      "128/128 [==============================] - 47s 367ms/step - loss: 0.1270 - accuracy: 0.9517 - val_loss: 0.1591 - val_accuracy: 0.9479\n",
      "Epoch 181/6000\n",
      "128/128 [==============================] - 48s 372ms/step - loss: 0.1282 - accuracy: 0.9510 - val_loss: 0.1680 - val_accuracy: 0.9450\n",
      "Epoch 182/6000\n",
      "128/128 [==============================] - 47s 371ms/step - loss: 0.1280 - accuracy: 0.9515 - val_loss: 0.1555 - val_accuracy: 0.9486\n",
      "Epoch 183/6000\n",
      "128/128 [==============================] - 48s 373ms/step - loss: 0.1271 - accuracy: 0.9518 - val_loss: 0.1641 - val_accuracy: 0.9438\n",
      "Epoch 184/6000\n",
      "128/128 [==============================] - 48s 374ms/step - loss: 0.1263 - accuracy: 0.9520 - val_loss: 0.1611 - val_accuracy: 0.9467\n",
      "Epoch 185/6000\n",
      "128/128 [==============================] - 48s 377ms/step - loss: 0.1263 - accuracy: 0.9524 - val_loss: 0.1524 - val_accuracy: 0.9495\n",
      "Epoch 186/6000\n",
      "128/128 [==============================] - 47s 369ms/step - loss: 0.1265 - accuracy: 0.9516 - val_loss: 0.1551 - val_accuracy: 0.9473\n",
      "Epoch 187/6000\n",
      "128/128 [==============================] - 47s 365ms/step - loss: 0.1253 - accuracy: 0.9523 - val_loss: 0.1598 - val_accuracy: 0.9474\n",
      "Epoch 188/6000\n",
      "128/128 [==============================] - 47s 370ms/step - loss: 0.1243 - accuracy: 0.9526 - val_loss: 0.1588 - val_accuracy: 0.9481\n",
      "Epoch 189/6000\n",
      "128/128 [==============================] - 47s 368ms/step - loss: 0.1242 - accuracy: 0.9531 - val_loss: 0.1552 - val_accuracy: 0.9489\n",
      "Epoch 190/6000\n",
      "128/128 [==============================] - 48s 372ms/step - loss: 0.1242 - accuracy: 0.9531 - val_loss: 0.1558 - val_accuracy: 0.9483\n",
      "Epoch 191/6000\n",
      "128/128 [==============================] - 47s 370ms/step - loss: 0.1238 - accuracy: 0.9531 - val_loss: 0.1561 - val_accuracy: 0.9485\n",
      "Epoch 192/6000\n",
      "128/128 [==============================] - 48s 372ms/step - loss: 0.1229 - accuracy: 0.9537 - val_loss: 0.1570 - val_accuracy: 0.9483\n",
      "Epoch 193/6000\n",
      "128/128 [==============================] - 47s 365ms/step - loss: 0.1228 - accuracy: 0.9539 - val_loss: 0.1557 - val_accuracy: 0.9486\n",
      "Epoch 194/6000\n",
      "128/128 [==============================] - 48s 373ms/step - loss: 0.1226 - accuracy: 0.9538 - val_loss: 0.1559 - val_accuracy: 0.9498\n",
      "Epoch 195/6000\n",
      "128/128 [==============================] - 47s 366ms/step - loss: 0.1211 - accuracy: 0.9544 - val_loss: 0.1564 - val_accuracy: 0.9489\n",
      "Epoch 196/6000\n",
      "128/128 [==============================] - 47s 368ms/step - loss: 0.1223 - accuracy: 0.9536 - val_loss: 0.1579 - val_accuracy: 0.9481\n",
      "Epoch 197/6000\n",
      "128/128 [==============================] - 48s 378ms/step - loss: 0.1209 - accuracy: 0.9543 - val_loss: 0.1564 - val_accuracy: 0.9482\n",
      "Epoch 198/6000\n",
      "128/128 [==============================] - 47s 370ms/step - loss: 0.1230 - accuracy: 0.9532 - val_loss: 0.1541 - val_accuracy: 0.9500\n",
      "Epoch 199/6000\n",
      "128/128 [==============================] - 47s 370ms/step - loss: 0.1188 - accuracy: 0.9552 - val_loss: 0.1553 - val_accuracy: 0.9492\n",
      "Epoch 200/6000\n",
      "128/128 [==============================] - 47s 369ms/step - loss: 0.1199 - accuracy: 0.9548 - val_loss: 0.1572 - val_accuracy: 0.9491\n",
      "Epoch 201/6000\n",
      "128/128 [==============================] - 47s 369ms/step - loss: 0.1209 - accuracy: 0.9545 - val_loss: 0.1584 - val_accuracy: 0.9485\n",
      "Epoch 202/6000\n",
      "128/128 [==============================] - 47s 371ms/step - loss: 0.1199 - accuracy: 0.9545 - val_loss: 0.1542 - val_accuracy: 0.9500\n",
      "Epoch 203/6000\n",
      "128/128 [==============================] - 48s 374ms/step - loss: 0.1206 - accuracy: 0.9545 - val_loss: 0.1509 - val_accuracy: 0.9501\n",
      "Epoch 204/6000\n",
      "128/128 [==============================] - 47s 366ms/step - loss: 0.1194 - accuracy: 0.9547 - val_loss: 0.1604 - val_accuracy: 0.9465\n",
      "Epoch 205/6000\n",
      "128/128 [==============================] - 49s 381ms/step - loss: 0.1167 - accuracy: 0.9563 - val_loss: 0.1520 - val_accuracy: 0.9510\n",
      "Epoch 206/6000\n",
      "128/128 [==============================] - 48s 373ms/step - loss: 0.1178 - accuracy: 0.9556 - val_loss: 0.1543 - val_accuracy: 0.9497\n",
      "Epoch 207/6000\n",
      "128/128 [==============================] - 47s 370ms/step - loss: 0.1170 - accuracy: 0.9558 - val_loss: 0.1598 - val_accuracy: 0.9474\n",
      "Epoch 208/6000\n",
      "128/128 [==============================] - 47s 369ms/step - loss: 0.1188 - accuracy: 0.9553 - val_loss: 0.1543 - val_accuracy: 0.9505\n",
      "Epoch 209/6000\n",
      "128/128 [==============================] - 48s 377ms/step - loss: 0.1173 - accuracy: 0.9559 - val_loss: 0.1526 - val_accuracy: 0.9514\n",
      "Epoch 210/6000\n",
      "128/128 [==============================] - 49s 381ms/step - loss: 0.1170 - accuracy: 0.9560 - val_loss: 0.1539 - val_accuracy: 0.9506\n",
      "Epoch 211/6000\n",
      "128/128 [==============================] - 48s 372ms/step - loss: 0.1158 - accuracy: 0.9568 - val_loss: 0.1538 - val_accuracy: 0.9496\n",
      "Epoch 212/6000\n",
      "128/128 [==============================] - 47s 368ms/step - loss: 0.1166 - accuracy: 0.9558 - val_loss: 0.1524 - val_accuracy: 0.9512\n",
      "Epoch 213/6000\n",
      "128/128 [==============================] - 47s 370ms/step - loss: 0.1152 - accuracy: 0.9567 - val_loss: 0.1541 - val_accuracy: 0.9509\n",
      "Epoch 214/6000\n",
      "128/128 [==============================] - 47s 367ms/step - loss: 0.1155 - accuracy: 0.9565 - val_loss: 0.1540 - val_accuracy: 0.9502\n",
      "Epoch 215/6000\n",
      "128/128 [==============================] - 48s 373ms/step - loss: 0.1151 - accuracy: 0.9566 - val_loss: 0.1609 - val_accuracy: 0.9485\n",
      "Epoch 216/6000\n",
      "128/128 [==============================] - 48s 372ms/step - loss: 0.1148 - accuracy: 0.9567 - val_loss: 0.1520 - val_accuracy: 0.9506\n",
      "Epoch 217/6000\n",
      "128/128 [==============================] - 48s 375ms/step - loss: 0.1152 - accuracy: 0.9567 - val_loss: 0.1566 - val_accuracy: 0.9498\n",
      "Epoch 218/6000\n",
      "128/128 [==============================] - 47s 366ms/step - loss: 0.1170 - accuracy: 0.9561 - val_loss: 0.1500 - val_accuracy: 0.9510\n",
      "Epoch 219/6000\n",
      "128/128 [==============================] - 49s 380ms/step - loss: 0.1145 - accuracy: 0.9570 - val_loss: 0.1538 - val_accuracy: 0.9505\n",
      "Epoch 220/6000\n",
      "128/128 [==============================] - 47s 368ms/step - loss: 0.1144 - accuracy: 0.9572 - val_loss: 0.1566 - val_accuracy: 0.9494\n",
      "Epoch 221/6000\n",
      "128/128 [==============================] - 48s 377ms/step - loss: 0.1153 - accuracy: 0.9566 - val_loss: 0.1511 - val_accuracy: 0.9506\n",
      "Epoch 222/6000\n",
      "128/128 [==============================] - 48s 373ms/step - loss: 0.1128 - accuracy: 0.9578 - val_loss: 0.1559 - val_accuracy: 0.9499\n",
      "Epoch 223/6000\n",
      "128/128 [==============================] - 48s 376ms/step - loss: 0.1117 - accuracy: 0.9582 - val_loss: 0.1504 - val_accuracy: 0.9511\n",
      "Epoch 224/6000\n",
      "128/128 [==============================] - 48s 372ms/step - loss: 0.1117 - accuracy: 0.9580 - val_loss: 0.1622 - val_accuracy: 0.9484\n",
      "Epoch 224: early stopping\n",
      "##########################################################################\n",
      "------val_accuracy-----> 95.14 | 95.82 <----------accuracy----------\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/GALA-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/GALA-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "working on pair: SHIB/USDT\n",
      "One_pair_AI_Gen : SHIB/USDT\n",
      "price_volatility_15m:0.43%\n",
      "mini_expand : SHIB/USDT\n",
      "---buy_simple_up--- Buy pct: 0.5%\n",
      "---buy_only--- Max time window: 10%\n",
      "---buy_only--- no b\n",
      "---buy_only--- no sell\n",
      "df original shape (407577, 1607)\n",
      "df original shape buy mean : 9.340566322437233\n",
      "df choosen data shape(407576, 1607)\n",
      "pair: True\n",
      "81515\n",
      "normalizing ...\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/SHIB-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_76 (Dense)            (None, 250)               401750    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 250)               0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 20)                5020      \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,871\n",
      "Trainable params: 407,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_UP_CLOSE/SHIB-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "Epoch 1/6000\n",
      "128/128 [==============================] - 26s 161ms/step - loss: 0.5512 - accuracy: 0.7176 - val_loss: 0.5219 - val_accuracy: 0.7384\n",
      "Epoch 2/6000\n",
      "128/128 [==============================] - 17s 131ms/step - loss: 0.5040 - accuracy: 0.7525 - val_loss: 0.4775 - val_accuracy: 0.7724\n",
      "Epoch 3/6000\n",
      "128/128 [==============================] - 16s 128ms/step - loss: 0.4669 - accuracy: 0.7780 - val_loss: 0.4413 - val_accuracy: 0.7944\n",
      "Epoch 4/6000\n",
      "128/128 [==============================] - 16s 127ms/step - loss: 0.4320 - accuracy: 0.7990 - val_loss: 0.3967 - val_accuracy: 0.8236\n",
      "Epoch 5/6000\n",
      "128/128 [==============================] - 16s 128ms/step - loss: 0.4032 - accuracy: 0.8173 - val_loss: 0.3799 - val_accuracy: 0.8295\n",
      "Epoch 6/6000\n",
      "128/128 [==============================] - 16s 125ms/step - loss: 0.3768 - accuracy: 0.8318 - val_loss: 0.3494 - val_accuracy: 0.8503\n",
      "Epoch 7/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.3571 - accuracy: 0.8440 - val_loss: 0.3292 - val_accuracy: 0.8604\n",
      "Epoch 8/6000\n",
      "128/128 [==============================] - 16s 127ms/step - loss: 0.3406 - accuracy: 0.8521 - val_loss: 0.3095 - val_accuracy: 0.8706\n",
      "Epoch 9/6000\n",
      "128/128 [==============================] - 21s 168ms/step - loss: 0.3260 - accuracy: 0.8599 - val_loss: 0.3026 - val_accuracy: 0.8730\n",
      "Epoch 10/6000\n",
      "128/128 [==============================] - 16s 127ms/step - loss: 0.3129 - accuracy: 0.8663 - val_loss: 0.2898 - val_accuracy: 0.8795\n",
      "Epoch 11/6000\n",
      "128/128 [==============================] - 20s 158ms/step - loss: 0.3008 - accuracy: 0.8730 - val_loss: 0.2759 - val_accuracy: 0.8870\n",
      "Epoch 12/6000\n",
      "128/128 [==============================] - 22s 169ms/step - loss: 0.2939 - accuracy: 0.8764 - val_loss: 0.2658 - val_accuracy: 0.8918\n",
      "Epoch 13/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.2834 - accuracy: 0.8821 - val_loss: 0.2623 - val_accuracy: 0.8935\n",
      "Epoch 14/6000\n",
      "128/128 [==============================] - 21s 167ms/step - loss: 0.2763 - accuracy: 0.8853 - val_loss: 0.2515 - val_accuracy: 0.8998\n",
      "Epoch 15/6000\n",
      "128/128 [==============================] - 16s 126ms/step - loss: 0.2675 - accuracy: 0.8894 - val_loss: 0.2465 - val_accuracy: 0.9015\n",
      "Epoch 16/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.2614 - accuracy: 0.8930 - val_loss: 0.2357 - val_accuracy: 0.9062\n",
      "Epoch 17/6000\n",
      "128/128 [==============================] - 20s 160ms/step - loss: 0.2570 - accuracy: 0.8947 - val_loss: 0.2333 - val_accuracy: 0.9083\n",
      "Epoch 18/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.2502 - accuracy: 0.8980 - val_loss: 0.2295 - val_accuracy: 0.9105\n",
      "Epoch 19/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.2452 - accuracy: 0.9004 - val_loss: 0.2273 - val_accuracy: 0.9107\n",
      "Epoch 20/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.2403 - accuracy: 0.9025 - val_loss: 0.2172 - val_accuracy: 0.9157\n",
      "Epoch 21/6000\n",
      "128/128 [==============================] - 16s 127ms/step - loss: 0.2348 - accuracy: 0.9048 - val_loss: 0.2179 - val_accuracy: 0.9152\n",
      "Epoch 22/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.2327 - accuracy: 0.9062 - val_loss: 0.2195 - val_accuracy: 0.9131\n",
      "Epoch 23/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.2283 - accuracy: 0.9084 - val_loss: 0.2101 - val_accuracy: 0.9173\n",
      "Epoch 24/6000\n",
      "128/128 [==============================] - 19s 152ms/step - loss: 0.2233 - accuracy: 0.9104 - val_loss: 0.2057 - val_accuracy: 0.9199\n",
      "Epoch 25/6000\n",
      "128/128 [==============================] - 19s 146ms/step - loss: 0.2197 - accuracy: 0.9121 - val_loss: 0.1969 - val_accuracy: 0.9245\n",
      "Epoch 26/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.2157 - accuracy: 0.9140 - val_loss: 0.1960 - val_accuracy: 0.9245\n",
      "Epoch 27/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.2121 - accuracy: 0.9157 - val_loss: 0.1921 - val_accuracy: 0.9269\n",
      "Epoch 28/6000\n",
      "128/128 [==============================] - 16s 126ms/step - loss: 0.2099 - accuracy: 0.9166 - val_loss: 0.1908 - val_accuracy: 0.9275\n",
      "Epoch 29/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.2055 - accuracy: 0.9182 - val_loss: 0.1881 - val_accuracy: 0.9290\n",
      "Epoch 30/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.2045 - accuracy: 0.9192 - val_loss: 0.1895 - val_accuracy: 0.9276\n",
      "Epoch 31/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.2020 - accuracy: 0.9201 - val_loss: 0.1825 - val_accuracy: 0.9304\n",
      "Epoch 32/6000\n",
      "128/128 [==============================] - 16s 124ms/step - loss: 0.1980 - accuracy: 0.9221 - val_loss: 0.1821 - val_accuracy: 0.9312\n",
      "Epoch 33/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.1964 - accuracy: 0.9233 - val_loss: 0.1822 - val_accuracy: 0.9312\n",
      "Epoch 34/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.1925 - accuracy: 0.9246 - val_loss: 0.1769 - val_accuracy: 0.9340\n",
      "Epoch 35/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.1902 - accuracy: 0.9253 - val_loss: 0.1870 - val_accuracy: 0.9291\n",
      "Epoch 36/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.1874 - accuracy: 0.9267 - val_loss: 0.1775 - val_accuracy: 0.9339\n",
      "Epoch 37/6000\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 0.1852 - accuracy: 0.9275 - val_loss: 0.1722 - val_accuracy: 0.9360\n",
      "Epoch 38/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.1848 - accuracy: 0.9281 - val_loss: 0.1669 - val_accuracy: 0.9381\n",
      "Epoch 39/6000\n",
      "128/128 [==============================] - 21s 168ms/step - loss: 0.1818 - accuracy: 0.9291 - val_loss: 0.1697 - val_accuracy: 0.9374\n",
      "Epoch 40/6000\n",
      "128/128 [==============================] - 20s 159ms/step - loss: 0.1784 - accuracy: 0.9307 - val_loss: 0.1705 - val_accuracy: 0.9366\n",
      "Epoch 41/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.1780 - accuracy: 0.9311 - val_loss: 0.1707 - val_accuracy: 0.9367\n",
      "Epoch 42/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1762 - accuracy: 0.9314 - val_loss: 0.1627 - val_accuracy: 0.9400\n",
      "Epoch 43/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.1734 - accuracy: 0.9330 - val_loss: 0.1654 - val_accuracy: 0.9395\n",
      "Epoch 44/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.1721 - accuracy: 0.9338 - val_loss: 0.1657 - val_accuracy: 0.9377\n",
      "Epoch 45/6000\n",
      "128/128 [==============================] - 18s 137ms/step - loss: 0.1698 - accuracy: 0.9344 - val_loss: 0.1605 - val_accuracy: 0.9409\n",
      "Epoch 46/6000\n",
      "128/128 [==============================] - 21s 161ms/step - loss: 0.1699 - accuracy: 0.9347 - val_loss: 0.1613 - val_accuracy: 0.9415\n",
      "Epoch 47/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.1667 - accuracy: 0.9361 - val_loss: 0.1528 - val_accuracy: 0.9452\n",
      "Epoch 48/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1640 - accuracy: 0.9374 - val_loss: 0.1565 - val_accuracy: 0.9436\n",
      "Epoch 49/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1628 - accuracy: 0.9378 - val_loss: 0.1646 - val_accuracy: 0.9398\n",
      "Epoch 50/6000\n",
      "128/128 [==============================] - 16s 126ms/step - loss: 0.1604 - accuracy: 0.9384 - val_loss: 0.1533 - val_accuracy: 0.9445\n",
      "Epoch 51/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1615 - accuracy: 0.9386 - val_loss: 0.1555 - val_accuracy: 0.9436\n",
      "Epoch 52/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.1597 - accuracy: 0.9388 - val_loss: 0.1520 - val_accuracy: 0.9449\n",
      "Epoch 53/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.1550 - accuracy: 0.9410 - val_loss: 0.1518 - val_accuracy: 0.9453\n",
      "Epoch 54/6000\n",
      "128/128 [==============================] - 16s 126ms/step - loss: 0.1552 - accuracy: 0.9409 - val_loss: 0.1510 - val_accuracy: 0.9464\n",
      "Epoch 55/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1545 - accuracy: 0.9410 - val_loss: 0.1545 - val_accuracy: 0.9441\n",
      "Epoch 56/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.1516 - accuracy: 0.9421 - val_loss: 0.1439 - val_accuracy: 0.9491\n",
      "Epoch 57/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.1526 - accuracy: 0.9421 - val_loss: 0.1444 - val_accuracy: 0.9482\n",
      "Epoch 58/6000\n",
      "128/128 [==============================] - 19s 151ms/step - loss: 0.1503 - accuracy: 0.9428 - val_loss: 0.1435 - val_accuracy: 0.9493\n",
      "Epoch 59/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.1474 - accuracy: 0.9444 - val_loss: 0.1468 - val_accuracy: 0.9471\n",
      "Epoch 60/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1486 - accuracy: 0.9439 - val_loss: 0.1431 - val_accuracy: 0.9495\n",
      "Epoch 61/6000\n",
      "128/128 [==============================] - 17s 132ms/step - loss: 0.1446 - accuracy: 0.9454 - val_loss: 0.1405 - val_accuracy: 0.9510\n",
      "Epoch 62/6000\n",
      "128/128 [==============================] - 21s 165ms/step - loss: 0.1455 - accuracy: 0.9449 - val_loss: 0.1434 - val_accuracy: 0.9490\n",
      "Epoch 63/6000\n",
      "128/128 [==============================] - 21s 167ms/step - loss: 0.1445 - accuracy: 0.9457 - val_loss: 0.1431 - val_accuracy: 0.9495\n",
      "Epoch 64/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1436 - accuracy: 0.9456 - val_loss: 0.1460 - val_accuracy: 0.9479\n",
      "Epoch 65/6000\n",
      "128/128 [==============================] - 16s 126ms/step - loss: 0.1415 - accuracy: 0.9465 - val_loss: 0.1414 - val_accuracy: 0.9502\n",
      "Epoch 66/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1414 - accuracy: 0.9468 - val_loss: 0.1350 - val_accuracy: 0.9539\n",
      "Epoch 67/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1391 - accuracy: 0.9478 - val_loss: 0.1527 - val_accuracy: 0.9459\n",
      "Epoch 68/6000\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 0.1403 - accuracy: 0.9473 - val_loss: 0.1357 - val_accuracy: 0.9531\n",
      "Epoch 69/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.1386 - accuracy: 0.9478 - val_loss: 0.1325 - val_accuracy: 0.9547\n",
      "Epoch 70/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1355 - accuracy: 0.9492 - val_loss: 0.1399 - val_accuracy: 0.9508\n",
      "Epoch 71/6000\n",
      "128/128 [==============================] - 21s 161ms/step - loss: 0.1364 - accuracy: 0.9488 - val_loss: 0.1316 - val_accuracy: 0.9543\n",
      "Epoch 72/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1338 - accuracy: 0.9496 - val_loss: 0.1321 - val_accuracy: 0.9531\n",
      "Epoch 73/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1330 - accuracy: 0.9502 - val_loss: 0.1379 - val_accuracy: 0.9519\n",
      "Epoch 74/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.1334 - accuracy: 0.9501 - val_loss: 0.1321 - val_accuracy: 0.9555\n",
      "Epoch 75/6000\n",
      "128/128 [==============================] - 16s 126ms/step - loss: 0.1317 - accuracy: 0.9510 - val_loss: 0.1325 - val_accuracy: 0.9542\n",
      "Epoch 76/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.1298 - accuracy: 0.9513 - val_loss: 0.1303 - val_accuracy: 0.9552\n",
      "Epoch 77/6000\n",
      "128/128 [==============================] - 21s 161ms/step - loss: 0.1305 - accuracy: 0.9517 - val_loss: 0.1352 - val_accuracy: 0.9523\n",
      "Epoch 78/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1279 - accuracy: 0.9522 - val_loss: 0.1353 - val_accuracy: 0.9528\n",
      "Epoch 79/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.1282 - accuracy: 0.9519 - val_loss: 0.1329 - val_accuracy: 0.9546\n",
      "Epoch 80/6000\n",
      "128/128 [==============================] - 18s 136ms/step - loss: 0.1270 - accuracy: 0.9527 - val_loss: 0.1275 - val_accuracy: 0.9577\n",
      "Epoch 81/6000\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 0.1256 - accuracy: 0.9533 - val_loss: 0.1295 - val_accuracy: 0.9553\n",
      "Epoch 82/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1262 - accuracy: 0.9531 - val_loss: 0.1308 - val_accuracy: 0.9560\n",
      "Epoch 83/6000\n",
      "128/128 [==============================] - 22s 169ms/step - loss: 0.1242 - accuracy: 0.9543 - val_loss: 0.1238 - val_accuracy: 0.9582\n",
      "Epoch 84/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1224 - accuracy: 0.9540 - val_loss: 0.1243 - val_accuracy: 0.9580\n",
      "Epoch 85/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1227 - accuracy: 0.9543 - val_loss: 0.1264 - val_accuracy: 0.9576\n",
      "Epoch 86/6000\n",
      "128/128 [==============================] - 19s 145ms/step - loss: 0.1225 - accuracy: 0.9541 - val_loss: 0.1329 - val_accuracy: 0.9549\n",
      "Epoch 87/6000\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 0.1211 - accuracy: 0.9549 - val_loss: 0.1247 - val_accuracy: 0.9584\n",
      "Epoch 88/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.1197 - accuracy: 0.9557 - val_loss: 0.1218 - val_accuracy: 0.9593\n",
      "Epoch 89/6000\n",
      "128/128 [==============================] - 16s 127ms/step - loss: 0.1197 - accuracy: 0.9558 - val_loss: 0.1280 - val_accuracy: 0.9563\n",
      "Epoch 90/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1193 - accuracy: 0.9561 - val_loss: 0.1252 - val_accuracy: 0.9578\n",
      "Epoch 91/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1171 - accuracy: 0.9569 - val_loss: 0.1263 - val_accuracy: 0.9586\n",
      "Epoch 92/6000\n",
      "128/128 [==============================] - 19s 148ms/step - loss: 0.1165 - accuracy: 0.9569 - val_loss: 0.1230 - val_accuracy: 0.9591\n",
      "Epoch 93/6000\n",
      "128/128 [==============================] - 20s 158ms/step - loss: 0.1162 - accuracy: 0.9572 - val_loss: 0.1242 - val_accuracy: 0.9588\n",
      "Epoch 94/6000\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 0.1155 - accuracy: 0.9574 - val_loss: 0.1272 - val_accuracy: 0.9574\n",
      "Epoch 95/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.1148 - accuracy: 0.9580 - val_loss: 0.1220 - val_accuracy: 0.9591\n",
      "Epoch 96/6000\n",
      "128/128 [==============================] - 19s 151ms/step - loss: 0.1143 - accuracy: 0.9579 - val_loss: 0.1237 - val_accuracy: 0.9587\n",
      "Epoch 97/6000\n",
      "128/128 [==============================] - 21s 161ms/step - loss: 0.1132 - accuracy: 0.9587 - val_loss: 0.1181 - val_accuracy: 0.9612\n",
      "Epoch 98/6000\n",
      "128/128 [==============================] - 21s 160ms/step - loss: 0.1120 - accuracy: 0.9585 - val_loss: 0.1232 - val_accuracy: 0.9597\n",
      "Epoch 99/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1135 - accuracy: 0.9581 - val_loss: 0.1173 - val_accuracy: 0.9607\n",
      "Epoch 100/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.1117 - accuracy: 0.9591 - val_loss: 0.1278 - val_accuracy: 0.9579\n",
      "Epoch 101/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.1115 - accuracy: 0.9589 - val_loss: 0.1197 - val_accuracy: 0.9604\n",
      "Epoch 102/6000\n",
      "128/128 [==============================] - 20s 153ms/step - loss: 0.1096 - accuracy: 0.9596 - val_loss: 0.1195 - val_accuracy: 0.9605\n",
      "Epoch 103/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.1090 - accuracy: 0.9596 - val_loss: 0.1146 - val_accuracy: 0.9622\n",
      "Epoch 104/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.1084 - accuracy: 0.9605 - val_loss: 0.1182 - val_accuracy: 0.9607\n",
      "Epoch 105/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1075 - accuracy: 0.9607 - val_loss: 0.1181 - val_accuracy: 0.9615\n",
      "Epoch 106/6000\n",
      "128/128 [==============================] - 16s 124ms/step - loss: 0.1097 - accuracy: 0.9595 - val_loss: 0.1170 - val_accuracy: 0.9612\n",
      "Epoch 107/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1080 - accuracy: 0.9603 - val_loss: 0.1151 - val_accuracy: 0.9623\n",
      "Epoch 108/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.1056 - accuracy: 0.9614 - val_loss: 0.1116 - val_accuracy: 0.9634\n",
      "Epoch 109/6000\n",
      "128/128 [==============================] - 20s 157ms/step - loss: 0.1057 - accuracy: 0.9612 - val_loss: 0.1107 - val_accuracy: 0.9642\n",
      "Epoch 110/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.1058 - accuracy: 0.9613 - val_loss: 0.1174 - val_accuracy: 0.9613\n",
      "Epoch 111/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1043 - accuracy: 0.9621 - val_loss: 0.1195 - val_accuracy: 0.9600\n",
      "Epoch 112/6000\n",
      "128/128 [==============================] - 21s 162ms/step - loss: 0.1034 - accuracy: 0.9621 - val_loss: 0.1124 - val_accuracy: 0.9638\n",
      "Epoch 113/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1043 - accuracy: 0.9620 - val_loss: 0.1140 - val_accuracy: 0.9628\n",
      "Epoch 114/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.1012 - accuracy: 0.9635 - val_loss: 0.1144 - val_accuracy: 0.9631\n",
      "Epoch 115/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1023 - accuracy: 0.9630 - val_loss: 0.1188 - val_accuracy: 0.9607\n",
      "Epoch 116/6000\n",
      "128/128 [==============================] - 16s 127ms/step - loss: 0.1026 - accuracy: 0.9623 - val_loss: 0.1135 - val_accuracy: 0.9630\n",
      "Epoch 117/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.1025 - accuracy: 0.9626 - val_loss: 0.1195 - val_accuracy: 0.9618\n",
      "Epoch 118/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1009 - accuracy: 0.9636 - val_loss: 0.1105 - val_accuracy: 0.9640\n",
      "Epoch 119/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.0995 - accuracy: 0.9634 - val_loss: 0.1107 - val_accuracy: 0.9640\n",
      "Epoch 120/6000\n",
      "128/128 [==============================] - 17s 131ms/step - loss: 0.1018 - accuracy: 0.9629 - val_loss: 0.1242 - val_accuracy: 0.9592\n",
      "Epoch 121/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.0992 - accuracy: 0.9639 - val_loss: 0.1093 - val_accuracy: 0.9643\n",
      "Epoch 122/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.0990 - accuracy: 0.9640 - val_loss: 0.1237 - val_accuracy: 0.9591\n",
      "Epoch 123/6000\n",
      "128/128 [==============================] - 21s 167ms/step - loss: 0.0972 - accuracy: 0.9646 - val_loss: 0.1088 - val_accuracy: 0.9650\n",
      "Epoch 124/6000\n",
      "128/128 [==============================] - 20s 159ms/step - loss: 0.0966 - accuracy: 0.9648 - val_loss: 0.1085 - val_accuracy: 0.9643\n",
      "Epoch 125/6000\n",
      "128/128 [==============================] - 19s 147ms/step - loss: 0.0962 - accuracy: 0.9651 - val_loss: 0.1175 - val_accuracy: 0.9620\n",
      "Epoch 126/6000\n",
      "128/128 [==============================] - 21s 168ms/step - loss: 0.0969 - accuracy: 0.9649 - val_loss: 0.1154 - val_accuracy: 0.9632\n",
      "Epoch 127/6000\n",
      "128/128 [==============================] - 23s 184ms/step - loss: 0.0965 - accuracy: 0.9649 - val_loss: 0.1106 - val_accuracy: 0.9642\n",
      "Epoch 128/6000\n",
      "128/128 [==============================] - 17s 131ms/step - loss: 0.0960 - accuracy: 0.9652 - val_loss: 0.1081 - val_accuracy: 0.9661\n",
      "Epoch 129/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.0958 - accuracy: 0.9650 - val_loss: 0.1124 - val_accuracy: 0.9638\n",
      "Epoch 130/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.0948 - accuracy: 0.9653 - val_loss: 0.1158 - val_accuracy: 0.9625\n",
      "Epoch 131/6000\n",
      "128/128 [==============================] - 21s 167ms/step - loss: 0.0951 - accuracy: 0.9656 - val_loss: 0.1091 - val_accuracy: 0.9650\n",
      "Epoch 132/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.0941 - accuracy: 0.9656 - val_loss: 0.1108 - val_accuracy: 0.9650\n",
      "Epoch 133/6000\n",
      "128/128 [==============================] - 21s 160ms/step - loss: 0.0930 - accuracy: 0.9662 - val_loss: 0.1144 - val_accuracy: 0.9634\n",
      "Epoch 134/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.0936 - accuracy: 0.9663 - val_loss: 0.1086 - val_accuracy: 0.9655\n",
      "Epoch 135/6000\n",
      "128/128 [==============================] - 21s 168ms/step - loss: 0.0931 - accuracy: 0.9667 - val_loss: 0.1124 - val_accuracy: 0.9648\n",
      "Epoch 136/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.0921 - accuracy: 0.9669 - val_loss: 0.1061 - val_accuracy: 0.9660\n",
      "Epoch 137/6000\n",
      "128/128 [==============================] - 16s 128ms/step - loss: 0.0910 - accuracy: 0.9670 - val_loss: 0.1119 - val_accuracy: 0.9641\n",
      "Epoch 138/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.0925 - accuracy: 0.9663 - val_loss: 0.1063 - val_accuracy: 0.9662\n",
      "Epoch 139/6000\n",
      "128/128 [==============================] - 21s 160ms/step - loss: 0.0904 - accuracy: 0.9674 - val_loss: 0.1050 - val_accuracy: 0.9670\n",
      "Epoch 140/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.0898 - accuracy: 0.9677 - val_loss: 0.1067 - val_accuracy: 0.9666\n",
      "Epoch 141/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.0891 - accuracy: 0.9678 - val_loss: 0.1057 - val_accuracy: 0.9670\n",
      "Epoch 142/6000\n",
      "128/128 [==============================] - 19s 152ms/step - loss: 0.0893 - accuracy: 0.9678 - val_loss: 0.1159 - val_accuracy: 0.9639\n",
      "Epoch 143/6000\n",
      "128/128 [==============================] - 20s 155ms/step - loss: 0.0881 - accuracy: 0.9684 - val_loss: 0.1005 - val_accuracy: 0.9682\n",
      "Epoch 144/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.0885 - accuracy: 0.9680 - val_loss: 0.1054 - val_accuracy: 0.9675\n",
      "Epoch 145/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.0867 - accuracy: 0.9686 - val_loss: 0.1072 - val_accuracy: 0.9664\n",
      "Epoch 146/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.0886 - accuracy: 0.9679 - val_loss: 0.1055 - val_accuracy: 0.9666\n",
      "Epoch 147/6000\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 0.0863 - accuracy: 0.9688 - val_loss: 0.1106 - val_accuracy: 0.9655\n",
      "Epoch 148/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.0861 - accuracy: 0.9689 - val_loss: 0.1094 - val_accuracy: 0.9661\n",
      "Epoch 149/6000\n",
      "128/128 [==============================] - 16s 128ms/step - loss: 0.0868 - accuracy: 0.9685 - val_loss: 0.1171 - val_accuracy: 0.9636\n",
      "Epoch 150/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.0855 - accuracy: 0.9691 - val_loss: 0.1038 - val_accuracy: 0.9678\n",
      "Epoch 151/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.0844 - accuracy: 0.9696 - val_loss: 0.1101 - val_accuracy: 0.9657\n",
      "Epoch 152/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.0846 - accuracy: 0.9693 - val_loss: 0.1072 - val_accuracy: 0.9662\n",
      "Epoch 153/6000\n",
      "128/128 [==============================] - 16s 127ms/step - loss: 0.0855 - accuracy: 0.9692 - val_loss: 0.1165 - val_accuracy: 0.9636\n",
      "Epoch 154/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.0838 - accuracy: 0.9698 - val_loss: 0.1091 - val_accuracy: 0.9659\n",
      "Epoch 155/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.0854 - accuracy: 0.9694 - val_loss: 0.1051 - val_accuracy: 0.9672\n",
      "Epoch 156/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.0833 - accuracy: 0.9701 - val_loss: 0.0996 - val_accuracy: 0.9698\n",
      "Epoch 157/6000\n",
      "128/128 [==============================] - 16s 126ms/step - loss: 0.0825 - accuracy: 0.9706 - val_loss: 0.1068 - val_accuracy: 0.9676\n",
      "Epoch 158/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.0840 - accuracy: 0.9699 - val_loss: 0.1123 - val_accuracy: 0.9654\n",
      "Epoch 159/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.0829 - accuracy: 0.9700 - val_loss: 0.1111 - val_accuracy: 0.9653\n",
      "Epoch 160/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.0838 - accuracy: 0.9696 - val_loss: 0.1055 - val_accuracy: 0.9679\n",
      "Epoch 161/6000\n",
      "128/128 [==============================] - 17s 135ms/step - loss: 0.0819 - accuracy: 0.9704 - val_loss: 0.1106 - val_accuracy: 0.9666\n",
      "Epoch 162/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.0829 - accuracy: 0.9702 - val_loss: 0.1073 - val_accuracy: 0.9670\n",
      "Epoch 163/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.0809 - accuracy: 0.9710 - val_loss: 0.1026 - val_accuracy: 0.9685\n",
      "Epoch 164/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.0790 - accuracy: 0.9717 - val_loss: 0.1031 - val_accuracy: 0.9684\n",
      "Epoch 165/6000\n",
      "128/128 [==============================] - 20s 155ms/step - loss: 0.0807 - accuracy: 0.9708 - val_loss: 0.1087 - val_accuracy: 0.9669\n",
      "Epoch 166/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.0803 - accuracy: 0.9712 - val_loss: 0.1021 - val_accuracy: 0.9685\n",
      "Epoch 167/6000\n",
      "128/128 [==============================] - 20s 155ms/step - loss: 0.0806 - accuracy: 0.9709 - val_loss: 0.1106 - val_accuracy: 0.9660\n",
      "Epoch 168/6000\n",
      "128/128 [==============================] - 20s 153ms/step - loss: 0.0787 - accuracy: 0.9718 - val_loss: 0.1015 - val_accuracy: 0.9691\n",
      "Epoch 169/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.0779 - accuracy: 0.9718 - val_loss: 0.1006 - val_accuracy: 0.9698\n",
      "Epoch 170/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.0784 - accuracy: 0.9718 - val_loss: 0.1018 - val_accuracy: 0.9693\n",
      "Epoch 171/6000\n",
      "128/128 [==============================] - 16s 126ms/step - loss: 0.0801 - accuracy: 0.9709 - val_loss: 0.1152 - val_accuracy: 0.9648\n",
      "Epoch 172/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.0780 - accuracy: 0.9720 - val_loss: 0.1007 - val_accuracy: 0.9697\n",
      "Epoch 173/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.0779 - accuracy: 0.9719 - val_loss: 0.1080 - val_accuracy: 0.9670\n",
      "Epoch 174/6000\n",
      "128/128 [==============================] - 19s 149ms/step - loss: 0.0789 - accuracy: 0.9720 - val_loss: 0.0979 - val_accuracy: 0.9703\n",
      "Epoch 175/6000\n",
      "128/128 [==============================] - 21s 167ms/step - loss: 0.0770 - accuracy: 0.9726 - val_loss: 0.0997 - val_accuracy: 0.9702\n",
      "Epoch 176/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.0762 - accuracy: 0.9729 - val_loss: 0.1009 - val_accuracy: 0.9697\n",
      "Epoch 177/6000\n",
      "128/128 [==============================] - 17s 135ms/step - loss: 0.0768 - accuracy: 0.9724 - val_loss: 0.1008 - val_accuracy: 0.9696\n",
      "Epoch 178/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.0756 - accuracy: 0.9731 - val_loss: 0.1039 - val_accuracy: 0.9683\n",
      "Epoch 179/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.0748 - accuracy: 0.9733 - val_loss: 0.1024 - val_accuracy: 0.9683\n",
      "Epoch 180/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.0767 - accuracy: 0.9728 - val_loss: 0.1051 - val_accuracy: 0.9683\n",
      "Epoch 181/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.0766 - accuracy: 0.9727 - val_loss: 0.1009 - val_accuracy: 0.9694\n",
      "Epoch 182/6000\n",
      "128/128 [==============================] - 21s 160ms/step - loss: 0.0757 - accuracy: 0.9729 - val_loss: 0.1137 - val_accuracy: 0.9662\n",
      "Epoch 183/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.0743 - accuracy: 0.9733 - val_loss: 0.0965 - val_accuracy: 0.9713\n",
      "Epoch 184/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.0741 - accuracy: 0.9733 - val_loss: 0.1035 - val_accuracy: 0.9686\n",
      "Epoch 185/6000\n",
      "128/128 [==============================] - 20s 154ms/step - loss: 0.0760 - accuracy: 0.9728 - val_loss: 0.1020 - val_accuracy: 0.9696\n",
      "Epoch 186/6000\n",
      "128/128 [==============================] - 19s 145ms/step - loss: 0.0751 - accuracy: 0.9729 - val_loss: 0.1010 - val_accuracy: 0.9692\n",
      "Epoch 187/6000\n",
      "128/128 [==============================] - 23s 175ms/step - loss: 0.0750 - accuracy: 0.9729 - val_loss: 0.0998 - val_accuracy: 0.9705\n",
      "Epoch 188/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.0721 - accuracy: 0.9744 - val_loss: 0.0976 - val_accuracy: 0.9715\n",
      "Epoch 189/6000\n",
      "128/128 [==============================] - 17s 133ms/step - loss: 0.0724 - accuracy: 0.9744 - val_loss: 0.1071 - val_accuracy: 0.9685\n",
      "Epoch 190/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.0728 - accuracy: 0.9739 - val_loss: 0.1080 - val_accuracy: 0.9676\n",
      "Epoch 191/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.0714 - accuracy: 0.9744 - val_loss: 0.0956 - val_accuracy: 0.9712\n",
      "Epoch 192/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.0726 - accuracy: 0.9740 - val_loss: 0.0958 - val_accuracy: 0.9712\n",
      "Epoch 193/6000\n",
      "128/128 [==============================] - 20s 158ms/step - loss: 0.0724 - accuracy: 0.9738 - val_loss: 0.1004 - val_accuracy: 0.9697\n",
      "Epoch 194/6000\n",
      "128/128 [==============================] - 19s 150ms/step - loss: 0.0707 - accuracy: 0.9748 - val_loss: 0.0947 - val_accuracy: 0.9713\n",
      "Epoch 195/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.0716 - accuracy: 0.9742 - val_loss: 0.0928 - val_accuracy: 0.9716\n",
      "Epoch 196/6000\n",
      "128/128 [==============================] - 22s 169ms/step - loss: 0.0724 - accuracy: 0.9744 - val_loss: 0.1001 - val_accuracy: 0.9709\n",
      "Epoch 197/6000\n",
      "128/128 [==============================] - 20s 160ms/step - loss: 0.0705 - accuracy: 0.9748 - val_loss: 0.0993 - val_accuracy: 0.9707\n",
      "Epoch 198/6000\n",
      "128/128 [==============================] - 19s 144ms/step - loss: 0.0699 - accuracy: 0.9752 - val_loss: 0.0951 - val_accuracy: 0.9719\n",
      "Epoch 199/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.0708 - accuracy: 0.9749 - val_loss: 0.1003 - val_accuracy: 0.9697\n",
      "Epoch 200/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.0703 - accuracy: 0.9752 - val_loss: 0.0930 - val_accuracy: 0.9720\n",
      "Epoch 201/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.0696 - accuracy: 0.9750 - val_loss: 0.1030 - val_accuracy: 0.9695\n",
      "Epoch 202/6000\n",
      "128/128 [==============================] - 18s 143ms/step - loss: 0.0689 - accuracy: 0.9755 - val_loss: 0.1040 - val_accuracy: 0.9692\n",
      "Epoch 203/6000\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 0.0695 - accuracy: 0.9754 - val_loss: 0.1043 - val_accuracy: 0.9696\n",
      "Epoch 204/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.0692 - accuracy: 0.9752 - val_loss: 0.1042 - val_accuracy: 0.9690\n",
      "Epoch 205/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.0696 - accuracy: 0.9753 - val_loss: 0.1068 - val_accuracy: 0.9687\n",
      "Epoch 206/6000\n",
      "128/128 [==============================] - 19s 146ms/step - loss: 0.0672 - accuracy: 0.9762 - val_loss: 0.1001 - val_accuracy: 0.9707\n",
      "Epoch 207/6000\n",
      "128/128 [==============================] - 21s 160ms/step - loss: 0.0678 - accuracy: 0.9760 - val_loss: 0.1076 - val_accuracy: 0.9684\n",
      "Epoch 208/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.0673 - accuracy: 0.9760 - val_loss: 0.1006 - val_accuracy: 0.9702\n",
      "Epoch 209/6000\n",
      "128/128 [==============================] - 22s 169ms/step - loss: 0.0682 - accuracy: 0.9758 - val_loss: 0.1045 - val_accuracy: 0.9695\n",
      "Epoch 210/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.0685 - accuracy: 0.9754 - val_loss: 0.0938 - val_accuracy: 0.9726\n",
      "Epoch 211/6000\n",
      "128/128 [==============================] - 16s 127ms/step - loss: 0.0673 - accuracy: 0.9765 - val_loss: 0.1009 - val_accuracy: 0.9713\n",
      "Epoch 212/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.0690 - accuracy: 0.9756 - val_loss: 0.0924 - val_accuracy: 0.9728\n",
      "Epoch 213/6000\n",
      "128/128 [==============================] - 21s 160ms/step - loss: 0.0676 - accuracy: 0.9760 - val_loss: 0.1025 - val_accuracy: 0.9698\n",
      "Epoch 214/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.0664 - accuracy: 0.9766 - val_loss: 0.0946 - val_accuracy: 0.9719\n",
      "Epoch 215/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.0670 - accuracy: 0.9761 - val_loss: 0.0985 - val_accuracy: 0.9711\n",
      "Epoch 216/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.0666 - accuracy: 0.9764 - val_loss: 0.0995 - val_accuracy: 0.9704\n",
      "Epoch 217/6000\n",
      "128/128 [==============================] - 22s 169ms/step - loss: 0.0662 - accuracy: 0.9764 - val_loss: 0.0947 - val_accuracy: 0.9720\n",
      "Epoch 218/6000\n",
      "128/128 [==============================] - 19s 149ms/step - loss: 0.0659 - accuracy: 0.9766 - val_loss: 0.1030 - val_accuracy: 0.9703\n",
      "Epoch 219/6000\n",
      "128/128 [==============================] - 19s 146ms/step - loss: 0.0657 - accuracy: 0.9769 - val_loss: 0.0959 - val_accuracy: 0.9720\n",
      "Epoch 220/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.0641 - accuracy: 0.9770 - val_loss: 0.0996 - val_accuracy: 0.9710\n",
      "Epoch 221/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.0657 - accuracy: 0.9770 - val_loss: 0.0985 - val_accuracy: 0.9713\n",
      "Epoch 222/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.0650 - accuracy: 0.9768 - val_loss: 0.1036 - val_accuracy: 0.9702\n",
      "Epoch 223/6000\n",
      "128/128 [==============================] - 22s 169ms/step - loss: 0.0651 - accuracy: 0.9768 - val_loss: 0.1061 - val_accuracy: 0.9693\n",
      "Epoch 224/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.0648 - accuracy: 0.9770 - val_loss: 0.1018 - val_accuracy: 0.9705\n",
      "Epoch 225/6000\n",
      "128/128 [==============================] - 21s 167ms/step - loss: 0.0630 - accuracy: 0.9777 - val_loss: 0.0947 - val_accuracy: 0.9727\n",
      "Epoch 226/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.0637 - accuracy: 0.9773 - val_loss: 0.0977 - val_accuracy: 0.9714\n",
      "Epoch 227/6000\n",
      "128/128 [==============================] - 22s 169ms/step - loss: 0.0646 - accuracy: 0.9771 - val_loss: 0.0984 - val_accuracy: 0.9714\n",
      "Epoch 227: early stopping\n",
      "##########################################################################\n",
      "------val_accuracy-----> 97.28 | 97.77 <----------accuracy----------\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/SHIB-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/SHIB-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "working on pair: ZIL/USDT\n",
      "One_pair_AI_Gen : ZIL/USDT\n",
      "price_volatility_15m:0.44%\n",
      "mini_expand : ZIL/USDT\n",
      "---buy_simple_up--- Buy pct: 0.5%\n",
      "---buy_only--- Max time window: 10%\n",
      "---buy_only--- no b\n",
      "---buy_only--- no sell\n",
      "df original shape (407578, 1607)\n",
      "df original shape buy mean : 11.843867922213661\n",
      "df choosen data shape(407578, 1607)\n",
      "pair: True\n",
      "81515\n",
      "normalizing ...\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/ZIL-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_80 (Dense)            (None, 250)               401750    \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 250)               0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 20)                5020      \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,871\n",
      "Trainable params: 407,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_UP_CLOSE/ZIL-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "Epoch 1/6000\n",
      "128/128 [==============================] - 25s 164ms/step - loss: 0.5771 - accuracy: 0.6966 - val_loss: 0.5507 - val_accuracy: 0.7176\n",
      "Epoch 2/6000\n",
      "128/128 [==============================] - 17s 133ms/step - loss: 0.5451 - accuracy: 0.7208 - val_loss: 0.5268 - val_accuracy: 0.7350\n",
      "Epoch 3/6000\n",
      "128/128 [==============================] - 17s 133ms/step - loss: 0.5210 - accuracy: 0.7385 - val_loss: 0.5011 - val_accuracy: 0.7539\n",
      "Epoch 4/6000\n",
      "128/128 [==============================] - 17s 132ms/step - loss: 0.4982 - accuracy: 0.7540 - val_loss: 0.4779 - val_accuracy: 0.7727\n",
      "Epoch 5/6000\n",
      "128/128 [==============================] - 17s 132ms/step - loss: 0.4770 - accuracy: 0.7690 - val_loss: 0.4501 - val_accuracy: 0.7875\n",
      "Epoch 6/6000\n",
      "128/128 [==============================] - 17s 129ms/step - loss: 0.4574 - accuracy: 0.7818 - val_loss: 0.4335 - val_accuracy: 0.8043\n",
      "Epoch 7/6000\n",
      "128/128 [==============================] - 16s 129ms/step - loss: 0.4365 - accuracy: 0.7961 - val_loss: 0.4158 - val_accuracy: 0.8104\n",
      "Epoch 8/6000\n",
      "128/128 [==============================] - 16s 128ms/step - loss: 0.4215 - accuracy: 0.8044 - val_loss: 0.3975 - val_accuracy: 0.8202\n",
      "Epoch 9/6000\n",
      "128/128 [==============================] - 17s 131ms/step - loss: 0.4054 - accuracy: 0.8145 - val_loss: 0.3825 - val_accuracy: 0.8286\n",
      "Epoch 10/6000\n",
      "128/128 [==============================] - 20s 159ms/step - loss: 0.3925 - accuracy: 0.8224 - val_loss: 0.3635 - val_accuracy: 0.8406\n",
      "Epoch 11/6000\n",
      "128/128 [==============================] - 21s 168ms/step - loss: 0.3812 - accuracy: 0.8288 - val_loss: 0.3538 - val_accuracy: 0.8464\n",
      "Epoch 12/6000\n",
      "128/128 [==============================] - 17s 133ms/step - loss: 0.3703 - accuracy: 0.8348 - val_loss: 0.3461 - val_accuracy: 0.8491\n",
      "Epoch 13/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.3615 - accuracy: 0.8399 - val_loss: 0.3411 - val_accuracy: 0.8529\n",
      "Epoch 14/6000\n",
      "128/128 [==============================] - 17s 129ms/step - loss: 0.3498 - accuracy: 0.8456 - val_loss: 0.3281 - val_accuracy: 0.8604\n",
      "Epoch 15/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.3423 - accuracy: 0.8503 - val_loss: 0.3178 - val_accuracy: 0.8651\n",
      "Epoch 16/6000\n",
      "128/128 [==============================] - 16s 128ms/step - loss: 0.3346 - accuracy: 0.8540 - val_loss: 0.3186 - val_accuracy: 0.8639\n",
      "Epoch 17/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.3280 - accuracy: 0.8582 - val_loss: 0.3068 - val_accuracy: 0.8694\n",
      "Epoch 18/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.3210 - accuracy: 0.8611 - val_loss: 0.2939 - val_accuracy: 0.8774\n",
      "Epoch 19/6000\n",
      "128/128 [==============================] - 17s 132ms/step - loss: 0.3131 - accuracy: 0.8651 - val_loss: 0.2943 - val_accuracy: 0.8782\n",
      "Epoch 20/6000\n",
      "128/128 [==============================] - 21s 161ms/step - loss: 0.3073 - accuracy: 0.8682 - val_loss: 0.2879 - val_accuracy: 0.8800\n",
      "Epoch 21/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.3020 - accuracy: 0.8710 - val_loss: 0.2831 - val_accuracy: 0.8828\n",
      "Epoch 22/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.2981 - accuracy: 0.8730 - val_loss: 0.2752 - val_accuracy: 0.8869\n",
      "Epoch 23/6000\n",
      "128/128 [==============================] - 16s 127ms/step - loss: 0.2925 - accuracy: 0.8761 - val_loss: 0.2805 - val_accuracy: 0.8847\n",
      "Epoch 24/6000\n",
      "128/128 [==============================] - 22s 169ms/step - loss: 0.2846 - accuracy: 0.8800 - val_loss: 0.2696 - val_accuracy: 0.8889\n",
      "Epoch 25/6000\n",
      "128/128 [==============================] - 22s 169ms/step - loss: 0.2830 - accuracy: 0.8804 - val_loss: 0.2684 - val_accuracy: 0.8904\n",
      "Epoch 26/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.2789 - accuracy: 0.8827 - val_loss: 0.2700 - val_accuracy: 0.8898\n",
      "Epoch 27/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.2740 - accuracy: 0.8848 - val_loss: 0.2522 - val_accuracy: 0.8963\n",
      "Epoch 28/6000\n",
      "128/128 [==============================] - 20s 155ms/step - loss: 0.2702 - accuracy: 0.8873 - val_loss: 0.2532 - val_accuracy: 0.8977\n",
      "Epoch 29/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.2659 - accuracy: 0.8889 - val_loss: 0.2455 - val_accuracy: 0.9014\n",
      "Epoch 30/6000\n",
      "128/128 [==============================] - 20s 160ms/step - loss: 0.2620 - accuracy: 0.8906 - val_loss: 0.2481 - val_accuracy: 0.9006\n",
      "Epoch 31/6000\n",
      "128/128 [==============================] - 19s 144ms/step - loss: 0.2595 - accuracy: 0.8926 - val_loss: 0.2498 - val_accuracy: 0.8989\n",
      "Epoch 32/6000\n",
      "128/128 [==============================] - 21s 160ms/step - loss: 0.2561 - accuracy: 0.8938 - val_loss: 0.2408 - val_accuracy: 0.9036\n",
      "Epoch 33/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.2521 - accuracy: 0.8959 - val_loss: 0.2347 - val_accuracy: 0.9057\n",
      "Epoch 34/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.2508 - accuracy: 0.8965 - val_loss: 0.2355 - val_accuracy: 0.9069\n",
      "Epoch 35/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.2476 - accuracy: 0.8979 - val_loss: 0.2392 - val_accuracy: 0.9047\n",
      "Epoch 36/6000\n",
      "128/128 [==============================] - 24s 184ms/step - loss: 0.2448 - accuracy: 0.8990 - val_loss: 0.2320 - val_accuracy: 0.9091\n",
      "Epoch 37/6000\n",
      "128/128 [==============================] - 17s 130ms/step - loss: 0.2415 - accuracy: 0.9010 - val_loss: 0.2319 - val_accuracy: 0.9087\n",
      "Epoch 38/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.2385 - accuracy: 0.9023 - val_loss: 0.2265 - val_accuracy: 0.9116\n",
      "Epoch 39/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.2358 - accuracy: 0.9037 - val_loss: 0.2285 - val_accuracy: 0.9096\n",
      "Epoch 40/6000\n",
      "128/128 [==============================] - 22s 169ms/step - loss: 0.2335 - accuracy: 0.9045 - val_loss: 0.2226 - val_accuracy: 0.9111\n",
      "Epoch 41/6000\n",
      "128/128 [==============================] - 16s 128ms/step - loss: 0.2323 - accuracy: 0.9050 - val_loss: 0.2282 - val_accuracy: 0.9107\n",
      "Epoch 42/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.2281 - accuracy: 0.9071 - val_loss: 0.2186 - val_accuracy: 0.9154\n",
      "Epoch 43/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.2253 - accuracy: 0.9081 - val_loss: 0.2174 - val_accuracy: 0.9152\n",
      "Epoch 44/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.2246 - accuracy: 0.9092 - val_loss: 0.2136 - val_accuracy: 0.9165\n",
      "Epoch 45/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.2223 - accuracy: 0.9106 - val_loss: 0.2141 - val_accuracy: 0.9181\n",
      "Epoch 46/6000\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 0.2210 - accuracy: 0.9107 - val_loss: 0.2129 - val_accuracy: 0.9168\n",
      "Epoch 47/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.2174 - accuracy: 0.9123 - val_loss: 0.2127 - val_accuracy: 0.9183\n",
      "Epoch 48/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.2163 - accuracy: 0.9129 - val_loss: 0.2105 - val_accuracy: 0.9178\n",
      "Epoch 49/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.2154 - accuracy: 0.9130 - val_loss: 0.2115 - val_accuracy: 0.9186\n",
      "Epoch 50/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.2127 - accuracy: 0.9148 - val_loss: 0.2050 - val_accuracy: 0.9210\n",
      "Epoch 51/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.2114 - accuracy: 0.9154 - val_loss: 0.2069 - val_accuracy: 0.9204\n",
      "Epoch 52/6000\n",
      "128/128 [==============================] - 18s 137ms/step - loss: 0.2065 - accuracy: 0.9174 - val_loss: 0.2046 - val_accuracy: 0.9224\n",
      "Epoch 53/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.2072 - accuracy: 0.9175 - val_loss: 0.2097 - val_accuracy: 0.9199\n",
      "Epoch 54/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.2048 - accuracy: 0.9181 - val_loss: 0.1999 - val_accuracy: 0.9234\n",
      "Epoch 55/6000\n",
      "128/128 [==============================] - 21s 168ms/step - loss: 0.2049 - accuracy: 0.9181 - val_loss: 0.1978 - val_accuracy: 0.9242\n",
      "Epoch 56/6000\n",
      "128/128 [==============================] - 18s 143ms/step - loss: 0.2019 - accuracy: 0.9191 - val_loss: 0.2071 - val_accuracy: 0.9214\n",
      "Epoch 57/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1990 - accuracy: 0.9207 - val_loss: 0.1966 - val_accuracy: 0.9262\n",
      "Epoch 58/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1983 - accuracy: 0.9213 - val_loss: 0.1951 - val_accuracy: 0.9253\n",
      "Epoch 59/6000\n",
      "128/128 [==============================] - 19s 145ms/step - loss: 0.2000 - accuracy: 0.9200 - val_loss: 0.1926 - val_accuracy: 0.9284\n",
      "Epoch 60/6000\n",
      "128/128 [==============================] - 21s 162ms/step - loss: 0.1938 - accuracy: 0.9231 - val_loss: 0.1913 - val_accuracy: 0.9285\n",
      "Epoch 61/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1934 - accuracy: 0.9233 - val_loss: 0.1913 - val_accuracy: 0.9275\n",
      "Epoch 62/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1916 - accuracy: 0.9241 - val_loss: 0.1881 - val_accuracy: 0.9288\n",
      "Epoch 63/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.1898 - accuracy: 0.9252 - val_loss: 0.1903 - val_accuracy: 0.9276\n",
      "Epoch 64/6000\n",
      "128/128 [==============================] - 17s 132ms/step - loss: 0.1896 - accuracy: 0.9249 - val_loss: 0.1913 - val_accuracy: 0.9288\n",
      "Epoch 65/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.1878 - accuracy: 0.9256 - val_loss: 0.1921 - val_accuracy: 0.9275\n",
      "Epoch 66/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1878 - accuracy: 0.9259 - val_loss: 0.1843 - val_accuracy: 0.9323\n",
      "Epoch 67/6000\n",
      "128/128 [==============================] - 17s 131ms/step - loss: 0.1848 - accuracy: 0.9270 - val_loss: 0.1855 - val_accuracy: 0.9310\n",
      "Epoch 68/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1827 - accuracy: 0.9280 - val_loss: 0.1888 - val_accuracy: 0.9293\n",
      "Epoch 69/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.1827 - accuracy: 0.9283 - val_loss: 0.1889 - val_accuracy: 0.9299\n",
      "Epoch 70/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1824 - accuracy: 0.9278 - val_loss: 0.1841 - val_accuracy: 0.9321\n",
      "Epoch 71/6000\n",
      "128/128 [==============================] - 17s 131ms/step - loss: 0.1810 - accuracy: 0.9288 - val_loss: 0.1857 - val_accuracy: 0.9313\n",
      "Epoch 72/6000\n",
      "128/128 [==============================] - 21s 167ms/step - loss: 0.1796 - accuracy: 0.9289 - val_loss: 0.1810 - val_accuracy: 0.9336\n",
      "Epoch 73/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1776 - accuracy: 0.9300 - val_loss: 0.1794 - val_accuracy: 0.9346\n",
      "Epoch 74/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.1769 - accuracy: 0.9308 - val_loss: 0.1838 - val_accuracy: 0.9325\n",
      "Epoch 75/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1744 - accuracy: 0.9313 - val_loss: 0.1762 - val_accuracy: 0.9354\n",
      "Epoch 76/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.1749 - accuracy: 0.9312 - val_loss: 0.1764 - val_accuracy: 0.9359\n",
      "Epoch 77/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.1710 - accuracy: 0.9332 - val_loss: 0.1708 - val_accuracy: 0.9378\n",
      "Epoch 78/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1712 - accuracy: 0.9331 - val_loss: 0.1797 - val_accuracy: 0.9335\n",
      "Epoch 79/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.1701 - accuracy: 0.9333 - val_loss: 0.1770 - val_accuracy: 0.9341\n",
      "Epoch 80/6000\n",
      "128/128 [==============================] - 20s 154ms/step - loss: 0.1710 - accuracy: 0.9333 - val_loss: 0.1801 - val_accuracy: 0.9343\n",
      "Epoch 81/6000\n",
      "128/128 [==============================] - 19s 143ms/step - loss: 0.1702 - accuracy: 0.9336 - val_loss: 0.1748 - val_accuracy: 0.9365\n",
      "Epoch 82/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.1661 - accuracy: 0.9352 - val_loss: 0.1707 - val_accuracy: 0.9370\n",
      "Epoch 83/6000\n",
      "128/128 [==============================] - 23s 184ms/step - loss: 0.1682 - accuracy: 0.9341 - val_loss: 0.1774 - val_accuracy: 0.9366\n",
      "Epoch 84/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1655 - accuracy: 0.9364 - val_loss: 0.1739 - val_accuracy: 0.9363\n",
      "Epoch 85/6000\n",
      "128/128 [==============================] - 17s 130ms/step - loss: 0.1651 - accuracy: 0.9359 - val_loss: 0.1771 - val_accuracy: 0.9352\n",
      "Epoch 86/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.1634 - accuracy: 0.9367 - val_loss: 0.1697 - val_accuracy: 0.9395\n",
      "Epoch 87/6000\n",
      "128/128 [==============================] - 23s 184ms/step - loss: 0.1627 - accuracy: 0.9375 - val_loss: 0.1719 - val_accuracy: 0.9380\n",
      "Epoch 88/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.1622 - accuracy: 0.9372 - val_loss: 0.1702 - val_accuracy: 0.9378\n",
      "Epoch 89/6000\n",
      "128/128 [==============================] - 19s 144ms/step - loss: 0.1626 - accuracy: 0.9368 - val_loss: 0.1665 - val_accuracy: 0.9402\n",
      "Epoch 90/6000\n",
      "128/128 [==============================] - 20s 156ms/step - loss: 0.1604 - accuracy: 0.9375 - val_loss: 0.1679 - val_accuracy: 0.9393\n",
      "Epoch 91/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1593 - accuracy: 0.9385 - val_loss: 0.1714 - val_accuracy: 0.9395\n",
      "Epoch 92/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1592 - accuracy: 0.9383 - val_loss: 0.1731 - val_accuracy: 0.9382\n",
      "Epoch 93/6000\n",
      "128/128 [==============================] - 20s 154ms/step - loss: 0.1581 - accuracy: 0.9385 - val_loss: 0.1660 - val_accuracy: 0.9398\n",
      "Epoch 94/6000\n",
      "128/128 [==============================] - 19s 151ms/step - loss: 0.1563 - accuracy: 0.9397 - val_loss: 0.1659 - val_accuracy: 0.9408\n",
      "Epoch 95/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.1559 - accuracy: 0.9397 - val_loss: 0.1685 - val_accuracy: 0.9391\n",
      "Epoch 96/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1566 - accuracy: 0.9396 - val_loss: 0.1616 - val_accuracy: 0.9431\n",
      "Epoch 97/6000\n",
      "128/128 [==============================] - 16s 128ms/step - loss: 0.1547 - accuracy: 0.9400 - val_loss: 0.1621 - val_accuracy: 0.9426\n",
      "Epoch 98/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1538 - accuracy: 0.9403 - val_loss: 0.1667 - val_accuracy: 0.9403\n",
      "Epoch 99/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.1546 - accuracy: 0.9405 - val_loss: 0.1609 - val_accuracy: 0.9432\n",
      "Epoch 100/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1529 - accuracy: 0.9413 - val_loss: 0.1636 - val_accuracy: 0.9424\n",
      "Epoch 101/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.1516 - accuracy: 0.9417 - val_loss: 0.1631 - val_accuracy: 0.9428\n",
      "Epoch 102/6000\n",
      "128/128 [==============================] - 17s 131ms/step - loss: 0.1527 - accuracy: 0.9413 - val_loss: 0.1659 - val_accuracy: 0.9409\n",
      "Epoch 103/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1490 - accuracy: 0.9426 - val_loss: 0.1694 - val_accuracy: 0.9395\n",
      "Epoch 104/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1485 - accuracy: 0.9431 - val_loss: 0.1608 - val_accuracy: 0.9431\n",
      "Epoch 105/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1464 - accuracy: 0.9440 - val_loss: 0.1559 - val_accuracy: 0.9446\n",
      "Epoch 106/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.1471 - accuracy: 0.9437 - val_loss: 0.1625 - val_accuracy: 0.9434\n",
      "Epoch 107/6000\n",
      "128/128 [==============================] - 22s 167ms/step - loss: 0.1474 - accuracy: 0.9436 - val_loss: 0.1589 - val_accuracy: 0.9443\n",
      "Epoch 108/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1466 - accuracy: 0.9433 - val_loss: 0.1624 - val_accuracy: 0.9425\n",
      "Epoch 109/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1465 - accuracy: 0.9436 - val_loss: 0.1603 - val_accuracy: 0.9439\n",
      "Epoch 110/6000\n",
      "128/128 [==============================] - 17s 132ms/step - loss: 0.1459 - accuracy: 0.9444 - val_loss: 0.1590 - val_accuracy: 0.9448\n",
      "Epoch 111/6000\n",
      "128/128 [==============================] - 23s 184ms/step - loss: 0.1425 - accuracy: 0.9453 - val_loss: 0.1598 - val_accuracy: 0.9428\n",
      "Epoch 112/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1433 - accuracy: 0.9451 - val_loss: 0.1598 - val_accuracy: 0.9441\n",
      "Epoch 113/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1435 - accuracy: 0.9446 - val_loss: 0.1686 - val_accuracy: 0.9409\n",
      "Epoch 114/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1406 - accuracy: 0.9459 - val_loss: 0.1576 - val_accuracy: 0.9454\n",
      "Epoch 115/6000\n",
      "128/128 [==============================] - 19s 149ms/step - loss: 0.1400 - accuracy: 0.9460 - val_loss: 0.1590 - val_accuracy: 0.9450\n",
      "Epoch 116/6000\n",
      "128/128 [==============================] - 20s 155ms/step - loss: 0.1425 - accuracy: 0.9452 - val_loss: 0.1542 - val_accuracy: 0.9457\n",
      "Epoch 117/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1401 - accuracy: 0.9462 - val_loss: 0.1509 - val_accuracy: 0.9470\n",
      "Epoch 118/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1385 - accuracy: 0.9477 - val_loss: 0.1575 - val_accuracy: 0.9454\n",
      "Epoch 119/6000\n",
      "128/128 [==============================] - 17s 129ms/step - loss: 0.1393 - accuracy: 0.9467 - val_loss: 0.1553 - val_accuracy: 0.9465\n",
      "Epoch 120/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1384 - accuracy: 0.9472 - val_loss: 0.1580 - val_accuracy: 0.9450\n",
      "Epoch 121/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.1381 - accuracy: 0.9474 - val_loss: 0.1522 - val_accuracy: 0.9468\n",
      "Epoch 122/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1376 - accuracy: 0.9473 - val_loss: 0.1559 - val_accuracy: 0.9460\n",
      "Epoch 123/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1345 - accuracy: 0.9487 - val_loss: 0.1566 - val_accuracy: 0.9464\n",
      "Epoch 124/6000\n",
      "128/128 [==============================] - 17s 133ms/step - loss: 0.1354 - accuracy: 0.9488 - val_loss: 0.1552 - val_accuracy: 0.9460\n",
      "Epoch 125/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1339 - accuracy: 0.9492 - val_loss: 0.1520 - val_accuracy: 0.9477\n",
      "Epoch 126/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1358 - accuracy: 0.9485 - val_loss: 0.1539 - val_accuracy: 0.9466\n",
      "Epoch 127/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.1326 - accuracy: 0.9496 - val_loss: 0.1561 - val_accuracy: 0.9463\n",
      "Epoch 128/6000\n",
      "128/128 [==============================] - 20s 156ms/step - loss: 0.1346 - accuracy: 0.9488 - val_loss: 0.1558 - val_accuracy: 0.9458\n",
      "Epoch 129/6000\n",
      "128/128 [==============================] - 19s 150ms/step - loss: 0.1315 - accuracy: 0.9503 - val_loss: 0.1513 - val_accuracy: 0.9474\n",
      "Epoch 130/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.1325 - accuracy: 0.9494 - val_loss: 0.1518 - val_accuracy: 0.9476\n",
      "Epoch 131/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1304 - accuracy: 0.9501 - val_loss: 0.1627 - val_accuracy: 0.9450\n",
      "Epoch 132/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.1312 - accuracy: 0.9505 - val_loss: 0.1496 - val_accuracy: 0.9490\n",
      "Epoch 133/6000\n",
      "128/128 [==============================] - 19s 144ms/step - loss: 0.1312 - accuracy: 0.9501 - val_loss: 0.1569 - val_accuracy: 0.9464\n",
      "Epoch 134/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1283 - accuracy: 0.9514 - val_loss: 0.1593 - val_accuracy: 0.9449\n",
      "Epoch 135/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1287 - accuracy: 0.9510 - val_loss: 0.1582 - val_accuracy: 0.9456\n",
      "Epoch 136/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1290 - accuracy: 0.9511 - val_loss: 0.1553 - val_accuracy: 0.9468\n",
      "Epoch 137/6000\n",
      "128/128 [==============================] - 17s 129ms/step - loss: 0.1289 - accuracy: 0.9515 - val_loss: 0.1495 - val_accuracy: 0.9493\n",
      "Epoch 138/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.1263 - accuracy: 0.9520 - val_loss: 0.1554 - val_accuracy: 0.9471\n",
      "Epoch 139/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.1298 - accuracy: 0.9506 - val_loss: 0.1521 - val_accuracy: 0.9478\n",
      "Epoch 140/6000\n",
      "128/128 [==============================] - 19s 150ms/step - loss: 0.1274 - accuracy: 0.9509 - val_loss: 0.1451 - val_accuracy: 0.9506\n",
      "Epoch 141/6000\n",
      "128/128 [==============================] - 19s 147ms/step - loss: 0.1281 - accuracy: 0.9515 - val_loss: 0.1492 - val_accuracy: 0.9494\n",
      "Epoch 142/6000\n",
      "128/128 [==============================] - 24s 184ms/step - loss: 0.1253 - accuracy: 0.9526 - val_loss: 0.1469 - val_accuracy: 0.9500\n",
      "Epoch 143/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1235 - accuracy: 0.9531 - val_loss: 0.1550 - val_accuracy: 0.9478\n",
      "Epoch 144/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1261 - accuracy: 0.9518 - val_loss: 0.1432 - val_accuracy: 0.9513\n",
      "Epoch 145/6000\n",
      "128/128 [==============================] - 18s 140ms/step - loss: 0.1238 - accuracy: 0.9534 - val_loss: 0.1481 - val_accuracy: 0.9496\n",
      "Epoch 146/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.1229 - accuracy: 0.9538 - val_loss: 0.1643 - val_accuracy: 0.9447\n",
      "Epoch 147/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1235 - accuracy: 0.9539 - val_loss: 0.1496 - val_accuracy: 0.9496\n",
      "Epoch 148/6000\n",
      "128/128 [==============================] - 20s 155ms/step - loss: 0.1227 - accuracy: 0.9534 - val_loss: 0.1572 - val_accuracy: 0.9466\n",
      "Epoch 149/6000\n",
      "128/128 [==============================] - 19s 150ms/step - loss: 0.1237 - accuracy: 0.9535 - val_loss: 0.1645 - val_accuracy: 0.9459\n",
      "Epoch 150/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1222 - accuracy: 0.9541 - val_loss: 0.1543 - val_accuracy: 0.9480\n",
      "Epoch 151/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.1214 - accuracy: 0.9545 - val_loss: 0.1433 - val_accuracy: 0.9518\n",
      "Epoch 152/6000\n",
      "128/128 [==============================] - 24s 184ms/step - loss: 0.1207 - accuracy: 0.9545 - val_loss: 0.1459 - val_accuracy: 0.9506\n",
      "Epoch 153/6000\n",
      "128/128 [==============================] - 17s 130ms/step - loss: 0.1207 - accuracy: 0.9545 - val_loss: 0.1433 - val_accuracy: 0.9511\n",
      "Epoch 154/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.1215 - accuracy: 0.9542 - val_loss: 0.1411 - val_accuracy: 0.9524\n",
      "Epoch 155/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1201 - accuracy: 0.9550 - val_loss: 0.1432 - val_accuracy: 0.9519\n",
      "Epoch 156/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1195 - accuracy: 0.9551 - val_loss: 0.1443 - val_accuracy: 0.9522\n",
      "Epoch 157/6000\n",
      "128/128 [==============================] - 18s 137ms/step - loss: 0.1183 - accuracy: 0.9554 - val_loss: 0.1520 - val_accuracy: 0.9502\n",
      "Epoch 158/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.1192 - accuracy: 0.9551 - val_loss: 0.1495 - val_accuracy: 0.9515\n",
      "Epoch 159/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1183 - accuracy: 0.9556 - val_loss: 0.1424 - val_accuracy: 0.9517\n",
      "Epoch 160/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1193 - accuracy: 0.9552 - val_loss: 0.1408 - val_accuracy: 0.9524\n",
      "Epoch 161/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.1153 - accuracy: 0.9568 - val_loss: 0.1560 - val_accuracy: 0.9484\n",
      "Epoch 162/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.1159 - accuracy: 0.9563 - val_loss: 0.1500 - val_accuracy: 0.9497\n",
      "Epoch 163/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1171 - accuracy: 0.9563 - val_loss: 0.1437 - val_accuracy: 0.9524\n",
      "Epoch 164/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1168 - accuracy: 0.9561 - val_loss: 0.1446 - val_accuracy: 0.9522\n",
      "Epoch 165/6000\n",
      "128/128 [==============================] - 21s 165ms/step - loss: 0.1157 - accuracy: 0.9565 - val_loss: 0.1442 - val_accuracy: 0.9515\n",
      "Epoch 166/6000\n",
      "128/128 [==============================] - 19s 146ms/step - loss: 0.1161 - accuracy: 0.9565 - val_loss: 0.1435 - val_accuracy: 0.9526\n",
      "Epoch 167/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.1143 - accuracy: 0.9573 - val_loss: 0.1435 - val_accuracy: 0.9520\n",
      "Epoch 168/6000\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 0.1153 - accuracy: 0.9566 - val_loss: 0.1457 - val_accuracy: 0.9513\n",
      "Epoch 169/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.1139 - accuracy: 0.9573 - val_loss: 0.1575 - val_accuracy: 0.9480\n",
      "Epoch 170/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1131 - accuracy: 0.9574 - val_loss: 0.1419 - val_accuracy: 0.9523\n",
      "Epoch 171/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1124 - accuracy: 0.9578 - val_loss: 0.1428 - val_accuracy: 0.9533\n",
      "Epoch 172/6000\n",
      "128/128 [==============================] - 18s 140ms/step - loss: 0.1123 - accuracy: 0.9580 - val_loss: 0.1451 - val_accuracy: 0.9519\n",
      "Epoch 173/6000\n",
      "128/128 [==============================] - 21s 165ms/step - loss: 0.1117 - accuracy: 0.9584 - val_loss: 0.1443 - val_accuracy: 0.9527\n",
      "Epoch 174/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1148 - accuracy: 0.9568 - val_loss: 0.1499 - val_accuracy: 0.9491\n",
      "Epoch 175/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1131 - accuracy: 0.9577 - val_loss: 0.1510 - val_accuracy: 0.9509\n",
      "Epoch 176/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1121 - accuracy: 0.9577 - val_loss: 0.1413 - val_accuracy: 0.9528\n",
      "Epoch 177/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.1114 - accuracy: 0.9585 - val_loss: 0.1398 - val_accuracy: 0.9538\n",
      "Epoch 178/6000\n",
      "128/128 [==============================] - 23s 175ms/step - loss: 0.1115 - accuracy: 0.9582 - val_loss: 0.1441 - val_accuracy: 0.9527\n",
      "Epoch 179/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1094 - accuracy: 0.9592 - val_loss: 0.1424 - val_accuracy: 0.9534\n",
      "Epoch 180/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1101 - accuracy: 0.9590 - val_loss: 0.1432 - val_accuracy: 0.9530\n",
      "Epoch 181/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1100 - accuracy: 0.9587 - val_loss: 0.1414 - val_accuracy: 0.9538\n",
      "Epoch 182/6000\n",
      "128/128 [==============================] - 17s 137ms/step - loss: 0.1098 - accuracy: 0.9591 - val_loss: 0.1504 - val_accuracy: 0.9509\n",
      "Epoch 183/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.1101 - accuracy: 0.9585 - val_loss: 0.1447 - val_accuracy: 0.9526\n",
      "Epoch 184/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1086 - accuracy: 0.9595 - val_loss: 0.1395 - val_accuracy: 0.9532\n",
      "Epoch 185/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1083 - accuracy: 0.9594 - val_loss: 0.1402 - val_accuracy: 0.9536\n",
      "Epoch 186/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1087 - accuracy: 0.9594 - val_loss: 0.1391 - val_accuracy: 0.9558\n",
      "Epoch 187/6000\n",
      "128/128 [==============================] - 17s 131ms/step - loss: 0.1082 - accuracy: 0.9596 - val_loss: 0.1407 - val_accuracy: 0.9550\n",
      "Epoch 188/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1058 - accuracy: 0.9607 - val_loss: 0.1411 - val_accuracy: 0.9541\n",
      "Epoch 189/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1081 - accuracy: 0.9600 - val_loss: 0.1360 - val_accuracy: 0.9563\n",
      "Epoch 190/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1045 - accuracy: 0.9610 - val_loss: 0.1368 - val_accuracy: 0.9555\n",
      "Epoch 191/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1058 - accuracy: 0.9608 - val_loss: 0.1325 - val_accuracy: 0.9568\n",
      "Epoch 192/6000\n",
      "128/128 [==============================] - 16s 128ms/step - loss: 0.1044 - accuracy: 0.9611 - val_loss: 0.1551 - val_accuracy: 0.9501\n",
      "Epoch 193/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1073 - accuracy: 0.9601 - val_loss: 0.1422 - val_accuracy: 0.9540\n",
      "Epoch 194/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1061 - accuracy: 0.9601 - val_loss: 0.1385 - val_accuracy: 0.9553\n",
      "Epoch 195/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.1042 - accuracy: 0.9609 - val_loss: 0.1448 - val_accuracy: 0.9537\n",
      "Epoch 196/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1046 - accuracy: 0.9610 - val_loss: 0.1387 - val_accuracy: 0.9547\n",
      "Epoch 197/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.1044 - accuracy: 0.9610 - val_loss: 0.1350 - val_accuracy: 0.9560\n",
      "Epoch 198/6000\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 0.1047 - accuracy: 0.9607 - val_loss: 0.1415 - val_accuracy: 0.9541\n",
      "Epoch 199/6000\n",
      "128/128 [==============================] - 21s 167ms/step - loss: 0.1035 - accuracy: 0.9613 - val_loss: 0.1365 - val_accuracy: 0.9554\n",
      "Epoch 200/6000\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 0.1041 - accuracy: 0.9611 - val_loss: 0.1430 - val_accuracy: 0.9550\n",
      "Epoch 201/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1041 - accuracy: 0.9614 - val_loss: 0.1335 - val_accuracy: 0.9570\n",
      "Epoch 202/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1030 - accuracy: 0.9621 - val_loss: 0.1405 - val_accuracy: 0.9560\n",
      "Epoch 203/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1023 - accuracy: 0.9621 - val_loss: 0.1342 - val_accuracy: 0.9581\n",
      "Epoch 204/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1017 - accuracy: 0.9625 - val_loss: 0.1381 - val_accuracy: 0.9556\n",
      "Epoch 205/6000\n",
      "128/128 [==============================] - 17s 133ms/step - loss: 0.1009 - accuracy: 0.9627 - val_loss: 0.1406 - val_accuracy: 0.9548\n",
      "Epoch 206/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1027 - accuracy: 0.9615 - val_loss: 0.1512 - val_accuracy: 0.9518\n",
      "Epoch 207/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.1006 - accuracy: 0.9626 - val_loss: 0.1385 - val_accuracy: 0.9558\n",
      "Epoch 208/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1000 - accuracy: 0.9630 - val_loss: 0.1356 - val_accuracy: 0.9559\n",
      "Epoch 209/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.0994 - accuracy: 0.9630 - val_loss: 0.1409 - val_accuracy: 0.9560\n",
      "Epoch 210/6000\n",
      "128/128 [==============================] - 18s 140ms/step - loss: 0.1000 - accuracy: 0.9624 - val_loss: 0.1424 - val_accuracy: 0.9537\n",
      "Epoch 211/6000\n",
      "128/128 [==============================] - 22s 169ms/step - loss: 0.0993 - accuracy: 0.9631 - val_loss: 0.1387 - val_accuracy: 0.9560\n",
      "Epoch 212/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1002 - accuracy: 0.9627 - val_loss: 0.1383 - val_accuracy: 0.9566\n",
      "Epoch 213/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.0997 - accuracy: 0.9629 - val_loss: 0.1429 - val_accuracy: 0.9541\n",
      "Epoch 214/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.0988 - accuracy: 0.9637 - val_loss: 0.1355 - val_accuracy: 0.9572\n",
      "Epoch 215/6000\n",
      "128/128 [==============================] - 17s 130ms/step - loss: 0.0996 - accuracy: 0.9629 - val_loss: 0.1364 - val_accuracy: 0.9571\n",
      "Epoch 216/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.0982 - accuracy: 0.9635 - val_loss: 0.1377 - val_accuracy: 0.9554\n",
      "Epoch 217/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.0992 - accuracy: 0.9631 - val_loss: 0.1418 - val_accuracy: 0.9554\n",
      "Epoch 218/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.0983 - accuracy: 0.9640 - val_loss: 0.1383 - val_accuracy: 0.9567\n",
      "Epoch 218: early stopping\n",
      "##########################################################################\n",
      "------val_accuracy-----> 95.81 | 96.4 <----------accuracy----------\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/ZIL-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/ZIL-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "working on pair: ENS/USDT\n",
      "One_pair_AI_Gen : ENS/USDT\n",
      "price_volatility_15m:0.55%\n",
      "mini_expand : ENS/USDT\n",
      "---buy_simple_up--- Buy pct: 0.55%\n",
      "---buy_only--- Max time window: 10%\n",
      "---buy_only--- no b\n",
      "---buy_only--- no sell\n",
      "df original shape (407578, 1607)\n",
      "df original shape buy mean : 16.084037901947603\n",
      "df choosen data shape(407578, 1607)\n",
      "pair: True\n",
      "81515\n",
      "normalizing ...\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/ENS-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_84 (Dense)            (None, 250)               401750    \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 250)               0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 20)                5020      \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,871\n",
      "Trainable params: 407,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_UP_CLOSE/ENS-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "Epoch 1/6000\n",
      "128/128 [==============================] - 27s 173ms/step - loss: 0.6278 - accuracy: 0.6487 - val_loss: 0.6116 - val_accuracy: 0.6648\n",
      "Epoch 2/6000\n",
      "128/128 [==============================] - 18s 137ms/step - loss: 0.6040 - accuracy: 0.6711 - val_loss: 0.5894 - val_accuracy: 0.6839\n",
      "Epoch 3/6000\n",
      "128/128 [==============================] - 17s 132ms/step - loss: 0.5833 - accuracy: 0.6884 - val_loss: 0.5664 - val_accuracy: 0.7049\n",
      "Epoch 4/6000\n",
      "128/128 [==============================] - 17s 132ms/step - loss: 0.5629 - accuracy: 0.7051 - val_loss: 0.5416 - val_accuracy: 0.7247\n",
      "Epoch 5/6000\n",
      "128/128 [==============================] - 17s 133ms/step - loss: 0.5397 - accuracy: 0.7230 - val_loss: 0.5217 - val_accuracy: 0.7405\n",
      "Epoch 6/6000\n",
      "128/128 [==============================] - 17s 133ms/step - loss: 0.5193 - accuracy: 0.7390 - val_loss: 0.4989 - val_accuracy: 0.7558\n",
      "Epoch 7/6000\n",
      "128/128 [==============================] - 17s 135ms/step - loss: 0.5000 - accuracy: 0.7524 - val_loss: 0.4868 - val_accuracy: 0.7626\n",
      "Epoch 8/6000\n",
      "128/128 [==============================] - 17s 132ms/step - loss: 0.4826 - accuracy: 0.7634 - val_loss: 0.4620 - val_accuracy: 0.7794\n",
      "Epoch 9/6000\n",
      "128/128 [==============================] - 17s 129ms/step - loss: 0.4675 - accuracy: 0.7736 - val_loss: 0.4473 - val_accuracy: 0.7900\n",
      "Epoch 10/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.4526 - accuracy: 0.7831 - val_loss: 0.4320 - val_accuracy: 0.7980\n",
      "Epoch 11/6000\n",
      "128/128 [==============================] - 17s 130ms/step - loss: 0.4396 - accuracy: 0.7915 - val_loss: 0.4196 - val_accuracy: 0.8087\n",
      "Epoch 12/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.4271 - accuracy: 0.7982 - val_loss: 0.4094 - val_accuracy: 0.8120\n",
      "Epoch 13/6000\n",
      "128/128 [==============================] - 18s 139ms/step - loss: 0.4183 - accuracy: 0.8038 - val_loss: 0.4024 - val_accuracy: 0.8127\n",
      "Epoch 14/6000\n",
      "128/128 [==============================] - 21s 162ms/step - loss: 0.4079 - accuracy: 0.8100 - val_loss: 0.3922 - val_accuracy: 0.8234\n",
      "Epoch 15/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.4005 - accuracy: 0.8153 - val_loss: 0.3799 - val_accuracy: 0.8312\n",
      "Epoch 16/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.3919 - accuracy: 0.8190 - val_loss: 0.3729 - val_accuracy: 0.8332\n",
      "Epoch 17/6000\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 0.3824 - accuracy: 0.8248 - val_loss: 0.3732 - val_accuracy: 0.8328\n",
      "Epoch 18/6000\n",
      "128/128 [==============================] - 21s 168ms/step - loss: 0.3766 - accuracy: 0.8278 - val_loss: 0.3662 - val_accuracy: 0.8364\n",
      "Epoch 19/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.3701 - accuracy: 0.8315 - val_loss: 0.3567 - val_accuracy: 0.8435\n",
      "Epoch 20/6000\n",
      "128/128 [==============================] - 17s 132ms/step - loss: 0.3630 - accuracy: 0.8353 - val_loss: 0.3525 - val_accuracy: 0.8452\n",
      "Epoch 21/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.3606 - accuracy: 0.8376 - val_loss: 0.3441 - val_accuracy: 0.8499\n",
      "Epoch 22/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.3540 - accuracy: 0.8403 - val_loss: 0.3390 - val_accuracy: 0.8519\n",
      "Epoch 23/6000\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 0.3478 - accuracy: 0.8436 - val_loss: 0.3380 - val_accuracy: 0.8511\n",
      "Epoch 24/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.3428 - accuracy: 0.8462 - val_loss: 0.3292 - val_accuracy: 0.8574\n",
      "Epoch 25/6000\n",
      "128/128 [==============================] - 16s 129ms/step - loss: 0.3397 - accuracy: 0.8482 - val_loss: 0.3309 - val_accuracy: 0.8546\n",
      "Epoch 26/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.3330 - accuracy: 0.8524 - val_loss: 0.3260 - val_accuracy: 0.8605\n",
      "Epoch 27/6000\n",
      "128/128 [==============================] - 17s 136ms/step - loss: 0.3288 - accuracy: 0.8540 - val_loss: 0.3189 - val_accuracy: 0.8622\n",
      "Epoch 28/6000\n",
      "128/128 [==============================] - 22s 169ms/step - loss: 0.3262 - accuracy: 0.8553 - val_loss: 0.3206 - val_accuracy: 0.8624\n",
      "Epoch 29/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.3231 - accuracy: 0.8574 - val_loss: 0.3142 - val_accuracy: 0.8666\n",
      "Epoch 30/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.3185 - accuracy: 0.8600 - val_loss: 0.3088 - val_accuracy: 0.8695\n",
      "Epoch 31/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.3158 - accuracy: 0.8613 - val_loss: 0.3066 - val_accuracy: 0.8681\n",
      "Epoch 32/6000\n",
      "128/128 [==============================] - 17s 134ms/step - loss: 0.3113 - accuracy: 0.8631 - val_loss: 0.3033 - val_accuracy: 0.8714\n",
      "Epoch 33/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.3092 - accuracy: 0.8639 - val_loss: 0.2999 - val_accuracy: 0.8723\n",
      "Epoch 34/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.3044 - accuracy: 0.8669 - val_loss: 0.2953 - val_accuracy: 0.8747\n",
      "Epoch 35/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.3018 - accuracy: 0.8678 - val_loss: 0.2936 - val_accuracy: 0.8745\n",
      "Epoch 36/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.2999 - accuracy: 0.8691 - val_loss: 0.2940 - val_accuracy: 0.8754\n",
      "Epoch 37/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.2956 - accuracy: 0.8714 - val_loss: 0.2904 - val_accuracy: 0.8776\n",
      "Epoch 38/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.2935 - accuracy: 0.8728 - val_loss: 0.2876 - val_accuracy: 0.8804\n",
      "Epoch 39/6000\n",
      "128/128 [==============================] - 16s 128ms/step - loss: 0.2919 - accuracy: 0.8737 - val_loss: 0.2898 - val_accuracy: 0.8780\n",
      "Epoch 40/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.2901 - accuracy: 0.8743 - val_loss: 0.2820 - val_accuracy: 0.8822\n",
      "Epoch 41/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.2860 - accuracy: 0.8760 - val_loss: 0.2871 - val_accuracy: 0.8796\n",
      "Epoch 42/6000\n",
      "128/128 [==============================] - 21s 167ms/step - loss: 0.2839 - accuracy: 0.8772 - val_loss: 0.2825 - val_accuracy: 0.8832\n",
      "Epoch 43/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.2814 - accuracy: 0.8790 - val_loss: 0.2801 - val_accuracy: 0.8820\n",
      "Epoch 44/6000\n",
      "128/128 [==============================] - 17s 135ms/step - loss: 0.2790 - accuracy: 0.8795 - val_loss: 0.2777 - val_accuracy: 0.8848\n",
      "Epoch 45/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.2769 - accuracy: 0.8808 - val_loss: 0.2755 - val_accuracy: 0.8858\n",
      "Epoch 46/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.2741 - accuracy: 0.8824 - val_loss: 0.2782 - val_accuracy: 0.8837\n",
      "Epoch 47/6000\n",
      "128/128 [==============================] - 20s 157ms/step - loss: 0.2721 - accuracy: 0.8830 - val_loss: 0.2750 - val_accuracy: 0.8854\n",
      "Epoch 48/6000\n",
      "128/128 [==============================] - 20s 151ms/step - loss: 0.2719 - accuracy: 0.8835 - val_loss: 0.2697 - val_accuracy: 0.8892\n",
      "Epoch 49/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.2680 - accuracy: 0.8850 - val_loss: 0.2677 - val_accuracy: 0.8890\n",
      "Epoch 50/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.2665 - accuracy: 0.8851 - val_loss: 0.2689 - val_accuracy: 0.8903\n",
      "Epoch 51/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.2653 - accuracy: 0.8870 - val_loss: 0.2689 - val_accuracy: 0.8892\n",
      "Epoch 52/6000\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 0.2615 - accuracy: 0.8890 - val_loss: 0.2613 - val_accuracy: 0.8933\n",
      "Epoch 53/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.2612 - accuracy: 0.8881 - val_loss: 0.2584 - val_accuracy: 0.8939\n",
      "Epoch 54/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.2583 - accuracy: 0.8902 - val_loss: 0.2570 - val_accuracy: 0.8951\n",
      "Epoch 55/6000\n",
      "128/128 [==============================] - 20s 158ms/step - loss: 0.2565 - accuracy: 0.8909 - val_loss: 0.2566 - val_accuracy: 0.8960\n",
      "Epoch 56/6000\n",
      "128/128 [==============================] - 19s 150ms/step - loss: 0.2546 - accuracy: 0.8912 - val_loss: 0.2523 - val_accuracy: 0.8973\n",
      "Epoch 57/6000\n",
      "128/128 [==============================] - 25s 192ms/step - loss: 0.2534 - accuracy: 0.8926 - val_loss: 0.2545 - val_accuracy: 0.8966\n",
      "Epoch 58/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.2520 - accuracy: 0.8931 - val_loss: 0.2518 - val_accuracy: 0.8972\n",
      "Epoch 59/6000\n",
      "128/128 [==============================] - 19s 150ms/step - loss: 0.2497 - accuracy: 0.8944 - val_loss: 0.2510 - val_accuracy: 0.8986\n",
      "Epoch 60/6000\n",
      "128/128 [==============================] - 19s 151ms/step - loss: 0.2476 - accuracy: 0.8948 - val_loss: 0.2488 - val_accuracy: 0.8992\n",
      "Epoch 61/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.2458 - accuracy: 0.8960 - val_loss: 0.2468 - val_accuracy: 0.9011\n",
      "Epoch 62/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.2444 - accuracy: 0.8974 - val_loss: 0.2477 - val_accuracy: 0.8997\n",
      "Epoch 63/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.2434 - accuracy: 0.8972 - val_loss: 0.2452 - val_accuracy: 0.9018\n",
      "Epoch 64/6000\n",
      "128/128 [==============================] - 17s 135ms/step - loss: 0.2414 - accuracy: 0.8986 - val_loss: 0.2492 - val_accuracy: 0.8997\n",
      "Epoch 65/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.2417 - accuracy: 0.8978 - val_loss: 0.2507 - val_accuracy: 0.8998\n",
      "Epoch 66/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.2391 - accuracy: 0.9000 - val_loss: 0.2457 - val_accuracy: 0.9023\n",
      "Epoch 67/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.2364 - accuracy: 0.9013 - val_loss: 0.2458 - val_accuracy: 0.9014\n",
      "Epoch 68/6000\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 0.2373 - accuracy: 0.9003 - val_loss: 0.2457 - val_accuracy: 0.9021\n",
      "Epoch 69/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.2354 - accuracy: 0.9016 - val_loss: 0.2409 - val_accuracy: 0.9036\n",
      "Epoch 70/6000\n",
      "128/128 [==============================] - 17s 133ms/step - loss: 0.2319 - accuracy: 0.9030 - val_loss: 0.2452 - val_accuracy: 0.9026\n",
      "Epoch 71/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.2325 - accuracy: 0.9027 - val_loss: 0.2409 - val_accuracy: 0.9048\n",
      "Epoch 72/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.2300 - accuracy: 0.9037 - val_loss: 0.2400 - val_accuracy: 0.9051\n",
      "Epoch 73/6000\n",
      "128/128 [==============================] - 23s 184ms/step - loss: 0.2311 - accuracy: 0.9031 - val_loss: 0.2413 - val_accuracy: 0.9051\n",
      "Epoch 74/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.2283 - accuracy: 0.9050 - val_loss: 0.2365 - val_accuracy: 0.9071\n",
      "Epoch 75/6000\n",
      "128/128 [==============================] - 17s 134ms/step - loss: 0.2276 - accuracy: 0.9048 - val_loss: 0.2407 - val_accuracy: 0.9054\n",
      "Epoch 76/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.2253 - accuracy: 0.9060 - val_loss: 0.2349 - val_accuracy: 0.9068\n",
      "Epoch 77/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.2271 - accuracy: 0.9054 - val_loss: 0.2427 - val_accuracy: 0.9064\n",
      "Epoch 78/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.2234 - accuracy: 0.9070 - val_loss: 0.2368 - val_accuracy: 0.9066\n",
      "Epoch 79/6000\n",
      "128/128 [==============================] - 17s 131ms/step - loss: 0.2220 - accuracy: 0.9080 - val_loss: 0.2325 - val_accuracy: 0.9079\n",
      "Epoch 80/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.2201 - accuracy: 0.9089 - val_loss: 0.2302 - val_accuracy: 0.9073\n",
      "Epoch 81/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.2191 - accuracy: 0.9089 - val_loss: 0.2309 - val_accuracy: 0.9102\n",
      "Epoch 82/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.2179 - accuracy: 0.9095 - val_loss: 0.2304 - val_accuracy: 0.9102\n",
      "Epoch 83/6000\n",
      "128/128 [==============================] - 17s 134ms/step - loss: 0.2186 - accuracy: 0.9097 - val_loss: 0.2308 - val_accuracy: 0.9095\n",
      "Epoch 84/6000\n",
      "128/128 [==============================] - 23s 175ms/step - loss: 0.2169 - accuracy: 0.9104 - val_loss: 0.2265 - val_accuracy: 0.9110\n",
      "Epoch 85/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.2153 - accuracy: 0.9109 - val_loss: 0.2304 - val_accuracy: 0.9102\n",
      "Epoch 86/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.2149 - accuracy: 0.9108 - val_loss: 0.2261 - val_accuracy: 0.9129\n",
      "Epoch 87/6000\n",
      "128/128 [==============================] - 18s 139ms/step - loss: 0.2127 - accuracy: 0.9121 - val_loss: 0.2292 - val_accuracy: 0.9107\n",
      "Epoch 88/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.2110 - accuracy: 0.9132 - val_loss: 0.2212 - val_accuracy: 0.9133\n",
      "Epoch 89/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.2109 - accuracy: 0.9134 - val_loss: 0.2295 - val_accuracy: 0.9126\n",
      "Epoch 90/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.2086 - accuracy: 0.9140 - val_loss: 0.2218 - val_accuracy: 0.9147\n",
      "Epoch 91/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.2083 - accuracy: 0.9143 - val_loss: 0.2212 - val_accuracy: 0.9147\n",
      "Epoch 92/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.2071 - accuracy: 0.9149 - val_loss: 0.2191 - val_accuracy: 0.9159\n",
      "Epoch 93/6000\n",
      "128/128 [==============================] - 18s 145ms/step - loss: 0.2069 - accuracy: 0.9147 - val_loss: 0.2235 - val_accuracy: 0.9135\n",
      "Epoch 94/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.2065 - accuracy: 0.9153 - val_loss: 0.2199 - val_accuracy: 0.9171\n",
      "Epoch 95/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.2057 - accuracy: 0.9153 - val_loss: 0.2197 - val_accuracy: 0.9153\n",
      "Epoch 96/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.2034 - accuracy: 0.9167 - val_loss: 0.2180 - val_accuracy: 0.9165\n",
      "Epoch 97/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.2023 - accuracy: 0.9169 - val_loss: 0.2212 - val_accuracy: 0.9157\n",
      "Epoch 98/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.2011 - accuracy: 0.9172 - val_loss: 0.2213 - val_accuracy: 0.9142\n",
      "Epoch 99/6000\n",
      "128/128 [==============================] - 18s 137ms/step - loss: 0.2012 - accuracy: 0.9171 - val_loss: 0.2201 - val_accuracy: 0.9157\n",
      "Epoch 100/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.2008 - accuracy: 0.9184 - val_loss: 0.2145 - val_accuracy: 0.9176\n",
      "Epoch 101/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.1988 - accuracy: 0.9192 - val_loss: 0.2123 - val_accuracy: 0.9187\n",
      "Epoch 102/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1992 - accuracy: 0.9190 - val_loss: 0.2156 - val_accuracy: 0.9179\n",
      "Epoch 103/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.1982 - accuracy: 0.9191 - val_loss: 0.2094 - val_accuracy: 0.9203\n",
      "Epoch 104/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1976 - accuracy: 0.9198 - val_loss: 0.2154 - val_accuracy: 0.9174\n",
      "Epoch 105/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1945 - accuracy: 0.9208 - val_loss: 0.2139 - val_accuracy: 0.9185\n",
      "Epoch 106/6000\n",
      "128/128 [==============================] - 19s 149ms/step - loss: 0.1950 - accuracy: 0.9207 - val_loss: 0.2124 - val_accuracy: 0.9200\n",
      "Epoch 107/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.1935 - accuracy: 0.9215 - val_loss: 0.2109 - val_accuracy: 0.9201\n",
      "Epoch 108/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1924 - accuracy: 0.9218 - val_loss: 0.2100 - val_accuracy: 0.9210\n",
      "Epoch 109/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1914 - accuracy: 0.9220 - val_loss: 0.2128 - val_accuracy: 0.9203\n",
      "Epoch 110/6000\n",
      "128/128 [==============================] - 17s 136ms/step - loss: 0.1917 - accuracy: 0.9226 - val_loss: 0.2153 - val_accuracy: 0.9192\n",
      "Epoch 111/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1910 - accuracy: 0.9227 - val_loss: 0.2117 - val_accuracy: 0.9201\n",
      "Epoch 112/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.1875 - accuracy: 0.9237 - val_loss: 0.2161 - val_accuracy: 0.9182\n",
      "Epoch 113/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1885 - accuracy: 0.9238 - val_loss: 0.2083 - val_accuracy: 0.9208\n",
      "Epoch 114/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1876 - accuracy: 0.9237 - val_loss: 0.2070 - val_accuracy: 0.9222\n",
      "Epoch 115/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1876 - accuracy: 0.9239 - val_loss: 0.2031 - val_accuracy: 0.9231\n",
      "Epoch 116/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.1858 - accuracy: 0.9249 - val_loss: 0.2062 - val_accuracy: 0.9215\n",
      "Epoch 117/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1861 - accuracy: 0.9249 - val_loss: 0.2102 - val_accuracy: 0.9199\n",
      "Epoch 118/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.1846 - accuracy: 0.9258 - val_loss: 0.2077 - val_accuracy: 0.9231\n",
      "Epoch 119/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1850 - accuracy: 0.9256 - val_loss: 0.2065 - val_accuracy: 0.9218\n",
      "Epoch 120/6000\n",
      "128/128 [==============================] - 20s 158ms/step - loss: 0.1817 - accuracy: 0.9269 - val_loss: 0.2047 - val_accuracy: 0.9245\n",
      "Epoch 121/6000\n",
      "128/128 [==============================] - 20s 153ms/step - loss: 0.1834 - accuracy: 0.9264 - val_loss: 0.2059 - val_accuracy: 0.9229\n",
      "Epoch 122/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1842 - accuracy: 0.9256 - val_loss: 0.2058 - val_accuracy: 0.9237\n",
      "Epoch 123/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1824 - accuracy: 0.9264 - val_loss: 0.2038 - val_accuracy: 0.9225\n",
      "Epoch 124/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1822 - accuracy: 0.9266 - val_loss: 0.2097 - val_accuracy: 0.9220\n",
      "Epoch 125/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1806 - accuracy: 0.9278 - val_loss: 0.2013 - val_accuracy: 0.9261\n",
      "Epoch 126/6000\n",
      "128/128 [==============================] - 22s 169ms/step - loss: 0.1807 - accuracy: 0.9273 - val_loss: 0.2011 - val_accuracy: 0.9259\n",
      "Epoch 127/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.1767 - accuracy: 0.9291 - val_loss: 0.2036 - val_accuracy: 0.9252\n",
      "Epoch 128/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.1761 - accuracy: 0.9290 - val_loss: 0.2016 - val_accuracy: 0.9259\n",
      "Epoch 129/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.1769 - accuracy: 0.9288 - val_loss: 0.2035 - val_accuracy: 0.9249\n",
      "Epoch 130/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1767 - accuracy: 0.9290 - val_loss: 0.2007 - val_accuracy: 0.9258\n",
      "Epoch 131/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.1770 - accuracy: 0.9289 - val_loss: 0.1976 - val_accuracy: 0.9274\n",
      "Epoch 132/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.1756 - accuracy: 0.9295 - val_loss: 0.2005 - val_accuracy: 0.9265\n",
      "Epoch 133/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1743 - accuracy: 0.9300 - val_loss: 0.1993 - val_accuracy: 0.9266\n",
      "Epoch 134/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1741 - accuracy: 0.9305 - val_loss: 0.2036 - val_accuracy: 0.9239\n",
      "Epoch 135/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1739 - accuracy: 0.9306 - val_loss: 0.1998 - val_accuracy: 0.9260\n",
      "Epoch 136/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.1729 - accuracy: 0.9312 - val_loss: 0.1962 - val_accuracy: 0.9281\n",
      "Epoch 137/6000\n",
      "128/128 [==============================] - 20s 153ms/step - loss: 0.1704 - accuracy: 0.9322 - val_loss: 0.1977 - val_accuracy: 0.9274\n",
      "Epoch 138/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1691 - accuracy: 0.9324 - val_loss: 0.1984 - val_accuracy: 0.9271\n",
      "Epoch 139/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.1697 - accuracy: 0.9321 - val_loss: 0.2004 - val_accuracy: 0.9281\n",
      "Epoch 140/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.1715 - accuracy: 0.9312 - val_loss: 0.1955 - val_accuracy: 0.9282\n",
      "Epoch 141/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.1689 - accuracy: 0.9334 - val_loss: 0.1946 - val_accuracy: 0.9292\n",
      "Epoch 142/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1687 - accuracy: 0.9329 - val_loss: 0.1929 - val_accuracy: 0.9307\n",
      "Epoch 143/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.1684 - accuracy: 0.9333 - val_loss: 0.1950 - val_accuracy: 0.9285\n",
      "Epoch 144/6000\n",
      "128/128 [==============================] - 22s 167ms/step - loss: 0.1656 - accuracy: 0.9344 - val_loss: 0.2027 - val_accuracy: 0.9262\n",
      "Epoch 145/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1680 - accuracy: 0.9329 - val_loss: 0.2007 - val_accuracy: 0.9283\n",
      "Epoch 146/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1646 - accuracy: 0.9345 - val_loss: 0.2011 - val_accuracy: 0.9276\n",
      "Epoch 147/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1674 - accuracy: 0.9338 - val_loss: 0.1945 - val_accuracy: 0.9288\n",
      "Epoch 148/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1659 - accuracy: 0.9340 - val_loss: 0.1977 - val_accuracy: 0.9271\n",
      "Epoch 149/6000\n",
      "128/128 [==============================] - 20s 153ms/step - loss: 0.1648 - accuracy: 0.9345 - val_loss: 0.1927 - val_accuracy: 0.9300\n",
      "Epoch 150/6000\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 0.1650 - accuracy: 0.9344 - val_loss: 0.1934 - val_accuracy: 0.9297\n",
      "Epoch 151/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.1638 - accuracy: 0.9352 - val_loss: 0.1981 - val_accuracy: 0.9287\n",
      "Epoch 152/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1636 - accuracy: 0.9353 - val_loss: 0.1920 - val_accuracy: 0.9309\n",
      "Epoch 153/6000\n",
      "128/128 [==============================] - 20s 156ms/step - loss: 0.1618 - accuracy: 0.9356 - val_loss: 0.1927 - val_accuracy: 0.9303\n",
      "Epoch 154/6000\n",
      "128/128 [==============================] - 21s 161ms/step - loss: 0.1615 - accuracy: 0.9359 - val_loss: 0.1938 - val_accuracy: 0.9307\n",
      "Epoch 155/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1627 - accuracy: 0.9354 - val_loss: 0.1945 - val_accuracy: 0.9291\n",
      "Epoch 156/6000\n",
      "128/128 [==============================] - 23s 184ms/step - loss: 0.1600 - accuracy: 0.9371 - val_loss: 0.1896 - val_accuracy: 0.9325\n",
      "Epoch 157/6000\n",
      "128/128 [==============================] - 20s 156ms/step - loss: 0.1589 - accuracy: 0.9376 - val_loss: 0.1869 - val_accuracy: 0.9317\n",
      "Epoch 158/6000\n",
      "128/128 [==============================] - 20s 156ms/step - loss: 0.1594 - accuracy: 0.9367 - val_loss: 0.1931 - val_accuracy: 0.9311\n",
      "Epoch 159/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1593 - accuracy: 0.9373 - val_loss: 0.1917 - val_accuracy: 0.9323\n",
      "Epoch 160/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1575 - accuracy: 0.9383 - val_loss: 0.1899 - val_accuracy: 0.9314\n",
      "Epoch 161/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1568 - accuracy: 0.9385 - val_loss: 0.1903 - val_accuracy: 0.9321\n",
      "Epoch 162/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1577 - accuracy: 0.9377 - val_loss: 0.1918 - val_accuracy: 0.9309\n",
      "Epoch 163/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1573 - accuracy: 0.9376 - val_loss: 0.1865 - val_accuracy: 0.9332\n",
      "Epoch 164/6000\n",
      "128/128 [==============================] - 18s 139ms/step - loss: 0.1562 - accuracy: 0.9380 - val_loss: 0.1944 - val_accuracy: 0.9308\n",
      "Epoch 165/6000\n",
      "128/128 [==============================] - 24s 184ms/step - loss: 0.1577 - accuracy: 0.9377 - val_loss: 0.1949 - val_accuracy: 0.9308\n",
      "Epoch 166/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.1545 - accuracy: 0.9400 - val_loss: 0.1870 - val_accuracy: 0.9334\n",
      "Epoch 167/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.1557 - accuracy: 0.9386 - val_loss: 0.1915 - val_accuracy: 0.9314\n",
      "Epoch 168/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1532 - accuracy: 0.9398 - val_loss: 0.1906 - val_accuracy: 0.9319\n",
      "Epoch 169/6000\n",
      "128/128 [==============================] - 24s 184ms/step - loss: 0.1540 - accuracy: 0.9393 - val_loss: 0.1820 - val_accuracy: 0.9363\n",
      "Epoch 170/6000\n",
      "128/128 [==============================] - 18s 139ms/step - loss: 0.1518 - accuracy: 0.9402 - val_loss: 0.1891 - val_accuracy: 0.9322\n",
      "Epoch 171/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.1531 - accuracy: 0.9398 - val_loss: 0.1856 - val_accuracy: 0.9341\n",
      "Epoch 172/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1535 - accuracy: 0.9397 - val_loss: 0.1954 - val_accuracy: 0.9310\n",
      "Epoch 173/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.1517 - accuracy: 0.9407 - val_loss: 0.1870 - val_accuracy: 0.9338\n",
      "Epoch 174/6000\n",
      "128/128 [==============================] - 18s 145ms/step - loss: 0.1513 - accuracy: 0.9406 - val_loss: 0.1880 - val_accuracy: 0.9340\n",
      "Epoch 175/6000\n",
      "128/128 [==============================] - 20s 158ms/step - loss: 0.1516 - accuracy: 0.9409 - val_loss: 0.1900 - val_accuracy: 0.9332\n",
      "Epoch 176/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1505 - accuracy: 0.9410 - val_loss: 0.1830 - val_accuracy: 0.9355\n",
      "Epoch 177/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1490 - accuracy: 0.9418 - val_loss: 0.1855 - val_accuracy: 0.9343\n",
      "Epoch 178/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1482 - accuracy: 0.9416 - val_loss: 0.1890 - val_accuracy: 0.9343\n",
      "Epoch 179/6000\n",
      "128/128 [==============================] - 17s 133ms/step - loss: 0.1485 - accuracy: 0.9420 - val_loss: 0.1920 - val_accuracy: 0.9319\n",
      "Epoch 180/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1498 - accuracy: 0.9415 - val_loss: 0.1873 - val_accuracy: 0.9341\n",
      "Epoch 181/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1483 - accuracy: 0.9417 - val_loss: 0.1869 - val_accuracy: 0.9349\n",
      "Epoch 182/6000\n",
      "128/128 [==============================] - 17s 130ms/step - loss: 0.1497 - accuracy: 0.9415 - val_loss: 0.1835 - val_accuracy: 0.9356\n",
      "Epoch 183/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1461 - accuracy: 0.9429 - val_loss: 0.1871 - val_accuracy: 0.9348\n",
      "Epoch 184/6000\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 0.1452 - accuracy: 0.9430 - val_loss: 0.1932 - val_accuracy: 0.9342\n",
      "Epoch 184: early stopping\n",
      "##########################################################################\n",
      "------val_accuracy-----> 93.63 | 94.3 <----------accuracy----------\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/ENS-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/ENS-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "working on pair: DOGE/USDT\n",
      "One_pair_AI_Gen : DOGE/USDT\n",
      "price_volatility_15m:0.55%\n",
      "mini_expand : DOGE/USDT\n",
      "---buy_simple_up--- Buy pct: 0.55%\n",
      "---buy_only--- Max time window: 10%\n",
      "---buy_only--- no b\n",
      "---buy_only--- no sell\n",
      "df original shape (932520, 1607)\n",
      "df original shape buy mean : 10.481812722515334\n",
      "df choosen data shape(500000, 1607)\n",
      "pair: True\n",
      "100000\n",
      "normalizing ...\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/DOGE-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_88 (Dense)            (None, 250)               401750    \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 250)               0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 20)                5020      \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,871\n",
      "Trainable params: 407,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_UP_CLOSE/DOGE-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "Epoch 1/6000\n",
      "157/157 [==============================] - 38s 178ms/step - loss: 0.5384 - accuracy: 0.7334 - val_loss: 0.5174 - val_accuracy: 0.7456\n",
      "Epoch 2/6000\n",
      "157/157 [==============================] - 22s 142ms/step - loss: 0.5147 - accuracy: 0.7487 - val_loss: 0.5036 - val_accuracy: 0.7555\n",
      "Epoch 3/6000\n",
      "157/157 [==============================] - 21s 137ms/step - loss: 0.5020 - accuracy: 0.7558 - val_loss: 0.4902 - val_accuracy: 0.7624\n",
      "Epoch 4/6000\n",
      "157/157 [==============================] - 22s 137ms/step - loss: 0.4895 - accuracy: 0.7631 - val_loss: 0.4824 - val_accuracy: 0.7685\n",
      "Epoch 5/6000\n",
      "157/157 [==============================] - 22s 138ms/step - loss: 0.4765 - accuracy: 0.7710 - val_loss: 0.4654 - val_accuracy: 0.7771\n",
      "Epoch 6/6000\n",
      "157/157 [==============================] - 21s 136ms/step - loss: 0.4644 - accuracy: 0.7777 - val_loss: 0.4533 - val_accuracy: 0.7840\n",
      "Epoch 7/6000\n",
      "157/157 [==============================] - 21s 136ms/step - loss: 0.4516 - accuracy: 0.7865 - val_loss: 0.4400 - val_accuracy: 0.7924\n",
      "Epoch 8/6000\n",
      "157/157 [==============================] - 22s 138ms/step - loss: 0.4402 - accuracy: 0.7932 - val_loss: 0.4325 - val_accuracy: 0.7970\n",
      "Epoch 9/6000\n",
      "157/157 [==============================] - 21s 132ms/step - loss: 0.4298 - accuracy: 0.7999 - val_loss: 0.4245 - val_accuracy: 0.8038\n",
      "Epoch 10/6000\n",
      "157/157 [==============================] - 26s 168ms/step - loss: 0.4218 - accuracy: 0.8055 - val_loss: 0.4078 - val_accuracy: 0.8134\n",
      "Epoch 11/6000\n",
      "157/157 [==============================] - 23s 145ms/step - loss: 0.4111 - accuracy: 0.8121 - val_loss: 0.4028 - val_accuracy: 0.8169\n",
      "Epoch 12/6000\n",
      "157/157 [==============================] - 24s 152ms/step - loss: 0.4037 - accuracy: 0.8163 - val_loss: 0.3914 - val_accuracy: 0.8243\n",
      "Epoch 13/6000\n",
      "157/157 [==============================] - 27s 169ms/step - loss: 0.3946 - accuracy: 0.8219 - val_loss: 0.3859 - val_accuracy: 0.8267\n",
      "Epoch 14/6000\n",
      "157/157 [==============================] - 26s 164ms/step - loss: 0.3875 - accuracy: 0.8258 - val_loss: 0.3794 - val_accuracy: 0.8331\n",
      "Epoch 15/6000\n",
      "157/157 [==============================] - 24s 150ms/step - loss: 0.3819 - accuracy: 0.8296 - val_loss: 0.3726 - val_accuracy: 0.8359\n",
      "Epoch 16/6000\n",
      "157/157 [==============================] - 24s 150ms/step - loss: 0.3757 - accuracy: 0.8330 - val_loss: 0.3695 - val_accuracy: 0.8373\n",
      "Epoch 17/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.3684 - accuracy: 0.8374 - val_loss: 0.3633 - val_accuracy: 0.8402\n",
      "Epoch 18/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.3638 - accuracy: 0.8404 - val_loss: 0.3540 - val_accuracy: 0.8470\n",
      "Epoch 19/6000\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.3577 - accuracy: 0.8440 - val_loss: 0.3529 - val_accuracy: 0.8461\n",
      "Epoch 20/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.3516 - accuracy: 0.8470 - val_loss: 0.3463 - val_accuracy: 0.8499\n",
      "Epoch 21/6000\n",
      "157/157 [==============================] - 22s 137ms/step - loss: 0.3487 - accuracy: 0.8482 - val_loss: 0.3403 - val_accuracy: 0.8539\n",
      "Epoch 22/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.3450 - accuracy: 0.8506 - val_loss: 0.3369 - val_accuracy: 0.8569\n",
      "Epoch 23/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.3399 - accuracy: 0.8529 - val_loss: 0.3352 - val_accuracy: 0.8569\n",
      "Epoch 24/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.3377 - accuracy: 0.8548 - val_loss: 0.3354 - val_accuracy: 0.8573\n",
      "Epoch 25/6000\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.3327 - accuracy: 0.8570 - val_loss: 0.3294 - val_accuracy: 0.8607\n",
      "Epoch 26/6000\n",
      "157/157 [==============================] - 26s 169ms/step - loss: 0.3290 - accuracy: 0.8590 - val_loss: 0.3278 - val_accuracy: 0.8605\n",
      "Epoch 27/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.3255 - accuracy: 0.8613 - val_loss: 0.3227 - val_accuracy: 0.8636\n",
      "Epoch 28/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.3229 - accuracy: 0.8627 - val_loss: 0.3223 - val_accuracy: 0.8633\n",
      "Epoch 29/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.3202 - accuracy: 0.8636 - val_loss: 0.3162 - val_accuracy: 0.8676\n",
      "Epoch 30/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.3161 - accuracy: 0.8662 - val_loss: 0.3135 - val_accuracy: 0.8700\n",
      "Epoch 31/6000\n",
      "157/157 [==============================] - 22s 143ms/step - loss: 0.3131 - accuracy: 0.8672 - val_loss: 0.3124 - val_accuracy: 0.8697\n",
      "Epoch 32/6000\n",
      "157/157 [==============================] - 28s 175ms/step - loss: 0.3115 - accuracy: 0.8682 - val_loss: 0.3086 - val_accuracy: 0.8713\n",
      "Epoch 33/6000\n",
      "157/157 [==============================] - 26s 162ms/step - loss: 0.3070 - accuracy: 0.8708 - val_loss: 0.3070 - val_accuracy: 0.8722\n",
      "Epoch 34/6000\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.3057 - accuracy: 0.8713 - val_loss: 0.3079 - val_accuracy: 0.8719\n",
      "Epoch 35/6000\n",
      "157/157 [==============================] - 34s 215ms/step - loss: 0.3041 - accuracy: 0.8723 - val_loss: 0.3037 - val_accuracy: 0.8740\n",
      "Epoch 36/6000\n",
      "157/157 [==============================] - 22s 140ms/step - loss: 0.3018 - accuracy: 0.8732 - val_loss: 0.3018 - val_accuracy: 0.8747\n",
      "Epoch 37/6000\n",
      "157/157 [==============================] - 31s 197ms/step - loss: 0.2973 - accuracy: 0.8754 - val_loss: 0.2986 - val_accuracy: 0.8761\n",
      "Epoch 38/6000\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.2951 - accuracy: 0.8765 - val_loss: 0.2955 - val_accuracy: 0.8781\n",
      "Epoch 39/6000\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.2933 - accuracy: 0.8774 - val_loss: 0.2938 - val_accuracy: 0.8787\n",
      "Epoch 40/6000\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.2915 - accuracy: 0.8784 - val_loss: 0.2944 - val_accuracy: 0.8789\n",
      "Epoch 41/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.2896 - accuracy: 0.8800 - val_loss: 0.2899 - val_accuracy: 0.8833\n",
      "Epoch 42/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.2869 - accuracy: 0.8808 - val_loss: 0.2852 - val_accuracy: 0.8843\n",
      "Epoch 43/6000\n",
      "157/157 [==============================] - 28s 181ms/step - loss: 0.2846 - accuracy: 0.8817 - val_loss: 0.2903 - val_accuracy: 0.8812\n",
      "Epoch 44/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.2834 - accuracy: 0.8826 - val_loss: 0.2882 - val_accuracy: 0.8823\n",
      "Epoch 45/6000\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 0.2814 - accuracy: 0.8835 - val_loss: 0.2866 - val_accuracy: 0.8834\n",
      "Epoch 46/6000\n",
      "157/157 [==============================] - 21s 133ms/step - loss: 0.2786 - accuracy: 0.8849 - val_loss: 0.2850 - val_accuracy: 0.8847\n",
      "Epoch 47/6000\n",
      "157/157 [==============================] - 30s 189ms/step - loss: 0.2778 - accuracy: 0.8855 - val_loss: 0.2928 - val_accuracy: 0.8802\n",
      "Epoch 48/6000\n",
      "157/157 [==============================] - 23s 148ms/step - loss: 0.2759 - accuracy: 0.8861 - val_loss: 0.2792 - val_accuracy: 0.8883\n",
      "Epoch 49/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.2763 - accuracy: 0.8863 - val_loss: 0.2789 - val_accuracy: 0.8874\n",
      "Epoch 50/6000\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 0.2716 - accuracy: 0.8885 - val_loss: 0.2793 - val_accuracy: 0.8873\n",
      "Epoch 51/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.2701 - accuracy: 0.8892 - val_loss: 0.2760 - val_accuracy: 0.8879\n",
      "Epoch 52/6000\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 0.2680 - accuracy: 0.8900 - val_loss: 0.2791 - val_accuracy: 0.8870\n",
      "Epoch 53/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.2670 - accuracy: 0.8912 - val_loss: 0.2732 - val_accuracy: 0.8903\n",
      "Epoch 54/6000\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.2657 - accuracy: 0.8912 - val_loss: 0.2779 - val_accuracy: 0.8885\n",
      "Epoch 55/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.2652 - accuracy: 0.8917 - val_loss: 0.2729 - val_accuracy: 0.8896\n",
      "Epoch 56/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.2637 - accuracy: 0.8924 - val_loss: 0.2756 - val_accuracy: 0.8882\n",
      "Epoch 57/6000\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 0.2623 - accuracy: 0.8924 - val_loss: 0.2696 - val_accuracy: 0.8916\n",
      "Epoch 58/6000\n",
      "157/157 [==============================] - 25s 161ms/step - loss: 0.2604 - accuracy: 0.8940 - val_loss: 0.2721 - val_accuracy: 0.8918\n",
      "Epoch 59/6000\n",
      "157/157 [==============================] - 31s 199ms/step - loss: 0.2595 - accuracy: 0.8940 - val_loss: 0.2762 - val_accuracy: 0.8900\n",
      "Epoch 60/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.2567 - accuracy: 0.8957 - val_loss: 0.2669 - val_accuracy: 0.8926\n",
      "Epoch 61/6000\n",
      "157/157 [==============================] - 25s 157ms/step - loss: 0.2566 - accuracy: 0.8961 - val_loss: 0.2690 - val_accuracy: 0.8922\n",
      "Epoch 62/6000\n",
      "157/157 [==============================] - 23s 147ms/step - loss: 0.2547 - accuracy: 0.8967 - val_loss: 0.2696 - val_accuracy: 0.8924\n",
      "Epoch 63/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.2530 - accuracy: 0.8972 - val_loss: 0.2717 - val_accuracy: 0.8918\n",
      "Epoch 64/6000\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 0.2529 - accuracy: 0.8972 - val_loss: 0.2640 - val_accuracy: 0.8950\n",
      "Epoch 65/6000\n",
      "157/157 [==============================] - 28s 175ms/step - loss: 0.2528 - accuracy: 0.8977 - val_loss: 0.2611 - val_accuracy: 0.8946\n",
      "Epoch 66/6000\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 0.2496 - accuracy: 0.8990 - val_loss: 0.2624 - val_accuracy: 0.8953\n",
      "Epoch 67/6000\n",
      "157/157 [==============================] - 27s 168ms/step - loss: 0.2490 - accuracy: 0.8991 - val_loss: 0.2556 - val_accuracy: 0.8994\n",
      "Epoch 68/6000\n",
      "157/157 [==============================] - 24s 153ms/step - loss: 0.2471 - accuracy: 0.9005 - val_loss: 0.2627 - val_accuracy: 0.8964\n",
      "Epoch 69/6000\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.2447 - accuracy: 0.9014 - val_loss: 0.2608 - val_accuracy: 0.8967\n",
      "Epoch 70/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.2458 - accuracy: 0.9008 - val_loss: 0.2600 - val_accuracy: 0.8983\n",
      "Epoch 71/6000\n",
      "157/157 [==============================] - 29s 181ms/step - loss: 0.2443 - accuracy: 0.9014 - val_loss: 0.2554 - val_accuracy: 0.9003\n",
      "Epoch 72/6000\n",
      "157/157 [==============================] - 26s 162ms/step - loss: 0.2430 - accuracy: 0.9020 - val_loss: 0.2611 - val_accuracy: 0.8968\n",
      "Epoch 73/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.2424 - accuracy: 0.9022 - val_loss: 0.2582 - val_accuracy: 0.8981\n",
      "Epoch 74/6000\n",
      "157/157 [==============================] - 28s 175ms/step - loss: 0.2414 - accuracy: 0.9023 - val_loss: 0.2563 - val_accuracy: 0.8991\n",
      "Epoch 75/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.2383 - accuracy: 0.9039 - val_loss: 0.2565 - val_accuracy: 0.8993\n",
      "Epoch 76/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.2384 - accuracy: 0.9040 - val_loss: 0.2486 - val_accuracy: 0.9028\n",
      "Epoch 77/6000\n",
      "157/157 [==============================] - 30s 190ms/step - loss: 0.2371 - accuracy: 0.9046 - val_loss: 0.2518 - val_accuracy: 0.9014\n",
      "Epoch 78/6000\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.2376 - accuracy: 0.9050 - val_loss: 0.2574 - val_accuracy: 0.8983\n",
      "Epoch 79/6000\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.2355 - accuracy: 0.9057 - val_loss: 0.2502 - val_accuracy: 0.9023\n",
      "Epoch 80/6000\n",
      "157/157 [==============================] - 21s 136ms/step - loss: 0.2348 - accuracy: 0.9054 - val_loss: 0.2530 - val_accuracy: 0.9012\n",
      "Epoch 81/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.2331 - accuracy: 0.9063 - val_loss: 0.2470 - val_accuracy: 0.9041\n",
      "Epoch 82/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.2325 - accuracy: 0.9069 - val_loss: 0.2538 - val_accuracy: 0.9010\n",
      "Epoch 83/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.2310 - accuracy: 0.9076 - val_loss: 0.2507 - val_accuracy: 0.9024\n",
      "Epoch 84/6000\n",
      "157/157 [==============================] - 25s 156ms/step - loss: 0.2318 - accuracy: 0.9072 - val_loss: 0.2479 - val_accuracy: 0.9036\n",
      "Epoch 85/6000\n",
      "157/157 [==============================] - 31s 194ms/step - loss: 0.2307 - accuracy: 0.9077 - val_loss: 0.2484 - val_accuracy: 0.9039\n",
      "Epoch 86/6000\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 0.2282 - accuracy: 0.9085 - val_loss: 0.2504 - val_accuracy: 0.9024\n",
      "Epoch 87/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.2276 - accuracy: 0.9092 - val_loss: 0.2516 - val_accuracy: 0.9014\n",
      "Epoch 88/6000\n",
      "157/157 [==============================] - 29s 182ms/step - loss: 0.2270 - accuracy: 0.9091 - val_loss: 0.2486 - val_accuracy: 0.9038\n",
      "Epoch 89/6000\n",
      "157/157 [==============================] - 21s 131ms/step - loss: 0.2276 - accuracy: 0.9089 - val_loss: 0.2469 - val_accuracy: 0.9049\n",
      "Epoch 90/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.2267 - accuracy: 0.9092 - val_loss: 0.2428 - val_accuracy: 0.9053\n",
      "Epoch 91/6000\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.2236 - accuracy: 0.9110 - val_loss: 0.2459 - val_accuracy: 0.9047\n",
      "Epoch 92/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.2238 - accuracy: 0.9106 - val_loss: 0.2450 - val_accuracy: 0.9056\n",
      "Epoch 93/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.2222 - accuracy: 0.9114 - val_loss: 0.2423 - val_accuracy: 0.9063\n",
      "Epoch 94/6000\n",
      "157/157 [==============================] - 30s 191ms/step - loss: 0.2215 - accuracy: 0.9118 - val_loss: 0.2509 - val_accuracy: 0.9018\n",
      "Epoch 95/6000\n",
      "157/157 [==============================] - 26s 164ms/step - loss: 0.2206 - accuracy: 0.9122 - val_loss: 0.2395 - val_accuracy: 0.9080\n",
      "Epoch 96/6000\n",
      "157/157 [==============================] - 23s 145ms/step - loss: 0.2205 - accuracy: 0.9119 - val_loss: 0.2520 - val_accuracy: 0.9021\n",
      "Epoch 97/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.2192 - accuracy: 0.9130 - val_loss: 0.2444 - val_accuracy: 0.9065\n",
      "Epoch 98/6000\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.2189 - accuracy: 0.9131 - val_loss: 0.2425 - val_accuracy: 0.9071\n",
      "Epoch 99/6000\n",
      "157/157 [==============================] - 29s 186ms/step - loss: 0.2169 - accuracy: 0.9137 - val_loss: 0.2440 - val_accuracy: 0.9060\n",
      "Epoch 100/6000\n",
      "157/157 [==============================] - 29s 181ms/step - loss: 0.2180 - accuracy: 0.9129 - val_loss: 0.2435 - val_accuracy: 0.9066\n",
      "Epoch 101/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.2156 - accuracy: 0.9144 - val_loss: 0.2432 - val_accuracy: 0.9070\n",
      "Epoch 102/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.2163 - accuracy: 0.9142 - val_loss: 0.2446 - val_accuracy: 0.9065\n",
      "Epoch 103/6000\n",
      "157/157 [==============================] - 27s 169ms/step - loss: 0.2166 - accuracy: 0.9137 - val_loss: 0.2463 - val_accuracy: 0.9058\n",
      "Epoch 104/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.2139 - accuracy: 0.9151 - val_loss: 0.2423 - val_accuracy: 0.9076\n",
      "Epoch 105/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.2129 - accuracy: 0.9157 - val_loss: 0.2424 - val_accuracy: 0.9078\n",
      "Epoch 106/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.2136 - accuracy: 0.9151 - val_loss: 0.2426 - val_accuracy: 0.9079\n",
      "Epoch 107/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.2120 - accuracy: 0.9164 - val_loss: 0.2446 - val_accuracy: 0.9073\n",
      "Epoch 108/6000\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.2112 - accuracy: 0.9164 - val_loss: 0.2340 - val_accuracy: 0.9109\n",
      "Epoch 109/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.2104 - accuracy: 0.9165 - val_loss: 0.2343 - val_accuracy: 0.9108\n",
      "Epoch 110/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.2092 - accuracy: 0.9175 - val_loss: 0.2357 - val_accuracy: 0.9104\n",
      "Epoch 111/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.2093 - accuracy: 0.9173 - val_loss: 0.2377 - val_accuracy: 0.9101\n",
      "Epoch 112/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.2077 - accuracy: 0.9179 - val_loss: 0.2434 - val_accuracy: 0.9079\n",
      "Epoch 113/6000\n",
      "157/157 [==============================] - 27s 175ms/step - loss: 0.2084 - accuracy: 0.9178 - val_loss: 0.2373 - val_accuracy: 0.9105\n",
      "Epoch 114/6000\n",
      "157/157 [==============================] - 25s 160ms/step - loss: 0.2064 - accuracy: 0.9187 - val_loss: 0.2351 - val_accuracy: 0.9108\n",
      "Epoch 115/6000\n",
      "157/157 [==============================] - 23s 146ms/step - loss: 0.2071 - accuracy: 0.9182 - val_loss: 0.2422 - val_accuracy: 0.9077\n",
      "Epoch 116/6000\n",
      "157/157 [==============================] - 29s 182ms/step - loss: 0.2036 - accuracy: 0.9197 - val_loss: 0.2357 - val_accuracy: 0.9103\n",
      "Epoch 117/6000\n",
      "157/157 [==============================] - 26s 162ms/step - loss: 0.2047 - accuracy: 0.9191 - val_loss: 0.2360 - val_accuracy: 0.9111\n",
      "Epoch 118/6000\n",
      "157/157 [==============================] - 29s 186ms/step - loss: 0.2047 - accuracy: 0.9192 - val_loss: 0.2321 - val_accuracy: 0.9133\n",
      "Epoch 119/6000\n",
      "157/157 [==============================] - 27s 168ms/step - loss: 0.2039 - accuracy: 0.9192 - val_loss: 0.2349 - val_accuracy: 0.9118\n",
      "Epoch 120/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.2041 - accuracy: 0.9191 - val_loss: 0.2379 - val_accuracy: 0.9098\n",
      "Epoch 121/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.2031 - accuracy: 0.9193 - val_loss: 0.2355 - val_accuracy: 0.9122\n",
      "Epoch 122/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.2020 - accuracy: 0.9204 - val_loss: 0.2323 - val_accuracy: 0.9128\n",
      "Epoch 123/6000\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 0.2010 - accuracy: 0.9205 - val_loss: 0.2321 - val_accuracy: 0.9123\n",
      "Epoch 124/6000\n",
      "157/157 [==============================] - 25s 158ms/step - loss: 0.2003 - accuracy: 0.9213 - val_loss: 0.2329 - val_accuracy: 0.9127\n",
      "Epoch 125/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.2001 - accuracy: 0.9208 - val_loss: 0.2286 - val_accuracy: 0.9148\n",
      "Epoch 126/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.1995 - accuracy: 0.9217 - val_loss: 0.2391 - val_accuracy: 0.9103\n",
      "Epoch 127/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.1994 - accuracy: 0.9212 - val_loss: 0.2340 - val_accuracy: 0.9118\n",
      "Epoch 128/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.1989 - accuracy: 0.9218 - val_loss: 0.2312 - val_accuracy: 0.9136\n",
      "Epoch 129/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.1978 - accuracy: 0.9221 - val_loss: 0.2293 - val_accuracy: 0.9139\n",
      "Epoch 130/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.1967 - accuracy: 0.9227 - val_loss: 0.2280 - val_accuracy: 0.9145\n",
      "Epoch 131/6000\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.1952 - accuracy: 0.9231 - val_loss: 0.2376 - val_accuracy: 0.9110\n",
      "Epoch 132/6000\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.1960 - accuracy: 0.9232 - val_loss: 0.2336 - val_accuracy: 0.9119\n",
      "Epoch 133/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.1953 - accuracy: 0.9230 - val_loss: 0.2269 - val_accuracy: 0.9157\n",
      "Epoch 134/6000\n",
      "157/157 [==============================] - 25s 158ms/step - loss: 0.1943 - accuracy: 0.9239 - val_loss: 0.2318 - val_accuracy: 0.9135\n",
      "Epoch 135/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.1938 - accuracy: 0.9238 - val_loss: 0.2277 - val_accuracy: 0.9155\n",
      "Epoch 136/6000\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 0.1945 - accuracy: 0.9235 - val_loss: 0.2352 - val_accuracy: 0.9123\n",
      "Epoch 137/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.1924 - accuracy: 0.9244 - val_loss: 0.2281 - val_accuracy: 0.9156\n",
      "Epoch 138/6000\n",
      "157/157 [==============================] - 31s 196ms/step - loss: 0.1920 - accuracy: 0.9248 - val_loss: 0.2279 - val_accuracy: 0.9153\n",
      "Epoch 139/6000\n",
      "157/157 [==============================] - 23s 142ms/step - loss: 0.1910 - accuracy: 0.9251 - val_loss: 0.2251 - val_accuracy: 0.9160\n",
      "Epoch 140/6000\n",
      "157/157 [==============================] - 31s 194ms/step - loss: 0.1911 - accuracy: 0.9251 - val_loss: 0.2243 - val_accuracy: 0.9171\n",
      "Epoch 141/6000\n",
      "157/157 [==============================] - 23s 148ms/step - loss: 0.1914 - accuracy: 0.9248 - val_loss: 0.2293 - val_accuracy: 0.9159\n",
      "Epoch 142/6000\n",
      "157/157 [==============================] - 30s 188ms/step - loss: 0.1901 - accuracy: 0.9255 - val_loss: 0.2250 - val_accuracy: 0.9172\n",
      "Epoch 143/6000\n",
      "157/157 [==============================] - 24s 152ms/step - loss: 0.1895 - accuracy: 0.9256 - val_loss: 0.2316 - val_accuracy: 0.9149\n",
      "Epoch 144/6000\n",
      "157/157 [==============================] - 26s 162ms/step - loss: 0.1894 - accuracy: 0.9254 - val_loss: 0.2267 - val_accuracy: 0.9151\n",
      "Epoch 145/6000\n",
      "157/157 [==============================] - 29s 186ms/step - loss: 0.1892 - accuracy: 0.9259 - val_loss: 0.2310 - val_accuracy: 0.9141\n",
      "Epoch 146/6000\n",
      "157/157 [==============================] - 30s 192ms/step - loss: 0.1879 - accuracy: 0.9264 - val_loss: 0.2257 - val_accuracy: 0.9165\n",
      "Epoch 147/6000\n",
      "157/157 [==============================] - 21s 133ms/step - loss: 0.1856 - accuracy: 0.9277 - val_loss: 0.2277 - val_accuracy: 0.9160\n",
      "Epoch 148/6000\n",
      "157/157 [==============================] - 29s 181ms/step - loss: 0.1877 - accuracy: 0.9268 - val_loss: 0.2266 - val_accuracy: 0.9171\n",
      "Epoch 149/6000\n",
      "157/157 [==============================] - 25s 160ms/step - loss: 0.1871 - accuracy: 0.9268 - val_loss: 0.2312 - val_accuracy: 0.9141\n",
      "Epoch 150/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.1857 - accuracy: 0.9277 - val_loss: 0.2203 - val_accuracy: 0.9190\n",
      "Epoch 151/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.1867 - accuracy: 0.9269 - val_loss: 0.2216 - val_accuracy: 0.9183\n",
      "Epoch 152/6000\n",
      "157/157 [==============================] - 31s 196ms/step - loss: 0.1850 - accuracy: 0.9276 - val_loss: 0.2204 - val_accuracy: 0.9186\n",
      "Epoch 153/6000\n",
      "157/157 [==============================] - 26s 168ms/step - loss: 0.1838 - accuracy: 0.9280 - val_loss: 0.2319 - val_accuracy: 0.9144\n",
      "Epoch 154/6000\n",
      "157/157 [==============================] - 28s 175ms/step - loss: 0.1831 - accuracy: 0.9288 - val_loss: 0.2296 - val_accuracy: 0.9155\n",
      "Epoch 155/6000\n",
      "157/157 [==============================] - 23s 148ms/step - loss: 0.1832 - accuracy: 0.9283 - val_loss: 0.2227 - val_accuracy: 0.9186\n",
      "Epoch 156/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.1838 - accuracy: 0.9284 - val_loss: 0.2254 - val_accuracy: 0.9174\n",
      "Epoch 157/6000\n",
      "157/157 [==============================] - 27s 169ms/step - loss: 0.1832 - accuracy: 0.9282 - val_loss: 0.2211 - val_accuracy: 0.9191\n",
      "Epoch 158/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.1809 - accuracy: 0.9294 - val_loss: 0.2234 - val_accuracy: 0.9192\n",
      "Epoch 159/6000\n",
      "157/157 [==============================] - 25s 161ms/step - loss: 0.1827 - accuracy: 0.9284 - val_loss: 0.2196 - val_accuracy: 0.9196\n",
      "Epoch 160/6000\n",
      "157/157 [==============================] - 34s 214ms/step - loss: 0.1813 - accuracy: 0.9295 - val_loss: 0.2234 - val_accuracy: 0.9173\n",
      "Epoch 161/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.1820 - accuracy: 0.9291 - val_loss: 0.2300 - val_accuracy: 0.9164\n",
      "Epoch 162/6000\n",
      "157/157 [==============================] - 22s 142ms/step - loss: 0.1801 - accuracy: 0.9296 - val_loss: 0.2240 - val_accuracy: 0.9189\n",
      "Epoch 163/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.1802 - accuracy: 0.9295 - val_loss: 0.2211 - val_accuracy: 0.9197\n",
      "Epoch 164/6000\n",
      "157/157 [==============================] - 31s 195ms/step - loss: 0.1807 - accuracy: 0.9294 - val_loss: 0.2234 - val_accuracy: 0.9188\n",
      "Epoch 165/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.1788 - accuracy: 0.9305 - val_loss: 0.2176 - val_accuracy: 0.9201\n",
      "Epoch 166/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.1781 - accuracy: 0.9308 - val_loss: 0.2215 - val_accuracy: 0.9186\n",
      "Epoch 167/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.1792 - accuracy: 0.9304 - val_loss: 0.2228 - val_accuracy: 0.9185\n",
      "Epoch 168/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.1761 - accuracy: 0.9312 - val_loss: 0.2189 - val_accuracy: 0.9200\n",
      "Epoch 169/6000\n",
      "157/157 [==============================] - 26s 168ms/step - loss: 0.1772 - accuracy: 0.9305 - val_loss: 0.2304 - val_accuracy: 0.9157\n",
      "Epoch 170/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.1780 - accuracy: 0.9312 - val_loss: 0.2240 - val_accuracy: 0.9184\n",
      "Epoch 171/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.1767 - accuracy: 0.9311 - val_loss: 0.2274 - val_accuracy: 0.9175\n",
      "Epoch 172/6000\n",
      "157/157 [==============================] - 27s 175ms/step - loss: 0.1766 - accuracy: 0.9313 - val_loss: 0.2209 - val_accuracy: 0.9202\n",
      "Epoch 173/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.1749 - accuracy: 0.9322 - val_loss: 0.2252 - val_accuracy: 0.9190\n",
      "Epoch 174/6000\n",
      "157/157 [==============================] - 24s 153ms/step - loss: 0.1744 - accuracy: 0.9320 - val_loss: 0.2233 - val_accuracy: 0.9187\n",
      "Epoch 175/6000\n",
      "157/157 [==============================] - 29s 186ms/step - loss: 0.1745 - accuracy: 0.9320 - val_loss: 0.2198 - val_accuracy: 0.9194\n",
      "Epoch 176/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.1742 - accuracy: 0.9326 - val_loss: 0.2208 - val_accuracy: 0.9198\n",
      "Epoch 177/6000\n",
      "157/157 [==============================] - 26s 164ms/step - loss: 0.1738 - accuracy: 0.9325 - val_loss: 0.2211 - val_accuracy: 0.9204\n",
      "Epoch 178/6000\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.1736 - accuracy: 0.9327 - val_loss: 0.2240 - val_accuracy: 0.9188\n",
      "Epoch 179/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.1740 - accuracy: 0.9324 - val_loss: 0.2249 - val_accuracy: 0.9192\n",
      "Epoch 180/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.1729 - accuracy: 0.9327 - val_loss: 0.2205 - val_accuracy: 0.9206\n",
      "Epoch 181/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.1726 - accuracy: 0.9332 - val_loss: 0.2217 - val_accuracy: 0.9202\n",
      "Epoch 182/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.1719 - accuracy: 0.9331 - val_loss: 0.2323 - val_accuracy: 0.9167\n",
      "Epoch 183/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.1722 - accuracy: 0.9331 - val_loss: 0.2213 - val_accuracy: 0.9206\n",
      "Epoch 184/6000\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 0.1718 - accuracy: 0.9335 - val_loss: 0.2205 - val_accuracy: 0.9205\n",
      "Epoch 185/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.1715 - accuracy: 0.9333 - val_loss: 0.2194 - val_accuracy: 0.9215\n",
      "Epoch 186/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.1703 - accuracy: 0.9337 - val_loss: 0.2208 - val_accuracy: 0.9200\n",
      "Epoch 187/6000\n",
      "157/157 [==============================] - 24s 153ms/step - loss: 0.1695 - accuracy: 0.9341 - val_loss: 0.2244 - val_accuracy: 0.9194\n",
      "Epoch 188/6000\n",
      "157/157 [==============================] - 31s 197ms/step - loss: 0.1691 - accuracy: 0.9347 - val_loss: 0.2216 - val_accuracy: 0.9210\n",
      "Epoch 189/6000\n",
      "157/157 [==============================] - 26s 169ms/step - loss: 0.1686 - accuracy: 0.9349 - val_loss: 0.2182 - val_accuracy: 0.9218\n",
      "Epoch 190/6000\n",
      "157/157 [==============================] - 23s 148ms/step - loss: 0.1674 - accuracy: 0.9352 - val_loss: 0.2158 - val_accuracy: 0.9230\n",
      "Epoch 191/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.1674 - accuracy: 0.9350 - val_loss: 0.2182 - val_accuracy: 0.9219\n",
      "Epoch 192/6000\n",
      "157/157 [==============================] - 29s 184ms/step - loss: 0.1669 - accuracy: 0.9360 - val_loss: 0.2148 - val_accuracy: 0.9234\n",
      "Epoch 193/6000\n",
      "157/157 [==============================] - 29s 186ms/step - loss: 0.1680 - accuracy: 0.9349 - val_loss: 0.2193 - val_accuracy: 0.9215\n",
      "Epoch 194/6000\n",
      "157/157 [==============================] - 23s 147ms/step - loss: 0.1672 - accuracy: 0.9354 - val_loss: 0.2142 - val_accuracy: 0.9238\n",
      "Epoch 195/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.1650 - accuracy: 0.9359 - val_loss: 0.2163 - val_accuracy: 0.9226\n",
      "Epoch 196/6000\n",
      "157/157 [==============================] - 27s 168ms/step - loss: 0.1666 - accuracy: 0.9356 - val_loss: 0.2135 - val_accuracy: 0.9244\n",
      "Epoch 197/6000\n",
      "157/157 [==============================] - 26s 162ms/step - loss: 0.1652 - accuracy: 0.9358 - val_loss: 0.2160 - val_accuracy: 0.9235\n",
      "Epoch 198/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.1653 - accuracy: 0.9361 - val_loss: 0.2151 - val_accuracy: 0.9228\n",
      "Epoch 199/6000\n",
      "157/157 [==============================] - 25s 158ms/step - loss: 0.1653 - accuracy: 0.9358 - val_loss: 0.2182 - val_accuracy: 0.9222\n",
      "Epoch 200/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.1647 - accuracy: 0.9362 - val_loss: 0.2160 - val_accuracy: 0.9220\n",
      "Epoch 201/6000\n",
      "157/157 [==============================] - 26s 162ms/step - loss: 0.1625 - accuracy: 0.9373 - val_loss: 0.2180 - val_accuracy: 0.9226\n",
      "Epoch 202/6000\n",
      "157/157 [==============================] - 29s 184ms/step - loss: 0.1644 - accuracy: 0.9369 - val_loss: 0.2126 - val_accuracy: 0.9248\n",
      "Epoch 203/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.1627 - accuracy: 0.9371 - val_loss: 0.2175 - val_accuracy: 0.9227\n",
      "Epoch 204/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.1628 - accuracy: 0.9368 - val_loss: 0.2166 - val_accuracy: 0.9231\n",
      "Epoch 205/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.1634 - accuracy: 0.9367 - val_loss: 0.2211 - val_accuracy: 0.9221\n",
      "Epoch 206/6000\n",
      "157/157 [==============================] - 29s 185ms/step - loss: 0.1634 - accuracy: 0.9375 - val_loss: 0.2196 - val_accuracy: 0.9222\n",
      "Epoch 207/6000\n",
      "157/157 [==============================] - 23s 143ms/step - loss: 0.1631 - accuracy: 0.9368 - val_loss: 0.2172 - val_accuracy: 0.9228\n",
      "Epoch 208/6000\n",
      "157/157 [==============================] - 28s 175ms/step - loss: 0.1604 - accuracy: 0.9380 - val_loss: 0.2235 - val_accuracy: 0.9217\n",
      "Epoch 209/6000\n",
      "157/157 [==============================] - 27s 169ms/step - loss: 0.1612 - accuracy: 0.9375 - val_loss: 0.2169 - val_accuracy: 0.9236\n",
      "Epoch 210/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.1607 - accuracy: 0.9380 - val_loss: 0.2155 - val_accuracy: 0.9249\n",
      "Epoch 211/6000\n",
      "157/157 [==============================] - 28s 175ms/step - loss: 0.1603 - accuracy: 0.9381 - val_loss: 0.2133 - val_accuracy: 0.9251\n",
      "Epoch 212/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.1599 - accuracy: 0.9385 - val_loss: 0.2194 - val_accuracy: 0.9224\n",
      "Epoch 213/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.1617 - accuracy: 0.9376 - val_loss: 0.2213 - val_accuracy: 0.9222\n",
      "Epoch 214/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.1600 - accuracy: 0.9383 - val_loss: 0.2219 - val_accuracy: 0.9230\n",
      "Epoch 215/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.1602 - accuracy: 0.9382 - val_loss: 0.2200 - val_accuracy: 0.9236\n",
      "Epoch 216/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.1585 - accuracy: 0.9388 - val_loss: 0.2149 - val_accuracy: 0.9246\n",
      "Epoch 217/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.1599 - accuracy: 0.9386 - val_loss: 0.2133 - val_accuracy: 0.9256\n",
      "Epoch 218/6000\n",
      "157/157 [==============================] - 25s 161ms/step - loss: 0.1591 - accuracy: 0.9389 - val_loss: 0.2157 - val_accuracy: 0.9252\n",
      "Epoch 219/6000\n",
      "157/157 [==============================] - 29s 185ms/step - loss: 0.1571 - accuracy: 0.9395 - val_loss: 0.2110 - val_accuracy: 0.9260\n",
      "Epoch 220/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.1579 - accuracy: 0.9390 - val_loss: 0.2162 - val_accuracy: 0.9248\n",
      "Epoch 221/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.1578 - accuracy: 0.9396 - val_loss: 0.2163 - val_accuracy: 0.9240\n",
      "Epoch 222/6000\n",
      "157/157 [==============================] - 25s 159ms/step - loss: 0.1564 - accuracy: 0.9399 - val_loss: 0.2152 - val_accuracy: 0.9249\n",
      "Epoch 223/6000\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 0.1585 - accuracy: 0.9390 - val_loss: 0.2119 - val_accuracy: 0.9239\n",
      "Epoch 224/6000\n",
      "157/157 [==============================] - 21s 137ms/step - loss: 0.1547 - accuracy: 0.9403 - val_loss: 0.2154 - val_accuracy: 0.9244\n",
      "Epoch 225/6000\n",
      "157/157 [==============================] - 30s 192ms/step - loss: 0.1559 - accuracy: 0.9402 - val_loss: 0.2132 - val_accuracy: 0.9243\n",
      "Epoch 226/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.1566 - accuracy: 0.9395 - val_loss: 0.2160 - val_accuracy: 0.9247\n",
      "Epoch 227/6000\n",
      "157/157 [==============================] - 29s 185ms/step - loss: 0.1561 - accuracy: 0.9398 - val_loss: 0.2105 - val_accuracy: 0.9265\n",
      "Epoch 228/6000\n",
      "157/157 [==============================] - 23s 147ms/step - loss: 0.1563 - accuracy: 0.9397 - val_loss: 0.2188 - val_accuracy: 0.9237\n",
      "Epoch 229/6000\n",
      "157/157 [==============================] - 27s 168ms/step - loss: 0.1553 - accuracy: 0.9407 - val_loss: 0.2125 - val_accuracy: 0.9257\n",
      "Epoch 230/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.1554 - accuracy: 0.9401 - val_loss: 0.2100 - val_accuracy: 0.9265\n",
      "Epoch 231/6000\n",
      "157/157 [==============================] - 27s 169ms/step - loss: 0.1539 - accuracy: 0.9405 - val_loss: 0.2181 - val_accuracy: 0.9230\n",
      "Epoch 232/6000\n",
      "157/157 [==============================] - 29s 183ms/step - loss: 0.1541 - accuracy: 0.9406 - val_loss: 0.2231 - val_accuracy: 0.9230\n",
      "Epoch 233/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.1530 - accuracy: 0.9410 - val_loss: 0.2138 - val_accuracy: 0.9264\n",
      "Epoch 234/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.1528 - accuracy: 0.9410 - val_loss: 0.2193 - val_accuracy: 0.9243\n",
      "Epoch 235/6000\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.1542 - accuracy: 0.9404 - val_loss: 0.2172 - val_accuracy: 0.9245\n",
      "Epoch 236/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.1525 - accuracy: 0.9415 - val_loss: 0.2113 - val_accuracy: 0.9265\n",
      "Epoch 237/6000\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.1525 - accuracy: 0.9416 - val_loss: 0.2135 - val_accuracy: 0.9251\n",
      "Epoch 238/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.1514 - accuracy: 0.9420 - val_loss: 0.2166 - val_accuracy: 0.9238\n",
      "Epoch 239/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.1510 - accuracy: 0.9418 - val_loss: 0.2156 - val_accuracy: 0.9246\n",
      "Epoch 240/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.1510 - accuracy: 0.9419 - val_loss: 0.2226 - val_accuracy: 0.9232\n",
      "Epoch 241/6000\n",
      "157/157 [==============================] - 24s 151ms/step - loss: 0.1510 - accuracy: 0.9417 - val_loss: 0.2138 - val_accuracy: 0.9255\n",
      "Epoch 242/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.1503 - accuracy: 0.9419 - val_loss: 0.2215 - val_accuracy: 0.9238\n",
      "Epoch 242: early stopping\n",
      "##########################################################################\n",
      "------val_accuracy-----> 92.65 | 94.2 <----------accuracy----------\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/DOGE-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/DOGE-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "working on pair: LTC/USDT\n",
      "One_pair_AI_Gen : LTC/USDT\n",
      "price_volatility_15m:0.42%\n",
      "mini_expand : LTC/USDT\n",
      "---buy_simple_up--- Buy pct: 0.5%\n",
      "---buy_only--- Max time window: 10%\n",
      "---buy_only--- no b\n",
      "---buy_only--- no sell\n",
      "df original shape (932519, 1607)\n",
      "df original shape buy mean : 10.023924445507276\n",
      "df choosen data shape(500000, 1607)\n",
      "pair: True\n",
      "100000\n",
      "normalizing ...\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/LTC-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_92 (Dense)            (None, 250)               401750    \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 250)               0         \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 20)                5020      \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,871\n",
      "Trainable params: 407,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_UP_CLOSE/LTC-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "Epoch 1/6000\n",
      "157/157 [==============================] - 39s 179ms/step - loss: 0.5853 - accuracy: 0.6922 - val_loss: 0.5664 - val_accuracy: 0.7086\n",
      "Epoch 2/6000\n",
      "157/157 [==============================] - 22s 143ms/step - loss: 0.5633 - accuracy: 0.7085 - val_loss: 0.5504 - val_accuracy: 0.7199\n",
      "Epoch 3/6000\n",
      "157/157 [==============================] - 21s 136ms/step - loss: 0.5492 - accuracy: 0.7181 - val_loss: 0.5354 - val_accuracy: 0.7291\n",
      "Epoch 4/6000\n",
      "157/157 [==============================] - 21s 136ms/step - loss: 0.5361 - accuracy: 0.7288 - val_loss: 0.5237 - val_accuracy: 0.7374\n",
      "Epoch 5/6000\n",
      "157/157 [==============================] - 21s 136ms/step - loss: 0.5214 - accuracy: 0.7379 - val_loss: 0.5114 - val_accuracy: 0.7484\n",
      "Epoch 6/6000\n",
      "157/157 [==============================] - 22s 141ms/step - loss: 0.5077 - accuracy: 0.7478 - val_loss: 0.4933 - val_accuracy: 0.7582\n",
      "Epoch 7/6000\n",
      "157/157 [==============================] - 21s 134ms/step - loss: 0.4930 - accuracy: 0.7587 - val_loss: 0.4784 - val_accuracy: 0.7684\n",
      "Epoch 8/6000\n",
      "157/157 [==============================] - 22s 138ms/step - loss: 0.4824 - accuracy: 0.7656 - val_loss: 0.4678 - val_accuracy: 0.7766\n",
      "Epoch 9/6000\n",
      "157/157 [==============================] - 25s 163ms/step - loss: 0.4685 - accuracy: 0.7749 - val_loss: 0.4577 - val_accuracy: 0.7833\n",
      "Epoch 10/6000\n",
      "157/157 [==============================] - 21s 133ms/step - loss: 0.4573 - accuracy: 0.7819 - val_loss: 0.4375 - val_accuracy: 0.7960\n",
      "Epoch 11/6000\n",
      "157/157 [==============================] - 27s 175ms/step - loss: 0.4471 - accuracy: 0.7884 - val_loss: 0.4328 - val_accuracy: 0.8009\n",
      "Epoch 12/6000\n",
      "157/157 [==============================] - 24s 156ms/step - loss: 0.4387 - accuracy: 0.7937 - val_loss: 0.4184 - val_accuracy: 0.8083\n",
      "Epoch 13/6000\n",
      "157/157 [==============================] - 23s 147ms/step - loss: 0.4292 - accuracy: 0.7996 - val_loss: 0.4140 - val_accuracy: 0.8102\n",
      "Epoch 14/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.4218 - accuracy: 0.8041 - val_loss: 0.4056 - val_accuracy: 0.8168\n",
      "Epoch 15/6000\n",
      "157/157 [==============================] - 22s 141ms/step - loss: 0.4132 - accuracy: 0.8093 - val_loss: 0.4037 - val_accuracy: 0.8166\n",
      "Epoch 16/6000\n",
      "157/157 [==============================] - 26s 162ms/step - loss: 0.4058 - accuracy: 0.8131 - val_loss: 0.3889 - val_accuracy: 0.8245\n",
      "Epoch 17/6000\n",
      "157/157 [==============================] - 27s 175ms/step - loss: 0.4001 - accuracy: 0.8176 - val_loss: 0.3847 - val_accuracy: 0.8285\n",
      "Epoch 18/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.3947 - accuracy: 0.8201 - val_loss: 0.3808 - val_accuracy: 0.8300\n",
      "Epoch 19/6000\n",
      "157/157 [==============================] - 22s 138ms/step - loss: 0.3891 - accuracy: 0.8237 - val_loss: 0.3726 - val_accuracy: 0.8346\n",
      "Epoch 20/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.3844 - accuracy: 0.8262 - val_loss: 0.3728 - val_accuracy: 0.8354\n",
      "Epoch 21/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.3789 - accuracy: 0.8297 - val_loss: 0.3673 - val_accuracy: 0.8371\n",
      "Epoch 22/6000\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 0.3742 - accuracy: 0.8322 - val_loss: 0.3637 - val_accuracy: 0.8400\n",
      "Epoch 23/6000\n",
      "157/157 [==============================] - 24s 153ms/step - loss: 0.3707 - accuracy: 0.8340 - val_loss: 0.3573 - val_accuracy: 0.8424\n",
      "Epoch 24/6000\n",
      "157/157 [==============================] - 27s 175ms/step - loss: 0.3661 - accuracy: 0.8369 - val_loss: 0.3585 - val_accuracy: 0.8426\n",
      "Epoch 25/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.3618 - accuracy: 0.8389 - val_loss: 0.3526 - val_accuracy: 0.8474\n",
      "Epoch 26/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.3580 - accuracy: 0.8417 - val_loss: 0.3541 - val_accuracy: 0.8447\n",
      "Epoch 27/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.3547 - accuracy: 0.8432 - val_loss: 0.3417 - val_accuracy: 0.8519\n",
      "Epoch 28/6000\n",
      "157/157 [==============================] - 25s 156ms/step - loss: 0.3497 - accuracy: 0.8458 - val_loss: 0.3410 - val_accuracy: 0.8520\n",
      "Epoch 29/6000\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 0.3482 - accuracy: 0.8466 - val_loss: 0.3410 - val_accuracy: 0.8515\n",
      "Epoch 30/6000\n",
      "157/157 [==============================] - 24s 150ms/step - loss: 0.3442 - accuracy: 0.8490 - val_loss: 0.3337 - val_accuracy: 0.8587\n",
      "Epoch 31/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.3429 - accuracy: 0.8499 - val_loss: 0.3357 - val_accuracy: 0.8552\n",
      "Epoch 32/6000\n",
      "157/157 [==============================] - 25s 160ms/step - loss: 0.3386 - accuracy: 0.8517 - val_loss: 0.3332 - val_accuracy: 0.8580\n",
      "Epoch 33/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.3361 - accuracy: 0.8531 - val_loss: 0.3342 - val_accuracy: 0.8560\n",
      "Epoch 34/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.3329 - accuracy: 0.8551 - val_loss: 0.3276 - val_accuracy: 0.8606\n",
      "Epoch 35/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.3317 - accuracy: 0.8555 - val_loss: 0.3261 - val_accuracy: 0.8613\n",
      "Epoch 36/6000\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.3288 - accuracy: 0.8573 - val_loss: 0.3281 - val_accuracy: 0.8604\n",
      "Epoch 37/6000\n",
      "157/157 [==============================] - 26s 164ms/step - loss: 0.3262 - accuracy: 0.8590 - val_loss: 0.3230 - val_accuracy: 0.8626\n",
      "Epoch 38/6000\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.3238 - accuracy: 0.8594 - val_loss: 0.3219 - val_accuracy: 0.8643\n",
      "Epoch 39/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.3214 - accuracy: 0.8608 - val_loss: 0.3143 - val_accuracy: 0.8675\n",
      "Epoch 40/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.3183 - accuracy: 0.8629 - val_loss: 0.3208 - val_accuracy: 0.8624\n",
      "Epoch 41/6000\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.3169 - accuracy: 0.8631 - val_loss: 0.3152 - val_accuracy: 0.8667\n",
      "Epoch 42/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.3153 - accuracy: 0.8640 - val_loss: 0.3109 - val_accuracy: 0.8698\n",
      "Epoch 43/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.3136 - accuracy: 0.8652 - val_loss: 0.3066 - val_accuracy: 0.8716\n",
      "Epoch 44/6000\n",
      "157/157 [==============================] - 24s 155ms/step - loss: 0.3108 - accuracy: 0.8668 - val_loss: 0.3077 - val_accuracy: 0.8703\n",
      "Epoch 45/6000\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 0.3105 - accuracy: 0.8664 - val_loss: 0.3077 - val_accuracy: 0.8706\n",
      "Epoch 46/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.3071 - accuracy: 0.8689 - val_loss: 0.3070 - val_accuracy: 0.8710\n",
      "Epoch 47/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.3042 - accuracy: 0.8695 - val_loss: 0.3066 - val_accuracy: 0.8722\n",
      "Epoch 48/6000\n",
      "157/157 [==============================] - 24s 149ms/step - loss: 0.3041 - accuracy: 0.8699 - val_loss: 0.3037 - val_accuracy: 0.8740\n",
      "Epoch 49/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.3032 - accuracy: 0.8708 - val_loss: 0.3016 - val_accuracy: 0.8744\n",
      "Epoch 50/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.3018 - accuracy: 0.8717 - val_loss: 0.3037 - val_accuracy: 0.8729\n",
      "Epoch 51/6000\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.2991 - accuracy: 0.8728 - val_loss: 0.2988 - val_accuracy: 0.8768\n",
      "Epoch 52/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.2969 - accuracy: 0.8741 - val_loss: 0.2964 - val_accuracy: 0.8777\n",
      "Epoch 53/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.2964 - accuracy: 0.8746 - val_loss: 0.3000 - val_accuracy: 0.8756\n",
      "Epoch 54/6000\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 0.2935 - accuracy: 0.8755 - val_loss: 0.2966 - val_accuracy: 0.8763\n",
      "Epoch 55/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.2925 - accuracy: 0.8763 - val_loss: 0.2940 - val_accuracy: 0.8791\n",
      "Epoch 56/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.2908 - accuracy: 0.8774 - val_loss: 0.2985 - val_accuracy: 0.8763\n",
      "Epoch 57/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.2904 - accuracy: 0.8773 - val_loss: 0.2924 - val_accuracy: 0.8789\n",
      "Epoch 58/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.2888 - accuracy: 0.8783 - val_loss: 0.2942 - val_accuracy: 0.8785\n",
      "Epoch 59/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.2871 - accuracy: 0.8791 - val_loss: 0.2896 - val_accuracy: 0.8816\n",
      "Epoch 60/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.2849 - accuracy: 0.8802 - val_loss: 0.2939 - val_accuracy: 0.8791\n",
      "Epoch 61/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.2847 - accuracy: 0.8801 - val_loss: 0.2875 - val_accuracy: 0.8817\n",
      "Epoch 62/6000\n",
      "157/157 [==============================] - 22s 138ms/step - loss: 0.2833 - accuracy: 0.8810 - val_loss: 0.2892 - val_accuracy: 0.8816\n",
      "Epoch 63/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.2810 - accuracy: 0.8816 - val_loss: 0.2870 - val_accuracy: 0.8818\n",
      "Epoch 64/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.2809 - accuracy: 0.8821 - val_loss: 0.2944 - val_accuracy: 0.8789\n",
      "Epoch 65/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.2794 - accuracy: 0.8827 - val_loss: 0.2839 - val_accuracy: 0.8839\n",
      "Epoch 66/6000\n",
      "157/157 [==============================] - 28s 182ms/step - loss: 0.2775 - accuracy: 0.8839 - val_loss: 0.2840 - val_accuracy: 0.8846\n",
      "Epoch 67/6000\n",
      "157/157 [==============================] - 29s 185ms/step - loss: 0.2761 - accuracy: 0.8848 - val_loss: 0.2943 - val_accuracy: 0.8785\n",
      "Epoch 68/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.2772 - accuracy: 0.8847 - val_loss: 0.2831 - val_accuracy: 0.8849\n",
      "Epoch 69/6000\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.2744 - accuracy: 0.8853 - val_loss: 0.2842 - val_accuracy: 0.8852\n",
      "Epoch 70/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.2735 - accuracy: 0.8859 - val_loss: 0.2785 - val_accuracy: 0.8869\n",
      "Epoch 71/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.2724 - accuracy: 0.8867 - val_loss: 0.2812 - val_accuracy: 0.8864\n",
      "Epoch 72/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.2702 - accuracy: 0.8870 - val_loss: 0.2798 - val_accuracy: 0.8874\n",
      "Epoch 73/6000\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.2703 - accuracy: 0.8874 - val_loss: 0.2870 - val_accuracy: 0.8837\n",
      "Epoch 74/6000\n",
      "157/157 [==============================] - 28s 174ms/step - loss: 0.2690 - accuracy: 0.8884 - val_loss: 0.2765 - val_accuracy: 0.8885\n",
      "Epoch 75/6000\n",
      "157/157 [==============================] - 22s 139ms/step - loss: 0.2669 - accuracy: 0.8891 - val_loss: 0.2767 - val_accuracy: 0.8882\n",
      "Epoch 76/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.2680 - accuracy: 0.8888 - val_loss: 0.2771 - val_accuracy: 0.8874\n",
      "Epoch 77/6000\n",
      "157/157 [==============================] - 27s 168ms/step - loss: 0.2653 - accuracy: 0.8898 - val_loss: 0.2772 - val_accuracy: 0.8880\n",
      "Epoch 78/6000\n",
      "157/157 [==============================] - 28s 175ms/step - loss: 0.2653 - accuracy: 0.8900 - val_loss: 0.2755 - val_accuracy: 0.8894\n",
      "Epoch 79/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.2642 - accuracy: 0.8909 - val_loss: 0.2779 - val_accuracy: 0.8873\n",
      "Epoch 80/6000\n",
      "157/157 [==============================] - 29s 184ms/step - loss: 0.2627 - accuracy: 0.8907 - val_loss: 0.2727 - val_accuracy: 0.8909\n",
      "Epoch 81/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.2602 - accuracy: 0.8926 - val_loss: 0.2740 - val_accuracy: 0.8897\n",
      "Epoch 82/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.2600 - accuracy: 0.8927 - val_loss: 0.2700 - val_accuracy: 0.8914\n",
      "Epoch 83/6000\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.2593 - accuracy: 0.8930 - val_loss: 0.2724 - val_accuracy: 0.8901\n",
      "Epoch 84/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.2582 - accuracy: 0.8937 - val_loss: 0.2714 - val_accuracy: 0.8913\n",
      "Epoch 85/6000\n",
      "157/157 [==============================] - 27s 169ms/step - loss: 0.2574 - accuracy: 0.8940 - val_loss: 0.2711 - val_accuracy: 0.8918\n",
      "Epoch 86/6000\n",
      "157/157 [==============================] - 30s 193ms/step - loss: 0.2559 - accuracy: 0.8947 - val_loss: 0.2720 - val_accuracy: 0.8910\n",
      "Epoch 87/6000\n",
      "157/157 [==============================] - 28s 181ms/step - loss: 0.2546 - accuracy: 0.8950 - val_loss: 0.2657 - val_accuracy: 0.8942\n",
      "Epoch 88/6000\n",
      "157/157 [==============================] - 25s 155ms/step - loss: 0.2559 - accuracy: 0.8944 - val_loss: 0.2718 - val_accuracy: 0.8905\n",
      "Epoch 89/6000\n",
      "157/157 [==============================] - 27s 171ms/step - loss: 0.2539 - accuracy: 0.8962 - val_loss: 0.2656 - val_accuracy: 0.8943\n",
      "Epoch 90/6000\n",
      "157/157 [==============================] - 26s 168ms/step - loss: 0.2526 - accuracy: 0.8960 - val_loss: 0.2694 - val_accuracy: 0.8923\n",
      "Epoch 91/6000\n",
      "157/157 [==============================] - 31s 201ms/step - loss: 0.2520 - accuracy: 0.8966 - val_loss: 0.2655 - val_accuracy: 0.8939\n",
      "Epoch 92/6000\n",
      "157/157 [==============================] - 41s 257ms/step - loss: 0.2514 - accuracy: 0.8966 - val_loss: 0.2663 - val_accuracy: 0.8940\n",
      "Epoch 93/6000\n",
      "157/157 [==============================] - 29s 187ms/step - loss: 0.2496 - accuracy: 0.8977 - val_loss: 0.2778 - val_accuracy: 0.8891\n",
      "Epoch 94/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.2485 - accuracy: 0.8984 - val_loss: 0.2606 - val_accuracy: 0.8968\n",
      "Epoch 95/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.2478 - accuracy: 0.8987 - val_loss: 0.2666 - val_accuracy: 0.8945\n",
      "Epoch 96/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.2474 - accuracy: 0.8995 - val_loss: 0.2606 - val_accuracy: 0.8963\n",
      "Epoch 97/6000\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.2455 - accuracy: 0.9000 - val_loss: 0.2656 - val_accuracy: 0.8951\n",
      "Epoch 98/6000\n",
      "157/157 [==============================] - 25s 162ms/step - loss: 0.2456 - accuracy: 0.8997 - val_loss: 0.2640 - val_accuracy: 0.8959\n",
      "Epoch 99/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.2448 - accuracy: 0.9003 - val_loss: 0.2603 - val_accuracy: 0.8963\n",
      "Epoch 100/6000\n",
      "157/157 [==============================] - 30s 190ms/step - loss: 0.2446 - accuracy: 0.9002 - val_loss: 0.2644 - val_accuracy: 0.8962\n",
      "Epoch 101/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.2431 - accuracy: 0.9012 - val_loss: 0.2594 - val_accuracy: 0.8973\n",
      "Epoch 102/6000\n",
      "157/157 [==============================] - 33s 212ms/step - loss: 0.2433 - accuracy: 0.9002 - val_loss: 0.2617 - val_accuracy: 0.8965\n",
      "Epoch 103/6000\n",
      "157/157 [==============================] - 27s 175ms/step - loss: 0.2409 - accuracy: 0.9021 - val_loss: 0.2614 - val_accuracy: 0.8977\n",
      "Epoch 104/6000\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 0.2405 - accuracy: 0.9018 - val_loss: 0.2584 - val_accuracy: 0.8982\n",
      "Epoch 105/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.2395 - accuracy: 0.9032 - val_loss: 0.2580 - val_accuracy: 0.8984\n",
      "Epoch 106/6000\n",
      "157/157 [==============================] - 25s 160ms/step - loss: 0.2395 - accuracy: 0.9024 - val_loss: 0.2596 - val_accuracy: 0.8987\n",
      "Epoch 107/6000\n",
      "157/157 [==============================] - 27s 169ms/step - loss: 0.2394 - accuracy: 0.9028 - val_loss: 0.2582 - val_accuracy: 0.8994\n",
      "Epoch 108/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.2388 - accuracy: 0.9032 - val_loss: 0.2599 - val_accuracy: 0.8988\n",
      "Epoch 109/6000\n",
      "157/157 [==============================] - 28s 175ms/step - loss: 0.2365 - accuracy: 0.9037 - val_loss: 0.2596 - val_accuracy: 0.8983\n",
      "Epoch 110/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.2361 - accuracy: 0.9041 - val_loss: 0.2568 - val_accuracy: 0.8997\n",
      "Epoch 111/6000\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 0.2370 - accuracy: 0.9036 - val_loss: 0.2533 - val_accuracy: 0.9014\n",
      "Epoch 112/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.2335 - accuracy: 0.9051 - val_loss: 0.2532 - val_accuracy: 0.9018\n",
      "Epoch 113/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.2347 - accuracy: 0.9055 - val_loss: 0.2550 - val_accuracy: 0.8996\n",
      "Epoch 114/6000\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 0.2338 - accuracy: 0.9052 - val_loss: 0.2494 - val_accuracy: 0.9033\n",
      "Epoch 115/6000\n",
      "157/157 [==============================] - 25s 161ms/step - loss: 0.2330 - accuracy: 0.9058 - val_loss: 0.2547 - val_accuracy: 0.9010\n",
      "Epoch 116/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.2321 - accuracy: 0.9064 - val_loss: 0.2515 - val_accuracy: 0.9026\n",
      "Epoch 117/6000\n",
      "157/157 [==============================] - 29s 182ms/step - loss: 0.2329 - accuracy: 0.9060 - val_loss: 0.2567 - val_accuracy: 0.9006\n",
      "Epoch 118/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.2303 - accuracy: 0.9071 - val_loss: 0.2583 - val_accuracy: 0.8997\n",
      "Epoch 119/6000\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.2305 - accuracy: 0.9065 - val_loss: 0.2492 - val_accuracy: 0.9032\n",
      "Epoch 120/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.2299 - accuracy: 0.9070 - val_loss: 0.2519 - val_accuracy: 0.9018\n",
      "Epoch 121/6000\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 0.2294 - accuracy: 0.9075 - val_loss: 0.2535 - val_accuracy: 0.9021\n",
      "Epoch 122/6000\n",
      "157/157 [==============================] - 28s 175ms/step - loss: 0.2292 - accuracy: 0.9078 - val_loss: 0.2500 - val_accuracy: 0.9027\n",
      "Epoch 123/6000\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.2288 - accuracy: 0.9079 - val_loss: 0.2529 - val_accuracy: 0.9028\n",
      "Epoch 124/6000\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 0.2276 - accuracy: 0.9081 - val_loss: 0.2497 - val_accuracy: 0.9040\n",
      "Epoch 125/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.2250 - accuracy: 0.9094 - val_loss: 0.2495 - val_accuracy: 0.9036\n",
      "Epoch 126/6000\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.2242 - accuracy: 0.9100 - val_loss: 0.2524 - val_accuracy: 0.9018\n",
      "Epoch 127/6000\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 0.2256 - accuracy: 0.9095 - val_loss: 0.2502 - val_accuracy: 0.9039\n",
      "Epoch 128/6000\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.2241 - accuracy: 0.9100 - val_loss: 0.2529 - val_accuracy: 0.9040\n",
      "Epoch 129/6000\n",
      "157/157 [==============================] - 29s 183ms/step - loss: 0.2259 - accuracy: 0.9097 - val_loss: 0.2549 - val_accuracy: 0.9016\n",
      "Epoch 130/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.2234 - accuracy: 0.9103 - val_loss: 0.2461 - val_accuracy: 0.9067\n",
      "Epoch 131/6000\n",
      "157/157 [==============================] - 29s 187ms/step - loss: 0.2230 - accuracy: 0.9107 - val_loss: 0.2438 - val_accuracy: 0.9070\n",
      "Epoch 132/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.2228 - accuracy: 0.9107 - val_loss: 0.2471 - val_accuracy: 0.9053\n",
      "Epoch 133/6000\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 0.2223 - accuracy: 0.9110 - val_loss: 0.2449 - val_accuracy: 0.9056\n",
      "Epoch 134/6000\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 0.2205 - accuracy: 0.9116 - val_loss: 0.2514 - val_accuracy: 0.9030\n",
      "Epoch 135/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.2197 - accuracy: 0.9121 - val_loss: 0.2472 - val_accuracy: 0.9054\n",
      "Epoch 136/6000\n",
      "157/157 [==============================] - 25s 161ms/step - loss: 0.2194 - accuracy: 0.9123 - val_loss: 0.2498 - val_accuracy: 0.9046\n",
      "Epoch 137/6000\n",
      "157/157 [==============================] - 28s 181ms/step - loss: 0.2196 - accuracy: 0.9123 - val_loss: 0.2490 - val_accuracy: 0.9058\n",
      "Epoch 138/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.2183 - accuracy: 0.9127 - val_loss: 0.2454 - val_accuracy: 0.9065\n",
      "Epoch 139/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.2181 - accuracy: 0.9124 - val_loss: 0.2452 - val_accuracy: 0.9072\n",
      "Epoch 140/6000\n",
      "157/157 [==============================] - 25s 161ms/step - loss: 0.2178 - accuracy: 0.9130 - val_loss: 0.2480 - val_accuracy: 0.9059\n",
      "Epoch 141/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.2167 - accuracy: 0.9133 - val_loss: 0.2484 - val_accuracy: 0.9054\n",
      "Epoch 142/6000\n",
      "157/157 [==============================] - 29s 181ms/step - loss: 0.2162 - accuracy: 0.9136 - val_loss: 0.2400 - val_accuracy: 0.9080\n",
      "Epoch 143/6000\n",
      "157/157 [==============================] - 29s 181ms/step - loss: 0.2161 - accuracy: 0.9139 - val_loss: 0.2483 - val_accuracy: 0.9057\n",
      "Epoch 144/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.2168 - accuracy: 0.9139 - val_loss: 0.2446 - val_accuracy: 0.9072\n",
      "Epoch 145/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.2159 - accuracy: 0.9140 - val_loss: 0.2443 - val_accuracy: 0.9068\n",
      "Epoch 146/6000\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 0.2150 - accuracy: 0.9142 - val_loss: 0.2429 - val_accuracy: 0.9085\n",
      "Epoch 147/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.2121 - accuracy: 0.9157 - val_loss: 0.2486 - val_accuracy: 0.9052\n",
      "Epoch 148/6000\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 0.2131 - accuracy: 0.9154 - val_loss: 0.2424 - val_accuracy: 0.9072\n",
      "Epoch 149/6000\n",
      "157/157 [==============================] - 27s 175ms/step - loss: 0.2136 - accuracy: 0.9151 - val_loss: 0.2455 - val_accuracy: 0.9068\n",
      "Epoch 150/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.2131 - accuracy: 0.9149 - val_loss: 0.2416 - val_accuracy: 0.9092\n",
      "Epoch 151/6000\n",
      "157/157 [==============================] - 28s 181ms/step - loss: 0.2109 - accuracy: 0.9168 - val_loss: 0.2407 - val_accuracy: 0.9095\n",
      "Epoch 152/6000\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.2091 - accuracy: 0.9172 - val_loss: 0.2448 - val_accuracy: 0.9074\n",
      "Epoch 153/6000\n",
      "157/157 [==============================] - 28s 182ms/step - loss: 0.2106 - accuracy: 0.9162 - val_loss: 0.2431 - val_accuracy: 0.9081\n",
      "Epoch 154/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.2104 - accuracy: 0.9166 - val_loss: 0.2529 - val_accuracy: 0.9046\n",
      "Epoch 155/6000\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.2103 - accuracy: 0.9165 - val_loss: 0.2421 - val_accuracy: 0.9092\n",
      "Epoch 156/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.2092 - accuracy: 0.9171 - val_loss: 0.2395 - val_accuracy: 0.9100\n",
      "Epoch 157/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.2079 - accuracy: 0.9176 - val_loss: 0.2398 - val_accuracy: 0.9095\n",
      "Epoch 158/6000\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.2085 - accuracy: 0.9174 - val_loss: 0.2389 - val_accuracy: 0.9107\n",
      "Epoch 159/6000\n",
      "157/157 [==============================] - 27s 175ms/step - loss: 0.2081 - accuracy: 0.9176 - val_loss: 0.2350 - val_accuracy: 0.9114\n",
      "Epoch 160/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.2073 - accuracy: 0.9179 - val_loss: 0.2410 - val_accuracy: 0.9100\n",
      "Epoch 161/6000\n",
      "157/157 [==============================] - 29s 185ms/step - loss: 0.2075 - accuracy: 0.9183 - val_loss: 0.2344 - val_accuracy: 0.9126\n",
      "Epoch 162/6000\n",
      "157/157 [==============================] - 21s 136ms/step - loss: 0.2056 - accuracy: 0.9184 - val_loss: 0.2457 - val_accuracy: 0.9074\n",
      "Epoch 163/6000\n",
      "157/157 [==============================] - 29s 182ms/step - loss: 0.2056 - accuracy: 0.9188 - val_loss: 0.2345 - val_accuracy: 0.9129\n",
      "Epoch 164/6000\n",
      "157/157 [==============================] - 32s 205ms/step - loss: 0.2041 - accuracy: 0.9196 - val_loss: 0.2406 - val_accuracy: 0.9096\n",
      "Epoch 165/6000\n",
      "157/157 [==============================] - 22s 139ms/step - loss: 0.2043 - accuracy: 0.9191 - val_loss: 0.2453 - val_accuracy: 0.9083\n",
      "Epoch 166/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.2043 - accuracy: 0.9196 - val_loss: 0.2347 - val_accuracy: 0.9118\n",
      "Epoch 167/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.2058 - accuracy: 0.9185 - val_loss: 0.2329 - val_accuracy: 0.9136\n",
      "Epoch 168/6000\n",
      "157/157 [==============================] - 29s 182ms/step - loss: 0.2041 - accuracy: 0.9193 - val_loss: 0.2395 - val_accuracy: 0.9108\n",
      "Epoch 169/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.2034 - accuracy: 0.9199 - val_loss: 0.2405 - val_accuracy: 0.9104\n",
      "Epoch 170/6000\n",
      "157/157 [==============================] - 27s 168ms/step - loss: 0.2022 - accuracy: 0.9202 - val_loss: 0.2359 - val_accuracy: 0.9113\n",
      "Epoch 171/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.2023 - accuracy: 0.9202 - val_loss: 0.2345 - val_accuracy: 0.9133\n",
      "Epoch 172/6000\n",
      "157/157 [==============================] - 29s 185ms/step - loss: 0.2026 - accuracy: 0.9204 - val_loss: 0.2373 - val_accuracy: 0.9122\n",
      "Epoch 173/6000\n",
      "157/157 [==============================] - 33s 213ms/step - loss: 0.2000 - accuracy: 0.9212 - val_loss: 0.2440 - val_accuracy: 0.9087\n",
      "Epoch 174/6000\n",
      "157/157 [==============================] - 32s 205ms/step - loss: 0.2015 - accuracy: 0.9206 - val_loss: 0.2379 - val_accuracy: 0.9108\n",
      "Epoch 175/6000\n",
      "157/157 [==============================] - 31s 195ms/step - loss: 0.2008 - accuracy: 0.9210 - val_loss: 0.2351 - val_accuracy: 0.9124\n",
      "Epoch 176/6000\n",
      "157/157 [==============================] - 33s 208ms/step - loss: 0.2004 - accuracy: 0.9209 - val_loss: 0.2358 - val_accuracy: 0.9125\n",
      "Epoch 177/6000\n",
      "157/157 [==============================] - 30s 194ms/step - loss: 0.1987 - accuracy: 0.9221 - val_loss: 0.2365 - val_accuracy: 0.9119\n",
      "Epoch 178/6000\n",
      "157/157 [==============================] - 30s 189ms/step - loss: 0.1979 - accuracy: 0.9221 - val_loss: 0.2357 - val_accuracy: 0.9130\n",
      "Epoch 179/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.1985 - accuracy: 0.9221 - val_loss: 0.2395 - val_accuracy: 0.9109\n",
      "Epoch 180/6000\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 0.1981 - accuracy: 0.9221 - val_loss: 0.2323 - val_accuracy: 0.9143\n",
      "Epoch 181/6000\n",
      "157/157 [==============================] - 27s 175ms/step - loss: 0.1983 - accuracy: 0.9220 - val_loss: 0.2306 - val_accuracy: 0.9140\n",
      "Epoch 182/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.1988 - accuracy: 0.9214 - val_loss: 0.2379 - val_accuracy: 0.9119\n",
      "Epoch 183/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.1955 - accuracy: 0.9231 - val_loss: 0.2384 - val_accuracy: 0.9118\n",
      "Epoch 184/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.1980 - accuracy: 0.9224 - val_loss: 0.2328 - val_accuracy: 0.9144\n",
      "Epoch 185/6000\n",
      "157/157 [==============================] - 22s 141ms/step - loss: 0.1964 - accuracy: 0.9230 - val_loss: 0.2388 - val_accuracy: 0.9106\n",
      "Epoch 186/6000\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 0.1972 - accuracy: 0.9226 - val_loss: 0.2357 - val_accuracy: 0.9128\n",
      "Epoch 187/6000\n",
      "157/157 [==============================] - 27s 168ms/step - loss: 0.1949 - accuracy: 0.9236 - val_loss: 0.2333 - val_accuracy: 0.9134\n",
      "Epoch 188/6000\n",
      "157/157 [==============================] - 30s 188ms/step - loss: 0.1944 - accuracy: 0.9237 - val_loss: 0.2318 - val_accuracy: 0.9151\n",
      "Epoch 189/6000\n",
      "157/157 [==============================] - 27s 168ms/step - loss: 0.1954 - accuracy: 0.9234 - val_loss: 0.2356 - val_accuracy: 0.9129\n",
      "Epoch 190/6000\n",
      "157/157 [==============================] - 27s 168ms/step - loss: 0.1948 - accuracy: 0.9238 - val_loss: 0.2326 - val_accuracy: 0.9136\n",
      "Epoch 191/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.1944 - accuracy: 0.9242 - val_loss: 0.2344 - val_accuracy: 0.9129\n",
      "Epoch 192/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.1930 - accuracy: 0.9243 - val_loss: 0.2341 - val_accuracy: 0.9145\n",
      "Epoch 193/6000\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.1941 - accuracy: 0.9240 - val_loss: 0.2330 - val_accuracy: 0.9151\n",
      "Epoch 194/6000\n",
      "157/157 [==============================] - 30s 191ms/step - loss: 0.1929 - accuracy: 0.9247 - val_loss: 0.2353 - val_accuracy: 0.9141\n",
      "Epoch 195/6000\n",
      "157/157 [==============================] - 26s 164ms/step - loss: 0.1942 - accuracy: 0.9237 - val_loss: 0.2336 - val_accuracy: 0.9148\n",
      "Epoch 196/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.1903 - accuracy: 0.9254 - val_loss: 0.2403 - val_accuracy: 0.9118\n",
      "Epoch 197/6000\n",
      "157/157 [==============================] - 27s 175ms/step - loss: 0.1921 - accuracy: 0.9251 - val_loss: 0.2311 - val_accuracy: 0.9148\n",
      "Epoch 198/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.1928 - accuracy: 0.9248 - val_loss: 0.2308 - val_accuracy: 0.9149\n",
      "Epoch 199/6000\n",
      "157/157 [==============================] - 31s 195ms/step - loss: 0.1898 - accuracy: 0.9257 - val_loss: 0.2348 - val_accuracy: 0.9132\n",
      "Epoch 200/6000\n",
      "157/157 [==============================] - 24s 151ms/step - loss: 0.1907 - accuracy: 0.9256 - val_loss: 0.2319 - val_accuracy: 0.9155\n",
      "Epoch 201/6000\n",
      "157/157 [==============================] - 29s 182ms/step - loss: 0.1901 - accuracy: 0.9258 - val_loss: 0.2316 - val_accuracy: 0.9151\n",
      "Epoch 202/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.1899 - accuracy: 0.9259 - val_loss: 0.2326 - val_accuracy: 0.9155\n",
      "Epoch 203/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.1909 - accuracy: 0.9256 - val_loss: 0.2283 - val_accuracy: 0.9164\n",
      "Epoch 204/6000\n",
      "157/157 [==============================] - 28s 181ms/step - loss: 0.1877 - accuracy: 0.9274 - val_loss: 0.2302 - val_accuracy: 0.9169\n",
      "Epoch 205/6000\n",
      "157/157 [==============================] - 29s 182ms/step - loss: 0.1885 - accuracy: 0.9264 - val_loss: 0.2289 - val_accuracy: 0.9165\n",
      "Epoch 206/6000\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.1877 - accuracy: 0.9267 - val_loss: 0.2249 - val_accuracy: 0.9179\n",
      "Epoch 207/6000\n",
      "157/157 [==============================] - 26s 162ms/step - loss: 0.1877 - accuracy: 0.9266 - val_loss: 0.2273 - val_accuracy: 0.9171\n",
      "Epoch 208/6000\n",
      "157/157 [==============================] - 26s 168ms/step - loss: 0.1877 - accuracy: 0.9270 - val_loss: 0.2263 - val_accuracy: 0.9179\n",
      "Epoch 209/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.1860 - accuracy: 0.9275 - val_loss: 0.2233 - val_accuracy: 0.9184\n",
      "Epoch 210/6000\n",
      "157/157 [==============================] - 28s 175ms/step - loss: 0.1874 - accuracy: 0.9271 - val_loss: 0.2331 - val_accuracy: 0.9153\n",
      "Epoch 211/6000\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 0.1868 - accuracy: 0.9275 - val_loss: 0.2287 - val_accuracy: 0.9171\n",
      "Epoch 212/6000\n",
      "157/157 [==============================] - 26s 163ms/step - loss: 0.1856 - accuracy: 0.9274 - val_loss: 0.2226 - val_accuracy: 0.9190\n",
      "Epoch 213/6000\n",
      "157/157 [==============================] - 28s 175ms/step - loss: 0.1862 - accuracy: 0.9278 - val_loss: 0.2264 - val_accuracy: 0.9172\n",
      "Epoch 214/6000\n",
      "157/157 [==============================] - 27s 175ms/step - loss: 0.1838 - accuracy: 0.9283 - val_loss: 0.2218 - val_accuracy: 0.9194\n",
      "Epoch 215/6000\n",
      "157/157 [==============================] - 27s 173ms/step - loss: 0.1846 - accuracy: 0.9277 - val_loss: 0.2308 - val_accuracy: 0.9160\n",
      "Epoch 216/6000\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 0.1849 - accuracy: 0.9281 - val_loss: 0.2312 - val_accuracy: 0.9154\n",
      "Epoch 217/6000\n",
      "157/157 [==============================] - 27s 175ms/step - loss: 0.1842 - accuracy: 0.9284 - val_loss: 0.2315 - val_accuracy: 0.9158\n",
      "Epoch 218/6000\n",
      "157/157 [==============================] - 27s 174ms/step - loss: 0.1838 - accuracy: 0.9289 - val_loss: 0.2276 - val_accuracy: 0.9172\n",
      "Epoch 219/6000\n",
      "157/157 [==============================] - 29s 182ms/step - loss: 0.1838 - accuracy: 0.9288 - val_loss: 0.2258 - val_accuracy: 0.9188\n",
      "Epoch 220/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.1838 - accuracy: 0.9286 - val_loss: 0.2250 - val_accuracy: 0.9188\n",
      "Epoch 221/6000\n",
      "157/157 [==============================] - 28s 181ms/step - loss: 0.1835 - accuracy: 0.9286 - val_loss: 0.2275 - val_accuracy: 0.9174\n",
      "Epoch 222/6000\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 0.1814 - accuracy: 0.9296 - val_loss: 0.2302 - val_accuracy: 0.9174\n",
      "Epoch 223/6000\n",
      "157/157 [==============================] - 26s 169ms/step - loss: 0.1820 - accuracy: 0.9293 - val_loss: 0.2208 - val_accuracy: 0.9192\n",
      "Epoch 224/6000\n",
      "157/157 [==============================] - 27s 172ms/step - loss: 0.1822 - accuracy: 0.9294 - val_loss: 0.2310 - val_accuracy: 0.9171\n",
      "Epoch 225/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.1812 - accuracy: 0.9297 - val_loss: 0.2259 - val_accuracy: 0.9177\n",
      "Epoch 226/6000\n",
      "157/157 [==============================] - 28s 181ms/step - loss: 0.1812 - accuracy: 0.9298 - val_loss: 0.2204 - val_accuracy: 0.9212\n",
      "Epoch 227/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.1804 - accuracy: 0.9302 - val_loss: 0.2267 - val_accuracy: 0.9179\n",
      "Epoch 228/6000\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 0.1806 - accuracy: 0.9297 - val_loss: 0.2267 - val_accuracy: 0.9189\n",
      "Epoch 229/6000\n",
      "157/157 [==============================] - 24s 151ms/step - loss: 0.1806 - accuracy: 0.9301 - val_loss: 0.2246 - val_accuracy: 0.9185\n",
      "Epoch 230/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.1794 - accuracy: 0.9305 - val_loss: 0.2236 - val_accuracy: 0.9199\n",
      "Epoch 231/6000\n",
      "157/157 [==============================] - 30s 190ms/step - loss: 0.1801 - accuracy: 0.9302 - val_loss: 0.2208 - val_accuracy: 0.9204\n",
      "Epoch 232/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.1794 - accuracy: 0.9306 - val_loss: 0.2380 - val_accuracy: 0.9142\n",
      "Epoch 233/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.1783 - accuracy: 0.9312 - val_loss: 0.2280 - val_accuracy: 0.9180\n",
      "Epoch 234/6000\n",
      "157/157 [==============================] - 24s 154ms/step - loss: 0.1797 - accuracy: 0.9302 - val_loss: 0.2258 - val_accuracy: 0.9183\n",
      "Epoch 235/6000\n",
      "157/157 [==============================] - 26s 165ms/step - loss: 0.1797 - accuracy: 0.9308 - val_loss: 0.2267 - val_accuracy: 0.9191\n",
      "Epoch 236/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.1784 - accuracy: 0.9313 - val_loss: 0.2271 - val_accuracy: 0.9180\n",
      "Epoch 237/6000\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 0.1771 - accuracy: 0.9313 - val_loss: 0.2328 - val_accuracy: 0.9168\n",
      "Epoch 238/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.1763 - accuracy: 0.9319 - val_loss: 0.2292 - val_accuracy: 0.9177\n",
      "Epoch 239/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.1782 - accuracy: 0.9309 - val_loss: 0.2186 - val_accuracy: 0.9216\n",
      "Epoch 240/6000\n",
      "157/157 [==============================] - 25s 156ms/step - loss: 0.1754 - accuracy: 0.9322 - val_loss: 0.2258 - val_accuracy: 0.9188\n",
      "Epoch 241/6000\n",
      "157/157 [==============================] - 27s 170ms/step - loss: 0.1765 - accuracy: 0.9317 - val_loss: 0.2175 - val_accuracy: 0.9218\n",
      "Epoch 242/6000\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 0.1766 - accuracy: 0.9318 - val_loss: 0.2269 - val_accuracy: 0.9191\n",
      "Epoch 243/6000\n",
      "157/157 [==============================] - 28s 182ms/step - loss: 0.1765 - accuracy: 0.9311 - val_loss: 0.2185 - val_accuracy: 0.9227\n",
      "Epoch 244/6000\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 0.1747 - accuracy: 0.9325 - val_loss: 0.2236 - val_accuracy: 0.9204\n",
      "Epoch 245/6000\n",
      "157/157 [==============================] - 24s 153ms/step - loss: 0.1772 - accuracy: 0.9316 - val_loss: 0.2250 - val_accuracy: 0.9200\n",
      "Epoch 246/6000\n",
      "157/157 [==============================] - 29s 182ms/step - loss: 0.1752 - accuracy: 0.9324 - val_loss: 0.2213 - val_accuracy: 0.9202\n",
      "Epoch 247/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.1756 - accuracy: 0.9321 - val_loss: 0.2199 - val_accuracy: 0.9218\n",
      "Epoch 248/6000\n",
      "157/157 [==============================] - 28s 181ms/step - loss: 0.1736 - accuracy: 0.9332 - val_loss: 0.2247 - val_accuracy: 0.9194\n",
      "Epoch 249/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.1745 - accuracy: 0.9324 - val_loss: 0.2207 - val_accuracy: 0.9212\n",
      "Epoch 250/6000\n",
      "157/157 [==============================] - 29s 182ms/step - loss: 0.1754 - accuracy: 0.9325 - val_loss: 0.2340 - val_accuracy: 0.9163\n",
      "Epoch 251/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.1751 - accuracy: 0.9325 - val_loss: 0.2242 - val_accuracy: 0.9201\n",
      "Epoch 252/6000\n",
      "157/157 [==============================] - 26s 162ms/step - loss: 0.1741 - accuracy: 0.9327 - val_loss: 0.2172 - val_accuracy: 0.9219\n",
      "Epoch 253/6000\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 0.1736 - accuracy: 0.9333 - val_loss: 0.2202 - val_accuracy: 0.9209\n",
      "Epoch 254/6000\n",
      "157/157 [==============================] - 26s 166ms/step - loss: 0.1710 - accuracy: 0.9340 - val_loss: 0.2225 - val_accuracy: 0.9208\n",
      "Epoch 255/6000\n",
      "157/157 [==============================] - 26s 169ms/step - loss: 0.1717 - accuracy: 0.9338 - val_loss: 0.2197 - val_accuracy: 0.9218\n",
      "Epoch 256/6000\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 0.1705 - accuracy: 0.9344 - val_loss: 0.2231 - val_accuracy: 0.9214\n",
      "Epoch 257/6000\n",
      "157/157 [==============================] - 27s 169ms/step - loss: 0.1724 - accuracy: 0.9335 - val_loss: 0.2244 - val_accuracy: 0.9200\n",
      "Epoch 258/6000\n",
      "157/157 [==============================] - 26s 167ms/step - loss: 0.1721 - accuracy: 0.9341 - val_loss: 0.2240 - val_accuracy: 0.9202\n",
      "Epoch 258: early stopping\n",
      "##########################################################################\n",
      "------val_accuracy-----> 92.27 | 93.44 <----------accuracy----------\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/LTC-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/LTC-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "working on pair: EUR/USDT\n",
      "One_pair_AI_Gen : EUR/USDT\n",
      "price_volatility_15m:0.05%\n",
      "mini_expand : EUR/USDT\n",
      "---buy_simple_up--- Buy pct: 0.5%\n",
      "---buy_only--- Max time window: 10%\n",
      "---buy_only--- no b\n",
      "---buy_only--- no sell\n",
      "df original shape (407580, 1607)\n",
      "df original shape buy mean : 0.04956082241523137\n",
      "df choosen data shape(407580, 1607)\n",
      "pair: True\n",
      "81516\n",
      "normalizing ...\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/EUR-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_96 (Dense)            (None, 250)               401750    \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 250)               0         \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 20)                5020      \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,871\n",
      "Trainable params: 407,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_UP_CLOSE/EUR-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "Epoch 1/6000\n",
      "128/128 [==============================] - 33s 182ms/step - loss: 0.0568 - accuracy: 0.9762 - val_loss: 0.0040 - val_accuracy: 0.9990\n",
      "Epoch 2/6000\n",
      "128/128 [==============================] - 18s 144ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0022 - val_accuracy: 0.9996\n",
      "Epoch 3/6000\n",
      "128/128 [==============================] - 17s 137ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.0018 - val_accuracy: 0.9997\n",
      "Epoch 4/6000\n",
      "128/128 [==============================] - 18s 140ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
      "Epoch 5/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "Epoch 6/6000\n",
      "128/128 [==============================] - 17s 135ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 7/6000\n",
      "128/128 [==============================] - 17s 136ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 8/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 9/6000\n",
      "128/128 [==============================] - 17s 135ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "Epoch 10/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
      "Epoch 11/6000\n",
      "128/128 [==============================] - 18s 139ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
      "Epoch 12/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "Epoch 13/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 9.5937e-04 - accuracy: 0.9998 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
      "Epoch 14/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0021 - val_accuracy: 0.9998\n",
      "Epoch 15/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 8.7933e-04 - accuracy: 0.9999 - val_loss: 9.9339e-04 - val_accuracy: 0.9999\n",
      "Epoch 16/6000\n",
      "128/128 [==============================] - 22s 169ms/step - loss: 8.7461e-04 - accuracy: 0.9998 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
      "Epoch 17/6000\n",
      "128/128 [==============================] - 19s 144ms/step - loss: 7.4602e-04 - accuracy: 0.9999 - val_loss: 9.7342e-04 - val_accuracy: 0.9999\n",
      "Epoch 18/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 8.0408e-04 - accuracy: 0.9999 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
      "Epoch 19/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 8.6864e-04 - accuracy: 0.9998 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
      "Epoch 20/6000\n",
      "128/128 [==============================] - 18s 140ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
      "Epoch 21/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0011 - val_accuracy: 0.9999\n",
      "Epoch 22/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 9.0103e-04 - accuracy: 0.9998 - val_loss: 9.8916e-04 - val_accuracy: 0.9999\n",
      "Epoch 23/6000\n",
      "128/128 [==============================] - 17s 135ms/step - loss: 6.5182e-04 - accuracy: 0.9999 - val_loss: 0.0011 - val_accuracy: 0.9999\n",
      "Epoch 24/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 5.6901e-04 - accuracy: 0.9999 - val_loss: 0.0011 - val_accuracy: 0.9999\n",
      "Epoch 25/6000\n",
      "128/128 [==============================] - 23s 184ms/step - loss: 4.4853e-04 - accuracy: 0.9999 - val_loss: 0.0010 - val_accuracy: 0.9999\n",
      "Epoch 26/6000\n",
      "128/128 [==============================] - 20s 157ms/step - loss: 5.2404e-04 - accuracy: 0.9999 - val_loss: 0.0011 - val_accuracy: 0.9999\n",
      "Epoch 27/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 7.8145e-04 - accuracy: 0.9998 - val_loss: 0.0011 - val_accuracy: 0.9999\n",
      "Epoch 28/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 4.7887e-04 - accuracy: 0.9999 - val_loss: 8.9569e-04 - val_accuracy: 0.9999\n",
      "Epoch 29/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 7.4284e-04 - accuracy: 0.9998 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
      "Epoch 30/6000\n",
      "128/128 [==============================] - 17s 136ms/step - loss: 7.4067e-04 - accuracy: 0.9998 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
      "Epoch 31/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 6.8681e-04 - accuracy: 0.9999 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
      "Epoch 32/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 9.3922e-04 - val_accuracy: 0.9999\n",
      "Epoch 33/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 6.2965e-04 - accuracy: 0.9999 - val_loss: 9.9825e-04 - val_accuracy: 0.9999\n",
      "Epoch 34/6000\n",
      "128/128 [==============================] - 17s 134ms/step - loss: 8.2359e-04 - accuracy: 0.9999 - val_loss: 0.0016 - val_accuracy: 0.9999\n",
      "Epoch 35/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 6.1498e-04 - accuracy: 0.9999 - val_loss: 0.0011 - val_accuracy: 0.9999\n",
      "Epoch 36/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 4.3045e-04 - accuracy: 0.9999 - val_loss: 9.5477e-04 - val_accuracy: 0.9999\n",
      "Epoch 37/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 4.0076e-04 - accuracy: 0.9999 - val_loss: 9.3800e-04 - val_accuracy: 0.9999\n",
      "Epoch 38/6000\n",
      "128/128 [==============================] - 17s 135ms/step - loss: 3.0760e-04 - accuracy: 0.9999 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
      "Epoch 39/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 8.4635e-04 - accuracy: 0.9998 - val_loss: 0.0035 - val_accuracy: 0.9995\n",
      "Epoch 39: early stopping\n",
      "##########################################################################\n",
      "------val_accuracy-----> 99.99 | 99.99 <----------accuracy----------\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/EUR-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/EUR-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "working on pair: MANA/USDT\n",
      "One_pair_AI_Gen : MANA/USDT\n",
      "price_volatility_15m:0.4%\n",
      "mini_expand : MANA/USDT\n",
      "---buy_simple_up--- Buy pct: 0.5%\n",
      "---buy_only--- Max time window: 10%\n",
      "---buy_only--- no b\n",
      "---buy_only--- no sell\n",
      "df original shape (402150, 1607)\n",
      "df original shape buy mean : 9.367897550665175\n",
      "df choosen data shape(402150, 1607)\n",
      "pair: True\n",
      "80430\n",
      "normalizing ...\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/MANA-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_100 (Dense)           (None, 250)               401750    \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 250)               0         \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 20)                5020      \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,871\n",
      "Trainable params: 407,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_UP_CLOSE/MANA-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "Epoch 1/6000\n",
      "126/126 [==============================] - 32s 186ms/step - loss: 0.5637 - accuracy: 0.7063 - val_loss: 0.5311 - val_accuracy: 0.7342\n",
      "Epoch 2/6000\n",
      "126/126 [==============================] - 18s 145ms/step - loss: 0.5208 - accuracy: 0.7406 - val_loss: 0.4885 - val_accuracy: 0.7642\n",
      "Epoch 3/6000\n",
      "126/126 [==============================] - 18s 142ms/step - loss: 0.4854 - accuracy: 0.7653 - val_loss: 0.4617 - val_accuracy: 0.7825\n",
      "Epoch 4/6000\n",
      "126/126 [==============================] - 18s 141ms/step - loss: 0.4534 - accuracy: 0.7863 - val_loss: 0.4224 - val_accuracy: 0.8127\n",
      "Epoch 5/6000\n",
      "126/126 [==============================] - 17s 137ms/step - loss: 0.4255 - accuracy: 0.8045 - val_loss: 0.3904 - val_accuracy: 0.8290\n",
      "Epoch 6/6000\n",
      "126/126 [==============================] - 18s 139ms/step - loss: 0.4003 - accuracy: 0.8201 - val_loss: 0.3695 - val_accuracy: 0.8391\n",
      "Epoch 7/6000\n",
      "126/126 [==============================] - 17s 138ms/step - loss: 0.3818 - accuracy: 0.8293 - val_loss: 0.3496 - val_accuracy: 0.8494\n",
      "Epoch 8/6000\n",
      "126/126 [==============================] - 18s 139ms/step - loss: 0.3625 - accuracy: 0.8408 - val_loss: 0.3316 - val_accuracy: 0.8617\n",
      "Epoch 9/6000\n",
      "126/126 [==============================] - 20s 161ms/step - loss: 0.3470 - accuracy: 0.8491 - val_loss: 0.3211 - val_accuracy: 0.8641\n",
      "Epoch 10/6000\n",
      "126/126 [==============================] - 19s 147ms/step - loss: 0.3349 - accuracy: 0.8549 - val_loss: 0.3139 - val_accuracy: 0.8690\n",
      "Epoch 11/6000\n",
      "126/126 [==============================] - 17s 136ms/step - loss: 0.3232 - accuracy: 0.8617 - val_loss: 0.2909 - val_accuracy: 0.8800\n",
      "Epoch 12/6000\n",
      "126/126 [==============================] - 23s 181ms/step - loss: 0.3122 - accuracy: 0.8674 - val_loss: 0.2840 - val_accuracy: 0.8843\n",
      "Epoch 13/6000\n",
      "126/126 [==============================] - 18s 146ms/step - loss: 0.3030 - accuracy: 0.8718 - val_loss: 0.2743 - val_accuracy: 0.8880\n",
      "Epoch 14/6000\n",
      "126/126 [==============================] - 21s 162ms/step - loss: 0.2959 - accuracy: 0.8749 - val_loss: 0.2652 - val_accuracy: 0.8918\n",
      "Epoch 15/6000\n",
      "126/126 [==============================] - 24s 189ms/step - loss: 0.2880 - accuracy: 0.8796 - val_loss: 0.2682 - val_accuracy: 0.8916\n",
      "Epoch 16/6000\n",
      "126/126 [==============================] - 17s 135ms/step - loss: 0.2827 - accuracy: 0.8816 - val_loss: 0.2576 - val_accuracy: 0.8957\n",
      "Epoch 17/6000\n",
      "126/126 [==============================] - 22s 173ms/step - loss: 0.2747 - accuracy: 0.8855 - val_loss: 0.2529 - val_accuracy: 0.8987\n",
      "Epoch 18/6000\n",
      "126/126 [==============================] - 22s 178ms/step - loss: 0.2693 - accuracy: 0.8887 - val_loss: 0.2442 - val_accuracy: 0.9032\n",
      "Epoch 19/6000\n",
      "126/126 [==============================] - 17s 135ms/step - loss: 0.2626 - accuracy: 0.8915 - val_loss: 0.2411 - val_accuracy: 0.9063\n",
      "Epoch 20/6000\n",
      "126/126 [==============================] - 23s 182ms/step - loss: 0.2593 - accuracy: 0.8932 - val_loss: 0.2345 - val_accuracy: 0.9060\n",
      "Epoch 21/6000\n",
      "126/126 [==============================] - 21s 166ms/step - loss: 0.2538 - accuracy: 0.8960 - val_loss: 0.2363 - val_accuracy: 0.9069\n",
      "Epoch 22/6000\n",
      "126/126 [==============================] - 19s 146ms/step - loss: 0.2501 - accuracy: 0.8971 - val_loss: 0.2239 - val_accuracy: 0.9119\n",
      "Epoch 23/6000\n",
      "126/126 [==============================] - 22s 178ms/step - loss: 0.2450 - accuracy: 0.8999 - val_loss: 0.2231 - val_accuracy: 0.9144\n",
      "Epoch 24/6000\n",
      "126/126 [==============================] - 23s 185ms/step - loss: 0.2414 - accuracy: 0.9022 - val_loss: 0.2220 - val_accuracy: 0.9145\n",
      "Epoch 25/6000\n",
      "126/126 [==============================] - 17s 138ms/step - loss: 0.2379 - accuracy: 0.9033 - val_loss: 0.2330 - val_accuracy: 0.9067\n",
      "Epoch 26/6000\n",
      "126/126 [==============================] - 23s 179ms/step - loss: 0.2339 - accuracy: 0.9057 - val_loss: 0.2177 - val_accuracy: 0.9143\n",
      "Epoch 27/6000\n",
      "126/126 [==============================] - 23s 185ms/step - loss: 0.2307 - accuracy: 0.9073 - val_loss: 0.2111 - val_accuracy: 0.9181\n",
      "Epoch 28/6000\n",
      "126/126 [==============================] - 23s 185ms/step - loss: 0.2258 - accuracy: 0.9089 - val_loss: 0.2075 - val_accuracy: 0.9203\n",
      "Epoch 29/6000\n",
      "126/126 [==============================] - 19s 152ms/step - loss: 0.2229 - accuracy: 0.9107 - val_loss: 0.2084 - val_accuracy: 0.9210\n",
      "Epoch 30/6000\n",
      "126/126 [==============================] - 23s 177ms/step - loss: 0.2204 - accuracy: 0.9122 - val_loss: 0.2040 - val_accuracy: 0.9230\n",
      "Epoch 31/6000\n",
      "126/126 [==============================] - 23s 180ms/step - loss: 0.2176 - accuracy: 0.9132 - val_loss: 0.2031 - val_accuracy: 0.9216\n",
      "Epoch 32/6000\n",
      "126/126 [==============================] - 22s 176ms/step - loss: 0.2162 - accuracy: 0.9137 - val_loss: 0.2004 - val_accuracy: 0.9235\n",
      "Epoch 33/6000\n",
      "126/126 [==============================] - 19s 150ms/step - loss: 0.2134 - accuracy: 0.9149 - val_loss: 0.1997 - val_accuracy: 0.9241\n",
      "Epoch 34/6000\n",
      "126/126 [==============================] - 24s 187ms/step - loss: 0.2095 - accuracy: 0.9170 - val_loss: 0.1946 - val_accuracy: 0.9269\n",
      "Epoch 35/6000\n",
      "126/126 [==============================] - 22s 178ms/step - loss: 0.2072 - accuracy: 0.9180 - val_loss: 0.1943 - val_accuracy: 0.9269\n",
      "Epoch 36/6000\n",
      "126/126 [==============================] - 18s 146ms/step - loss: 0.2044 - accuracy: 0.9189 - val_loss: 0.2005 - val_accuracy: 0.9254\n",
      "Epoch 37/6000\n",
      "126/126 [==============================] - 23s 183ms/step - loss: 0.2034 - accuracy: 0.9196 - val_loss: 0.1908 - val_accuracy: 0.9292\n",
      "Epoch 38/6000\n",
      "126/126 [==============================] - 23s 179ms/step - loss: 0.2024 - accuracy: 0.9200 - val_loss: 0.1914 - val_accuracy: 0.9276\n",
      "Epoch 39/6000\n",
      "126/126 [==============================] - 23s 184ms/step - loss: 0.1987 - accuracy: 0.9213 - val_loss: 0.1862 - val_accuracy: 0.9308\n",
      "Epoch 40/6000\n",
      "126/126 [==============================] - 21s 165ms/step - loss: 0.1964 - accuracy: 0.9226 - val_loss: 0.1860 - val_accuracy: 0.9309\n",
      "Epoch 41/6000\n",
      "126/126 [==============================] - 22s 170ms/step - loss: 0.1936 - accuracy: 0.9243 - val_loss: 0.1874 - val_accuracy: 0.9318\n",
      "Epoch 42/6000\n",
      "126/126 [==============================] - 20s 161ms/step - loss: 0.1919 - accuracy: 0.9247 - val_loss: 0.1770 - val_accuracy: 0.9346\n",
      "Epoch 43/6000\n",
      "126/126 [==============================] - 24s 189ms/step - loss: 0.1907 - accuracy: 0.9258 - val_loss: 0.1779 - val_accuracy: 0.9359\n",
      "Epoch 44/6000\n",
      "126/126 [==============================] - 23s 180ms/step - loss: 0.1872 - accuracy: 0.9266 - val_loss: 0.1864 - val_accuracy: 0.9308\n",
      "Epoch 45/6000\n",
      "126/126 [==============================] - 22s 178ms/step - loss: 0.1858 - accuracy: 0.9277 - val_loss: 0.1772 - val_accuracy: 0.9358\n",
      "Epoch 46/6000\n",
      "126/126 [==============================] - 18s 140ms/step - loss: 0.1852 - accuracy: 0.9277 - val_loss: 0.1721 - val_accuracy: 0.9357\n",
      "Epoch 47/6000\n",
      "126/126 [==============================] - 23s 182ms/step - loss: 0.1835 - accuracy: 0.9288 - val_loss: 0.1690 - val_accuracy: 0.9379\n",
      "Epoch 48/6000\n",
      "126/126 [==============================] - 23s 185ms/step - loss: 0.1812 - accuracy: 0.9295 - val_loss: 0.1740 - val_accuracy: 0.9356\n",
      "Epoch 49/6000\n",
      "126/126 [==============================] - 18s 142ms/step - loss: 0.1802 - accuracy: 0.9298 - val_loss: 0.1675 - val_accuracy: 0.9389\n",
      "Epoch 50/6000\n",
      "126/126 [==============================] - 23s 181ms/step - loss: 0.1777 - accuracy: 0.9311 - val_loss: 0.1757 - val_accuracy: 0.9356\n",
      "Epoch 51/6000\n",
      "126/126 [==============================] - 23s 179ms/step - loss: 0.1771 - accuracy: 0.9317 - val_loss: 0.1695 - val_accuracy: 0.9376\n",
      "Epoch 52/6000\n",
      "126/126 [==============================] - 23s 184ms/step - loss: 0.1750 - accuracy: 0.9327 - val_loss: 0.1698 - val_accuracy: 0.9385\n",
      "Epoch 53/6000\n",
      "126/126 [==============================] - 18s 142ms/step - loss: 0.1746 - accuracy: 0.9321 - val_loss: 0.1666 - val_accuracy: 0.9400\n",
      "Epoch 54/6000\n",
      "126/126 [==============================] - 23s 180ms/step - loss: 0.1713 - accuracy: 0.9344 - val_loss: 0.1660 - val_accuracy: 0.9400\n",
      "Epoch 55/6000\n",
      "126/126 [==============================] - 23s 185ms/step - loss: 0.1707 - accuracy: 0.9343 - val_loss: 0.1613 - val_accuracy: 0.9417\n",
      "Epoch 56/6000\n",
      "126/126 [==============================] - 23s 180ms/step - loss: 0.1699 - accuracy: 0.9346 - val_loss: 0.1712 - val_accuracy: 0.9386\n",
      "Epoch 57/6000\n",
      "126/126 [==============================] - 18s 142ms/step - loss: 0.1658 - accuracy: 0.9365 - val_loss: 0.1661 - val_accuracy: 0.9402\n",
      "Epoch 58/6000\n",
      "126/126 [==============================] - 24s 187ms/step - loss: 0.1671 - accuracy: 0.9362 - val_loss: 0.1598 - val_accuracy: 0.9427\n",
      "Epoch 59/6000\n",
      "126/126 [==============================] - 24s 191ms/step - loss: 0.1660 - accuracy: 0.9362 - val_loss: 0.1664 - val_accuracy: 0.9408\n",
      "Epoch 60/6000\n",
      "126/126 [==============================] - 21s 168ms/step - loss: 0.1638 - accuracy: 0.9373 - val_loss: 0.1603 - val_accuracy: 0.9430\n",
      "Epoch 61/6000\n",
      "126/126 [==============================] - 20s 154ms/step - loss: 0.1634 - accuracy: 0.9375 - val_loss: 0.1697 - val_accuracy: 0.9381\n",
      "Epoch 62/6000\n",
      "126/126 [==============================] - 23s 187ms/step - loss: 0.1612 - accuracy: 0.9385 - val_loss: 0.1573 - val_accuracy: 0.9445\n",
      "Epoch 63/6000\n",
      "126/126 [==============================] - 24s 188ms/step - loss: 0.1617 - accuracy: 0.9383 - val_loss: 0.1571 - val_accuracy: 0.9446\n",
      "Epoch 64/6000\n",
      "126/126 [==============================] - 17s 135ms/step - loss: 0.1598 - accuracy: 0.9392 - val_loss: 0.1658 - val_accuracy: 0.9414\n",
      "Epoch 65/6000\n",
      "126/126 [==============================] - 23s 184ms/step - loss: 0.1578 - accuracy: 0.9396 - val_loss: 0.1627 - val_accuracy: 0.9427\n",
      "Epoch 66/6000\n",
      "126/126 [==============================] - 24s 194ms/step - loss: 0.1562 - accuracy: 0.9402 - val_loss: 0.1606 - val_accuracy: 0.9432\n",
      "Epoch 67/6000\n",
      "126/126 [==============================] - 22s 174ms/step - loss: 0.1547 - accuracy: 0.9414 - val_loss: 0.1512 - val_accuracy: 0.9470\n",
      "Epoch 68/6000\n",
      "126/126 [==============================] - 24s 190ms/step - loss: 0.1549 - accuracy: 0.9415 - val_loss: 0.1611 - val_accuracy: 0.9430\n",
      "Epoch 69/6000\n",
      "126/126 [==============================] - 17s 135ms/step - loss: 0.1528 - accuracy: 0.9422 - val_loss: 0.1501 - val_accuracy: 0.9479\n",
      "Epoch 70/6000\n",
      "126/126 [==============================] - 24s 194ms/step - loss: 0.1522 - accuracy: 0.9424 - val_loss: 0.1515 - val_accuracy: 0.9474\n",
      "Epoch 71/6000\n",
      "126/126 [==============================] - 23s 184ms/step - loss: 0.1516 - accuracy: 0.9429 - val_loss: 0.1555 - val_accuracy: 0.9454\n",
      "Epoch 72/6000\n",
      "126/126 [==============================] - 17s 137ms/step - loss: 0.1492 - accuracy: 0.9437 - val_loss: 0.1534 - val_accuracy: 0.9466\n",
      "Epoch 73/6000\n",
      "126/126 [==============================] - 23s 180ms/step - loss: 0.1506 - accuracy: 0.9433 - val_loss: 0.1495 - val_accuracy: 0.9483\n",
      "Epoch 74/6000\n",
      "126/126 [==============================] - 23s 186ms/step - loss: 0.1478 - accuracy: 0.9444 - val_loss: 0.1520 - val_accuracy: 0.9474\n",
      "Epoch 75/6000\n",
      "126/126 [==============================] - 23s 187ms/step - loss: 0.1459 - accuracy: 0.9443 - val_loss: 0.1507 - val_accuracy: 0.9477\n",
      "Epoch 76/6000\n",
      "126/126 [==============================] - 17s 137ms/step - loss: 0.1483 - accuracy: 0.9441 - val_loss: 0.1499 - val_accuracy: 0.9486\n",
      "Epoch 77/6000\n",
      "126/126 [==============================] - 23s 181ms/step - loss: 0.1446 - accuracy: 0.9456 - val_loss: 0.1478 - val_accuracy: 0.9490\n",
      "Epoch 78/6000\n",
      "126/126 [==============================] - 21s 170ms/step - loss: 0.1451 - accuracy: 0.9453 - val_loss: 0.1482 - val_accuracy: 0.9484\n",
      "Epoch 79/6000\n",
      "126/126 [==============================] - 23s 186ms/step - loss: 0.1429 - accuracy: 0.9462 - val_loss: 0.1447 - val_accuracy: 0.9511\n",
      "Epoch 80/6000\n",
      "126/126 [==============================] - 24s 194ms/step - loss: 0.1425 - accuracy: 0.9463 - val_loss: 0.1435 - val_accuracy: 0.9515\n",
      "Epoch 81/6000\n",
      "126/126 [==============================] - 17s 137ms/step - loss: 0.1407 - accuracy: 0.9470 - val_loss: 0.1591 - val_accuracy: 0.9453\n",
      "Epoch 82/6000\n",
      "126/126 [==============================] - 22s 176ms/step - loss: 0.1404 - accuracy: 0.9475 - val_loss: 0.1390 - val_accuracy: 0.9522\n",
      "Epoch 83/6000\n",
      "126/126 [==============================] - 24s 194ms/step - loss: 0.1400 - accuracy: 0.9472 - val_loss: 0.1552 - val_accuracy: 0.9468\n",
      "Epoch 84/6000\n",
      "126/126 [==============================] - 24s 188ms/step - loss: 0.1402 - accuracy: 0.9473 - val_loss: 0.1452 - val_accuracy: 0.9509\n",
      "Epoch 85/6000\n",
      "126/126 [==============================] - 18s 147ms/step - loss: 0.1378 - accuracy: 0.9480 - val_loss: 0.1498 - val_accuracy: 0.9482\n",
      "Epoch 86/6000\n",
      "126/126 [==============================] - 23s 180ms/step - loss: 0.1368 - accuracy: 0.9489 - val_loss: 0.1514 - val_accuracy: 0.9487\n",
      "Epoch 87/6000\n",
      "126/126 [==============================] - 23s 187ms/step - loss: 0.1368 - accuracy: 0.9488 - val_loss: 0.1407 - val_accuracy: 0.9531\n",
      "Epoch 88/6000\n",
      "126/126 [==============================] - 26s 204ms/step - loss: 0.1361 - accuracy: 0.9492 - val_loss: 0.1483 - val_accuracy: 0.9502\n",
      "Epoch 89/6000\n",
      "126/126 [==============================] - 24s 187ms/step - loss: 0.1354 - accuracy: 0.9493 - val_loss: 0.1493 - val_accuracy: 0.9495\n",
      "Epoch 90/6000\n",
      "126/126 [==============================] - 17s 134ms/step - loss: 0.1330 - accuracy: 0.9504 - val_loss: 0.1427 - val_accuracy: 0.9515\n",
      "Epoch 91/6000\n",
      "126/126 [==============================] - 24s 192ms/step - loss: 0.1340 - accuracy: 0.9500 - val_loss: 0.1489 - val_accuracy: 0.9510\n",
      "Epoch 92/6000\n",
      "126/126 [==============================] - 22s 178ms/step - loss: 0.1336 - accuracy: 0.9500 - val_loss: 0.1378 - val_accuracy: 0.9540\n",
      "Epoch 93/6000\n",
      "126/126 [==============================] - 17s 138ms/step - loss: 0.1308 - accuracy: 0.9516 - val_loss: 0.1373 - val_accuracy: 0.9545\n",
      "Epoch 94/6000\n",
      "126/126 [==============================] - 24s 189ms/step - loss: 0.1332 - accuracy: 0.9505 - val_loss: 0.1458 - val_accuracy: 0.9516\n",
      "Epoch 95/6000\n",
      "126/126 [==============================] - 24s 187ms/step - loss: 0.1299 - accuracy: 0.9522 - val_loss: 0.1460 - val_accuracy: 0.9507\n",
      "Epoch 96/6000\n",
      "126/126 [==============================] - 22s 173ms/step - loss: 0.1286 - accuracy: 0.9521 - val_loss: 0.1490 - val_accuracy: 0.9498\n",
      "Epoch 97/6000\n",
      "126/126 [==============================] - 19s 150ms/step - loss: 0.1291 - accuracy: 0.9521 - val_loss: 0.1421 - val_accuracy: 0.9521\n",
      "Epoch 98/6000\n",
      "126/126 [==============================] - 23s 185ms/step - loss: 0.1279 - accuracy: 0.9525 - val_loss: 0.1383 - val_accuracy: 0.9541\n",
      "Epoch 99/6000\n",
      "126/126 [==============================] - 21s 169ms/step - loss: 0.1269 - accuracy: 0.9530 - val_loss: 0.1432 - val_accuracy: 0.9521\n",
      "Epoch 100/6000\n",
      "126/126 [==============================] - 24s 188ms/step - loss: 0.1284 - accuracy: 0.9528 - val_loss: 0.1332 - val_accuracy: 0.9552\n",
      "Epoch 101/6000\n",
      "126/126 [==============================] - 23s 185ms/step - loss: 0.1276 - accuracy: 0.9529 - val_loss: 0.1411 - val_accuracy: 0.9524\n",
      "Epoch 102/6000\n",
      "126/126 [==============================] - 18s 139ms/step - loss: 0.1258 - accuracy: 0.9533 - val_loss: 0.1439 - val_accuracy: 0.9512\n",
      "Epoch 103/6000\n",
      "126/126 [==============================] - 24s 187ms/step - loss: 0.1238 - accuracy: 0.9544 - val_loss: 0.1343 - val_accuracy: 0.9555\n",
      "Epoch 104/6000\n",
      "126/126 [==============================] - 23s 184ms/step - loss: 0.1229 - accuracy: 0.9548 - val_loss: 0.1370 - val_accuracy: 0.9545\n",
      "Epoch 105/6000\n",
      "126/126 [==============================] - 24s 191ms/step - loss: 0.1225 - accuracy: 0.9549 - val_loss: 0.1342 - val_accuracy: 0.9555\n",
      "Epoch 106/6000\n",
      "126/126 [==============================] - 17s 135ms/step - loss: 0.1211 - accuracy: 0.9554 - val_loss: 0.1359 - val_accuracy: 0.9549\n",
      "Epoch 107/6000\n",
      "126/126 [==============================] - 24s 192ms/step - loss: 0.1207 - accuracy: 0.9557 - val_loss: 0.1408 - val_accuracy: 0.9539\n",
      "Epoch 108/6000\n",
      "126/126 [==============================] - 20s 161ms/step - loss: 0.1198 - accuracy: 0.9558 - val_loss: 0.1356 - val_accuracy: 0.9555\n",
      "Epoch 109/6000\n",
      "126/126 [==============================] - 20s 159ms/step - loss: 0.1203 - accuracy: 0.9555 - val_loss: 0.1319 - val_accuracy: 0.9568\n",
      "Epoch 110/6000\n",
      "126/126 [==============================] - 24s 188ms/step - loss: 0.1200 - accuracy: 0.9564 - val_loss: 0.1325 - val_accuracy: 0.9572\n",
      "Epoch 111/6000\n",
      "126/126 [==============================] - 23s 186ms/step - loss: 0.1189 - accuracy: 0.9565 - val_loss: 0.1366 - val_accuracy: 0.9563\n",
      "Epoch 112/6000\n",
      "126/126 [==============================] - 18s 140ms/step - loss: 0.1174 - accuracy: 0.9567 - val_loss: 0.1370 - val_accuracy: 0.9558\n",
      "Epoch 113/6000\n",
      "126/126 [==============================] - 23s 180ms/step - loss: 0.1184 - accuracy: 0.9563 - val_loss: 0.1330 - val_accuracy: 0.9562\n",
      "Epoch 114/6000\n",
      "126/126 [==============================] - 24s 191ms/step - loss: 0.1160 - accuracy: 0.9574 - val_loss: 0.1414 - val_accuracy: 0.9539\n",
      "Epoch 115/6000\n",
      "126/126 [==============================] - 18s 140ms/step - loss: 0.1170 - accuracy: 0.9567 - val_loss: 0.1398 - val_accuracy: 0.9544\n",
      "Epoch 116/6000\n",
      "126/126 [==============================] - 23s 183ms/step - loss: 0.1167 - accuracy: 0.9568 - val_loss: 0.1366 - val_accuracy: 0.9553\n",
      "Epoch 117/6000\n",
      "126/126 [==============================] - 23s 186ms/step - loss: 0.1139 - accuracy: 0.9584 - val_loss: 0.1303 - val_accuracy: 0.9571\n",
      "Epoch 118/6000\n",
      "126/126 [==============================] - 23s 180ms/step - loss: 0.1149 - accuracy: 0.9579 - val_loss: 0.1363 - val_accuracy: 0.9553\n",
      "Epoch 119/6000\n",
      "126/126 [==============================] - 24s 187ms/step - loss: 0.1147 - accuracy: 0.9581 - val_loss: 0.1358 - val_accuracy: 0.9557\n",
      "Epoch 120/6000\n",
      "126/126 [==============================] - 21s 170ms/step - loss: 0.1128 - accuracy: 0.9585 - val_loss: 0.1332 - val_accuracy: 0.9568\n",
      "Epoch 121/6000\n",
      "126/126 [==============================] - 21s 165ms/step - loss: 0.1123 - accuracy: 0.9590 - val_loss: 0.1331 - val_accuracy: 0.9567\n",
      "Epoch 122/6000\n",
      "126/126 [==============================] - 21s 166ms/step - loss: 0.1118 - accuracy: 0.9592 - val_loss: 0.1246 - val_accuracy: 0.9593\n",
      "Epoch 123/6000\n",
      "126/126 [==============================] - 23s 183ms/step - loss: 0.1117 - accuracy: 0.9593 - val_loss: 0.1362 - val_accuracy: 0.9559\n",
      "Epoch 124/6000\n",
      "126/126 [==============================] - 23s 185ms/step - loss: 0.1102 - accuracy: 0.9597 - val_loss: 0.1288 - val_accuracy: 0.9594\n",
      "Epoch 125/6000\n",
      "126/126 [==============================] - 23s 181ms/step - loss: 0.1126 - accuracy: 0.9589 - val_loss: 0.1327 - val_accuracy: 0.9565\n",
      "Epoch 126/6000\n",
      "126/126 [==============================] - 18s 142ms/step - loss: 0.1095 - accuracy: 0.9603 - val_loss: 0.1337 - val_accuracy: 0.9576\n",
      "Epoch 127/6000\n",
      "126/126 [==============================] - 22s 169ms/step - loss: 0.1093 - accuracy: 0.9598 - val_loss: 0.1252 - val_accuracy: 0.9604\n",
      "Epoch 128/6000\n",
      "126/126 [==============================] - 24s 187ms/step - loss: 0.1096 - accuracy: 0.9599 - val_loss: 0.1306 - val_accuracy: 0.9579\n",
      "Epoch 129/6000\n",
      "126/126 [==============================] - 23s 183ms/step - loss: 0.1075 - accuracy: 0.9609 - val_loss: 0.1271 - val_accuracy: 0.9591\n",
      "Epoch 130/6000\n",
      "126/126 [==============================] - 24s 188ms/step - loss: 0.1073 - accuracy: 0.9612 - val_loss: 0.1225 - val_accuracy: 0.9608\n",
      "Epoch 131/6000\n",
      "126/126 [==============================] - 19s 148ms/step - loss: 0.1086 - accuracy: 0.9602 - val_loss: 0.1291 - val_accuracy: 0.9591\n",
      "Epoch 132/6000\n",
      "126/126 [==============================] - 21s 168ms/step - loss: 0.1076 - accuracy: 0.9611 - val_loss: 0.1370 - val_accuracy: 0.9564\n",
      "Epoch 133/6000\n",
      "126/126 [==============================] - 23s 181ms/step - loss: 0.1062 - accuracy: 0.9614 - val_loss: 0.1220 - val_accuracy: 0.9608\n",
      "Epoch 134/6000\n",
      "126/126 [==============================] - 22s 173ms/step - loss: 0.1057 - accuracy: 0.9614 - val_loss: 0.1297 - val_accuracy: 0.9586\n",
      "Epoch 135/6000\n",
      "126/126 [==============================] - 23s 185ms/step - loss: 0.1064 - accuracy: 0.9612 - val_loss: 0.1276 - val_accuracy: 0.9597\n",
      "Epoch 136/6000\n",
      "126/126 [==============================] - 22s 171ms/step - loss: 0.1046 - accuracy: 0.9623 - val_loss: 0.1224 - val_accuracy: 0.9612\n",
      "Epoch 137/6000\n",
      "126/126 [==============================] - 20s 154ms/step - loss: 0.1047 - accuracy: 0.9617 - val_loss: 0.1222 - val_accuracy: 0.9612\n",
      "Epoch 138/6000\n",
      "126/126 [==============================] - 24s 191ms/step - loss: 0.1042 - accuracy: 0.9620 - val_loss: 0.1233 - val_accuracy: 0.9608\n",
      "Epoch 139/6000\n",
      "126/126 [==============================] - 23s 186ms/step - loss: 0.1049 - accuracy: 0.9619 - val_loss: 0.1237 - val_accuracy: 0.9611\n",
      "Epoch 140/6000\n",
      "126/126 [==============================] - 22s 179ms/step - loss: 0.1034 - accuracy: 0.9626 - val_loss: 0.1221 - val_accuracy: 0.9620\n",
      "Epoch 141/6000\n",
      "126/126 [==============================] - 19s 150ms/step - loss: 0.1025 - accuracy: 0.9628 - val_loss: 0.1258 - val_accuracy: 0.9607\n",
      "Epoch 142/6000\n",
      "126/126 [==============================] - 23s 187ms/step - loss: 0.1018 - accuracy: 0.9627 - val_loss: 0.1264 - val_accuracy: 0.9611\n",
      "Epoch 143/6000\n",
      "126/126 [==============================] - 22s 178ms/step - loss: 0.1020 - accuracy: 0.9631 - val_loss: 0.1301 - val_accuracy: 0.9587\n",
      "Epoch 144/6000\n",
      "126/126 [==============================] - 21s 165ms/step - loss: 0.1001 - accuracy: 0.9632 - val_loss: 0.1210 - val_accuracy: 0.9616\n",
      "Epoch 145/6000\n",
      "126/126 [==============================] - 23s 179ms/step - loss: 0.1020 - accuracy: 0.9623 - val_loss: 0.1244 - val_accuracy: 0.9613\n",
      "Epoch 146/6000\n",
      "126/126 [==============================] - 19s 148ms/step - loss: 0.0987 - accuracy: 0.9643 - val_loss: 0.1272 - val_accuracy: 0.9605\n",
      "Epoch 147/6000\n",
      "126/126 [==============================] - 24s 186ms/step - loss: 0.1008 - accuracy: 0.9633 - val_loss: 0.1298 - val_accuracy: 0.9591\n",
      "Epoch 148/6000\n",
      "126/126 [==============================] - 23s 184ms/step - loss: 0.0993 - accuracy: 0.9641 - val_loss: 0.1277 - val_accuracy: 0.9601\n",
      "Epoch 149/6000\n",
      "126/126 [==============================] - 22s 179ms/step - loss: 0.0995 - accuracy: 0.9638 - val_loss: 0.1250 - val_accuracy: 0.9610\n",
      "Epoch 150/6000\n",
      "126/126 [==============================] - 18s 144ms/step - loss: 0.0976 - accuracy: 0.9645 - val_loss: 0.1181 - val_accuracy: 0.9632\n",
      "Epoch 151/6000\n",
      "126/126 [==============================] - 23s 184ms/step - loss: 0.0994 - accuracy: 0.9637 - val_loss: 0.1239 - val_accuracy: 0.9606\n",
      "Epoch 152/6000\n",
      "126/126 [==============================] - 22s 172ms/step - loss: 0.0995 - accuracy: 0.9637 - val_loss: 0.1283 - val_accuracy: 0.9604\n",
      "Epoch 153/6000\n",
      "126/126 [==============================] - 23s 181ms/step - loss: 0.0971 - accuracy: 0.9646 - val_loss: 0.1202 - val_accuracy: 0.9628\n",
      "Epoch 154/6000\n",
      "126/126 [==============================] - 23s 185ms/step - loss: 0.0979 - accuracy: 0.9650 - val_loss: 0.1282 - val_accuracy: 0.9599\n",
      "Epoch 155/6000\n",
      "126/126 [==============================] - 17s 136ms/step - loss: 0.0968 - accuracy: 0.9654 - val_loss: 0.1202 - val_accuracy: 0.9633\n",
      "Epoch 156/6000\n",
      "126/126 [==============================] - 24s 187ms/step - loss: 0.0962 - accuracy: 0.9654 - val_loss: 0.1279 - val_accuracy: 0.9605\n",
      "Epoch 157/6000\n",
      "126/126 [==============================] - 24s 187ms/step - loss: 0.0962 - accuracy: 0.9655 - val_loss: 0.1236 - val_accuracy: 0.9616\n",
      "Epoch 158/6000\n",
      "126/126 [==============================] - 23s 185ms/step - loss: 0.0948 - accuracy: 0.9662 - val_loss: 0.1296 - val_accuracy: 0.9598\n",
      "Epoch 159/6000\n",
      "126/126 [==============================] - 17s 135ms/step - loss: 0.0963 - accuracy: 0.9654 - val_loss: 0.1228 - val_accuracy: 0.9627\n",
      "Epoch 160/6000\n",
      "126/126 [==============================] - 23s 185ms/step - loss: 0.0967 - accuracy: 0.9650 - val_loss: 0.1232 - val_accuracy: 0.9614\n",
      "Epoch 161/6000\n",
      "126/126 [==============================] - 23s 180ms/step - loss: 0.0966 - accuracy: 0.9649 - val_loss: 0.1166 - val_accuracy: 0.9634\n",
      "Epoch 162/6000\n",
      "126/126 [==============================] - 22s 177ms/step - loss: 0.0935 - accuracy: 0.9662 - val_loss: 0.1224 - val_accuracy: 0.9627\n",
      "Epoch 163/6000\n",
      "126/126 [==============================] - 22s 178ms/step - loss: 0.0941 - accuracy: 0.9662 - val_loss: 0.1333 - val_accuracy: 0.9599\n",
      "Epoch 164/6000\n",
      "126/126 [==============================] - 17s 136ms/step - loss: 0.0925 - accuracy: 0.9668 - val_loss: 0.1170 - val_accuracy: 0.9646\n",
      "Epoch 165/6000\n",
      "126/126 [==============================] - 24s 189ms/step - loss: 0.0928 - accuracy: 0.9667 - val_loss: 0.1183 - val_accuracy: 0.9643\n",
      "Epoch 166/6000\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.0934 - accuracy: 0.9663 - val_loss: 0.1257 - val_accuracy: 0.9613\n",
      "Epoch 167/6000\n",
      "126/126 [==============================] - 23s 185ms/step - loss: 0.0934 - accuracy: 0.9661 - val_loss: 0.1251 - val_accuracy: 0.9618\n",
      "Epoch 168/6000\n",
      "126/126 [==============================] - 18s 146ms/step - loss: 0.0916 - accuracy: 0.9667 - val_loss: 0.1200 - val_accuracy: 0.9635\n",
      "Epoch 169/6000\n",
      "126/126 [==============================] - 22s 172ms/step - loss: 0.0920 - accuracy: 0.9668 - val_loss: 0.1225 - val_accuracy: 0.9623\n",
      "Epoch 170/6000\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.0932 - accuracy: 0.9663 - val_loss: 0.1187 - val_accuracy: 0.9640\n",
      "Epoch 171/6000\n",
      "126/126 [==============================] - 23s 185ms/step - loss: 0.0906 - accuracy: 0.9676 - val_loss: 0.1163 - val_accuracy: 0.9643\n",
      "Epoch 172/6000\n",
      "126/126 [==============================] - 17s 137ms/step - loss: 0.0909 - accuracy: 0.9675 - val_loss: 0.1195 - val_accuracy: 0.9631\n",
      "Epoch 173/6000\n",
      "126/126 [==============================] - 23s 183ms/step - loss: 0.0918 - accuracy: 0.9670 - val_loss: 0.1118 - val_accuracy: 0.9658\n",
      "Epoch 174/6000\n",
      "126/126 [==============================] - 23s 183ms/step - loss: 0.0900 - accuracy: 0.9676 - val_loss: 0.1246 - val_accuracy: 0.9625\n",
      "Epoch 175/6000\n",
      "126/126 [==============================] - 23s 181ms/step - loss: 0.0896 - accuracy: 0.9681 - val_loss: 0.1160 - val_accuracy: 0.9653\n",
      "Epoch 176/6000\n",
      "126/126 [==============================] - 19s 148ms/step - loss: 0.0886 - accuracy: 0.9684 - val_loss: 0.1343 - val_accuracy: 0.9597\n",
      "Epoch 177/6000\n",
      "126/126 [==============================] - 24s 187ms/step - loss: 0.0890 - accuracy: 0.9682 - val_loss: 0.1179 - val_accuracy: 0.9646\n",
      "Epoch 178/6000\n",
      "126/126 [==============================] - 22s 178ms/step - loss: 0.0881 - accuracy: 0.9684 - val_loss: 0.1129 - val_accuracy: 0.9655\n",
      "Epoch 179/6000\n",
      "126/126 [==============================] - 23s 180ms/step - loss: 0.0888 - accuracy: 0.9681 - val_loss: 0.1167 - val_accuracy: 0.9640\n",
      "Epoch 180/6000\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.0911 - accuracy: 0.9671 - val_loss: 0.1215 - val_accuracy: 0.9622\n",
      "Epoch 181/6000\n",
      "126/126 [==============================] - 20s 160ms/step - loss: 0.0873 - accuracy: 0.9686 - val_loss: 0.1187 - val_accuracy: 0.9647\n",
      "Epoch 182/6000\n",
      "126/126 [==============================] - 20s 161ms/step - loss: 0.0872 - accuracy: 0.9685 - val_loss: 0.1151 - val_accuracy: 0.9645\n",
      "Epoch 183/6000\n",
      "126/126 [==============================] - 23s 185ms/step - loss: 0.0867 - accuracy: 0.9688 - val_loss: 0.1234 - val_accuracy: 0.9619\n",
      "Epoch 184/6000\n",
      "126/126 [==============================] - 23s 180ms/step - loss: 0.0869 - accuracy: 0.9688 - val_loss: 0.1153 - val_accuracy: 0.9653\n",
      "Epoch 185/6000\n",
      "126/126 [==============================] - 23s 184ms/step - loss: 0.0851 - accuracy: 0.9697 - val_loss: 0.1154 - val_accuracy: 0.9652\n",
      "Epoch 186/6000\n",
      "126/126 [==============================] - 18s 146ms/step - loss: 0.0849 - accuracy: 0.9698 - val_loss: 0.1230 - val_accuracy: 0.9630\n",
      "Epoch 187/6000\n",
      "126/126 [==============================] - 21s 168ms/step - loss: 0.0858 - accuracy: 0.9694 - val_loss: 0.1175 - val_accuracy: 0.9644\n",
      "Epoch 188/6000\n",
      "126/126 [==============================] - 23s 186ms/step - loss: 0.0856 - accuracy: 0.9697 - val_loss: 0.1178 - val_accuracy: 0.9639\n",
      "Epoch 188: early stopping\n",
      "##########################################################################\n",
      "------val_accuracy-----> 96.58 | 96.98 <----------accuracy----------\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/MANA-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/MANA-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "working on pair: DAR/USDT\n",
      "One_pair_AI_Gen : DAR/USDT\n",
      "price_volatility_15m:0.55%\n",
      "mini_expand : DAR/USDT\n",
      "---buy_simple_up--- Buy pct: 0.55%\n",
      "---buy_only--- Max time window: 10%\n",
      "---buy_only--- no b\n",
      "---buy_only--- no sell\n",
      "df original shape (407581, 1607)\n",
      "df original shape buy mean : 13.937352329966313\n",
      "df choosen data shape(407580, 1607)\n",
      "pair: True\n",
      "81516\n",
      "normalizing ...\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/DAR-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_104 (Dense)           (None, 250)               401750    \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 250)               0         \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 20)                5020      \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,871\n",
      "Trainable params: 407,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_UP_CLOSE/DAR-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "Epoch 1/6000\n",
      "128/128 [==============================] - 32s 182ms/step - loss: 0.5881 - accuracy: 0.6875 - val_loss: 0.5644 - val_accuracy: 0.7058\n",
      "Epoch 2/6000\n",
      "128/128 [==============================] - 18s 145ms/step - loss: 0.5591 - accuracy: 0.7095 - val_loss: 0.5421 - val_accuracy: 0.7193\n",
      "Epoch 3/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.5393 - accuracy: 0.7231 - val_loss: 0.5217 - val_accuracy: 0.7335\n",
      "Epoch 4/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.5185 - accuracy: 0.7377 - val_loss: 0.4998 - val_accuracy: 0.7526\n",
      "Epoch 5/6000\n",
      "128/128 [==============================] - 17s 137ms/step - loss: 0.4992 - accuracy: 0.7507 - val_loss: 0.4826 - val_accuracy: 0.7641\n",
      "Epoch 6/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.4813 - accuracy: 0.7646 - val_loss: 0.4611 - val_accuracy: 0.7775\n",
      "Epoch 7/6000\n",
      "128/128 [==============================] - 18s 139ms/step - loss: 0.4633 - accuracy: 0.7758 - val_loss: 0.4456 - val_accuracy: 0.7889\n",
      "Epoch 8/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.4470 - accuracy: 0.7865 - val_loss: 0.4242 - val_accuracy: 0.8030\n",
      "Epoch 9/6000\n",
      "128/128 [==============================] - 18s 139ms/step - loss: 0.4304 - accuracy: 0.7978 - val_loss: 0.4098 - val_accuracy: 0.8121\n",
      "Epoch 10/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.4173 - accuracy: 0.8056 - val_loss: 0.3953 - val_accuracy: 0.8208\n",
      "Epoch 11/6000\n",
      "128/128 [==============================] - 18s 137ms/step - loss: 0.4063 - accuracy: 0.8120 - val_loss: 0.3837 - val_accuracy: 0.8287\n",
      "Epoch 12/6000\n",
      "128/128 [==============================] - 20s 159ms/step - loss: 0.3940 - accuracy: 0.8193 - val_loss: 0.3772 - val_accuracy: 0.8333\n",
      "Epoch 13/6000\n",
      "128/128 [==============================] - 20s 156ms/step - loss: 0.3844 - accuracy: 0.8247 - val_loss: 0.3636 - val_accuracy: 0.8405\n",
      "Epoch 14/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.3744 - accuracy: 0.8306 - val_loss: 0.3534 - val_accuracy: 0.8451\n",
      "Epoch 15/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.3637 - accuracy: 0.8373 - val_loss: 0.3528 - val_accuracy: 0.8440\n",
      "Epoch 16/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.3587 - accuracy: 0.8402 - val_loss: 0.3359 - val_accuracy: 0.8558\n",
      "Epoch 17/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.3523 - accuracy: 0.8433 - val_loss: 0.3370 - val_accuracy: 0.8548\n",
      "Epoch 18/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.3448 - accuracy: 0.8478 - val_loss: 0.3261 - val_accuracy: 0.8606\n",
      "Epoch 19/6000\n",
      "128/128 [==============================] - 24s 183ms/step - loss: 0.3388 - accuracy: 0.8508 - val_loss: 0.3201 - val_accuracy: 0.8639\n",
      "Epoch 20/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.3337 - accuracy: 0.8537 - val_loss: 0.3158 - val_accuracy: 0.8658\n",
      "Epoch 21/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.3257 - accuracy: 0.8577 - val_loss: 0.3141 - val_accuracy: 0.8672\n",
      "Epoch 22/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.3196 - accuracy: 0.8611 - val_loss: 0.3080 - val_accuracy: 0.8689\n",
      "Epoch 23/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.3168 - accuracy: 0.8623 - val_loss: 0.2985 - val_accuracy: 0.8756\n",
      "Epoch 24/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.3128 - accuracy: 0.8652 - val_loss: 0.2937 - val_accuracy: 0.8759\n",
      "Epoch 25/6000\n",
      "128/128 [==============================] - 17s 136ms/step - loss: 0.3066 - accuracy: 0.8677 - val_loss: 0.2959 - val_accuracy: 0.8752\n",
      "Epoch 26/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.3031 - accuracy: 0.8698 - val_loss: 0.2878 - val_accuracy: 0.8785\n",
      "Epoch 27/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.2981 - accuracy: 0.8721 - val_loss: 0.2876 - val_accuracy: 0.8798\n",
      "Epoch 28/6000\n",
      "128/128 [==============================] - 18s 139ms/step - loss: 0.2947 - accuracy: 0.8741 - val_loss: 0.2806 - val_accuracy: 0.8833\n",
      "Epoch 29/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.2904 - accuracy: 0.8760 - val_loss: 0.2804 - val_accuracy: 0.8831\n",
      "Epoch 30/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.2886 - accuracy: 0.8775 - val_loss: 0.2747 - val_accuracy: 0.8859\n",
      "Epoch 31/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.2836 - accuracy: 0.8793 - val_loss: 0.2750 - val_accuracy: 0.8867\n",
      "Epoch 32/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.2807 - accuracy: 0.8806 - val_loss: 0.2674 - val_accuracy: 0.8896\n",
      "Epoch 33/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.2768 - accuracy: 0.8827 - val_loss: 0.2658 - val_accuracy: 0.8899\n",
      "Epoch 34/6000\n",
      "128/128 [==============================] - 20s 153ms/step - loss: 0.2752 - accuracy: 0.8839 - val_loss: 0.2685 - val_accuracy: 0.8888\n",
      "Epoch 35/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.2733 - accuracy: 0.8845 - val_loss: 0.2629 - val_accuracy: 0.8925\n",
      "Epoch 36/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.2691 - accuracy: 0.8869 - val_loss: 0.2625 - val_accuracy: 0.8931\n",
      "Epoch 37/6000\n",
      "128/128 [==============================] - 23s 184ms/step - loss: 0.2673 - accuracy: 0.8875 - val_loss: 0.2564 - val_accuracy: 0.8949\n",
      "Epoch 38/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.2611 - accuracy: 0.8906 - val_loss: 0.2528 - val_accuracy: 0.8969\n",
      "Epoch 39/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.2616 - accuracy: 0.8909 - val_loss: 0.2515 - val_accuracy: 0.8972\n",
      "Epoch 40/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.2583 - accuracy: 0.8923 - val_loss: 0.2535 - val_accuracy: 0.8960\n",
      "Epoch 41/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.2566 - accuracy: 0.8925 - val_loss: 0.2504 - val_accuracy: 0.8985\n",
      "Epoch 42/6000\n",
      "128/128 [==============================] - 24s 184ms/step - loss: 0.2530 - accuracy: 0.8950 - val_loss: 0.2500 - val_accuracy: 0.8990\n",
      "Epoch 43/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.2513 - accuracy: 0.8954 - val_loss: 0.2513 - val_accuracy: 0.8987\n",
      "Epoch 44/6000\n",
      "128/128 [==============================] - 20s 154ms/step - loss: 0.2504 - accuracy: 0.8960 - val_loss: 0.2446 - val_accuracy: 0.9012\n",
      "Epoch 45/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.2479 - accuracy: 0.8974 - val_loss: 0.2426 - val_accuracy: 0.9028\n",
      "Epoch 46/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.2455 - accuracy: 0.8983 - val_loss: 0.2355 - val_accuracy: 0.9047\n",
      "Epoch 47/6000\n",
      "128/128 [==============================] - 17s 135ms/step - loss: 0.2418 - accuracy: 0.8995 - val_loss: 0.2392 - val_accuracy: 0.9042\n",
      "Epoch 48/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.2421 - accuracy: 0.8995 - val_loss: 0.2323 - val_accuracy: 0.9069\n",
      "Epoch 49/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.2381 - accuracy: 0.9016 - val_loss: 0.2394 - val_accuracy: 0.9042\n",
      "Epoch 50/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.2365 - accuracy: 0.9025 - val_loss: 0.2328 - val_accuracy: 0.9078\n",
      "Epoch 51/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.2352 - accuracy: 0.9034 - val_loss: 0.2294 - val_accuracy: 0.9098\n",
      "Epoch 52/6000\n",
      "128/128 [==============================] - 19s 150ms/step - loss: 0.2316 - accuracy: 0.9051 - val_loss: 0.2305 - val_accuracy: 0.9087\n",
      "Epoch 53/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.2321 - accuracy: 0.9042 - val_loss: 0.2335 - val_accuracy: 0.9063\n",
      "Epoch 54/6000\n",
      "128/128 [==============================] - 23s 175ms/step - loss: 0.2286 - accuracy: 0.9063 - val_loss: 0.2308 - val_accuracy: 0.9081\n",
      "Epoch 55/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.2285 - accuracy: 0.9066 - val_loss: 0.2261 - val_accuracy: 0.9106\n",
      "Epoch 56/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.2245 - accuracy: 0.9085 - val_loss: 0.2252 - val_accuracy: 0.9111\n",
      "Epoch 57/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.2240 - accuracy: 0.9084 - val_loss: 0.2275 - val_accuracy: 0.9090\n",
      "Epoch 58/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.2239 - accuracy: 0.9082 - val_loss: 0.2244 - val_accuracy: 0.9112\n",
      "Epoch 59/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.2206 - accuracy: 0.9098 - val_loss: 0.2241 - val_accuracy: 0.9112\n",
      "Epoch 60/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.2203 - accuracy: 0.9103 - val_loss: 0.2253 - val_accuracy: 0.9108\n",
      "Epoch 61/6000\n",
      "128/128 [==============================] - 19s 149ms/step - loss: 0.2196 - accuracy: 0.9108 - val_loss: 0.2255 - val_accuracy: 0.9120\n",
      "Epoch 62/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.2161 - accuracy: 0.9121 - val_loss: 0.2192 - val_accuracy: 0.9142\n",
      "Epoch 63/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.2146 - accuracy: 0.9133 - val_loss: 0.2228 - val_accuracy: 0.9111\n",
      "Epoch 64/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.2123 - accuracy: 0.9139 - val_loss: 0.2173 - val_accuracy: 0.9144\n",
      "Epoch 65/6000\n",
      "128/128 [==============================] - 19s 150ms/step - loss: 0.2127 - accuracy: 0.9135 - val_loss: 0.2162 - val_accuracy: 0.9156\n",
      "Epoch 66/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.2115 - accuracy: 0.9146 - val_loss: 0.2168 - val_accuracy: 0.9157\n",
      "Epoch 67/6000\n",
      "128/128 [==============================] - 25s 192ms/step - loss: 0.2084 - accuracy: 0.9158 - val_loss: 0.2104 - val_accuracy: 0.9198\n",
      "Epoch 68/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.2091 - accuracy: 0.9158 - val_loss: 0.2131 - val_accuracy: 0.9169\n",
      "Epoch 69/6000\n",
      "128/128 [==============================] - 19s 148ms/step - loss: 0.2078 - accuracy: 0.9163 - val_loss: 0.2128 - val_accuracy: 0.9166\n",
      "Epoch 70/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.2057 - accuracy: 0.9170 - val_loss: 0.2174 - val_accuracy: 0.9150\n",
      "Epoch 71/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.2048 - accuracy: 0.9178 - val_loss: 0.2099 - val_accuracy: 0.9187\n",
      "Epoch 72/6000\n",
      "128/128 [==============================] - 23s 184ms/step - loss: 0.2025 - accuracy: 0.9184 - val_loss: 0.2079 - val_accuracy: 0.9196\n",
      "Epoch 73/6000\n",
      "128/128 [==============================] - 17s 136ms/step - loss: 0.1995 - accuracy: 0.9200 - val_loss: 0.2108 - val_accuracy: 0.9190\n",
      "Epoch 74/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.2012 - accuracy: 0.9189 - val_loss: 0.2021 - val_accuracy: 0.9213\n",
      "Epoch 75/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.1985 - accuracy: 0.9199 - val_loss: 0.2032 - val_accuracy: 0.9211\n",
      "Epoch 76/6000\n",
      "128/128 [==============================] - 25s 192ms/step - loss: 0.1973 - accuracy: 0.9207 - val_loss: 0.2025 - val_accuracy: 0.9216\n",
      "Epoch 77/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1974 - accuracy: 0.9206 - val_loss: 0.2013 - val_accuracy: 0.9228\n",
      "Epoch 78/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.1957 - accuracy: 0.9213 - val_loss: 0.2078 - val_accuracy: 0.9194\n",
      "Epoch 79/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1955 - accuracy: 0.9220 - val_loss: 0.2047 - val_accuracy: 0.9223\n",
      "Epoch 80/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1942 - accuracy: 0.9221 - val_loss: 0.2040 - val_accuracy: 0.9205\n",
      "Epoch 81/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1914 - accuracy: 0.9232 - val_loss: 0.2065 - val_accuracy: 0.9215\n",
      "Epoch 82/6000\n",
      "128/128 [==============================] - 19s 146ms/step - loss: 0.1921 - accuracy: 0.9231 - val_loss: 0.1978 - val_accuracy: 0.9242\n",
      "Epoch 83/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.1886 - accuracy: 0.9247 - val_loss: 0.2028 - val_accuracy: 0.9232\n",
      "Epoch 84/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1895 - accuracy: 0.9246 - val_loss: 0.1958 - val_accuracy: 0.9253\n",
      "Epoch 85/6000\n",
      "128/128 [==============================] - 25s 192ms/step - loss: 0.1871 - accuracy: 0.9253 - val_loss: 0.1984 - val_accuracy: 0.9260\n",
      "Epoch 86/6000\n",
      "128/128 [==============================] - 18s 137ms/step - loss: 0.1866 - accuracy: 0.9256 - val_loss: 0.1984 - val_accuracy: 0.9239\n",
      "Epoch 87/6000\n",
      "128/128 [==============================] - 24s 183ms/step - loss: 0.1840 - accuracy: 0.9268 - val_loss: 0.1969 - val_accuracy: 0.9265\n",
      "Epoch 88/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1860 - accuracy: 0.9259 - val_loss: 0.1994 - val_accuracy: 0.9246\n",
      "Epoch 89/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.1830 - accuracy: 0.9271 - val_loss: 0.1973 - val_accuracy: 0.9242\n",
      "Epoch 90/6000\n",
      "128/128 [==============================] - 20s 159ms/step - loss: 0.1839 - accuracy: 0.9261 - val_loss: 0.1914 - val_accuracy: 0.9284\n",
      "Epoch 91/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.1819 - accuracy: 0.9279 - val_loss: 0.1892 - val_accuracy: 0.9301\n",
      "Epoch 92/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1823 - accuracy: 0.9276 - val_loss: 0.1972 - val_accuracy: 0.9267\n",
      "Epoch 93/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1826 - accuracy: 0.9274 - val_loss: 0.1930 - val_accuracy: 0.9284\n",
      "Epoch 94/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.1776 - accuracy: 0.9296 - val_loss: 0.1925 - val_accuracy: 0.9282\n",
      "Epoch 95/6000\n",
      "128/128 [==============================] - 19s 147ms/step - loss: 0.1778 - accuracy: 0.9300 - val_loss: 0.1950 - val_accuracy: 0.9270\n",
      "Epoch 96/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1774 - accuracy: 0.9298 - val_loss: 0.1901 - val_accuracy: 0.9284\n",
      "Epoch 97/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.1770 - accuracy: 0.9298 - val_loss: 0.1938 - val_accuracy: 0.9279\n",
      "Epoch 98/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.1764 - accuracy: 0.9303 - val_loss: 0.1945 - val_accuracy: 0.9268\n",
      "Epoch 99/6000\n",
      "128/128 [==============================] - 23s 184ms/step - loss: 0.1742 - accuracy: 0.9317 - val_loss: 0.1938 - val_accuracy: 0.9274\n",
      "Epoch 100/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1743 - accuracy: 0.9309 - val_loss: 0.1869 - val_accuracy: 0.9302\n",
      "Epoch 101/6000\n",
      "128/128 [==============================] - 19s 147ms/step - loss: 0.1730 - accuracy: 0.9314 - val_loss: 0.1852 - val_accuracy: 0.9321\n",
      "Epoch 102/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1722 - accuracy: 0.9318 - val_loss: 0.1880 - val_accuracy: 0.9293\n",
      "Epoch 103/6000\n",
      "128/128 [==============================] - 21s 165ms/step - loss: 0.1714 - accuracy: 0.9323 - val_loss: 0.1916 - val_accuracy: 0.9292\n",
      "Epoch 104/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.1699 - accuracy: 0.9332 - val_loss: 0.1888 - val_accuracy: 0.9303\n",
      "Epoch 105/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1700 - accuracy: 0.9334 - val_loss: 0.1827 - val_accuracy: 0.9318\n",
      "Epoch 106/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1684 - accuracy: 0.9338 - val_loss: 0.1850 - val_accuracy: 0.9320\n",
      "Epoch 107/6000\n",
      "128/128 [==============================] - 25s 192ms/step - loss: 0.1676 - accuracy: 0.9338 - val_loss: 0.1869 - val_accuracy: 0.9312\n",
      "Epoch 108/6000\n",
      "128/128 [==============================] - 19s 150ms/step - loss: 0.1665 - accuracy: 0.9348 - val_loss: 0.1897 - val_accuracy: 0.9297\n",
      "Epoch 109/6000\n",
      "128/128 [==============================] - 24s 184ms/step - loss: 0.1672 - accuracy: 0.9340 - val_loss: 0.1852 - val_accuracy: 0.9310\n",
      "Epoch 110/6000\n",
      "128/128 [==============================] - 25s 194ms/step - loss: 0.1650 - accuracy: 0.9355 - val_loss: 0.1906 - val_accuracy: 0.9296\n",
      "Epoch 111/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1655 - accuracy: 0.9351 - val_loss: 0.1838 - val_accuracy: 0.9326\n",
      "Epoch 112/6000\n",
      "128/128 [==============================] - 17s 136ms/step - loss: 0.1650 - accuracy: 0.9356 - val_loss: 0.1821 - val_accuracy: 0.9338\n",
      "Epoch 113/6000\n",
      "128/128 [==============================] - 25s 194ms/step - loss: 0.1636 - accuracy: 0.9357 - val_loss: 0.1800 - val_accuracy: 0.9338\n",
      "Epoch 114/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.1624 - accuracy: 0.9360 - val_loss: 0.1863 - val_accuracy: 0.9314\n",
      "Epoch 115/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1632 - accuracy: 0.9361 - val_loss: 0.1856 - val_accuracy: 0.9322\n",
      "Epoch 116/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.1619 - accuracy: 0.9367 - val_loss: 0.1838 - val_accuracy: 0.9329\n",
      "Epoch 117/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1608 - accuracy: 0.9370 - val_loss: 0.1776 - val_accuracy: 0.9362\n",
      "Epoch 118/6000\n",
      "128/128 [==============================] - 20s 156ms/step - loss: 0.1606 - accuracy: 0.9368 - val_loss: 0.1866 - val_accuracy: 0.9331\n",
      "Epoch 119/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1584 - accuracy: 0.9379 - val_loss: 0.1773 - val_accuracy: 0.9355\n",
      "Epoch 120/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1584 - accuracy: 0.9377 - val_loss: 0.1804 - val_accuracy: 0.9348\n",
      "Epoch 121/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1571 - accuracy: 0.9390 - val_loss: 0.1826 - val_accuracy: 0.9330\n",
      "Epoch 122/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1578 - accuracy: 0.9382 - val_loss: 0.1802 - val_accuracy: 0.9336\n",
      "Epoch 123/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.1561 - accuracy: 0.9390 - val_loss: 0.1833 - val_accuracy: 0.9340\n",
      "Epoch 124/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1553 - accuracy: 0.9391 - val_loss: 0.1721 - val_accuracy: 0.9373\n",
      "Epoch 125/6000\n",
      "128/128 [==============================] - 17s 136ms/step - loss: 0.1532 - accuracy: 0.9406 - val_loss: 0.1742 - val_accuracy: 0.9374\n",
      "Epoch 126/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1543 - accuracy: 0.9402 - val_loss: 0.1795 - val_accuracy: 0.9342\n",
      "Epoch 127/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1529 - accuracy: 0.9407 - val_loss: 0.1763 - val_accuracy: 0.9368\n",
      "Epoch 128/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.1516 - accuracy: 0.9411 - val_loss: 0.1808 - val_accuracy: 0.9349\n",
      "Epoch 129/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.1528 - accuracy: 0.9403 - val_loss: 0.1784 - val_accuracy: 0.9354\n",
      "Epoch 130/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1531 - accuracy: 0.9405 - val_loss: 0.1733 - val_accuracy: 0.9359\n",
      "Epoch 131/6000\n",
      "128/128 [==============================] - 18s 139ms/step - loss: 0.1516 - accuracy: 0.9411 - val_loss: 0.1716 - val_accuracy: 0.9393\n",
      "Epoch 132/6000\n",
      "128/128 [==============================] - 25s 194ms/step - loss: 0.1480 - accuracy: 0.9428 - val_loss: 0.1759 - val_accuracy: 0.9364\n",
      "Epoch 133/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.1507 - accuracy: 0.9416 - val_loss: 0.1788 - val_accuracy: 0.9358\n",
      "Epoch 134/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1488 - accuracy: 0.9424 - val_loss: 0.1779 - val_accuracy: 0.9362\n",
      "Epoch 135/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1499 - accuracy: 0.9422 - val_loss: 0.1694 - val_accuracy: 0.9397\n",
      "Epoch 136/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1473 - accuracy: 0.9429 - val_loss: 0.1717 - val_accuracy: 0.9392\n",
      "Epoch 137/6000\n",
      "128/128 [==============================] - 20s 154ms/step - loss: 0.1471 - accuracy: 0.9427 - val_loss: 0.1694 - val_accuracy: 0.9401\n",
      "Epoch 138/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1477 - accuracy: 0.9430 - val_loss: 0.1656 - val_accuracy: 0.9414\n",
      "Epoch 139/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1474 - accuracy: 0.9426 - val_loss: 0.1794 - val_accuracy: 0.9363\n",
      "Epoch 140/6000\n",
      "128/128 [==============================] - 25s 194ms/step - loss: 0.1458 - accuracy: 0.9435 - val_loss: 0.1709 - val_accuracy: 0.9391\n",
      "Epoch 141/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.1431 - accuracy: 0.9446 - val_loss: 0.1646 - val_accuracy: 0.9420\n",
      "Epoch 142/6000\n",
      "128/128 [==============================] - 18s 140ms/step - loss: 0.1444 - accuracy: 0.9443 - val_loss: 0.1699 - val_accuracy: 0.9395\n",
      "Epoch 143/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1456 - accuracy: 0.9434 - val_loss: 0.1663 - val_accuracy: 0.9409\n",
      "Epoch 144/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1432 - accuracy: 0.9450 - val_loss: 0.1711 - val_accuracy: 0.9396\n",
      "Epoch 145/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1451 - accuracy: 0.9438 - val_loss: 0.1682 - val_accuracy: 0.9404\n",
      "Epoch 146/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1424 - accuracy: 0.9447 - val_loss: 0.1674 - val_accuracy: 0.9413\n",
      "Epoch 147/6000\n",
      "128/128 [==============================] - 17s 136ms/step - loss: 0.1422 - accuracy: 0.9446 - val_loss: 0.1721 - val_accuracy: 0.9403\n",
      "Epoch 148/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1413 - accuracy: 0.9455 - val_loss: 0.1688 - val_accuracy: 0.9403\n",
      "Epoch 149/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1411 - accuracy: 0.9455 - val_loss: 0.1681 - val_accuracy: 0.9405\n",
      "Epoch 150/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1399 - accuracy: 0.9456 - val_loss: 0.1709 - val_accuracy: 0.9396\n",
      "Epoch 151/6000\n",
      "128/128 [==============================] - 25s 194ms/step - loss: 0.1387 - accuracy: 0.9465 - val_loss: 0.1740 - val_accuracy: 0.9394\n",
      "Epoch 152/6000\n",
      "128/128 [==============================] - 17s 137ms/step - loss: 0.1397 - accuracy: 0.9458 - val_loss: 0.1682 - val_accuracy: 0.9405\n",
      "Epoch 153/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1393 - accuracy: 0.9462 - val_loss: 0.1779 - val_accuracy: 0.9371\n",
      "Epoch 154/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.1388 - accuracy: 0.9466 - val_loss: 0.1649 - val_accuracy: 0.9411\n",
      "Epoch 155/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1360 - accuracy: 0.9476 - val_loss: 0.1665 - val_accuracy: 0.9420\n",
      "Epoch 156/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1365 - accuracy: 0.9475 - val_loss: 0.1616 - val_accuracy: 0.9439\n",
      "Epoch 157/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.1359 - accuracy: 0.9478 - val_loss: 0.1666 - val_accuracy: 0.9424\n",
      "Epoch 158/6000\n",
      "128/128 [==============================] - 18s 143ms/step - loss: 0.1334 - accuracy: 0.9485 - val_loss: 0.1651 - val_accuracy: 0.9422\n",
      "Epoch 159/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.1351 - accuracy: 0.9478 - val_loss: 0.1724 - val_accuracy: 0.9410\n",
      "Epoch 160/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.1348 - accuracy: 0.9480 - val_loss: 0.1651 - val_accuracy: 0.9420\n",
      "Epoch 161/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1341 - accuracy: 0.9487 - val_loss: 0.1633 - val_accuracy: 0.9431\n",
      "Epoch 162/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1338 - accuracy: 0.9493 - val_loss: 0.1659 - val_accuracy: 0.9425\n",
      "Epoch 163/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.1325 - accuracy: 0.9495 - val_loss: 0.1708 - val_accuracy: 0.9415\n",
      "Epoch 164/6000\n",
      "128/128 [==============================] - 23s 175ms/step - loss: 0.1341 - accuracy: 0.9485 - val_loss: 0.1639 - val_accuracy: 0.9438\n",
      "Epoch 165/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1333 - accuracy: 0.9490 - val_loss: 0.1650 - val_accuracy: 0.9435\n",
      "Epoch 166/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1340 - accuracy: 0.9484 - val_loss: 0.1716 - val_accuracy: 0.9413\n",
      "Epoch 167/6000\n",
      "128/128 [==============================] - 25s 192ms/step - loss: 0.1329 - accuracy: 0.9489 - val_loss: 0.1600 - val_accuracy: 0.9447\n",
      "Epoch 168/6000\n",
      "128/128 [==============================] - 19s 151ms/step - loss: 0.1317 - accuracy: 0.9493 - val_loss: 0.1622 - val_accuracy: 0.9430\n",
      "Epoch 169/6000\n",
      "128/128 [==============================] - 23s 175ms/step - loss: 0.1299 - accuracy: 0.9501 - val_loss: 0.1599 - val_accuracy: 0.9441\n",
      "Epoch 170/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1299 - accuracy: 0.9505 - val_loss: 0.1642 - val_accuracy: 0.9428\n",
      "Epoch 171/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.1307 - accuracy: 0.9502 - val_loss: 0.1583 - val_accuracy: 0.9453\n",
      "Epoch 172/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1297 - accuracy: 0.9504 - val_loss: 0.1584 - val_accuracy: 0.9459\n",
      "Epoch 173/6000\n",
      "128/128 [==============================] - 19s 150ms/step - loss: 0.1311 - accuracy: 0.9498 - val_loss: 0.1627 - val_accuracy: 0.9437\n",
      "Epoch 174/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1286 - accuracy: 0.9510 - val_loss: 0.1610 - val_accuracy: 0.9446\n",
      "Epoch 175/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1270 - accuracy: 0.9511 - val_loss: 0.1628 - val_accuracy: 0.9439\n",
      "Epoch 176/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1290 - accuracy: 0.9506 - val_loss: 0.1580 - val_accuracy: 0.9456\n",
      "Epoch 177/6000\n",
      "128/128 [==============================] - 20s 158ms/step - loss: 0.1290 - accuracy: 0.9505 - val_loss: 0.1587 - val_accuracy: 0.9448\n",
      "Epoch 178/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.1280 - accuracy: 0.9509 - val_loss: 0.1651 - val_accuracy: 0.9448\n",
      "Epoch 179/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1261 - accuracy: 0.9517 - val_loss: 0.1655 - val_accuracy: 0.9441\n",
      "Epoch 180/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1250 - accuracy: 0.9523 - val_loss: 0.1601 - val_accuracy: 0.9460\n",
      "Epoch 181/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1261 - accuracy: 0.9515 - val_loss: 0.1655 - val_accuracy: 0.9443\n",
      "Epoch 182/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1265 - accuracy: 0.9515 - val_loss: 0.1599 - val_accuracy: 0.9462\n",
      "Epoch 183/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1269 - accuracy: 0.9513 - val_loss: 0.1554 - val_accuracy: 0.9465\n",
      "Epoch 184/6000\n",
      "128/128 [==============================] - 17s 136ms/step - loss: 0.1235 - accuracy: 0.9525 - val_loss: 0.1669 - val_accuracy: 0.9451\n",
      "Epoch 185/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1239 - accuracy: 0.9529 - val_loss: 0.1601 - val_accuracy: 0.9463\n",
      "Epoch 186/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1244 - accuracy: 0.9526 - val_loss: 0.1553 - val_accuracy: 0.9470\n",
      "Epoch 187/6000\n",
      "128/128 [==============================] - 25s 194ms/step - loss: 0.1232 - accuracy: 0.9529 - val_loss: 0.1597 - val_accuracy: 0.9460\n",
      "Epoch 188/6000\n",
      "128/128 [==============================] - 19s 145ms/step - loss: 0.1229 - accuracy: 0.9528 - val_loss: 0.1590 - val_accuracy: 0.9469\n",
      "Epoch 189/6000\n",
      "128/128 [==============================] - 23s 175ms/step - loss: 0.1231 - accuracy: 0.9529 - val_loss: 0.1610 - val_accuracy: 0.9469\n",
      "Epoch 190/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1226 - accuracy: 0.9532 - val_loss: 0.1635 - val_accuracy: 0.9455\n",
      "Epoch 191/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.1221 - accuracy: 0.9531 - val_loss: 0.1528 - val_accuracy: 0.9487\n",
      "Epoch 192/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1217 - accuracy: 0.9534 - val_loss: 0.1625 - val_accuracy: 0.9457\n",
      "Epoch 193/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.1203 - accuracy: 0.9543 - val_loss: 0.1569 - val_accuracy: 0.9474\n",
      "Epoch 194/6000\n",
      "128/128 [==============================] - 21s 161ms/step - loss: 0.1196 - accuracy: 0.9543 - val_loss: 0.1556 - val_accuracy: 0.9476\n",
      "Epoch 195/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.1191 - accuracy: 0.9544 - val_loss: 0.1568 - val_accuracy: 0.9475\n",
      "Epoch 196/6000\n",
      "128/128 [==============================] - 25s 192ms/step - loss: 0.1197 - accuracy: 0.9545 - val_loss: 0.1531 - val_accuracy: 0.9477\n",
      "Epoch 197/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1218 - accuracy: 0.9537 - val_loss: 0.1548 - val_accuracy: 0.9475\n",
      "Epoch 198/6000\n",
      "128/128 [==============================] - 19s 151ms/step - loss: 0.1187 - accuracy: 0.9547 - val_loss: 0.1556 - val_accuracy: 0.9485\n",
      "Epoch 199/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1175 - accuracy: 0.9553 - val_loss: 0.1611 - val_accuracy: 0.9467\n",
      "Epoch 200/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1198 - accuracy: 0.9541 - val_loss: 0.1587 - val_accuracy: 0.9470\n",
      "Epoch 201/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1180 - accuracy: 0.9551 - val_loss: 0.1635 - val_accuracy: 0.9464\n",
      "Epoch 202/6000\n",
      "128/128 [==============================] - 19s 146ms/step - loss: 0.1197 - accuracy: 0.9543 - val_loss: 0.1596 - val_accuracy: 0.9470\n",
      "Epoch 203/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1183 - accuracy: 0.9549 - val_loss: 0.1562 - val_accuracy: 0.9481\n",
      "Epoch 204/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.1158 - accuracy: 0.9560 - val_loss: 0.1547 - val_accuracy: 0.9482\n",
      "Epoch 205/6000\n",
      "128/128 [==============================] - 25s 194ms/step - loss: 0.1170 - accuracy: 0.9554 - val_loss: 0.1489 - val_accuracy: 0.9501\n",
      "Epoch 206/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1186 - accuracy: 0.9550 - val_loss: 0.1549 - val_accuracy: 0.9483\n",
      "Epoch 207/6000\n",
      "128/128 [==============================] - 20s 152ms/step - loss: 0.1150 - accuracy: 0.9563 - val_loss: 0.1529 - val_accuracy: 0.9485\n",
      "Epoch 208/6000\n",
      "128/128 [==============================] - 25s 199ms/step - loss: 0.1183 - accuracy: 0.9551 - val_loss: 0.1594 - val_accuracy: 0.9463\n",
      "Epoch 209/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1149 - accuracy: 0.9567 - val_loss: 0.1525 - val_accuracy: 0.9486\n",
      "Epoch 210/6000\n",
      "128/128 [==============================] - 17s 135ms/step - loss: 0.1153 - accuracy: 0.9560 - val_loss: 0.1540 - val_accuracy: 0.9483\n",
      "Epoch 211/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1153 - accuracy: 0.9559 - val_loss: 0.1513 - val_accuracy: 0.9491\n",
      "Epoch 212/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1145 - accuracy: 0.9565 - val_loss: 0.1505 - val_accuracy: 0.9504\n",
      "Epoch 213/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1123 - accuracy: 0.9576 - val_loss: 0.1508 - val_accuracy: 0.9509\n",
      "Epoch 214/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1139 - accuracy: 0.9567 - val_loss: 0.1506 - val_accuracy: 0.9500\n",
      "Epoch 215/6000\n",
      "128/128 [==============================] - 18s 140ms/step - loss: 0.1131 - accuracy: 0.9571 - val_loss: 0.1514 - val_accuracy: 0.9493\n",
      "Epoch 216/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1130 - accuracy: 0.9571 - val_loss: 0.1543 - val_accuracy: 0.9496\n",
      "Epoch 217/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1124 - accuracy: 0.9577 - val_loss: 0.1502 - val_accuracy: 0.9501\n",
      "Epoch 218/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1132 - accuracy: 0.9574 - val_loss: 0.1612 - val_accuracy: 0.9466\n",
      "Epoch 219/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1117 - accuracy: 0.9577 - val_loss: 0.1556 - val_accuracy: 0.9491\n",
      "Epoch 220/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.1119 - accuracy: 0.9577 - val_loss: 0.1554 - val_accuracy: 0.9487\n",
      "Epoch 221/6000\n",
      "128/128 [==============================] - 24s 183ms/step - loss: 0.1123 - accuracy: 0.9577 - val_loss: 0.1497 - val_accuracy: 0.9507\n",
      "Epoch 222/6000\n",
      "128/128 [==============================] - 24s 184ms/step - loss: 0.1096 - accuracy: 0.9586 - val_loss: 0.1573 - val_accuracy: 0.9483\n",
      "Epoch 223/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1108 - accuracy: 0.9579 - val_loss: 0.1501 - val_accuracy: 0.9503\n",
      "Epoch 224/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1107 - accuracy: 0.9580 - val_loss: 0.1569 - val_accuracy: 0.9485\n",
      "Epoch 225/6000\n",
      "128/128 [==============================] - 27s 211ms/step - loss: 0.1110 - accuracy: 0.9583 - val_loss: 0.1465 - val_accuracy: 0.9509\n",
      "Epoch 226/6000\n",
      "128/128 [==============================] - 17s 136ms/step - loss: 0.1089 - accuracy: 0.9588 - val_loss: 0.1532 - val_accuracy: 0.9489\n",
      "Epoch 227/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1100 - accuracy: 0.9584 - val_loss: 0.1478 - val_accuracy: 0.9512\n",
      "Epoch 228/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1090 - accuracy: 0.9589 - val_loss: 0.1514 - val_accuracy: 0.9509\n",
      "Epoch 229/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.1100 - accuracy: 0.9582 - val_loss: 0.1566 - val_accuracy: 0.9488\n",
      "Epoch 230/6000\n",
      "128/128 [==============================] - 17s 136ms/step - loss: 0.1096 - accuracy: 0.9592 - val_loss: 0.1513 - val_accuracy: 0.9507\n",
      "Epoch 231/6000\n",
      "128/128 [==============================] - 25s 197ms/step - loss: 0.1091 - accuracy: 0.9594 - val_loss: 0.1552 - val_accuracy: 0.9489\n",
      "Epoch 232/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1079 - accuracy: 0.9592 - val_loss: 0.1506 - val_accuracy: 0.9500\n",
      "Epoch 233/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1088 - accuracy: 0.9590 - val_loss: 0.1514 - val_accuracy: 0.9513\n",
      "Epoch 234/6000\n",
      "128/128 [==============================] - 25s 192ms/step - loss: 0.1065 - accuracy: 0.9598 - val_loss: 0.1516 - val_accuracy: 0.9496\n",
      "Epoch 235/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.1070 - accuracy: 0.9594 - val_loss: 0.1506 - val_accuracy: 0.9521\n",
      "Epoch 236/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1074 - accuracy: 0.9593 - val_loss: 0.1493 - val_accuracy: 0.9509\n",
      "Epoch 237/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.1071 - accuracy: 0.9595 - val_loss: 0.1503 - val_accuracy: 0.9514\n",
      "Epoch 238/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.1063 - accuracy: 0.9601 - val_loss: 0.1537 - val_accuracy: 0.9494\n",
      "Epoch 239/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1073 - accuracy: 0.9597 - val_loss: 0.1498 - val_accuracy: 0.9519\n",
      "Epoch 240/6000\n",
      "128/128 [==============================] - 18s 139ms/step - loss: 0.1036 - accuracy: 0.9609 - val_loss: 0.1499 - val_accuracy: 0.9505\n",
      "Epoch 241/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1054 - accuracy: 0.9602 - val_loss: 0.1441 - val_accuracy: 0.9535\n",
      "Epoch 242/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.1072 - accuracy: 0.9598 - val_loss: 0.1517 - val_accuracy: 0.9506\n",
      "Epoch 243/6000\n",
      "128/128 [==============================] - 25s 195ms/step - loss: 0.1062 - accuracy: 0.9599 - val_loss: 0.1481 - val_accuracy: 0.9511\n",
      "Epoch 244/6000\n",
      "128/128 [==============================] - 18s 144ms/step - loss: 0.1059 - accuracy: 0.9600 - val_loss: 0.1593 - val_accuracy: 0.9489\n",
      "Epoch 245/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1034 - accuracy: 0.9611 - val_loss: 0.1481 - val_accuracy: 0.9523\n",
      "Epoch 246/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1024 - accuracy: 0.9614 - val_loss: 0.1456 - val_accuracy: 0.9528\n",
      "Epoch 247/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1042 - accuracy: 0.9609 - val_loss: 0.1515 - val_accuracy: 0.9512\n",
      "Epoch 248/6000\n",
      "128/128 [==============================] - 22s 169ms/step - loss: 0.1025 - accuracy: 0.9617 - val_loss: 0.1480 - val_accuracy: 0.9525\n",
      "Epoch 249/6000\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 0.1040 - accuracy: 0.9609 - val_loss: 0.1472 - val_accuracy: 0.9516\n",
      "Epoch 250/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1014 - accuracy: 0.9618 - val_loss: 0.1541 - val_accuracy: 0.9505\n",
      "Epoch 251/6000\n",
      "128/128 [==============================] - 25s 194ms/step - loss: 0.1034 - accuracy: 0.9613 - val_loss: 0.1514 - val_accuracy: 0.9512\n",
      "Epoch 252/6000\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 0.1025 - accuracy: 0.9618 - val_loss: 0.1504 - val_accuracy: 0.9511\n",
      "Epoch 253/6000\n",
      "128/128 [==============================] - 21s 160ms/step - loss: 0.1032 - accuracy: 0.9613 - val_loss: 0.1440 - val_accuracy: 0.9537\n",
      "Epoch 254/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.1017 - accuracy: 0.9618 - val_loss: 0.1480 - val_accuracy: 0.9523\n",
      "Epoch 255/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1026 - accuracy: 0.9612 - val_loss: 0.1589 - val_accuracy: 0.9499\n",
      "Epoch 256/6000\n",
      "128/128 [==============================] - 25s 192ms/step - loss: 0.1019 - accuracy: 0.9616 - val_loss: 0.1442 - val_accuracy: 0.9536\n",
      "Epoch 257/6000\n",
      "128/128 [==============================] - 17s 136ms/step - loss: 0.1002 - accuracy: 0.9624 - val_loss: 0.1477 - val_accuracy: 0.9540\n",
      "Epoch 258/6000\n",
      "128/128 [==============================] - 24s 184ms/step - loss: 0.1011 - accuracy: 0.9616 - val_loss: 0.1465 - val_accuracy: 0.9526\n",
      "Epoch 259/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1011 - accuracy: 0.9620 - val_loss: 0.1439 - val_accuracy: 0.9549\n",
      "Epoch 260/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.0994 - accuracy: 0.9626 - val_loss: 0.1458 - val_accuracy: 0.9531\n",
      "Epoch 261/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.1013 - accuracy: 0.9617 - val_loss: 0.1533 - val_accuracy: 0.9511\n",
      "Epoch 262/6000\n",
      "128/128 [==============================] - 19s 147ms/step - loss: 0.0994 - accuracy: 0.9624 - val_loss: 0.1516 - val_accuracy: 0.9514\n",
      "Epoch 263/6000\n",
      "128/128 [==============================] - 24s 184ms/step - loss: 0.0982 - accuracy: 0.9631 - val_loss: 0.1491 - val_accuracy: 0.9524\n",
      "Epoch 264/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.1012 - accuracy: 0.9618 - val_loss: 0.1569 - val_accuracy: 0.9503\n",
      "Epoch 265/6000\n",
      "128/128 [==============================] - 25s 190ms/step - loss: 0.0993 - accuracy: 0.9627 - val_loss: 0.1506 - val_accuracy: 0.9527\n",
      "Epoch 266/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.0987 - accuracy: 0.9629 - val_loss: 0.1458 - val_accuracy: 0.9535\n",
      "Epoch 267/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.0996 - accuracy: 0.9628 - val_loss: 0.1560 - val_accuracy: 0.9513\n",
      "Epoch 268/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.0998 - accuracy: 0.9627 - val_loss: 0.1531 - val_accuracy: 0.9517\n",
      "Epoch 269/6000\n",
      "128/128 [==============================] - 20s 157ms/step - loss: 0.0988 - accuracy: 0.9630 - val_loss: 0.1447 - val_accuracy: 0.9536\n",
      "Epoch 270/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.0994 - accuracy: 0.9628 - val_loss: 0.1449 - val_accuracy: 0.9539\n",
      "Epoch 271/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.0986 - accuracy: 0.9631 - val_loss: 0.1471 - val_accuracy: 0.9536\n",
      "Epoch 272/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.0975 - accuracy: 0.9634 - val_loss: 0.1496 - val_accuracy: 0.9522\n",
      "Epoch 273/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.0975 - accuracy: 0.9634 - val_loss: 0.1432 - val_accuracy: 0.9544\n",
      "Epoch 274/6000\n",
      "128/128 [==============================] - 18s 144ms/step - loss: 0.0977 - accuracy: 0.9633 - val_loss: 0.1483 - val_accuracy: 0.9539\n",
      "Epoch 274: early stopping\n",
      "##########################################################################\n",
      "------val_accuracy-----> 95.49 | 96.34 <----------accuracy----------\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/DAR-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/DAR-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "working on pair: WAVES/USDT\n",
      "One_pair_AI_Gen : WAVES/USDT\n",
      "price_volatility_15m:0.51%\n",
      "mini_expand : WAVES/USDT\n",
      "---buy_simple_up--- Buy pct: 0.51%\n",
      "---buy_only--- Max time window: 10%\n",
      "---buy_only--- no b\n",
      "---buy_only--- no sell\n",
      "df original shape (407582, 1607)\n",
      "df original shape buy mean : 13.631858129161738\n",
      "df choosen data shape(407582, 1607)\n",
      "pair: True\n",
      "81516\n",
      "normalizing ...\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/WAVES-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_108 (Dense)           (None, 250)               401750    \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 250)               0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 20)                5020      \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,871\n",
      "Trainable params: 407,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_UP_CLOSE/WAVES-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "Epoch 1/6000\n",
      "128/128 [==============================] - 28s 173ms/step - loss: 0.5806 - accuracy: 0.6905 - val_loss: 0.5522 - val_accuracy: 0.7145\n",
      "Epoch 2/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.5486 - accuracy: 0.7152 - val_loss: 0.5266 - val_accuracy: 0.7328\n",
      "Epoch 3/6000\n",
      "128/128 [==============================] - 18s 144ms/step - loss: 0.5257 - accuracy: 0.7312 - val_loss: 0.5046 - val_accuracy: 0.7453\n",
      "Epoch 4/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.5025 - accuracy: 0.7466 - val_loss: 0.4770 - val_accuracy: 0.7664\n",
      "Epoch 5/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.4822 - accuracy: 0.7603 - val_loss: 0.4668 - val_accuracy: 0.7724\n",
      "Epoch 6/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.4635 - accuracy: 0.7718 - val_loss: 0.4452 - val_accuracy: 0.7877\n",
      "Epoch 7/6000\n",
      "128/128 [==============================] - 18s 143ms/step - loss: 0.4489 - accuracy: 0.7825 - val_loss: 0.4205 - val_accuracy: 0.8021\n",
      "Epoch 8/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.4343 - accuracy: 0.7915 - val_loss: 0.4115 - val_accuracy: 0.8074\n",
      "Epoch 9/6000\n",
      "128/128 [==============================] - 18s 140ms/step - loss: 0.4215 - accuracy: 0.7992 - val_loss: 0.3964 - val_accuracy: 0.8170\n",
      "Epoch 10/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.4094 - accuracy: 0.8077 - val_loss: 0.3882 - val_accuracy: 0.8210\n",
      "Epoch 11/6000\n",
      "128/128 [==============================] - 19s 147ms/step - loss: 0.3981 - accuracy: 0.8134 - val_loss: 0.3785 - val_accuracy: 0.8275\n",
      "Epoch 12/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.3899 - accuracy: 0.8187 - val_loss: 0.3730 - val_accuracy: 0.8309\n",
      "Epoch 13/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.3814 - accuracy: 0.8237 - val_loss: 0.3587 - val_accuracy: 0.8393\n",
      "Epoch 14/6000\n",
      "128/128 [==============================] - 18s 140ms/step - loss: 0.3712 - accuracy: 0.8295 - val_loss: 0.3510 - val_accuracy: 0.8454\n",
      "Epoch 15/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.3665 - accuracy: 0.8326 - val_loss: 0.3494 - val_accuracy: 0.8431\n",
      "Epoch 16/6000\n",
      "128/128 [==============================] - 18s 137ms/step - loss: 0.3577 - accuracy: 0.8372 - val_loss: 0.3414 - val_accuracy: 0.8489\n",
      "Epoch 17/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.3527 - accuracy: 0.8399 - val_loss: 0.3346 - val_accuracy: 0.8524\n",
      "Epoch 18/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.3455 - accuracy: 0.8441 - val_loss: 0.3284 - val_accuracy: 0.8559\n",
      "Epoch 19/6000\n",
      "128/128 [==============================] - 18s 140ms/step - loss: 0.3389 - accuracy: 0.8484 - val_loss: 0.3231 - val_accuracy: 0.8599\n",
      "Epoch 20/6000\n",
      "128/128 [==============================] - 24s 184ms/step - loss: 0.3341 - accuracy: 0.8511 - val_loss: 0.3134 - val_accuracy: 0.8640\n",
      "Epoch 21/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.3294 - accuracy: 0.8535 - val_loss: 0.3149 - val_accuracy: 0.8623\n",
      "Epoch 22/6000\n",
      "128/128 [==============================] - 19s 145ms/step - loss: 0.3250 - accuracy: 0.8557 - val_loss: 0.3073 - val_accuracy: 0.8675\n",
      "Epoch 23/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.3212 - accuracy: 0.8574 - val_loss: 0.3073 - val_accuracy: 0.8656\n",
      "Epoch 24/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.3153 - accuracy: 0.8606 - val_loss: 0.3005 - val_accuracy: 0.8713\n",
      "Epoch 25/6000\n",
      "128/128 [==============================] - 19s 148ms/step - loss: 0.3096 - accuracy: 0.8639 - val_loss: 0.2921 - val_accuracy: 0.8751\n",
      "Epoch 26/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.3067 - accuracy: 0.8660 - val_loss: 0.2912 - val_accuracy: 0.8745\n",
      "Epoch 27/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.3039 - accuracy: 0.8670 - val_loss: 0.2851 - val_accuracy: 0.8790\n",
      "Epoch 28/6000\n",
      "128/128 [==============================] - 19s 148ms/step - loss: 0.3004 - accuracy: 0.8690 - val_loss: 0.2810 - val_accuracy: 0.8815\n",
      "Epoch 29/6000\n",
      "128/128 [==============================] - 23s 175ms/step - loss: 0.2953 - accuracy: 0.8718 - val_loss: 0.2821 - val_accuracy: 0.8800\n",
      "Epoch 30/6000\n",
      "128/128 [==============================] - 24s 184ms/step - loss: 0.2922 - accuracy: 0.8735 - val_loss: 0.2757 - val_accuracy: 0.8850\n",
      "Epoch 31/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.2892 - accuracy: 0.8742 - val_loss: 0.2778 - val_accuracy: 0.8829\n",
      "Epoch 32/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.2853 - accuracy: 0.8764 - val_loss: 0.2707 - val_accuracy: 0.8885\n",
      "Epoch 33/6000\n",
      "128/128 [==============================] - 25s 191ms/step - loss: 0.2830 - accuracy: 0.8773 - val_loss: 0.2696 - val_accuracy: 0.8874\n",
      "Epoch 34/6000\n",
      "128/128 [==============================] - 23s 184ms/step - loss: 0.2799 - accuracy: 0.8792 - val_loss: 0.2647 - val_accuracy: 0.8908\n",
      "Epoch 35/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.2772 - accuracy: 0.8806 - val_loss: 0.2676 - val_accuracy: 0.8882\n",
      "Epoch 36/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.2731 - accuracy: 0.8823 - val_loss: 0.2615 - val_accuracy: 0.8913\n",
      "Epoch 37/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.2721 - accuracy: 0.8831 - val_loss: 0.2631 - val_accuracy: 0.8906\n",
      "Epoch 38/6000\n",
      "128/128 [==============================] - 25s 197ms/step - loss: 0.2677 - accuracy: 0.8860 - val_loss: 0.2575 - val_accuracy: 0.8947\n",
      "Epoch 39/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.2651 - accuracy: 0.8868 - val_loss: 0.2543 - val_accuracy: 0.8939\n",
      "Epoch 40/6000\n",
      "128/128 [==============================] - 20s 158ms/step - loss: 0.2632 - accuracy: 0.8876 - val_loss: 0.2560 - val_accuracy: 0.8938\n",
      "Epoch 41/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.2628 - accuracy: 0.8880 - val_loss: 0.2490 - val_accuracy: 0.8966\n",
      "Epoch 42/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.2583 - accuracy: 0.8898 - val_loss: 0.2497 - val_accuracy: 0.8972\n",
      "Epoch 43/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.2578 - accuracy: 0.8903 - val_loss: 0.2469 - val_accuracy: 0.8986\n",
      "Epoch 44/6000\n",
      "128/128 [==============================] - 25s 195ms/step - loss: 0.2552 - accuracy: 0.8920 - val_loss: 0.2474 - val_accuracy: 0.8979\n",
      "Epoch 45/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.2532 - accuracy: 0.8929 - val_loss: 0.2496 - val_accuracy: 0.8968\n",
      "Epoch 46/6000\n",
      "128/128 [==============================] - 18s 140ms/step - loss: 0.2505 - accuracy: 0.8936 - val_loss: 0.2473 - val_accuracy: 0.8992\n",
      "Epoch 47/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.2496 - accuracy: 0.8939 - val_loss: 0.2418 - val_accuracy: 0.9011\n",
      "Epoch 48/6000\n",
      "128/128 [==============================] - 26s 204ms/step - loss: 0.2438 - accuracy: 0.8969 - val_loss: 0.2376 - val_accuracy: 0.9036\n",
      "Epoch 49/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.2438 - accuracy: 0.8977 - val_loss: 0.2373 - val_accuracy: 0.9042\n",
      "Epoch 50/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.2409 - accuracy: 0.8985 - val_loss: 0.2381 - val_accuracy: 0.9040\n",
      "Epoch 51/6000\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 0.2408 - accuracy: 0.8987 - val_loss: 0.2357 - val_accuracy: 0.9043\n",
      "Epoch 52/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.2397 - accuracy: 0.8993 - val_loss: 0.2354 - val_accuracy: 0.9039\n",
      "Epoch 53/6000\n",
      "128/128 [==============================] - 23s 175ms/step - loss: 0.2367 - accuracy: 0.9006 - val_loss: 0.2307 - val_accuracy: 0.9083\n",
      "Epoch 54/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.2348 - accuracy: 0.9021 - val_loss: 0.2332 - val_accuracy: 0.9067\n",
      "Epoch 55/6000\n",
      "128/128 [==============================] - 21s 161ms/step - loss: 0.2330 - accuracy: 0.9021 - val_loss: 0.2285 - val_accuracy: 0.9087\n",
      "Epoch 56/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.2322 - accuracy: 0.9032 - val_loss: 0.2294 - val_accuracy: 0.9081\n",
      "Epoch 57/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.2285 - accuracy: 0.9042 - val_loss: 0.2262 - val_accuracy: 0.9111\n",
      "Epoch 58/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.2286 - accuracy: 0.9041 - val_loss: 0.2289 - val_accuracy: 0.9091\n",
      "Epoch 59/6000\n",
      "128/128 [==============================] - 18s 143ms/step - loss: 0.2263 - accuracy: 0.9056 - val_loss: 0.2233 - val_accuracy: 0.9109\n",
      "Epoch 60/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.2269 - accuracy: 0.9052 - val_loss: 0.2229 - val_accuracy: 0.9117\n",
      "Epoch 61/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.2235 - accuracy: 0.9073 - val_loss: 0.2247 - val_accuracy: 0.9098\n",
      "Epoch 62/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.2223 - accuracy: 0.9083 - val_loss: 0.2229 - val_accuracy: 0.9101\n",
      "Epoch 63/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.2208 - accuracy: 0.9082 - val_loss: 0.2205 - val_accuracy: 0.9123\n",
      "Epoch 64/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.2202 - accuracy: 0.9081 - val_loss: 0.2260 - val_accuracy: 0.9103\n",
      "Epoch 65/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.2173 - accuracy: 0.9102 - val_loss: 0.2152 - val_accuracy: 0.9157\n",
      "Epoch 66/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.2171 - accuracy: 0.9100 - val_loss: 0.2157 - val_accuracy: 0.9145\n",
      "Epoch 67/6000\n",
      "128/128 [==============================] - 21s 160ms/step - loss: 0.2145 - accuracy: 0.9110 - val_loss: 0.2182 - val_accuracy: 0.9134\n",
      "Epoch 68/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.2141 - accuracy: 0.9114 - val_loss: 0.2184 - val_accuracy: 0.9143\n",
      "Epoch 69/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.2136 - accuracy: 0.9114 - val_loss: 0.2172 - val_accuracy: 0.9153\n",
      "Epoch 70/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.2111 - accuracy: 0.9131 - val_loss: 0.2129 - val_accuracy: 0.9164\n",
      "Epoch 71/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.2095 - accuracy: 0.9138 - val_loss: 0.2133 - val_accuracy: 0.9164\n",
      "Epoch 72/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.2081 - accuracy: 0.9144 - val_loss: 0.2118 - val_accuracy: 0.9170\n",
      "Epoch 73/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.2068 - accuracy: 0.9153 - val_loss: 0.2145 - val_accuracy: 0.9177\n",
      "Epoch 74/6000\n",
      "128/128 [==============================] - 26s 202ms/step - loss: 0.2078 - accuracy: 0.9145 - val_loss: 0.2126 - val_accuracy: 0.9168\n",
      "Epoch 75/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.2036 - accuracy: 0.9167 - val_loss: 0.2125 - val_accuracy: 0.9179\n",
      "Epoch 76/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.2027 - accuracy: 0.9167 - val_loss: 0.2060 - val_accuracy: 0.9193\n",
      "Epoch 77/6000\n",
      "128/128 [==============================] - 25s 195ms/step - loss: 0.2023 - accuracy: 0.9172 - val_loss: 0.2097 - val_accuracy: 0.9180\n",
      "Epoch 78/6000\n",
      "128/128 [==============================] - 18s 137ms/step - loss: 0.2027 - accuracy: 0.9171 - val_loss: 0.2062 - val_accuracy: 0.9200\n",
      "Epoch 79/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.2006 - accuracy: 0.9184 - val_loss: 0.2029 - val_accuracy: 0.9229\n",
      "Epoch 80/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.1988 - accuracy: 0.9185 - val_loss: 0.2060 - val_accuracy: 0.9198\n",
      "Epoch 81/6000\n",
      "128/128 [==============================] - 25s 195ms/step - loss: 0.1994 - accuracy: 0.9189 - val_loss: 0.2085 - val_accuracy: 0.9197\n",
      "Epoch 82/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.1975 - accuracy: 0.9200 - val_loss: 0.2025 - val_accuracy: 0.9219\n",
      "Epoch 83/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1969 - accuracy: 0.9196 - val_loss: 0.2038 - val_accuracy: 0.9216\n",
      "Epoch 84/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1936 - accuracy: 0.9212 - val_loss: 0.2018 - val_accuracy: 0.9225\n",
      "Epoch 85/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1943 - accuracy: 0.9208 - val_loss: 0.1989 - val_accuracy: 0.9242\n",
      "Epoch 86/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.1922 - accuracy: 0.9222 - val_loss: 0.2056 - val_accuracy: 0.9201\n",
      "Epoch 87/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.1904 - accuracy: 0.9230 - val_loss: 0.2020 - val_accuracy: 0.9231\n",
      "Epoch 88/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1905 - accuracy: 0.9222 - val_loss: 0.2035 - val_accuracy: 0.9227\n",
      "Epoch 89/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1908 - accuracy: 0.9223 - val_loss: 0.1975 - val_accuracy: 0.9245\n",
      "Epoch 90/6000\n",
      "128/128 [==============================] - 25s 195ms/step - loss: 0.1878 - accuracy: 0.9243 - val_loss: 0.2013 - val_accuracy: 0.9235\n",
      "Epoch 91/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.1876 - accuracy: 0.9237 - val_loss: 0.1931 - val_accuracy: 0.9261\n",
      "Epoch 92/6000\n",
      "128/128 [==============================] - 22s 167ms/step - loss: 0.1857 - accuracy: 0.9253 - val_loss: 0.1926 - val_accuracy: 0.9274\n",
      "Epoch 93/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1847 - accuracy: 0.9254 - val_loss: 0.1945 - val_accuracy: 0.9260\n",
      "Epoch 94/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.1847 - accuracy: 0.9254 - val_loss: 0.1922 - val_accuracy: 0.9277\n",
      "Epoch 95/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1838 - accuracy: 0.9263 - val_loss: 0.1957 - val_accuracy: 0.9262\n",
      "Epoch 96/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1818 - accuracy: 0.9266 - val_loss: 0.1911 - val_accuracy: 0.9281\n",
      "Epoch 97/6000\n",
      "128/128 [==============================] - 17s 136ms/step - loss: 0.1814 - accuracy: 0.9269 - val_loss: 0.1949 - val_accuracy: 0.9260\n",
      "Epoch 98/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1836 - accuracy: 0.9260 - val_loss: 0.1919 - val_accuracy: 0.9279\n",
      "Epoch 99/6000\n",
      "128/128 [==============================] - 26s 202ms/step - loss: 0.1803 - accuracy: 0.9278 - val_loss: 0.1928 - val_accuracy: 0.9272\n",
      "Epoch 100/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.1792 - accuracy: 0.9277 - val_loss: 0.1891 - val_accuracy: 0.9290\n",
      "Epoch 101/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.1774 - accuracy: 0.9290 - val_loss: 0.1914 - val_accuracy: 0.9290\n",
      "Epoch 102/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.1781 - accuracy: 0.9284 - val_loss: 0.1904 - val_accuracy: 0.9288\n",
      "Epoch 103/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1786 - accuracy: 0.9285 - val_loss: 0.1884 - val_accuracy: 0.9301\n",
      "Epoch 104/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.1746 - accuracy: 0.9302 - val_loss: 0.1837 - val_accuracy: 0.9322\n",
      "Epoch 105/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1748 - accuracy: 0.9304 - val_loss: 0.1878 - val_accuracy: 0.9300\n",
      "Epoch 106/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1733 - accuracy: 0.9308 - val_loss: 0.1887 - val_accuracy: 0.9291\n",
      "Epoch 107/6000\n",
      "128/128 [==============================] - 25s 199ms/step - loss: 0.1750 - accuracy: 0.9296 - val_loss: 0.1868 - val_accuracy: 0.9309\n",
      "Epoch 108/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1722 - accuracy: 0.9312 - val_loss: 0.1866 - val_accuracy: 0.9300\n",
      "Epoch 109/6000\n",
      "128/128 [==============================] - 22s 173ms/step - loss: 0.1722 - accuracy: 0.9307 - val_loss: 0.1840 - val_accuracy: 0.9323\n",
      "Epoch 110/6000\n",
      "128/128 [==============================] - 20s 156ms/step - loss: 0.1721 - accuracy: 0.9313 - val_loss: 0.1848 - val_accuracy: 0.9327\n",
      "Epoch 111/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1714 - accuracy: 0.9317 - val_loss: 0.1849 - val_accuracy: 0.9320\n",
      "Epoch 112/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.1689 - accuracy: 0.9328 - val_loss: 0.1843 - val_accuracy: 0.9319\n",
      "Epoch 113/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.1672 - accuracy: 0.9336 - val_loss: 0.1818 - val_accuracy: 0.9332\n",
      "Epoch 114/6000\n",
      "128/128 [==============================] - 20s 151ms/step - loss: 0.1686 - accuracy: 0.9327 - val_loss: 0.1838 - val_accuracy: 0.9314\n",
      "Epoch 115/6000\n",
      "128/128 [==============================] - 25s 192ms/step - loss: 0.1670 - accuracy: 0.9335 - val_loss: 0.1848 - val_accuracy: 0.9327\n",
      "Epoch 116/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.1683 - accuracy: 0.9324 - val_loss: 0.1796 - val_accuracy: 0.9335\n",
      "Epoch 117/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.1644 - accuracy: 0.9345 - val_loss: 0.1782 - val_accuracy: 0.9341\n",
      "Epoch 118/6000\n",
      "128/128 [==============================] - 20s 153ms/step - loss: 0.1639 - accuracy: 0.9346 - val_loss: 0.1754 - val_accuracy: 0.9348\n",
      "Epoch 119/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1637 - accuracy: 0.9347 - val_loss: 0.1821 - val_accuracy: 0.9343\n",
      "Epoch 120/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1622 - accuracy: 0.9356 - val_loss: 0.1793 - val_accuracy: 0.9343\n",
      "Epoch 121/6000\n",
      "128/128 [==============================] - 25s 198ms/step - loss: 0.1610 - accuracy: 0.9360 - val_loss: 0.1819 - val_accuracy: 0.9343\n",
      "Epoch 122/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.1630 - accuracy: 0.9356 - val_loss: 0.1785 - val_accuracy: 0.9349\n",
      "Epoch 123/6000\n",
      "128/128 [==============================] - 18s 137ms/step - loss: 0.1604 - accuracy: 0.9364 - val_loss: 0.1805 - val_accuracy: 0.9340\n",
      "Epoch 124/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1613 - accuracy: 0.9362 - val_loss: 0.1766 - val_accuracy: 0.9364\n",
      "Epoch 125/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1609 - accuracy: 0.9366 - val_loss: 0.1767 - val_accuracy: 0.9356\n",
      "Epoch 126/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1588 - accuracy: 0.9371 - val_loss: 0.1760 - val_accuracy: 0.9366\n",
      "Epoch 127/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1582 - accuracy: 0.9374 - val_loss: 0.1729 - val_accuracy: 0.9367\n",
      "Epoch 128/6000\n",
      "128/128 [==============================] - 21s 161ms/step - loss: 0.1564 - accuracy: 0.9384 - val_loss: 0.1830 - val_accuracy: 0.9329\n",
      "Epoch 129/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.1577 - accuracy: 0.9372 - val_loss: 0.1724 - val_accuracy: 0.9365\n",
      "Epoch 130/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.1574 - accuracy: 0.9372 - val_loss: 0.1726 - val_accuracy: 0.9380\n",
      "Epoch 131/6000\n",
      "128/128 [==============================] - 26s 199ms/step - loss: 0.1552 - accuracy: 0.9384 - val_loss: 0.1762 - val_accuracy: 0.9355\n",
      "Epoch 132/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.1544 - accuracy: 0.9391 - val_loss: 0.1699 - val_accuracy: 0.9383\n",
      "Epoch 133/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1541 - accuracy: 0.9392 - val_loss: 0.1752 - val_accuracy: 0.9367\n",
      "Epoch 134/6000\n",
      "128/128 [==============================] - 26s 202ms/step - loss: 0.1560 - accuracy: 0.9384 - val_loss: 0.1707 - val_accuracy: 0.9383\n",
      "Epoch 135/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.1528 - accuracy: 0.9398 - val_loss: 0.1727 - val_accuracy: 0.9381\n",
      "Epoch 136/6000\n",
      "128/128 [==============================] - 19s 150ms/step - loss: 0.1530 - accuracy: 0.9395 - val_loss: 0.1719 - val_accuracy: 0.9393\n",
      "Epoch 137/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1517 - accuracy: 0.9402 - val_loss: 0.1722 - val_accuracy: 0.9376\n",
      "Epoch 138/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.1512 - accuracy: 0.9403 - val_loss: 0.1724 - val_accuracy: 0.9383\n",
      "Epoch 139/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.1518 - accuracy: 0.9403 - val_loss: 0.1726 - val_accuracy: 0.9380\n",
      "Epoch 140/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1505 - accuracy: 0.9404 - val_loss: 0.1790 - val_accuracy: 0.9360\n",
      "Epoch 141/6000\n",
      "128/128 [==============================] - 20s 155ms/step - loss: 0.1498 - accuracy: 0.9411 - val_loss: 0.1688 - val_accuracy: 0.9399\n",
      "Epoch 142/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1492 - accuracy: 0.9418 - val_loss: 0.1699 - val_accuracy: 0.9389\n",
      "Epoch 143/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.1484 - accuracy: 0.9421 - val_loss: 0.1740 - val_accuracy: 0.9372\n",
      "Epoch 144/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1484 - accuracy: 0.9415 - val_loss: 0.1695 - val_accuracy: 0.9394\n",
      "Epoch 145/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1476 - accuracy: 0.9418 - val_loss: 0.1693 - val_accuracy: 0.9400\n",
      "Epoch 146/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1469 - accuracy: 0.9424 - val_loss: 0.1693 - val_accuracy: 0.9382\n",
      "Epoch 147/6000\n",
      "128/128 [==============================] - 20s 160ms/step - loss: 0.1454 - accuracy: 0.9430 - val_loss: 0.1663 - val_accuracy: 0.9400\n",
      "Epoch 148/6000\n",
      "128/128 [==============================] - 22s 169ms/step - loss: 0.1449 - accuracy: 0.9428 - val_loss: 0.1659 - val_accuracy: 0.9406\n",
      "Epoch 149/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1455 - accuracy: 0.9430 - val_loss: 0.1721 - val_accuracy: 0.9383\n",
      "Epoch 150/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.1437 - accuracy: 0.9439 - val_loss: 0.1702 - val_accuracy: 0.9398\n",
      "Epoch 151/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1441 - accuracy: 0.9433 - val_loss: 0.1676 - val_accuracy: 0.9405\n",
      "Epoch 152/6000\n",
      "128/128 [==============================] - 19s 146ms/step - loss: 0.1429 - accuracy: 0.9441 - val_loss: 0.1646 - val_accuracy: 0.9410\n",
      "Epoch 153/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.1433 - accuracy: 0.9439 - val_loss: 0.1713 - val_accuracy: 0.9392\n",
      "Epoch 154/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1440 - accuracy: 0.9436 - val_loss: 0.1765 - val_accuracy: 0.9373\n",
      "Epoch 155/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1425 - accuracy: 0.9443 - val_loss: 0.1686 - val_accuracy: 0.9406\n",
      "Epoch 156/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1398 - accuracy: 0.9453 - val_loss: 0.1646 - val_accuracy: 0.9413\n",
      "Epoch 157/6000\n",
      "128/128 [==============================] - 19s 146ms/step - loss: 0.1414 - accuracy: 0.9449 - val_loss: 0.1691 - val_accuracy: 0.9402\n",
      "Epoch 158/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1390 - accuracy: 0.9460 - val_loss: 0.1674 - val_accuracy: 0.9408\n",
      "Epoch 159/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.1414 - accuracy: 0.9449 - val_loss: 0.1721 - val_accuracy: 0.9388\n",
      "Epoch 160/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1390 - accuracy: 0.9463 - val_loss: 0.1679 - val_accuracy: 0.9424\n",
      "Epoch 161/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1380 - accuracy: 0.9462 - val_loss: 0.1685 - val_accuracy: 0.9408\n",
      "Epoch 162/6000\n",
      "128/128 [==============================] - 18s 144ms/step - loss: 0.1388 - accuracy: 0.9458 - val_loss: 0.1643 - val_accuracy: 0.9430\n",
      "Epoch 163/6000\n",
      "128/128 [==============================] - 24s 184ms/step - loss: 0.1379 - accuracy: 0.9462 - val_loss: 0.1631 - val_accuracy: 0.9424\n",
      "Epoch 164/6000\n",
      "128/128 [==============================] - 25s 192ms/step - loss: 0.1394 - accuracy: 0.9460 - val_loss: 0.1629 - val_accuracy: 0.9428\n",
      "Epoch 165/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1348 - accuracy: 0.9477 - val_loss: 0.1643 - val_accuracy: 0.9428\n",
      "Epoch 166/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1367 - accuracy: 0.9468 - val_loss: 0.1636 - val_accuracy: 0.9423\n",
      "Epoch 167/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1374 - accuracy: 0.9466 - val_loss: 0.1605 - val_accuracy: 0.9430\n",
      "Epoch 168/6000\n",
      "128/128 [==============================] - 20s 158ms/step - loss: 0.1343 - accuracy: 0.9477 - val_loss: 0.1664 - val_accuracy: 0.9421\n",
      "Epoch 169/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1355 - accuracy: 0.9474 - val_loss: 0.1592 - val_accuracy: 0.9443\n",
      "Epoch 170/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.1333 - accuracy: 0.9483 - val_loss: 0.1550 - val_accuracy: 0.9448\n",
      "Epoch 171/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1337 - accuracy: 0.9484 - val_loss: 0.1623 - val_accuracy: 0.9439\n",
      "Epoch 172/6000\n",
      "128/128 [==============================] - 18s 143ms/step - loss: 0.1329 - accuracy: 0.9486 - val_loss: 0.1632 - val_accuracy: 0.9433\n",
      "Epoch 173/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1334 - accuracy: 0.9483 - val_loss: 0.1652 - val_accuracy: 0.9426\n",
      "Epoch 174/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1335 - accuracy: 0.9478 - val_loss: 0.1639 - val_accuracy: 0.9441\n",
      "Epoch 175/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1327 - accuracy: 0.9485 - val_loss: 0.1617 - val_accuracy: 0.9431\n",
      "Epoch 176/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.1321 - accuracy: 0.9485 - val_loss: 0.1691 - val_accuracy: 0.9407\n",
      "Epoch 177/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1314 - accuracy: 0.9495 - val_loss: 0.1606 - val_accuracy: 0.9439\n",
      "Epoch 178/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.1313 - accuracy: 0.9494 - val_loss: 0.1566 - val_accuracy: 0.9453\n",
      "Epoch 179/6000\n",
      "128/128 [==============================] - 19s 148ms/step - loss: 0.1305 - accuracy: 0.9494 - val_loss: 0.1613 - val_accuracy: 0.9439\n",
      "Epoch 180/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1300 - accuracy: 0.9496 - val_loss: 0.1560 - val_accuracy: 0.9451\n",
      "Epoch 181/6000\n",
      "128/128 [==============================] - 23s 175ms/step - loss: 0.1286 - accuracy: 0.9500 - val_loss: 0.1570 - val_accuracy: 0.9449\n",
      "Epoch 182/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1293 - accuracy: 0.9502 - val_loss: 0.1602 - val_accuracy: 0.9449\n",
      "Epoch 183/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1285 - accuracy: 0.9510 - val_loss: 0.1581 - val_accuracy: 0.9457\n",
      "Epoch 184/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1278 - accuracy: 0.9510 - val_loss: 0.1601 - val_accuracy: 0.9442\n",
      "Epoch 185/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1291 - accuracy: 0.9505 - val_loss: 0.1606 - val_accuracy: 0.9446\n",
      "Epoch 186/6000\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 0.1287 - accuracy: 0.9505 - val_loss: 0.1580 - val_accuracy: 0.9465\n",
      "Epoch 187/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.1274 - accuracy: 0.9511 - val_loss: 0.1605 - val_accuracy: 0.9456\n",
      "Epoch 188/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1269 - accuracy: 0.9508 - val_loss: 0.1544 - val_accuracy: 0.9466\n",
      "Epoch 189/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1257 - accuracy: 0.9517 - val_loss: 0.1534 - val_accuracy: 0.9478\n",
      "Epoch 190/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.1259 - accuracy: 0.9519 - val_loss: 0.1604 - val_accuracy: 0.9456\n",
      "Epoch 191/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1267 - accuracy: 0.9512 - val_loss: 0.1598 - val_accuracy: 0.9454\n",
      "Epoch 192/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1248 - accuracy: 0.9521 - val_loss: 0.1607 - val_accuracy: 0.9446\n",
      "Epoch 193/6000\n",
      "128/128 [==============================] - 25s 194ms/step - loss: 0.1248 - accuracy: 0.9520 - val_loss: 0.1619 - val_accuracy: 0.9437\n",
      "Epoch 194/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1252 - accuracy: 0.9517 - val_loss: 0.1556 - val_accuracy: 0.9470\n",
      "Epoch 195/6000\n",
      "128/128 [==============================] - 21s 159ms/step - loss: 0.1254 - accuracy: 0.9516 - val_loss: 0.1545 - val_accuracy: 0.9475\n",
      "Epoch 196/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1227 - accuracy: 0.9530 - val_loss: 0.1548 - val_accuracy: 0.9465\n",
      "Epoch 197/6000\n",
      "128/128 [==============================] - 24s 192ms/step - loss: 0.1228 - accuracy: 0.9525 - val_loss: 0.1532 - val_accuracy: 0.9471\n",
      "Epoch 198/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1231 - accuracy: 0.9525 - val_loss: 0.1546 - val_accuracy: 0.9477\n",
      "Epoch 199/6000\n",
      "128/128 [==============================] - 18s 140ms/step - loss: 0.1219 - accuracy: 0.9533 - val_loss: 0.1511 - val_accuracy: 0.9476\n",
      "Epoch 200/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1221 - accuracy: 0.9528 - val_loss: 0.1573 - val_accuracy: 0.9455\n",
      "Epoch 201/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1225 - accuracy: 0.9528 - val_loss: 0.1545 - val_accuracy: 0.9475\n",
      "Epoch 202/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1210 - accuracy: 0.9536 - val_loss: 0.1488 - val_accuracy: 0.9498\n",
      "Epoch 203/6000\n",
      "128/128 [==============================] - 25s 194ms/step - loss: 0.1218 - accuracy: 0.9535 - val_loss: 0.1566 - val_accuracy: 0.9467\n",
      "Epoch 204/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.1216 - accuracy: 0.9538 - val_loss: 0.1565 - val_accuracy: 0.9468\n",
      "Epoch 205/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1208 - accuracy: 0.9536 - val_loss: 0.1547 - val_accuracy: 0.9479\n",
      "Epoch 206/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.1196 - accuracy: 0.9539 - val_loss: 0.1528 - val_accuracy: 0.9482\n",
      "Epoch 207/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1200 - accuracy: 0.9540 - val_loss: 0.1535 - val_accuracy: 0.9468\n",
      "Epoch 208/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1201 - accuracy: 0.9538 - val_loss: 0.1534 - val_accuracy: 0.9487\n",
      "Epoch 209/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1194 - accuracy: 0.9544 - val_loss: 0.1600 - val_accuracy: 0.9457\n",
      "Epoch 210/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1175 - accuracy: 0.9548 - val_loss: 0.1499 - val_accuracy: 0.9488\n",
      "Epoch 211/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.1178 - accuracy: 0.9551 - val_loss: 0.1529 - val_accuracy: 0.9482\n",
      "Epoch 212/6000\n",
      "128/128 [==============================] - 25s 194ms/step - loss: 0.1169 - accuracy: 0.9551 - val_loss: 0.1528 - val_accuracy: 0.9485\n",
      "Epoch 213/6000\n",
      "128/128 [==============================] - 19s 147ms/step - loss: 0.1171 - accuracy: 0.9553 - val_loss: 0.1581 - val_accuracy: 0.9477\n",
      "Epoch 214/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1170 - accuracy: 0.9552 - val_loss: 0.1546 - val_accuracy: 0.9491\n",
      "Epoch 215/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1166 - accuracy: 0.9557 - val_loss: 0.1564 - val_accuracy: 0.9471\n",
      "Epoch 216/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.1158 - accuracy: 0.9559 - val_loss: 0.1512 - val_accuracy: 0.9495\n",
      "Epoch 217/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1159 - accuracy: 0.9555 - val_loss: 0.1503 - val_accuracy: 0.9495\n",
      "Epoch 217: early stopping\n",
      "##########################################################################\n",
      "------val_accuracy-----> 94.98 | 95.59 <----------accuracy----------\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/WAVES-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/WAVES-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "working on pair: LAZIO/USDT\n",
      "One_pair_AI_Gen : LAZIO/USDT\n",
      "price_volatility_15m:0.59%\n",
      "mini_expand : LAZIO/USDT\n",
      "---buy_simple_up--- Buy pct: 0.59%\n",
      "---buy_only--- Max time window: 10%\n",
      "---buy_only--- no b\n",
      "---buy_only--- no sell\n",
      "df original shape (407582, 1607)\n",
      "df original shape buy mean : 15.62998365972982\n",
      "df choosen data shape(407582, 1607)\n",
      "pair: True\n",
      "81516\n",
      "normalizing ...\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/LAZIO-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_112 (Dense)           (None, 250)               401750    \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 250)               0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 20)                5020      \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,871\n",
      "Trainable params: 407,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_UP_CLOSE/LAZIO-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "Epoch 1/6000\n",
      "128/128 [==============================] - 27s 170ms/step - loss: 0.5780 - accuracy: 0.7014 - val_loss: 0.5537 - val_accuracy: 0.7197\n",
      "Epoch 2/6000\n",
      "128/128 [==============================] - 19s 146ms/step - loss: 0.5464 - accuracy: 0.7264 - val_loss: 0.5265 - val_accuracy: 0.7380\n",
      "Epoch 3/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.5240 - accuracy: 0.7418 - val_loss: 0.5094 - val_accuracy: 0.7550\n",
      "Epoch 4/6000\n",
      "128/128 [==============================] - 18s 144ms/step - loss: 0.5023 - accuracy: 0.7568 - val_loss: 0.4801 - val_accuracy: 0.7727\n",
      "Epoch 5/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.4775 - accuracy: 0.7723 - val_loss: 0.4548 - val_accuracy: 0.7914\n",
      "Epoch 6/6000\n",
      "128/128 [==============================] - 18s 143ms/step - loss: 0.4593 - accuracy: 0.7844 - val_loss: 0.4421 - val_accuracy: 0.7978\n",
      "Epoch 7/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.4407 - accuracy: 0.7962 - val_loss: 0.4200 - val_accuracy: 0.8107\n",
      "Epoch 8/6000\n",
      "128/128 [==============================] - 18s 139ms/step - loss: 0.4231 - accuracy: 0.8066 - val_loss: 0.4033 - val_accuracy: 0.8212\n",
      "Epoch 9/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.4081 - accuracy: 0.8150 - val_loss: 0.3910 - val_accuracy: 0.8278\n",
      "Epoch 10/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.3946 - accuracy: 0.8226 - val_loss: 0.3682 - val_accuracy: 0.8395\n",
      "Epoch 11/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.3844 - accuracy: 0.8287 - val_loss: 0.3647 - val_accuracy: 0.8389\n",
      "Epoch 12/6000\n",
      "128/128 [==============================] - 19s 144ms/step - loss: 0.3748 - accuracy: 0.8335 - val_loss: 0.3515 - val_accuracy: 0.8475\n",
      "Epoch 13/6000\n",
      "128/128 [==============================] - 25s 192ms/step - loss: 0.3636 - accuracy: 0.8395 - val_loss: 0.3481 - val_accuracy: 0.8500\n",
      "Epoch 14/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.3554 - accuracy: 0.8436 - val_loss: 0.3305 - val_accuracy: 0.8590\n",
      "Epoch 15/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.3470 - accuracy: 0.8482 - val_loss: 0.3276 - val_accuracy: 0.8604\n",
      "Epoch 16/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.3411 - accuracy: 0.8518 - val_loss: 0.3228 - val_accuracy: 0.8632\n",
      "Epoch 17/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.3358 - accuracy: 0.8546 - val_loss: 0.3221 - val_accuracy: 0.8625\n",
      "Epoch 18/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.3276 - accuracy: 0.8582 - val_loss: 0.3130 - val_accuracy: 0.8678\n",
      "Epoch 19/6000\n",
      "128/128 [==============================] - 20s 159ms/step - loss: 0.3213 - accuracy: 0.8614 - val_loss: 0.3015 - val_accuracy: 0.8726\n",
      "Epoch 20/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.3174 - accuracy: 0.8638 - val_loss: 0.3018 - val_accuracy: 0.8732\n",
      "Epoch 21/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.3118 - accuracy: 0.8664 - val_loss: 0.2958 - val_accuracy: 0.8757\n",
      "Epoch 22/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.3075 - accuracy: 0.8686 - val_loss: 0.2923 - val_accuracy: 0.8767\n",
      "Epoch 23/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.3020 - accuracy: 0.8718 - val_loss: 0.2839 - val_accuracy: 0.8838\n",
      "Epoch 24/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.2999 - accuracy: 0.8726 - val_loss: 0.2854 - val_accuracy: 0.8810\n",
      "Epoch 25/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.2964 - accuracy: 0.8736 - val_loss: 0.2839 - val_accuracy: 0.8815\n",
      "Epoch 26/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.2904 - accuracy: 0.8775 - val_loss: 0.2781 - val_accuracy: 0.8848\n",
      "Epoch 27/6000\n",
      "128/128 [==============================] - 19s 145ms/step - loss: 0.2885 - accuracy: 0.8785 - val_loss: 0.2801 - val_accuracy: 0.8825\n",
      "Epoch 28/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.2844 - accuracy: 0.8802 - val_loss: 0.2705 - val_accuracy: 0.8891\n",
      "Epoch 29/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.2820 - accuracy: 0.8810 - val_loss: 0.2670 - val_accuracy: 0.8896\n",
      "Epoch 30/6000\n",
      "128/128 [==============================] - 26s 201ms/step - loss: 0.2760 - accuracy: 0.8843 - val_loss: 0.2647 - val_accuracy: 0.8901\n",
      "Epoch 31/6000\n",
      "128/128 [==============================] - 19s 145ms/step - loss: 0.2751 - accuracy: 0.8846 - val_loss: 0.2655 - val_accuracy: 0.8910\n",
      "Epoch 32/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.2706 - accuracy: 0.8872 - val_loss: 0.2674 - val_accuracy: 0.8898\n",
      "Epoch 33/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.2685 - accuracy: 0.8874 - val_loss: 0.2644 - val_accuracy: 0.8923\n",
      "Epoch 34/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.2664 - accuracy: 0.8886 - val_loss: 0.2569 - val_accuracy: 0.8934\n",
      "Epoch 35/6000\n",
      "128/128 [==============================] - 23s 184ms/step - loss: 0.2646 - accuracy: 0.8897 - val_loss: 0.2569 - val_accuracy: 0.8939\n",
      "Epoch 36/6000\n",
      "128/128 [==============================] - 18s 139ms/step - loss: 0.2625 - accuracy: 0.8909 - val_loss: 0.2550 - val_accuracy: 0.8956\n",
      "Epoch 37/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.2592 - accuracy: 0.8919 - val_loss: 0.2583 - val_accuracy: 0.8941\n",
      "Epoch 38/6000\n",
      "128/128 [==============================] - 24s 192ms/step - loss: 0.2560 - accuracy: 0.8937 - val_loss: 0.2467 - val_accuracy: 0.8990\n",
      "Epoch 39/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.2554 - accuracy: 0.8943 - val_loss: 0.2464 - val_accuracy: 0.8982\n",
      "Epoch 40/6000\n",
      "128/128 [==============================] - 18s 144ms/step - loss: 0.2527 - accuracy: 0.8959 - val_loss: 0.2455 - val_accuracy: 0.9000\n",
      "Epoch 41/6000\n",
      "128/128 [==============================] - 24s 184ms/step - loss: 0.2508 - accuracy: 0.8969 - val_loss: 0.2417 - val_accuracy: 0.9021\n",
      "Epoch 42/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.2483 - accuracy: 0.8975 - val_loss: 0.2452 - val_accuracy: 0.8992\n",
      "Epoch 43/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.2454 - accuracy: 0.8988 - val_loss: 0.2419 - val_accuracy: 0.9022\n",
      "Epoch 44/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.2457 - accuracy: 0.8987 - val_loss: 0.2365 - val_accuracy: 0.9050\n",
      "Epoch 45/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.2416 - accuracy: 0.9007 - val_loss: 0.2439 - val_accuracy: 0.9010\n",
      "Epoch 46/6000\n",
      "128/128 [==============================] - 23s 175ms/step - loss: 0.2409 - accuracy: 0.9011 - val_loss: 0.2394 - val_accuracy: 0.9025\n",
      "Epoch 47/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.2398 - accuracy: 0.9015 - val_loss: 0.2417 - val_accuracy: 0.9024\n",
      "Epoch 48/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.2363 - accuracy: 0.9032 - val_loss: 0.2330 - val_accuracy: 0.9055\n",
      "Epoch 49/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.2358 - accuracy: 0.9038 - val_loss: 0.2326 - val_accuracy: 0.9063\n",
      "Epoch 50/6000\n",
      "128/128 [==============================] - 18s 140ms/step - loss: 0.2347 - accuracy: 0.9044 - val_loss: 0.2361 - val_accuracy: 0.9043\n",
      "Epoch 51/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.2334 - accuracy: 0.9051 - val_loss: 0.2416 - val_accuracy: 0.9020\n",
      "Epoch 52/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.2297 - accuracy: 0.9062 - val_loss: 0.2325 - val_accuracy: 0.9065\n",
      "Epoch 53/6000\n",
      "128/128 [==============================] - 26s 200ms/step - loss: 0.2304 - accuracy: 0.9062 - val_loss: 0.2316 - val_accuracy: 0.9074\n",
      "Epoch 54/6000\n",
      "128/128 [==============================] - 18s 140ms/step - loss: 0.2284 - accuracy: 0.9072 - val_loss: 0.2254 - val_accuracy: 0.9105\n",
      "Epoch 55/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.2279 - accuracy: 0.9075 - val_loss: 0.2421 - val_accuracy: 0.9025\n",
      "Epoch 56/6000\n",
      "128/128 [==============================] - 24s 192ms/step - loss: 0.2250 - accuracy: 0.9090 - val_loss: 0.2338 - val_accuracy: 0.9073\n",
      "Epoch 57/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.2227 - accuracy: 0.9094 - val_loss: 0.2236 - val_accuracy: 0.9108\n",
      "Epoch 58/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.2224 - accuracy: 0.9097 - val_loss: 0.2240 - val_accuracy: 0.9113\n",
      "Epoch 59/6000\n",
      "128/128 [==============================] - 20s 155ms/step - loss: 0.2219 - accuracy: 0.9104 - val_loss: 0.2199 - val_accuracy: 0.9139\n",
      "Epoch 60/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.2197 - accuracy: 0.9111 - val_loss: 0.2282 - val_accuracy: 0.9093\n",
      "Epoch 61/6000\n",
      "128/128 [==============================] - 26s 203ms/step - loss: 0.2187 - accuracy: 0.9115 - val_loss: 0.2219 - val_accuracy: 0.9127\n",
      "Epoch 62/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.2193 - accuracy: 0.9112 - val_loss: 0.2267 - val_accuracy: 0.9102\n",
      "Epoch 63/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.2139 - accuracy: 0.9138 - val_loss: 0.2191 - val_accuracy: 0.9136\n",
      "Epoch 64/6000\n",
      "128/128 [==============================] - 24s 183ms/step - loss: 0.2148 - accuracy: 0.9136 - val_loss: 0.2194 - val_accuracy: 0.9128\n",
      "Epoch 65/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.2125 - accuracy: 0.9145 - val_loss: 0.2197 - val_accuracy: 0.9145\n",
      "Epoch 66/6000\n",
      "128/128 [==============================] - 25s 195ms/step - loss: 0.2129 - accuracy: 0.9140 - val_loss: 0.2181 - val_accuracy: 0.9145\n",
      "Epoch 67/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.2107 - accuracy: 0.9155 - val_loss: 0.2130 - val_accuracy: 0.9171\n",
      "Epoch 68/6000\n",
      "128/128 [==============================] - 18s 144ms/step - loss: 0.2110 - accuracy: 0.9152 - val_loss: 0.2242 - val_accuracy: 0.9129\n",
      "Epoch 69/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.2090 - accuracy: 0.9165 - val_loss: 0.2172 - val_accuracy: 0.9155\n",
      "Epoch 70/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.2063 - accuracy: 0.9173 - val_loss: 0.2076 - val_accuracy: 0.9195\n",
      "Epoch 71/6000\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 0.2046 - accuracy: 0.9178 - val_loss: 0.2149 - val_accuracy: 0.9163\n",
      "Epoch 72/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.2061 - accuracy: 0.9172 - val_loss: 0.2096 - val_accuracy: 0.9187\n",
      "Epoch 73/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.2040 - accuracy: 0.9187 - val_loss: 0.2139 - val_accuracy: 0.9161\n",
      "Epoch 74/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.2033 - accuracy: 0.9185 - val_loss: 0.2112 - val_accuracy: 0.9179\n",
      "Epoch 75/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.2019 - accuracy: 0.9195 - val_loss: 0.2086 - val_accuracy: 0.9195\n",
      "Epoch 76/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.1999 - accuracy: 0.9200 - val_loss: 0.2151 - val_accuracy: 0.9170\n",
      "Epoch 77/6000\n",
      "128/128 [==============================] - 18s 143ms/step - loss: 0.1983 - accuracy: 0.9210 - val_loss: 0.2127 - val_accuracy: 0.9183\n",
      "Epoch 78/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1990 - accuracy: 0.9210 - val_loss: 0.2024 - val_accuracy: 0.9225\n",
      "Epoch 79/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.1993 - accuracy: 0.9211 - val_loss: 0.2052 - val_accuracy: 0.9209\n",
      "Epoch 80/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.1977 - accuracy: 0.9215 - val_loss: 0.2154 - val_accuracy: 0.9169\n",
      "Epoch 81/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1956 - accuracy: 0.9224 - val_loss: 0.2060 - val_accuracy: 0.9202\n",
      "Epoch 82/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1949 - accuracy: 0.9225 - val_loss: 0.2055 - val_accuracy: 0.9215\n",
      "Epoch 83/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.1933 - accuracy: 0.9234 - val_loss: 0.2057 - val_accuracy: 0.9211\n",
      "Epoch 84/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.1926 - accuracy: 0.9237 - val_loss: 0.2081 - val_accuracy: 0.9201\n",
      "Epoch 85/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.1929 - accuracy: 0.9232 - val_loss: 0.2037 - val_accuracy: 0.9225\n",
      "Epoch 86/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1915 - accuracy: 0.9242 - val_loss: 0.2007 - val_accuracy: 0.9233\n",
      "Epoch 87/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1909 - accuracy: 0.9243 - val_loss: 0.2076 - val_accuracy: 0.9225\n",
      "Epoch 88/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.1889 - accuracy: 0.9253 - val_loss: 0.1989 - val_accuracy: 0.9244\n",
      "Epoch 89/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1877 - accuracy: 0.9260 - val_loss: 0.1997 - val_accuracy: 0.9246\n",
      "Epoch 90/6000\n",
      "128/128 [==============================] - 22s 175ms/step - loss: 0.1874 - accuracy: 0.9262 - val_loss: 0.1986 - val_accuracy: 0.9248\n",
      "Epoch 91/6000\n",
      "128/128 [==============================] - 21s 162ms/step - loss: 0.1860 - accuracy: 0.9270 - val_loss: 0.1968 - val_accuracy: 0.9262\n",
      "Epoch 92/6000\n",
      "128/128 [==============================] - 24s 183ms/step - loss: 0.1855 - accuracy: 0.9267 - val_loss: 0.1972 - val_accuracy: 0.9248\n",
      "Epoch 93/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1858 - accuracy: 0.9268 - val_loss: 0.1997 - val_accuracy: 0.9246\n",
      "Epoch 94/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1842 - accuracy: 0.9273 - val_loss: 0.1960 - val_accuracy: 0.9257\n",
      "Epoch 95/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.1836 - accuracy: 0.9277 - val_loss: 0.1952 - val_accuracy: 0.9248\n",
      "Epoch 96/6000\n",
      "128/128 [==============================] - 18s 139ms/step - loss: 0.1826 - accuracy: 0.9277 - val_loss: 0.2015 - val_accuracy: 0.9238\n",
      "Epoch 97/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1834 - accuracy: 0.9281 - val_loss: 0.2019 - val_accuracy: 0.9228\n",
      "Epoch 98/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1831 - accuracy: 0.9284 - val_loss: 0.2039 - val_accuracy: 0.9234\n",
      "Epoch 99/6000\n",
      "128/128 [==============================] - 25s 197ms/step - loss: 0.1807 - accuracy: 0.9293 - val_loss: 0.1976 - val_accuracy: 0.9252\n",
      "Epoch 100/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1784 - accuracy: 0.9298 - val_loss: 0.1927 - val_accuracy: 0.9272\n",
      "Epoch 101/6000\n",
      "128/128 [==============================] - 19s 148ms/step - loss: 0.1782 - accuracy: 0.9300 - val_loss: 0.1956 - val_accuracy: 0.9266\n",
      "Epoch 102/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1784 - accuracy: 0.9300 - val_loss: 0.1965 - val_accuracy: 0.9265\n",
      "Epoch 103/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1775 - accuracy: 0.9299 - val_loss: 0.1954 - val_accuracy: 0.9255\n",
      "Epoch 104/6000\n",
      "128/128 [==============================] - 23s 184ms/step - loss: 0.1792 - accuracy: 0.9301 - val_loss: 0.1999 - val_accuracy: 0.9250\n",
      "Epoch 105/6000\n",
      "128/128 [==============================] - 24s 184ms/step - loss: 0.1759 - accuracy: 0.9314 - val_loss: 0.1945 - val_accuracy: 0.9282\n",
      "Epoch 106/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1744 - accuracy: 0.9317 - val_loss: 0.1973 - val_accuracy: 0.9268\n",
      "Epoch 107/6000\n",
      "128/128 [==============================] - 23s 184ms/step - loss: 0.1748 - accuracy: 0.9315 - val_loss: 0.1888 - val_accuracy: 0.9288\n",
      "Epoch 108/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1750 - accuracy: 0.9314 - val_loss: 0.1924 - val_accuracy: 0.9278\n",
      "Epoch 109/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.1735 - accuracy: 0.9328 - val_loss: 0.1936 - val_accuracy: 0.9280\n",
      "Epoch 110/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.1727 - accuracy: 0.9326 - val_loss: 0.1917 - val_accuracy: 0.9284\n",
      "Epoch 111/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1723 - accuracy: 0.9327 - val_loss: 0.1894 - val_accuracy: 0.9291\n",
      "Epoch 112/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1714 - accuracy: 0.9327 - val_loss: 0.1882 - val_accuracy: 0.9306\n",
      "Epoch 113/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1704 - accuracy: 0.9337 - val_loss: 0.1926 - val_accuracy: 0.9282\n",
      "Epoch 114/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1715 - accuracy: 0.9331 - val_loss: 0.1922 - val_accuracy: 0.9291\n",
      "Epoch 115/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.1679 - accuracy: 0.9346 - val_loss: 0.1864 - val_accuracy: 0.9308\n",
      "Epoch 116/6000\n",
      "128/128 [==============================] - 18s 138ms/step - loss: 0.1685 - accuracy: 0.9348 - val_loss: 0.1890 - val_accuracy: 0.9304\n",
      "Epoch 117/6000\n",
      "128/128 [==============================] - 25s 197ms/step - loss: 0.1684 - accuracy: 0.9347 - val_loss: 0.1930 - val_accuracy: 0.9284\n",
      "Epoch 118/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1690 - accuracy: 0.9347 - val_loss: 0.1864 - val_accuracy: 0.9302\n",
      "Epoch 119/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1667 - accuracy: 0.9350 - val_loss: 0.1821 - val_accuracy: 0.9328\n",
      "Epoch 120/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.1652 - accuracy: 0.9354 - val_loss: 0.1873 - val_accuracy: 0.9317\n",
      "Epoch 121/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1664 - accuracy: 0.9355 - val_loss: 0.1863 - val_accuracy: 0.9318\n",
      "Epoch 122/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1651 - accuracy: 0.9360 - val_loss: 0.1889 - val_accuracy: 0.9298\n",
      "Epoch 123/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1640 - accuracy: 0.9364 - val_loss: 0.1980 - val_accuracy: 0.9279\n",
      "Epoch 124/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1652 - accuracy: 0.9362 - val_loss: 0.1882 - val_accuracy: 0.9311\n",
      "Epoch 125/6000\n",
      "128/128 [==============================] - 21s 161ms/step - loss: 0.1633 - accuracy: 0.9363 - val_loss: 0.1850 - val_accuracy: 0.9324\n",
      "Epoch 126/6000\n",
      "128/128 [==============================] - 21s 160ms/step - loss: 0.1646 - accuracy: 0.9361 - val_loss: 0.1935 - val_accuracy: 0.9298\n",
      "Epoch 127/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.1635 - accuracy: 0.9364 - val_loss: 0.1880 - val_accuracy: 0.9318\n",
      "Epoch 128/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.1625 - accuracy: 0.9372 - val_loss: 0.1873 - val_accuracy: 0.9315\n",
      "Epoch 129/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1611 - accuracy: 0.9375 - val_loss: 0.1834 - val_accuracy: 0.9338\n",
      "Epoch 130/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.1597 - accuracy: 0.9378 - val_loss: 0.1838 - val_accuracy: 0.9332\n",
      "Epoch 131/6000\n",
      "128/128 [==============================] - 18s 144ms/step - loss: 0.1584 - accuracy: 0.9391 - val_loss: 0.1881 - val_accuracy: 0.9318\n",
      "Epoch 132/6000\n",
      "128/128 [==============================] - 25s 192ms/step - loss: 0.1622 - accuracy: 0.9376 - val_loss: 0.1938 - val_accuracy: 0.9287\n",
      "Epoch 133/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1591 - accuracy: 0.9389 - val_loss: 0.1845 - val_accuracy: 0.9334\n",
      "Epoch 134/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1596 - accuracy: 0.9385 - val_loss: 0.1904 - val_accuracy: 0.9308\n",
      "Epoch 135/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1577 - accuracy: 0.9393 - val_loss: 0.1868 - val_accuracy: 0.9327\n",
      "Epoch 136/6000\n",
      "128/128 [==============================] - 21s 165ms/step - loss: 0.1581 - accuracy: 0.9387 - val_loss: 0.1855 - val_accuracy: 0.9335\n",
      "Epoch 137/6000\n",
      "128/128 [==============================] - 24s 183ms/step - loss: 0.1558 - accuracy: 0.9398 - val_loss: 0.1820 - val_accuracy: 0.9343\n",
      "Epoch 138/6000\n",
      "128/128 [==============================] - 25s 197ms/step - loss: 0.1558 - accuracy: 0.9402 - val_loss: 0.1927 - val_accuracy: 0.9315\n",
      "Epoch 139/6000\n",
      "128/128 [==============================] - 23s 184ms/step - loss: 0.1564 - accuracy: 0.9402 - val_loss: 0.1784 - val_accuracy: 0.9357\n",
      "Epoch 140/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1553 - accuracy: 0.9402 - val_loss: 0.1857 - val_accuracy: 0.9320\n",
      "Epoch 141/6000\n",
      "128/128 [==============================] - 25s 195ms/step - loss: 0.1549 - accuracy: 0.9404 - val_loss: 0.1769 - val_accuracy: 0.9360\n",
      "Epoch 142/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.1535 - accuracy: 0.9406 - val_loss: 0.1848 - val_accuracy: 0.9339\n",
      "Epoch 143/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1539 - accuracy: 0.9406 - val_loss: 0.1811 - val_accuracy: 0.9350\n",
      "Epoch 144/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.1538 - accuracy: 0.9407 - val_loss: 0.1872 - val_accuracy: 0.9344\n",
      "Epoch 145/6000\n",
      "128/128 [==============================] - 23s 184ms/step - loss: 0.1544 - accuracy: 0.9403 - val_loss: 0.1836 - val_accuracy: 0.9342\n",
      "Epoch 146/6000\n",
      "128/128 [==============================] - 19s 146ms/step - loss: 0.1528 - accuracy: 0.9414 - val_loss: 0.1897 - val_accuracy: 0.9308\n",
      "Epoch 147/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1519 - accuracy: 0.9418 - val_loss: 0.1801 - val_accuracy: 0.9360\n",
      "Epoch 148/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.1513 - accuracy: 0.9415 - val_loss: 0.1829 - val_accuracy: 0.9334\n",
      "Epoch 149/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1514 - accuracy: 0.9415 - val_loss: 0.1790 - val_accuracy: 0.9354\n",
      "Epoch 150/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1505 - accuracy: 0.9421 - val_loss: 0.1870 - val_accuracy: 0.9336\n",
      "Epoch 151/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.1491 - accuracy: 0.9430 - val_loss: 0.1782 - val_accuracy: 0.9369\n",
      "Epoch 152/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1499 - accuracy: 0.9420 - val_loss: 0.1835 - val_accuracy: 0.9349\n",
      "Epoch 153/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1490 - accuracy: 0.9434 - val_loss: 0.1796 - val_accuracy: 0.9361\n",
      "Epoch 154/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.1492 - accuracy: 0.9428 - val_loss: 0.1768 - val_accuracy: 0.9365\n",
      "Epoch 155/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1485 - accuracy: 0.9431 - val_loss: 0.1824 - val_accuracy: 0.9353\n",
      "Epoch 156/6000\n",
      "128/128 [==============================] - 19s 146ms/step - loss: 0.1489 - accuracy: 0.9429 - val_loss: 0.1867 - val_accuracy: 0.9343\n",
      "Epoch 157/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1475 - accuracy: 0.9438 - val_loss: 0.1829 - val_accuracy: 0.9357\n",
      "Epoch 158/6000\n",
      "128/128 [==============================] - 24s 186ms/step - loss: 0.1475 - accuracy: 0.9436 - val_loss: 0.1794 - val_accuracy: 0.9361\n",
      "Epoch 159/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1469 - accuracy: 0.9433 - val_loss: 0.1818 - val_accuracy: 0.9350\n",
      "Epoch 160/6000\n",
      "128/128 [==============================] - 20s 154ms/step - loss: 0.1461 - accuracy: 0.9441 - val_loss: 0.1787 - val_accuracy: 0.9368\n",
      "Epoch 161/6000\n",
      "128/128 [==============================] - 24s 183ms/step - loss: 0.1460 - accuracy: 0.9442 - val_loss: 0.1785 - val_accuracy: 0.9365\n",
      "Epoch 162/6000\n",
      "128/128 [==============================] - 23s 175ms/step - loss: 0.1464 - accuracy: 0.9439 - val_loss: 0.1748 - val_accuracy: 0.9374\n",
      "Epoch 163/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1450 - accuracy: 0.9445 - val_loss: 0.1792 - val_accuracy: 0.9358\n",
      "Epoch 164/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1451 - accuracy: 0.9447 - val_loss: 0.1767 - val_accuracy: 0.9371\n",
      "Epoch 165/6000\n",
      "128/128 [==============================] - 25s 192ms/step - loss: 0.1448 - accuracy: 0.9444 - val_loss: 0.1804 - val_accuracy: 0.9361\n",
      "Epoch 166/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1451 - accuracy: 0.9448 - val_loss: 0.1853 - val_accuracy: 0.9344\n",
      "Epoch 167/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1447 - accuracy: 0.9450 - val_loss: 0.1763 - val_accuracy: 0.9368\n",
      "Epoch 168/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1427 - accuracy: 0.9454 - val_loss: 0.1775 - val_accuracy: 0.9365\n",
      "Epoch 169/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1427 - accuracy: 0.9456 - val_loss: 0.1707 - val_accuracy: 0.9389\n",
      "Epoch 170/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.1423 - accuracy: 0.9459 - val_loss: 0.1729 - val_accuracy: 0.9382\n",
      "Epoch 171/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1420 - accuracy: 0.9459 - val_loss: 0.1727 - val_accuracy: 0.9391\n",
      "Epoch 172/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.1399 - accuracy: 0.9466 - val_loss: 0.1776 - val_accuracy: 0.9382\n",
      "Epoch 173/6000\n",
      "128/128 [==============================] - 21s 164ms/step - loss: 0.1408 - accuracy: 0.9464 - val_loss: 0.1721 - val_accuracy: 0.9388\n",
      "Epoch 174/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1392 - accuracy: 0.9471 - val_loss: 0.1782 - val_accuracy: 0.9373\n",
      "Epoch 175/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1408 - accuracy: 0.9465 - val_loss: 0.1777 - val_accuracy: 0.9375\n",
      "Epoch 176/6000\n",
      "128/128 [==============================] - 27s 209ms/step - loss: 0.1399 - accuracy: 0.9470 - val_loss: 0.1720 - val_accuracy: 0.9392\n",
      "Epoch 177/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1404 - accuracy: 0.9467 - val_loss: 0.1750 - val_accuracy: 0.9379\n",
      "Epoch 178/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1388 - accuracy: 0.9471 - val_loss: 0.1719 - val_accuracy: 0.9389\n",
      "Epoch 179/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1386 - accuracy: 0.9474 - val_loss: 0.1805 - val_accuracy: 0.9372\n",
      "Epoch 180/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.1384 - accuracy: 0.9475 - val_loss: 0.1749 - val_accuracy: 0.9385\n",
      "Epoch 181/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1386 - accuracy: 0.9473 - val_loss: 0.1770 - val_accuracy: 0.9384\n",
      "Epoch 182/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1374 - accuracy: 0.9479 - val_loss: 0.1745 - val_accuracy: 0.9391\n",
      "Epoch 183/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1371 - accuracy: 0.9477 - val_loss: 0.1802 - val_accuracy: 0.9370\n",
      "Epoch 184/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.1378 - accuracy: 0.9482 - val_loss: 0.1799 - val_accuracy: 0.9381\n",
      "Epoch 185/6000\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 0.1339 - accuracy: 0.9492 - val_loss: 0.1729 - val_accuracy: 0.9399\n",
      "Epoch 186/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1377 - accuracy: 0.9481 - val_loss: 0.1758 - val_accuracy: 0.9385\n",
      "Epoch 187/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1378 - accuracy: 0.9479 - val_loss: 0.1687 - val_accuracy: 0.9392\n",
      "Epoch 188/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1358 - accuracy: 0.9485 - val_loss: 0.1705 - val_accuracy: 0.9402\n",
      "Epoch 189/6000\n",
      "128/128 [==============================] - 22s 172ms/step - loss: 0.1354 - accuracy: 0.9492 - val_loss: 0.1690 - val_accuracy: 0.9407\n",
      "Epoch 190/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.1350 - accuracy: 0.9485 - val_loss: 0.1734 - val_accuracy: 0.9390\n",
      "Epoch 191/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.1338 - accuracy: 0.9493 - val_loss: 0.1718 - val_accuracy: 0.9403\n",
      "Epoch 192/6000\n",
      "128/128 [==============================] - 26s 202ms/step - loss: 0.1340 - accuracy: 0.9489 - val_loss: 0.1714 - val_accuracy: 0.9404\n",
      "Epoch 193/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1349 - accuracy: 0.9489 - val_loss: 0.1770 - val_accuracy: 0.9390\n",
      "Epoch 194/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1334 - accuracy: 0.9495 - val_loss: 0.1734 - val_accuracy: 0.9399\n",
      "Epoch 195/6000\n",
      "128/128 [==============================] - 19s 145ms/step - loss: 0.1332 - accuracy: 0.9496 - val_loss: 0.1762 - val_accuracy: 0.9395\n",
      "Epoch 196/6000\n",
      "128/128 [==============================] - 25s 197ms/step - loss: 0.1341 - accuracy: 0.9492 - val_loss: 0.1722 - val_accuracy: 0.9400\n",
      "Epoch 197/6000\n",
      "128/128 [==============================] - 25s 198ms/step - loss: 0.1319 - accuracy: 0.9504 - val_loss: 0.1704 - val_accuracy: 0.9409\n",
      "Epoch 198/6000\n",
      "128/128 [==============================] - 23s 177ms/step - loss: 0.1312 - accuracy: 0.9505 - val_loss: 0.1653 - val_accuracy: 0.9431\n",
      "Epoch 199/6000\n",
      "128/128 [==============================] - 19s 145ms/step - loss: 0.1301 - accuracy: 0.9510 - val_loss: 0.1699 - val_accuracy: 0.9410\n",
      "Epoch 200/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.1321 - accuracy: 0.9501 - val_loss: 0.1742 - val_accuracy: 0.9405\n",
      "Epoch 201/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.1307 - accuracy: 0.9508 - val_loss: 0.1682 - val_accuracy: 0.9424\n",
      "Epoch 202/6000\n",
      "128/128 [==============================] - 23s 184ms/step - loss: 0.1322 - accuracy: 0.9498 - val_loss: 0.1678 - val_accuracy: 0.9420\n",
      "Epoch 203/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.1310 - accuracy: 0.9506 - val_loss: 0.1771 - val_accuracy: 0.9389\n",
      "Epoch 204/6000\n",
      "128/128 [==============================] - 19s 147ms/step - loss: 0.1300 - accuracy: 0.9513 - val_loss: 0.1678 - val_accuracy: 0.9429\n",
      "Epoch 205/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1289 - accuracy: 0.9512 - val_loss: 0.1729 - val_accuracy: 0.9410\n",
      "Epoch 206/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1307 - accuracy: 0.9509 - val_loss: 0.1704 - val_accuracy: 0.9413\n",
      "Epoch 207/6000\n",
      "128/128 [==============================] - 25s 197ms/step - loss: 0.1300 - accuracy: 0.9506 - val_loss: 0.1596 - val_accuracy: 0.9446\n",
      "Epoch 208/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1298 - accuracy: 0.9510 - val_loss: 0.1745 - val_accuracy: 0.9399\n",
      "Epoch 209/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.1289 - accuracy: 0.9515 - val_loss: 0.1752 - val_accuracy: 0.9400\n",
      "Epoch 210/6000\n",
      "128/128 [==============================] - 22s 176ms/step - loss: 0.1277 - accuracy: 0.9519 - val_loss: 0.1740 - val_accuracy: 0.9408\n",
      "Epoch 211/6000\n",
      "128/128 [==============================] - 21s 161ms/step - loss: 0.1285 - accuracy: 0.9518 - val_loss: 0.1771 - val_accuracy: 0.9396\n",
      "Epoch 212/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1278 - accuracy: 0.9520 - val_loss: 0.1674 - val_accuracy: 0.9432\n",
      "Epoch 213/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1270 - accuracy: 0.9525 - val_loss: 0.1694 - val_accuracy: 0.9419\n",
      "Epoch 214/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.1264 - accuracy: 0.9525 - val_loss: 0.1742 - val_accuracy: 0.9412\n",
      "Epoch 215/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.1279 - accuracy: 0.9518 - val_loss: 0.1739 - val_accuracy: 0.9409\n",
      "Epoch 216/6000\n",
      "128/128 [==============================] - 18s 144ms/step - loss: 0.1279 - accuracy: 0.9519 - val_loss: 0.1655 - val_accuracy: 0.9436\n",
      "Epoch 217/6000\n",
      "128/128 [==============================] - 24s 184ms/step - loss: 0.1245 - accuracy: 0.9532 - val_loss: 0.1701 - val_accuracy: 0.9413\n",
      "Epoch 218/6000\n",
      "128/128 [==============================] - 24s 187ms/step - loss: 0.1243 - accuracy: 0.9533 - val_loss: 0.1673 - val_accuracy: 0.9430\n",
      "Epoch 219/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.1264 - accuracy: 0.9527 - val_loss: 0.1733 - val_accuracy: 0.9406\n",
      "Epoch 220/6000\n",
      "128/128 [==============================] - 25s 197ms/step - loss: 0.1255 - accuracy: 0.9530 - val_loss: 0.1695 - val_accuracy: 0.9424\n",
      "Epoch 221/6000\n",
      "128/128 [==============================] - 20s 154ms/step - loss: 0.1247 - accuracy: 0.9533 - val_loss: 0.1748 - val_accuracy: 0.9410\n",
      "Epoch 222/6000\n",
      "128/128 [==============================] - 23s 175ms/step - loss: 0.1246 - accuracy: 0.9533 - val_loss: 0.1800 - val_accuracy: 0.9395\n",
      "Epoch 222: early stopping\n",
      "##########################################################################\n",
      "------val_accuracy-----> 94.46 | 95.33 <----------accuracy----------\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/LAZIO-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/LAZIO-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "working on pair: ALICE/USDT\n",
      "One_pair_AI_Gen : ALICE/USDT\n",
      "price_volatility_15m:0.46%\n",
      "mini_expand : ALICE/USDT\n",
      "---buy_simple_up--- Buy pct: 0.5%\n",
      "---buy_only--- Max time window: 10%\n",
      "---buy_only--- no b\n",
      "---buy_only--- no sell\n",
      "df original shape (407583, 1607)\n",
      "df original shape buy mean : 12.330494647715925\n",
      "df choosen data shape(407582, 1607)\n",
      "pair: True\n",
      "81516\n",
      "normalizing ...\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/ALICE-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_116 (Dense)           (None, 250)               401750    \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 250)               0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 20)                5020      \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,871\n",
      "Trainable params: 407,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_UP_CLOSE/ALICE-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "Epoch 1/6000\n",
      "128/128 [==============================] - 27s 173ms/step - loss: 0.5973 - accuracy: 0.6745 - val_loss: 0.5680 - val_accuracy: 0.7028\n",
      "Epoch 2/6000\n",
      "128/128 [==============================] - 19s 148ms/step - loss: 0.5598 - accuracy: 0.7057 - val_loss: 0.5339 - val_accuracy: 0.7254\n",
      "Epoch 3/6000\n",
      "128/128 [==============================] - 18s 142ms/step - loss: 0.5301 - accuracy: 0.7283 - val_loss: 0.5035 - val_accuracy: 0.7497\n",
      "Epoch 4/6000\n",
      "128/128 [==============================] - 18s 144ms/step - loss: 0.5008 - accuracy: 0.7510 - val_loss: 0.4705 - val_accuracy: 0.7717\n",
      "Epoch 5/6000\n",
      "128/128 [==============================] - 18s 143ms/step - loss: 0.4743 - accuracy: 0.7680 - val_loss: 0.4451 - val_accuracy: 0.7884\n",
      "Epoch 6/6000\n",
      "128/128 [==============================] - 18s 143ms/step - loss: 0.4533 - accuracy: 0.7823 - val_loss: 0.4237 - val_accuracy: 0.8004\n",
      "Epoch 7/6000\n",
      "128/128 [==============================] - 18s 140ms/step - loss: 0.4316 - accuracy: 0.7951 - val_loss: 0.4083 - val_accuracy: 0.8139\n",
      "Epoch 8/6000\n",
      "128/128 [==============================] - 18s 141ms/step - loss: 0.4159 - accuracy: 0.8058 - val_loss: 0.3895 - val_accuracy: 0.8227\n",
      "Epoch 9/6000\n",
      "128/128 [==============================] - 19s 152ms/step - loss: 0.3999 - accuracy: 0.8151 - val_loss: 0.3716 - val_accuracy: 0.8357\n",
      "Epoch 10/6000\n",
      "128/128 [==============================] - 23s 176ms/step - loss: 0.3887 - accuracy: 0.8210 - val_loss: 0.3609 - val_accuracy: 0.8403\n",
      "Epoch 11/6000\n",
      "128/128 [==============================] - 20s 157ms/step - loss: 0.3741 - accuracy: 0.8294 - val_loss: 0.3520 - val_accuracy: 0.8423\n",
      "Epoch 12/6000\n",
      "128/128 [==============================] - 22s 169ms/step - loss: 0.3644 - accuracy: 0.8361 - val_loss: 0.3376 - val_accuracy: 0.8538\n",
      "Epoch 13/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.3555 - accuracy: 0.8403 - val_loss: 0.3313 - val_accuracy: 0.8559\n",
      "Epoch 14/6000\n",
      "128/128 [==============================] - 18s 143ms/step - loss: 0.3471 - accuracy: 0.8448 - val_loss: 0.3276 - val_accuracy: 0.8591\n",
      "Epoch 15/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.3391 - accuracy: 0.8489 - val_loss: 0.3185 - val_accuracy: 0.8615\n",
      "Epoch 16/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.3319 - accuracy: 0.8534 - val_loss: 0.3095 - val_accuracy: 0.8682\n",
      "Epoch 17/6000\n",
      "128/128 [==============================] - 18s 143ms/step - loss: 0.3243 - accuracy: 0.8563 - val_loss: 0.2979 - val_accuracy: 0.8748\n",
      "Epoch 18/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.3188 - accuracy: 0.8602 - val_loss: 0.2964 - val_accuracy: 0.8750\n",
      "Epoch 19/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.3115 - accuracy: 0.8641 - val_loss: 0.2920 - val_accuracy: 0.8767\n",
      "Epoch 20/6000\n",
      "128/128 [==============================] - 18s 140ms/step - loss: 0.3077 - accuracy: 0.8667 - val_loss: 0.2881 - val_accuracy: 0.8811\n",
      "Epoch 21/6000\n",
      "128/128 [==============================] - 24s 192ms/step - loss: 0.3021 - accuracy: 0.8690 - val_loss: 0.2828 - val_accuracy: 0.8823\n",
      "Epoch 22/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.2964 - accuracy: 0.8714 - val_loss: 0.2750 - val_accuracy: 0.8870\n",
      "Epoch 23/6000\n",
      "128/128 [==============================] - 19s 150ms/step - loss: 0.2932 - accuracy: 0.8734 - val_loss: 0.2707 - val_accuracy: 0.8874\n",
      "Epoch 24/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.2871 - accuracy: 0.8762 - val_loss: 0.2668 - val_accuracy: 0.8907\n",
      "Epoch 25/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.2834 - accuracy: 0.8787 - val_loss: 0.2675 - val_accuracy: 0.8889\n",
      "Epoch 26/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.2796 - accuracy: 0.8804 - val_loss: 0.2652 - val_accuracy: 0.8902\n",
      "Epoch 27/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.2755 - accuracy: 0.8827 - val_loss: 0.2599 - val_accuracy: 0.8928\n",
      "Epoch 28/6000\n",
      "128/128 [==============================] - 20s 157ms/step - loss: 0.2716 - accuracy: 0.8844 - val_loss: 0.2551 - val_accuracy: 0.8964\n",
      "Epoch 29/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.2684 - accuracy: 0.8860 - val_loss: 0.2564 - val_accuracy: 0.8940\n",
      "Epoch 30/6000\n",
      "128/128 [==============================] - 21s 162ms/step - loss: 0.2649 - accuracy: 0.8879 - val_loss: 0.2489 - val_accuracy: 0.8981\n",
      "Epoch 31/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.2627 - accuracy: 0.8897 - val_loss: 0.2459 - val_accuracy: 0.9000\n",
      "Epoch 32/6000\n",
      "128/128 [==============================] - 23s 184ms/step - loss: 0.2591 - accuracy: 0.8900 - val_loss: 0.2448 - val_accuracy: 0.9025\n",
      "Epoch 33/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.2555 - accuracy: 0.8925 - val_loss: 0.2411 - val_accuracy: 0.9023\n",
      "Epoch 34/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.2517 - accuracy: 0.8940 - val_loss: 0.2386 - val_accuracy: 0.9048\n",
      "Epoch 35/6000\n",
      "128/128 [==============================] - 24s 184ms/step - loss: 0.2503 - accuracy: 0.8957 - val_loss: 0.2321 - val_accuracy: 0.9097\n",
      "Epoch 36/6000\n",
      "128/128 [==============================] - 20s 160ms/step - loss: 0.2466 - accuracy: 0.8969 - val_loss: 0.2344 - val_accuracy: 0.9076\n",
      "Epoch 37/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.2425 - accuracy: 0.8990 - val_loss: 0.2295 - val_accuracy: 0.9091\n",
      "Epoch 38/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.2402 - accuracy: 0.9003 - val_loss: 0.2338 - val_accuracy: 0.9078\n",
      "Epoch 39/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.2402 - accuracy: 0.9001 - val_loss: 0.2287 - val_accuracy: 0.9093\n",
      "Epoch 40/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.2374 - accuracy: 0.9014 - val_loss: 0.2309 - val_accuracy: 0.9087\n",
      "Epoch 41/6000\n",
      "128/128 [==============================] - 24s 192ms/step - loss: 0.2359 - accuracy: 0.9024 - val_loss: 0.2232 - val_accuracy: 0.9129\n",
      "Epoch 42/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.2321 - accuracy: 0.9045 - val_loss: 0.2255 - val_accuracy: 0.9112\n",
      "Epoch 43/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.2298 - accuracy: 0.9056 - val_loss: 0.2202 - val_accuracy: 0.9138\n",
      "Epoch 44/6000\n",
      "128/128 [==============================] - 18s 143ms/step - loss: 0.2281 - accuracy: 0.9062 - val_loss: 0.2199 - val_accuracy: 0.9128\n",
      "Epoch 45/6000\n",
      "128/128 [==============================] - 26s 199ms/step - loss: 0.2270 - accuracy: 0.9065 - val_loss: 0.2172 - val_accuracy: 0.9148\n",
      "Epoch 46/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.2243 - accuracy: 0.9075 - val_loss: 0.2180 - val_accuracy: 0.9145\n",
      "Epoch 47/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.2227 - accuracy: 0.9090 - val_loss: 0.2162 - val_accuracy: 0.9165\n",
      "Epoch 48/6000\n",
      "128/128 [==============================] - 22s 174ms/step - loss: 0.2201 - accuracy: 0.9104 - val_loss: 0.2116 - val_accuracy: 0.9190\n",
      "Epoch 49/6000\n",
      "128/128 [==============================] - 21s 162ms/step - loss: 0.2193 - accuracy: 0.9102 - val_loss: 0.2133 - val_accuracy: 0.9168\n",
      "Epoch 50/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.2171 - accuracy: 0.9115 - val_loss: 0.2099 - val_accuracy: 0.9181\n",
      "Epoch 51/6000\n",
      "128/128 [==============================] - 23s 179ms/step - loss: 0.2138 - accuracy: 0.9129 - val_loss: 0.2127 - val_accuracy: 0.9173\n",
      "Epoch 52/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.2126 - accuracy: 0.9131 - val_loss: 0.2117 - val_accuracy: 0.9191\n",
      "Epoch 53/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.2110 - accuracy: 0.9136 - val_loss: 0.2087 - val_accuracy: 0.9194\n",
      "Epoch 54/6000\n",
      "128/128 [==============================] - 24s 185ms/step - loss: 0.2093 - accuracy: 0.9148 - val_loss: 0.2033 - val_accuracy: 0.9215\n",
      "Epoch 55/6000\n",
      "128/128 [==============================] - 19s 145ms/step - loss: 0.2085 - accuracy: 0.9145 - val_loss: 0.2092 - val_accuracy: 0.9194\n",
      "Epoch 56/6000\n",
      "128/128 [==============================] - 25s 192ms/step - loss: 0.2069 - accuracy: 0.9161 - val_loss: 0.2015 - val_accuracy: 0.9227\n",
      "Epoch 57/6000\n",
      "128/128 [==============================] - 23s 180ms/step - loss: 0.2034 - accuracy: 0.9181 - val_loss: 0.2026 - val_accuracy: 0.9223\n",
      "Epoch 58/6000\n",
      "128/128 [==============================] - 24s 192ms/step - loss: 0.2034 - accuracy: 0.9173 - val_loss: 0.1996 - val_accuracy: 0.9241\n",
      "Epoch 59/6000\n",
      "128/128 [==============================] - 24s 184ms/step - loss: 0.2032 - accuracy: 0.9180 - val_loss: 0.1990 - val_accuracy: 0.9251\n",
      "Epoch 60/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.2006 - accuracy: 0.9192 - val_loss: 0.1961 - val_accuracy: 0.9262\n",
      "Epoch 61/6000\n",
      "128/128 [==============================] - 18s 143ms/step - loss: 0.1991 - accuracy: 0.9197 - val_loss: 0.1978 - val_accuracy: 0.9261\n",
      "Epoch 62/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.1976 - accuracy: 0.9205 - val_loss: 0.1994 - val_accuracy: 0.9257\n",
      "Epoch 63/6000\n",
      "128/128 [==============================] - 24s 184ms/step - loss: 0.1952 - accuracy: 0.9214 - val_loss: 0.1971 - val_accuracy: 0.9264\n",
      "Epoch 64/6000\n",
      "128/128 [==============================] - 25s 194ms/step - loss: 0.1944 - accuracy: 0.9216 - val_loss: 0.1931 - val_accuracy: 0.9276\n",
      "Epoch 65/6000\n",
      "128/128 [==============================] - 22s 170ms/step - loss: 0.1939 - accuracy: 0.9221 - val_loss: 0.1958 - val_accuracy: 0.9258\n",
      "Epoch 66/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1920 - accuracy: 0.9228 - val_loss: 0.1911 - val_accuracy: 0.9302\n",
      "Epoch 67/6000\n",
      "128/128 [==============================] - 23s 175ms/step - loss: 0.1888 - accuracy: 0.9243 - val_loss: 0.1952 - val_accuracy: 0.9261\n",
      "Epoch 68/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1896 - accuracy: 0.9246 - val_loss: 0.1896 - val_accuracy: 0.9289\n",
      "Epoch 69/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.1879 - accuracy: 0.9251 - val_loss: 0.1861 - val_accuracy: 0.9314\n",
      "Epoch 70/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1855 - accuracy: 0.9257 - val_loss: 0.1887 - val_accuracy: 0.9300\n",
      "Epoch 71/6000\n",
      "128/128 [==============================] - 25s 198ms/step - loss: 0.1863 - accuracy: 0.9257 - val_loss: 0.1908 - val_accuracy: 0.9296\n",
      "Epoch 72/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1851 - accuracy: 0.9260 - val_loss: 0.1956 - val_accuracy: 0.9276\n",
      "Epoch 73/6000\n",
      "128/128 [==============================] - 18s 140ms/step - loss: 0.1841 - accuracy: 0.9265 - val_loss: 0.1858 - val_accuracy: 0.9313\n",
      "Epoch 74/6000\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 0.1839 - accuracy: 0.9267 - val_loss: 0.1836 - val_accuracy: 0.9327\n",
      "Epoch 75/6000\n",
      "128/128 [==============================] - 23s 175ms/step - loss: 0.1789 - accuracy: 0.9293 - val_loss: 0.1846 - val_accuracy: 0.9319\n",
      "Epoch 76/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1797 - accuracy: 0.9287 - val_loss: 0.1840 - val_accuracy: 0.9314\n",
      "Epoch 77/6000\n",
      "128/128 [==============================] - 23s 181ms/step - loss: 0.1787 - accuracy: 0.9287 - val_loss: 0.1794 - val_accuracy: 0.9341\n",
      "Epoch 78/6000\n",
      "128/128 [==============================] - 25s 197ms/step - loss: 0.1770 - accuracy: 0.9303 - val_loss: 0.1802 - val_accuracy: 0.9338\n",
      "Epoch 79/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1760 - accuracy: 0.9304 - val_loss: 0.1908 - val_accuracy: 0.9300\n",
      "Epoch 80/6000\n",
      "128/128 [==============================] - 22s 171ms/step - loss: 0.1763 - accuracy: 0.9298 - val_loss: 0.1768 - val_accuracy: 0.9357\n",
      "Epoch 81/6000\n",
      "128/128 [==============================] - 21s 165ms/step - loss: 0.1730 - accuracy: 0.9317 - val_loss: 0.1786 - val_accuracy: 0.9354\n",
      "Epoch 82/6000\n",
      "128/128 [==============================] - 25s 196ms/step - loss: 0.1734 - accuracy: 0.9312 - val_loss: 0.1837 - val_accuracy: 0.9326\n",
      "Epoch 83/6000\n",
      "128/128 [==============================] - 22s 168ms/step - loss: 0.1718 - accuracy: 0.9319 - val_loss: 0.1826 - val_accuracy: 0.9340\n",
      "Epoch 84/6000\n",
      "128/128 [==============================] - 24s 190ms/step - loss: 0.1692 - accuracy: 0.9332 - val_loss: 0.1790 - val_accuracy: 0.9339\n",
      "Epoch 85/6000\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 0.1708 - accuracy: 0.9325 - val_loss: 0.1764 - val_accuracy: 0.9368\n",
      "Epoch 86/6000\n",
      "128/128 [==============================] - 23s 183ms/step - loss: 0.1698 - accuracy: 0.9331 - val_loss: 0.1791 - val_accuracy: 0.9351\n",
      "Epoch 87/6000\n",
      "128/128 [==============================] - 25s 197ms/step - loss: 0.1692 - accuracy: 0.9331 - val_loss: 0.1777 - val_accuracy: 0.9362\n",
      "Epoch 88/6000\n",
      "128/128 [==============================] - 30s 233ms/step - loss: 0.1682 - accuracy: 0.9338 - val_loss: 0.1713 - val_accuracy: 0.9371\n",
      "Epoch 89/6000\n",
      "128/128 [==============================] - 38s 297ms/step - loss: 0.1651 - accuracy: 0.9351 - val_loss: 0.1737 - val_accuracy: 0.9375\n",
      "Epoch 90/6000\n",
      "128/128 [==============================] - 35s 272ms/step - loss: 0.1666 - accuracy: 0.9340 - val_loss: 0.1753 - val_accuracy: 0.9369\n",
      "Epoch 91/6000\n",
      "128/128 [==============================] - 27s 211ms/step - loss: 0.1629 - accuracy: 0.9358 - val_loss: 0.1700 - val_accuracy: 0.9392\n",
      "Epoch 92/6000\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 0.1614 - accuracy: 0.9369 - val_loss: 0.1699 - val_accuracy: 0.9395\n",
      "Epoch 93/6000\n",
      "128/128 [==============================] - 28s 220ms/step - loss: 0.1614 - accuracy: 0.9369 - val_loss: 0.1728 - val_accuracy: 0.9373\n",
      "Epoch 94/6000\n",
      "128/128 [==============================] - 21s 167ms/step - loss: 0.1614 - accuracy: 0.9364 - val_loss: 0.1747 - val_accuracy: 0.9369\n",
      "Epoch 95/6000\n",
      "128/128 [==============================] - 28s 217ms/step - loss: 0.1626 - accuracy: 0.9360 - val_loss: 0.1709 - val_accuracy: 0.9383\n",
      "Epoch 96/6000\n",
      "128/128 [==============================] - 31s 245ms/step - loss: 0.1585 - accuracy: 0.9378 - val_loss: 0.1700 - val_accuracy: 0.9390\n",
      "Epoch 97/6000\n",
      "128/128 [==============================] - 26s 198ms/step - loss: 0.1592 - accuracy: 0.9374 - val_loss: 0.1695 - val_accuracy: 0.9404\n",
      "Epoch 98/6000\n",
      "128/128 [==============================] - 27s 214ms/step - loss: 0.1601 - accuracy: 0.9373 - val_loss: 0.1667 - val_accuracy: 0.9400\n",
      "Epoch 99/6000\n",
      "128/128 [==============================] - 24s 189ms/step - loss: 0.1571 - accuracy: 0.9383 - val_loss: 0.1695 - val_accuracy: 0.9392\n",
      "Epoch 100/6000\n",
      "128/128 [==============================] - 28s 216ms/step - loss: 0.1568 - accuracy: 0.9387 - val_loss: 0.1708 - val_accuracy: 0.9400\n",
      "Epoch 101/6000\n",
      "128/128 [==============================] - 27s 211ms/step - loss: 0.1553 - accuracy: 0.9394 - val_loss: 0.1719 - val_accuracy: 0.9389\n",
      "Epoch 102/6000\n",
      "128/128 [==============================] - 27s 212ms/step - loss: 0.1547 - accuracy: 0.9394 - val_loss: 0.1713 - val_accuracy: 0.9397\n",
      "Epoch 103/6000\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 0.1543 - accuracy: 0.9396 - val_loss: 0.1703 - val_accuracy: 0.9399\n",
      "Epoch 104/6000\n",
      "128/128 [==============================] - 27s 211ms/step - loss: 0.1538 - accuracy: 0.9403 - val_loss: 0.1639 - val_accuracy: 0.9421\n",
      "Epoch 105/6000\n",
      "128/128 [==============================] - 27s 208ms/step - loss: 0.1522 - accuracy: 0.9404 - val_loss: 0.1653 - val_accuracy: 0.9418\n",
      "Epoch 106/6000\n",
      "128/128 [==============================] - 27s 211ms/step - loss: 0.1516 - accuracy: 0.9410 - val_loss: 0.1651 - val_accuracy: 0.9419\n",
      "Epoch 107/6000\n",
      "128/128 [==============================] - 28s 217ms/step - loss: 0.1505 - accuracy: 0.9415 - val_loss: 0.1672 - val_accuracy: 0.9411\n",
      "Epoch 108/6000\n",
      "128/128 [==============================] - 26s 202ms/step - loss: 0.1525 - accuracy: 0.9403 - val_loss: 0.1730 - val_accuracy: 0.9394\n",
      "Epoch 109/6000\n",
      "128/128 [==============================] - 22s 169ms/step - loss: 0.1497 - accuracy: 0.9414 - val_loss: 0.1622 - val_accuracy: 0.9433\n",
      "Epoch 110/6000\n",
      "128/128 [==============================] - 28s 215ms/step - loss: 0.1485 - accuracy: 0.9425 - val_loss: 0.1689 - val_accuracy: 0.9416\n",
      "Epoch 111/6000\n",
      "128/128 [==============================] - 27s 207ms/step - loss: 0.1502 - accuracy: 0.9414 - val_loss: 0.1647 - val_accuracy: 0.9416\n",
      "Epoch 112/6000\n",
      "128/128 [==============================] - 26s 202ms/step - loss: 0.1475 - accuracy: 0.9430 - val_loss: 0.1695 - val_accuracy: 0.9411\n",
      "Epoch 113/6000\n",
      "128/128 [==============================] - 28s 220ms/step - loss: 0.1451 - accuracy: 0.9441 - val_loss: 0.1682 - val_accuracy: 0.9408\n",
      "Epoch 114/6000\n",
      "128/128 [==============================] - 29s 222ms/step - loss: 0.1471 - accuracy: 0.9432 - val_loss: 0.1709 - val_accuracy: 0.9414\n",
      "Epoch 115/6000\n",
      "128/128 [==============================] - 26s 201ms/step - loss: 0.1458 - accuracy: 0.9436 - val_loss: 0.1616 - val_accuracy: 0.9438\n",
      "Epoch 116/6000\n",
      "128/128 [==============================] - 25s 190ms/step - loss: 0.1448 - accuracy: 0.9440 - val_loss: 0.1655 - val_accuracy: 0.9420\n",
      "Epoch 117/6000\n",
      "128/128 [==============================] - 27s 207ms/step - loss: 0.1439 - accuracy: 0.9441 - val_loss: 0.1639 - val_accuracy: 0.9425\n",
      "Epoch 118/6000\n",
      "128/128 [==============================] - 27s 215ms/step - loss: 0.1426 - accuracy: 0.9448 - val_loss: 0.1604 - val_accuracy: 0.9451\n",
      "Epoch 119/6000\n",
      "128/128 [==============================] - 29s 224ms/step - loss: 0.1422 - accuracy: 0.9445 - val_loss: 0.1598 - val_accuracy: 0.9449\n",
      "Epoch 120/6000\n",
      "128/128 [==============================] - 28s 218ms/step - loss: 0.1414 - accuracy: 0.9454 - val_loss: 0.1639 - val_accuracy: 0.9447\n",
      "Epoch 121/6000\n",
      "128/128 [==============================] - 21s 166ms/step - loss: 0.1417 - accuracy: 0.9457 - val_loss: 0.1644 - val_accuracy: 0.9431\n",
      "Epoch 122/6000\n",
      "128/128 [==============================] - 28s 217ms/step - loss: 0.1425 - accuracy: 0.9449 - val_loss: 0.1611 - val_accuracy: 0.9450\n",
      "Epoch 123/6000\n",
      "128/128 [==============================] - 27s 212ms/step - loss: 0.1380 - accuracy: 0.9471 - val_loss: 0.1600 - val_accuracy: 0.9453\n",
      "Epoch 124/6000\n",
      "128/128 [==============================] - 27s 212ms/step - loss: 0.1398 - accuracy: 0.9459 - val_loss: 0.1555 - val_accuracy: 0.9470\n",
      "Epoch 125/6000\n",
      "128/128 [==============================] - 26s 204ms/step - loss: 0.1380 - accuracy: 0.9469 - val_loss: 0.1606 - val_accuracy: 0.9453\n",
      "Epoch 126/6000\n",
      "128/128 [==============================] - 27s 208ms/step - loss: 0.1395 - accuracy: 0.9461 - val_loss: 0.1644 - val_accuracy: 0.9434\n",
      "Epoch 127/6000\n",
      "128/128 [==============================] - 26s 204ms/step - loss: 0.1384 - accuracy: 0.9466 - val_loss: 0.1594 - val_accuracy: 0.9457\n",
      "Epoch 128/6000\n",
      "128/128 [==============================] - 27s 209ms/step - loss: 0.1376 - accuracy: 0.9468 - val_loss: 0.1584 - val_accuracy: 0.9449\n",
      "Epoch 129/6000\n",
      "128/128 [==============================] - 26s 204ms/step - loss: 0.1360 - accuracy: 0.9477 - val_loss: 0.1573 - val_accuracy: 0.9459\n",
      "Epoch 130/6000\n",
      "128/128 [==============================] - 27s 212ms/step - loss: 0.1353 - accuracy: 0.9479 - val_loss: 0.1660 - val_accuracy: 0.9438\n",
      "Epoch 131/6000\n",
      "128/128 [==============================] - 26s 199ms/step - loss: 0.1338 - accuracy: 0.9484 - val_loss: 0.1587 - val_accuracy: 0.9465\n",
      "Epoch 132/6000\n",
      "128/128 [==============================] - 28s 217ms/step - loss: 0.1341 - accuracy: 0.9488 - val_loss: 0.1655 - val_accuracy: 0.9447\n",
      "Epoch 133/6000\n",
      "128/128 [==============================] - 28s 216ms/step - loss: 0.1337 - accuracy: 0.9488 - val_loss: 0.1539 - val_accuracy: 0.9479\n",
      "Epoch 134/6000\n",
      "128/128 [==============================] - 26s 204ms/step - loss: 0.1373 - accuracy: 0.9475 - val_loss: 0.1616 - val_accuracy: 0.9447\n",
      "Epoch 135/6000\n",
      "128/128 [==============================] - 26s 200ms/step - loss: 0.1339 - accuracy: 0.9486 - val_loss: 0.1637 - val_accuracy: 0.9437\n",
      "Epoch 136/6000\n",
      "128/128 [==============================] - 26s 204ms/step - loss: 0.1335 - accuracy: 0.9486 - val_loss: 0.1575 - val_accuracy: 0.9470\n",
      "Epoch 137/6000\n",
      "128/128 [==============================] - 27s 208ms/step - loss: 0.1315 - accuracy: 0.9503 - val_loss: 0.1593 - val_accuracy: 0.9461\n",
      "Epoch 138/6000\n",
      "128/128 [==============================] - 28s 220ms/step - loss: 0.1318 - accuracy: 0.9493 - val_loss: 0.1659 - val_accuracy: 0.9446\n",
      "Epoch 139/6000\n",
      "128/128 [==============================] - 26s 203ms/step - loss: 0.1310 - accuracy: 0.9499 - val_loss: 0.1530 - val_accuracy: 0.9483\n",
      "Epoch 140/6000\n",
      "128/128 [==============================] - 28s 217ms/step - loss: 0.1304 - accuracy: 0.9502 - val_loss: 0.1531 - val_accuracy: 0.9480\n",
      "Epoch 141/6000\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 0.1298 - accuracy: 0.9497 - val_loss: 0.1531 - val_accuracy: 0.9487\n",
      "Epoch 142/6000\n",
      "128/128 [==============================] - 25s 192ms/step - loss: 0.1302 - accuracy: 0.9505 - val_loss: 0.1514 - val_accuracy: 0.9492\n",
      "Epoch 143/6000\n",
      "128/128 [==============================] - 28s 217ms/step - loss: 0.1272 - accuracy: 0.9517 - val_loss: 0.1536 - val_accuracy: 0.9487\n",
      "Epoch 144/6000\n",
      "128/128 [==============================] - 25s 191ms/step - loss: 0.1270 - accuracy: 0.9514 - val_loss: 0.1511 - val_accuracy: 0.9501\n",
      "Epoch 145/6000\n",
      "128/128 [==============================] - 27s 214ms/step - loss: 0.1284 - accuracy: 0.9507 - val_loss: 0.1538 - val_accuracy: 0.9491\n",
      "Epoch 146/6000\n",
      "128/128 [==============================] - 25s 192ms/step - loss: 0.1271 - accuracy: 0.9515 - val_loss: 0.1647 - val_accuracy: 0.9453\n",
      "Epoch 147/6000\n",
      "128/128 [==============================] - 27s 210ms/step - loss: 0.1279 - accuracy: 0.9508 - val_loss: 0.1566 - val_accuracy: 0.9470\n",
      "Epoch 148/6000\n",
      "128/128 [==============================] - 27s 209ms/step - loss: 0.1267 - accuracy: 0.9518 - val_loss: 0.1547 - val_accuracy: 0.9470\n",
      "Epoch 149/6000\n",
      "128/128 [==============================] - 27s 212ms/step - loss: 0.1253 - accuracy: 0.9522 - val_loss: 0.1561 - val_accuracy: 0.9472\n",
      "Epoch 150/6000\n",
      "128/128 [==============================] - 28s 217ms/step - loss: 0.1247 - accuracy: 0.9526 - val_loss: 0.1573 - val_accuracy: 0.9453\n",
      "Epoch 151/6000\n",
      "128/128 [==============================] - 28s 220ms/step - loss: 0.1252 - accuracy: 0.9520 - val_loss: 0.1558 - val_accuracy: 0.9484\n",
      "Epoch 152/6000\n",
      "128/128 [==============================] - 28s 217ms/step - loss: 0.1237 - accuracy: 0.9529 - val_loss: 0.1569 - val_accuracy: 0.9485\n",
      "Epoch 153/6000\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 0.1248 - accuracy: 0.9526 - val_loss: 0.1496 - val_accuracy: 0.9506\n",
      "Epoch 154/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.1226 - accuracy: 0.9532 - val_loss: 0.1513 - val_accuracy: 0.9504\n",
      "Epoch 155/6000\n",
      "128/128 [==============================] - 29s 230ms/step - loss: 0.1217 - accuracy: 0.9534 - val_loss: 0.1475 - val_accuracy: 0.9515\n",
      "Epoch 156/6000\n",
      "128/128 [==============================] - 23s 178ms/step - loss: 0.1213 - accuracy: 0.9540 - val_loss: 0.1515 - val_accuracy: 0.9497\n",
      "Epoch 157/6000\n",
      "128/128 [==============================] - 26s 198ms/step - loss: 0.1226 - accuracy: 0.9538 - val_loss: 0.1507 - val_accuracy: 0.9503\n",
      "Epoch 158/6000\n",
      "128/128 [==============================] - 27s 209ms/step - loss: 0.1207 - accuracy: 0.9535 - val_loss: 0.1559 - val_accuracy: 0.9487\n",
      "Epoch 159/6000\n",
      "128/128 [==============================] - 27s 210ms/step - loss: 0.1236 - accuracy: 0.9526 - val_loss: 0.1520 - val_accuracy: 0.9507\n",
      "Epoch 160/6000\n",
      "128/128 [==============================] - 28s 217ms/step - loss: 0.1206 - accuracy: 0.9538 - val_loss: 0.1503 - val_accuracy: 0.9506\n",
      "Epoch 161/6000\n",
      "128/128 [==============================] - 27s 210ms/step - loss: 0.1219 - accuracy: 0.9538 - val_loss: 0.1525 - val_accuracy: 0.9507\n",
      "Epoch 162/6000\n",
      "128/128 [==============================] - 28s 217ms/step - loss: 0.1189 - accuracy: 0.9550 - val_loss: 0.1513 - val_accuracy: 0.9509\n",
      "Epoch 163/6000\n",
      "128/128 [==============================] - 27s 210ms/step - loss: 0.1193 - accuracy: 0.9547 - val_loss: 0.1500 - val_accuracy: 0.9512\n",
      "Epoch 164/6000\n",
      "128/128 [==============================] - 27s 213ms/step - loss: 0.1186 - accuracy: 0.9549 - val_loss: 0.1514 - val_accuracy: 0.9508\n",
      "Epoch 165/6000\n",
      "128/128 [==============================] - 28s 218ms/step - loss: 0.1187 - accuracy: 0.9548 - val_loss: 0.1454 - val_accuracy: 0.9522\n",
      "Epoch 166/6000\n",
      "128/128 [==============================] - 26s 204ms/step - loss: 0.1159 - accuracy: 0.9557 - val_loss: 0.1490 - val_accuracy: 0.9516\n",
      "Epoch 167/6000\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 0.1181 - accuracy: 0.9549 - val_loss: 0.1464 - val_accuracy: 0.9523\n",
      "Epoch 168/6000\n",
      "128/128 [==============================] - 26s 204ms/step - loss: 0.1163 - accuracy: 0.9562 - val_loss: 0.1572 - val_accuracy: 0.9495\n",
      "Epoch 169/6000\n",
      "128/128 [==============================] - 28s 216ms/step - loss: 0.1161 - accuracy: 0.9561 - val_loss: 0.1504 - val_accuracy: 0.9501\n",
      "Epoch 170/6000\n",
      "128/128 [==============================] - 23s 182ms/step - loss: 0.1159 - accuracy: 0.9564 - val_loss: 0.1540 - val_accuracy: 0.9497\n",
      "Epoch 171/6000\n",
      "128/128 [==============================] - 27s 209ms/step - loss: 0.1154 - accuracy: 0.9563 - val_loss: 0.1549 - val_accuracy: 0.9494\n",
      "Epoch 172/6000\n",
      "128/128 [==============================] - 24s 188ms/step - loss: 0.1147 - accuracy: 0.9566 - val_loss: 0.1462 - val_accuracy: 0.9525\n",
      "Epoch 173/6000\n",
      "128/128 [==============================] - 27s 208ms/step - loss: 0.1143 - accuracy: 0.9565 - val_loss: 0.1502 - val_accuracy: 0.9511\n",
      "Epoch 174/6000\n",
      "128/128 [==============================] - 27s 213ms/step - loss: 0.1142 - accuracy: 0.9564 - val_loss: 0.1442 - val_accuracy: 0.9535\n",
      "Epoch 175/6000\n",
      "128/128 [==============================] - 25s 192ms/step - loss: 0.1147 - accuracy: 0.9565 - val_loss: 0.1463 - val_accuracy: 0.9538\n",
      "Epoch 176/6000\n",
      "128/128 [==============================] - 27s 214ms/step - loss: 0.1139 - accuracy: 0.9571 - val_loss: 0.1520 - val_accuracy: 0.9497\n",
      "Epoch 177/6000\n",
      "128/128 [==============================] - 27s 212ms/step - loss: 0.1128 - accuracy: 0.9575 - val_loss: 0.1535 - val_accuracy: 0.9507\n",
      "Epoch 178/6000\n",
      "128/128 [==============================] - 26s 205ms/step - loss: 0.1132 - accuracy: 0.9573 - val_loss: 0.1478 - val_accuracy: 0.9511\n",
      "Epoch 179/6000\n",
      "128/128 [==============================] - 27s 212ms/step - loss: 0.1131 - accuracy: 0.9571 - val_loss: 0.1480 - val_accuracy: 0.9520\n",
      "Epoch 180/6000\n",
      "128/128 [==============================] - 25s 195ms/step - loss: 0.1135 - accuracy: 0.9573 - val_loss: 0.1465 - val_accuracy: 0.9534\n",
      "Epoch 181/6000\n",
      "128/128 [==============================] - 27s 211ms/step - loss: 0.1139 - accuracy: 0.9574 - val_loss: 0.1512 - val_accuracy: 0.9509\n",
      "Epoch 182/6000\n",
      "128/128 [==============================] - 28s 215ms/step - loss: 0.1121 - accuracy: 0.9577 - val_loss: 0.1462 - val_accuracy: 0.9538\n",
      "Epoch 183/6000\n",
      "128/128 [==============================] - 25s 193ms/step - loss: 0.1094 - accuracy: 0.9590 - val_loss: 0.1478 - val_accuracy: 0.9527\n",
      "Epoch 184/6000\n",
      "128/128 [==============================] - 28s 214ms/step - loss: 0.1096 - accuracy: 0.9588 - val_loss: 0.1415 - val_accuracy: 0.9550\n",
      "Epoch 185/6000\n",
      "128/128 [==============================] - 36s 278ms/step - loss: 0.1106 - accuracy: 0.9581 - val_loss: 0.1473 - val_accuracy: 0.9529\n",
      "Epoch 186/6000\n",
      "128/128 [==============================] - 38s 293ms/step - loss: 0.1102 - accuracy: 0.9588 - val_loss: 0.1453 - val_accuracy: 0.9537\n",
      "Epoch 187/6000\n",
      "128/128 [==============================] - 27s 211ms/step - loss: 0.1090 - accuracy: 0.9589 - val_loss: 0.1554 - val_accuracy: 0.9511\n",
      "Epoch 188/6000\n",
      "128/128 [==============================] - 27s 212ms/step - loss: 0.1113 - accuracy: 0.9575 - val_loss: 0.1478 - val_accuracy: 0.9532\n",
      "Epoch 189/6000\n",
      "128/128 [==============================] - 28s 219ms/step - loss: 0.1107 - accuracy: 0.9583 - val_loss: 0.1449 - val_accuracy: 0.9540\n",
      "Epoch 190/6000\n",
      "128/128 [==============================] - 27s 210ms/step - loss: 0.1100 - accuracy: 0.9583 - val_loss: 0.1525 - val_accuracy: 0.9518\n",
      "Epoch 191/6000\n",
      "128/128 [==============================] - 27s 212ms/step - loss: 0.1086 - accuracy: 0.9592 - val_loss: 0.1488 - val_accuracy: 0.9531\n",
      "Epoch 192/6000\n",
      "128/128 [==============================] - 27s 211ms/step - loss: 0.1079 - accuracy: 0.9597 - val_loss: 0.1421 - val_accuracy: 0.9538\n",
      "Epoch 193/6000\n",
      "128/128 [==============================] - 21s 163ms/step - loss: 0.1074 - accuracy: 0.9595 - val_loss: 0.1449 - val_accuracy: 0.9548\n",
      "Epoch 194/6000\n",
      "128/128 [==============================] - 30s 230ms/step - loss: 0.1073 - accuracy: 0.9595 - val_loss: 0.1473 - val_accuracy: 0.9530\n",
      "Epoch 195/6000\n",
      "128/128 [==============================] - 26s 201ms/step - loss: 0.1066 - accuracy: 0.9601 - val_loss: 0.1440 - val_accuracy: 0.9549\n",
      "Epoch 196/6000\n",
      "128/128 [==============================] - 27s 209ms/step - loss: 0.1060 - accuracy: 0.9604 - val_loss: 0.1480 - val_accuracy: 0.9528\n",
      "Epoch 197/6000\n",
      "128/128 [==============================] - 27s 213ms/step - loss: 0.1059 - accuracy: 0.9601 - val_loss: 0.1396 - val_accuracy: 0.9560\n",
      "Epoch 198/6000\n",
      "128/128 [==============================] - 27s 213ms/step - loss: 0.1051 - accuracy: 0.9606 - val_loss: 0.1419 - val_accuracy: 0.9546\n",
      "Epoch 199/6000\n",
      "128/128 [==============================] - 26s 205ms/step - loss: 0.1062 - accuracy: 0.9601 - val_loss: 0.1563 - val_accuracy: 0.9520\n",
      "Epoch 200/6000\n",
      "128/128 [==============================] - 28s 218ms/step - loss: 0.1050 - accuracy: 0.9606 - val_loss: 0.1382 - val_accuracy: 0.9565\n",
      "Epoch 201/6000\n",
      "128/128 [==============================] - 26s 203ms/step - loss: 0.1055 - accuracy: 0.9605 - val_loss: 0.1506 - val_accuracy: 0.9523\n",
      "Epoch 202/6000\n",
      "128/128 [==============================] - 26s 203ms/step - loss: 0.1053 - accuracy: 0.9606 - val_loss: 0.1375 - val_accuracy: 0.9562\n",
      "Epoch 203/6000\n",
      "128/128 [==============================] - 28s 221ms/step - loss: 0.1040 - accuracy: 0.9611 - val_loss: 0.1421 - val_accuracy: 0.9551\n",
      "Epoch 204/6000\n",
      "128/128 [==============================] - 31s 243ms/step - loss: 0.1050 - accuracy: 0.9608 - val_loss: 0.1440 - val_accuracy: 0.9548\n",
      "Epoch 205/6000\n",
      "128/128 [==============================] - 41s 321ms/step - loss: 0.1034 - accuracy: 0.9613 - val_loss: 0.1403 - val_accuracy: 0.9564\n",
      "Epoch 206/6000\n",
      "128/128 [==============================] - 46s 363ms/step - loss: 0.1039 - accuracy: 0.9611 - val_loss: 0.1440 - val_accuracy: 0.9547\n",
      "Epoch 207/6000\n",
      "128/128 [==============================] - 47s 367ms/step - loss: 0.1038 - accuracy: 0.9609 - val_loss: 0.1447 - val_accuracy: 0.9534\n",
      "Epoch 208/6000\n",
      "128/128 [==============================] - 43s 336ms/step - loss: 0.1036 - accuracy: 0.9614 - val_loss: 0.1405 - val_accuracy: 0.9559\n",
      "Epoch 209/6000\n",
      "128/128 [==============================] - 52s 409ms/step - loss: 0.1030 - accuracy: 0.9618 - val_loss: 0.1405 - val_accuracy: 0.9560\n",
      "Epoch 210/6000\n",
      "128/128 [==============================] - 42s 326ms/step - loss: 0.1015 - accuracy: 0.9620 - val_loss: 0.1459 - val_accuracy: 0.9532\n",
      "Epoch 211/6000\n",
      "128/128 [==============================] - 53s 417ms/step - loss: 0.1026 - accuracy: 0.9615 - val_loss: 0.1440 - val_accuracy: 0.9545\n",
      "Epoch 212/6000\n",
      "128/128 [==============================] - 49s 381ms/step - loss: 0.1018 - accuracy: 0.9617 - val_loss: 0.1361 - val_accuracy: 0.9574\n",
      "Epoch 213/6000\n",
      "128/128 [==============================] - 45s 350ms/step - loss: 0.1031 - accuracy: 0.9615 - val_loss: 0.1431 - val_accuracy: 0.9551\n",
      "Epoch 214/6000\n",
      "128/128 [==============================] - 53s 415ms/step - loss: 0.1027 - accuracy: 0.9616 - val_loss: 0.1411 - val_accuracy: 0.9554\n",
      "Epoch 215/6000\n",
      "128/128 [==============================] - 43s 335ms/step - loss: 0.1013 - accuracy: 0.9620 - val_loss: 0.1515 - val_accuracy: 0.9528\n",
      "Epoch 216/6000\n",
      "128/128 [==============================] - 52s 408ms/step - loss: 0.1018 - accuracy: 0.9620 - val_loss: 0.1359 - val_accuracy: 0.9574\n",
      "Epoch 217/6000\n",
      "128/128 [==============================] - 38s 299ms/step - loss: 0.0992 - accuracy: 0.9632 - val_loss: 0.1415 - val_accuracy: 0.9557\n",
      "Epoch 218/6000\n",
      "128/128 [==============================] - 42s 325ms/step - loss: 0.0998 - accuracy: 0.9627 - val_loss: 0.1518 - val_accuracy: 0.9536\n",
      "Epoch 219/6000\n",
      "128/128 [==============================] - 52s 406ms/step - loss: 0.0999 - accuracy: 0.9627 - val_loss: 0.1365 - val_accuracy: 0.9574\n",
      "Epoch 220/6000\n",
      "128/128 [==============================] - 53s 414ms/step - loss: 0.0996 - accuracy: 0.9629 - val_loss: 0.1406 - val_accuracy: 0.9566\n",
      "Epoch 221/6000\n",
      "128/128 [==============================] - 44s 342ms/step - loss: 0.0987 - accuracy: 0.9626 - val_loss: 0.1428 - val_accuracy: 0.9555\n",
      "Epoch 222/6000\n",
      "128/128 [==============================] - 57s 442ms/step - loss: 0.0978 - accuracy: 0.9631 - val_loss: 0.1416 - val_accuracy: 0.9555\n",
      "Epoch 223/6000\n",
      "128/128 [==============================] - 55s 430ms/step - loss: 0.0998 - accuracy: 0.9630 - val_loss: 0.1416 - val_accuracy: 0.9549\n",
      "Epoch 224/6000\n",
      "128/128 [==============================] - 45s 350ms/step - loss: 0.0995 - accuracy: 0.9631 - val_loss: 0.1450 - val_accuracy: 0.9542\n",
      "Epoch 225/6000\n",
      "128/128 [==============================] - 56s 437ms/step - loss: 0.0970 - accuracy: 0.9637 - val_loss: 0.1463 - val_accuracy: 0.9549\n",
      "Epoch 226/6000\n",
      "128/128 [==============================] - 56s 436ms/step - loss: 0.0989 - accuracy: 0.9633 - val_loss: 0.1416 - val_accuracy: 0.9561\n",
      "Epoch 227/6000\n",
      "128/128 [==============================] - 43s 336ms/step - loss: 0.0987 - accuracy: 0.9632 - val_loss: 0.1458 - val_accuracy: 0.9545\n",
      "Epoch 227: early stopping\n",
      "##########################################################################\n",
      "------val_accuracy-----> 95.74 | 96.37 <----------accuracy----------\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/ALICE-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/ALICE-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "working on pair: ROSE/USDT\n",
      "One_pair_AI_Gen : ROSE/USDT\n",
      "price_volatility_15m:0.49%\n",
      "mini_expand : ROSE/USDT\n",
      "---buy_simple_up--- Buy pct: 0.5%\n",
      "---buy_only--- Max time window: 10%\n",
      "---buy_only--- no b\n",
      "---buy_only--- no sell\n",
      "df original shape (407583, 1607)\n",
      "df original shape buy mean : 13.200992190547693\n",
      "df choosen data shape(407582, 1607)\n",
      "pair: True\n",
      "81516\n",
      "normalizing ...\n",
      "/UltimeTradingBot/Data/BUY_UP_CLOSE/ROSE-USDT-tp50_w40_max10min_Norm_v1.json\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_120 (Dense)           (None, 250)               401750    \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 250)               0         \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 20)                5020      \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,871\n",
      "Trainable params: 407,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_UP_CLOSE/ROSE-USDT-tp50_w40_max10min_Model_v1.hdf5\n",
      "Epoch 1/6000\n"
     ]
    }
   ],
   "source": [
    "if BUY_MODE==\"BUY_ONLY\":\n",
    "    buy_function=buy_up_only\n",
    "elif BUY_MODE==\"BUY_UP\":\n",
    "    buy_function=buy_up\n",
    "elif  BUY_MODE==\"BUY_DIP\":\n",
    "    buy_function=buy_min_up\n",
    "elif  BUY_MODE==\"AFTER_DEPTH\":\n",
    "    buy_function=buy_after_depth\n",
    "elif  BUY_MODE==\"BUY_UP_CLOSE\":\n",
    "    buy_function=buy_up_close\n",
    "\n",
    "errorlist={}\n",
    "histoplus={}\n",
    "gc.collect()\n",
    "for pair in Binance_USDT_HALAL[Binance_USDT_HALAL.index(\"ROSE/USDT\"):]:    # ICX/USDT min\n",
    "#for pair in Binance_USDT_HALAL:\n",
    "#for pair in VOLATILE_BUSD_PAIRS[:]:    # ICX/USDT min\n",
    "     print(f\"working on pair: {pair}\")\n",
    "     try:\n",
    "          m,h=One_pair_AI_Gen(pair)\n",
    "          histoplus.update(h)\n",
    "          del h\n",
    "          del m\n",
    "          gc.collect()\n",
    "     except Exception as e:\n",
    "          errorlist[pair]=e\n",
    "          print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histoplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Binance_USDT_HALAL[13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair=\"GMT/USDT\"\n",
    "price_volatility_15m=(100*(df_list15m[pair][\"high\"]-df_list15m[pair][\"low\"])/df_list15m[pair][\"high\"]).mean()\n",
    "print(f\"price_volatility_15m:{price_volatility_15m}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=mini_expand3(pair=pair,i=0,j=len(df_list1m[pair]),window=WINDOW_SIZE,metadata=MetaData,BUY_PCT=max(price_volatility_15m*0.5,BUY_PCT),SELL_PCT=SELL_PCT)\n",
    "print(\"df original shape \"+str(df.shape))\n",
    "print(f\"df original shape buy mean : {df.buy.mean()*100}\")\n",
    "df=df.reset_index()\n",
    "try:df.pop(\"num_index\")\n",
    "except: pass\n",
    "try:df.pop(\"index\")\n",
    "except: pass\n",
    "try:df.pop(\"date\")\n",
    "except: pass\n",
    "df=data_shufler(df)            \n",
    "#df=data_chooser(df,weight=50,row_numbers=df.buy.sum()*2)\n",
    "df=data_chooser50(df,row_numbers=500000)\n",
    "gc.collect()\n",
    "df=data_cleanup(df)\n",
    "df=df.dropna()\n",
    "#df.pop(\"price\");print(\"we work with no price\")\n",
    "#df.pop(\"BTC_price\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BTC\n",
    "df=mini_expand4_btc(i=0,j=len(df_list1m[pair]),window=100,metadata=MetaData,BUY_PCT=0.4,SELL_PCT=SELL_PCT)\n",
    "print(\"df original shape \"+str(df.shape))\n",
    "print(f\"df original shape buy mean : {df.buy.mean()*100}\")\n",
    "df=df.reset_index()\n",
    "try:df.pop(\"num_index\")\n",
    "except: pass\n",
    "try:df.pop(\"index\")\n",
    "except: pass\n",
    "try:df.pop(\"date\")\n",
    "except: pass\n",
    "df=data_shufler(df)            \n",
    "df=data_chooser50(df,row_numbers=500000)\n",
    "gc.collect()\n",
    "df=data_cleanup(df)\n",
    "df=df.dropna()\n",
    "#df.pop(\"price\");print(\"we work with no price\")\n",
    "#df.pop(\"BTC_price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResJS={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data_shufler(df)            \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df choosen data shape\"+str(df.shape))\n",
    "(df.shape[0]/2)==df.buy.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.buy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=df.to_numpy(dtype=np.float32)\n",
    "#dt=df.to_numpy()\n",
    "dt=np.nan_to_num(dt,nan=0)\n",
    "#dt=dt.astype(np.float32)\n",
    "dt=np.nan_to_num(dt, neginf=0) \n",
    "dt=np.nan_to_num(dt, posinf=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_20pct= int(0.2*len(dt[:,0]))\n",
    "print(index_20pct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_20pct= int(0.2*len(df.iloc[:,0]))\n",
    "# print(index_20pct)\n",
    "# XVALIDATION= df.iloc[:index_20pct, :-1]\n",
    "# YVALIDATION= df.iloc[:index_20pct,-1]\n",
    "# XTRAIN= df.iloc[index_20pct:, 0:-1]\n",
    "# YTRAIN= df.iloc[index_20pct:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if True:\n",
    "#     if True:\n",
    "#     #if True:\n",
    "#         print(\"normalizing ...\")\n",
    "#         mean = df.iloc[index_20pct:, 0:-1].mean(axis=0).values\n",
    "#         std = df.iloc[index_20pct:, 0:-1].std(axis=0).values\n",
    "\n",
    "\n",
    "#         # print(mean.values)\n",
    "#         df.iloc[index_20pct:, 0:-1] -= mean\n",
    "#         df.iloc[index_20pct:, 0:-1] /= std\n",
    "\n",
    "#         df.iloc[:index_20pct, :-1] -=mean\n",
    "#         df.iloc[:index_20pct, :-1] /= std\n",
    "#         FIRST_NORM_FLAG=False\n",
    "#         ######################### SAVIN NORM ################\n",
    "#         try:\n",
    "#             Normalization={\"mean\":mean.tolist(),\"std\":std.tolist()}\n",
    "#             with open(Normalization_File.replace(\"/UltimeTradingBot/Data/\", \"/UltimeTradingBot/Data/\"+pair.replace(\"/\", \"-\")+\"-\"), 'w+') as fp:\n",
    "#                         json.dump(Normalization, fp,  indent=4)\n",
    "#                         print(Normalization_File)\n",
    "#         except Exception as e:\n",
    "#             print(\"error Normalization in juppiter\")\n",
    "#             print(e)\n",
    "#     else:print(\"already normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if True:\n",
    "    if True:\n",
    "    #if True:\n",
    "        print(\"normalizing ...\")\n",
    "        mean = dt[index_20pct:, 0:-1].mean(axis=0)\n",
    "        std = dt[index_20pct:, 0:-1].std(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "        dt[index_20pct:, 0:-1] -= mean \n",
    "        dt[index_20pct:, 0:-1] /= std\n",
    "\n",
    "        dt[:index_20pct, :-1] -=mean\n",
    "        dt[:index_20pct, :-1] /= std\n",
    "        FIRST_NORM_FLAG=False\n",
    "        ######################### SAVIN NORM ################\n",
    "        try:\n",
    "            Normalization={\"mean\":mean.tolist(),\"std\":std.tolist()}\n",
    "            with open(f'{DATA_DIR}/{pair}-tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Norm_v{VERSION}.json', 'w+') as fp:\n",
    "                        json.dump(Normalization, fp,  indent=4)\n",
    "                        print(fp.name)\n",
    "        except Exception as e:\n",
    "            print(\"error Normalization in juppiter\")\n",
    "            print(e)\n",
    "    else:print(\"already normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=np.nan_to_num(dt,nan=0)\n",
    "dt=np.nan_to_num(dt, neginf=0) \n",
    "dt=np.nan_to_num(dt, posinf=0) \n",
    "dt=dt.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=dt[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt[index_20pct:, 0:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_DIM=dt.shape[1]-1\n",
    "model = Sequential()\n",
    "model.add(Dense(int(250),input_dim=IN_DIM,activation='relu')) #( 100=>66.23)\n",
    "# resultus withe 250 d0.3 50 d 20 d 8 = 65.6% vs  65.49 no droppout vs 65.78 d0.5 vs 65.68 d0.4 # 65.48 # one dropout of   0.5 = 66.11   #tanh 66.33 accuracy #softmax 66.12 #softplus 66.5 # sigmoid 66.21 / \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(int(20),activation='relu')) # best softplus 66.26(69) vs relu 66.65(70)  / -20 => 66.25 /250 ->65.78\n",
    "#model2.add(Dropout(0.1)) #5=> 66.00  66.21 vs no dopout 66.28\n",
    "#model2.add(Dense(int(20),activation='relu')) # disabled 6.24\n",
    "model.add(Dense(int(50),activation='relu')) # -4 -> -> 66.24\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "print(model.summary())\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "callbacks_a = ModelCheckpoint(filepath =MODEL_FILE.replace(\"/UltimeTradingBot/Data/\", \"/UltimeTradingBot/Data/\"+pair.replace(\"/\", \"-\")+\"-\"),monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "callbacks_b = EarlyStopping(monitor ='val_accuracy',mode='auto',patience=15,verbose=1)\n",
    "history = model.fit(dt[index_20pct:, 0:-1],\n",
    "                dt[index_20pct:,-1],\n",
    "                validation_data=(dt[:index_20pct, :-1],dt[:index_20pct,-1]),\n",
    "                epochs=6000,\n",
    "                batch_size=256*10,\n",
    "                callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "print('##########################################################################')\n",
    "print(MODEL_FILE.replace(\"/UltimeTradingBot/Data/\", \"/UltimeTradingBot/Data/\"+pair.replace(\"/\", \"-\")+\"-\"))\n",
    "print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "ResJS[pair]='{0:.4g}'.format(max(history.history['val_accuracy'])*100)\n",
    "#94%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Tests and evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair='SOL/USDT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_function=buy_after_depth\n",
    "df=mini_expand3(pair=pair,i=0,j=len(df_list1m[pair]),window=WINDOW_SIZE,metadata=MetaData,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT)\n",
    "print(\"df original shape \"+str(df.shape))\n",
    "print(f\"df original shape buy mean : {df.buy.mean()*100}\")\n",
    "df=df.reset_index()\n",
    "try:df.pop(\"num_index\")\n",
    "except: pass\n",
    "try:df.pop(\"index\")\n",
    "except: pass\n",
    "try:df.pop(\"date\")\n",
    "except: pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[39m.\u001b[39mindex[\u001b[39m100\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.index[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i_start=22500\n",
    "i_end=i_start+1000\n",
    "x = np.linspace(0, 10, 500)\n",
    "dashes = [10, 5, 100, 5]  # 10 points on, 5 off, 100 on, 5 off\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot(df.index[i_start:i_end], df.price[i_start:i_end], '-', linewidth=1,\n",
    "                 label='Dashes set retroactively')\n",
    "line1.set_dashes(dashes)\n",
    "plt.plot(df[i_start:i_end][df.buy[i_start:i_end]==1].index, df[i_start:i_end][df.buy[i_start:i_end]==1].price, 'ro')\n",
    "\n",
    "\n",
    "ax.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=NormalDataTest(pair=\"APE/USDT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i_start=22500\n",
    "i_end=i_start+1000\n",
    "x = np.linspace(0, 10, 500)\n",
    "dashes = [10, 5, 100, 5]  # 10 points on, 5 off, 100 on, 5 off\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot(np.arange(i_start,i_end), dt[i_start:i_end,0], '-', linewidth=1,\n",
    "                 label='Price')\n",
    "# line1.set_dashes(dashes)\n",
    "plt.plot(np.arange(i_start,i_end)[dt[i_start:i_end,-1]==1], dt[i_start:i_end,0][dt[i_start:i_end,-1]==1], 'ro')\n",
    "\n",
    "\n",
    "ax.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_20pct=dt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XVALIDATION= dt[:index_20pct, :-1]\n",
    "YVALIDATION= dt[:index_20pct,-1]\n",
    "XTRAIN= dt[index_20pct:, 0:-1]\n",
    "YTRAIN= dt[index_20pct:,-1]\n",
    "\n",
    "\n",
    "XX0=XVALIDATION[YVALIDATION==0]\n",
    "YY0=YVALIDATION[YVALIDATION==0]\n",
    "\n",
    "INDEX_SEP=int(XX0.shape[0]/4)\n",
    "XX0Train=XX0[INDEX_SEP:]\n",
    "YY0Train=YY0[INDEX_SEP:]\n",
    "\n",
    "XX0Val=XX0[:INDEX_SEP]\n",
    "YY0Val=YY0[:INDEX_SEP]\n",
    "\n",
    "XX1=XVALIDATION[YVALIDATION==1]\n",
    "YY1=YVALIDATION[YVALIDATION==1]\n",
    "\n",
    "INDEX_SEP=int(XX1.shape[0]/4)\n",
    "XX1Train=XX1[INDEX_SEP:]\n",
    "YY1Train=YY1[INDEX_SEP:]\n",
    "\n",
    "XX1Val=XX1[:INDEX_SEP]\n",
    "YY1Val=YY1[:INDEX_SEP]\n",
    "\n",
    "\n",
    "accuracy0 = model.evaluate(XX0, YY0)\n",
    "accuracy1 = model.evaluate(XX1, YY1)\n",
    "accuracy = model.evaluate(XVALIDATION, YVALIDATION)\n",
    "maxaccuracy = model.evaluate(dt[:,:-1], dt[:,-1])\n",
    "\n",
    "print(f\"class 0: {format(accuracy0[1]*100,'0.2f')} %\")\n",
    "print(f\"class 1: {format(accuracy1[1]*100,'0.2f')} %\")\n",
    "print(f\"FULL class : {format(accuracy[1]*100,'0.2f')} %\")\n",
    "print(f\"FULL class with all data: {format(maxaccuracy[1]*100,'0.2f')} %\")\n",
    "\n",
    "#accuracy = model.evaluate(dt[:,0:-1], dt[:,-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dftest=mini_expand3(pair=pair,i=0,j=len(df_list1m[pair]),window=WINDOW_SIZE,metadata=MetaData,BUY_PCT=0.4,SELL_PCT=SELL_PCT)\n",
    "dftest=df\n",
    "print(\"df original shape \"+str(dftest.shape))\n",
    "print(f\"df original shape buy mean : {dftest.buy.mean()*100}\")\n",
    "dftest=dftest.reset_index()\n",
    "try:dftest.pop(\"num_index\")\n",
    "except: pass\n",
    "try:dftest.pop(\"index\")\n",
    "except: pass\n",
    "try:dftest.pop(\"date\")\n",
    "except: pass\n",
    "dftest=data_shufler(dftest)            \n",
    "gc.collect()\n",
    "dftest=data_cleanup(dftest)\n",
    "dftest=dftest.dropna()\n",
    "df.pop(\"price\");print(\"we work with no price\")\n",
    "df.pop(\"BTC_price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest.buy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtt=dftest.to_numpy(dtype=np.float32)\n",
    "dtt=dt\n",
    "#dt=df.to_numpy()\n",
    "dtt=np.nan_to_num(dtt,nan=0)\n",
    "#dt=dt.astype(np.float32)\n",
    "dtt=np.nan_to_num(dtt, neginf=0) \n",
    "dtt=np.nan_to_num(dtt, posinf=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stats plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction2=(model.predict( dtt[:, 0:-1])).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ixx=dtt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "False_prediction=dtt[:ixx,-1][(prediction2[:ixx].transpose()[0]!=dtt[:ixx])]\n",
    "True_prediction=dtt[:ixx,-1][(prediction2[:ixx].transpose()[0]==dtt[:ixx])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtt[:,-1].mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp0=False_prediction[False_prediction==0].shape[0]*100/ixx #### it mean that 11.73 of the 0 class are wrong the buyed witch lead the losses\n",
    "print( f\"Prediction mean :{prediction2.mean()*100} %\"+'#### the colose to 50 the better')\n",
    "print( f\"False prediction class 0 :{fp0} %\"+'#### it mean that x of the 0 class are wrong the buyed witch lead the losses')\n",
    "fp1=False_prediction[False_prediction==1].shape[0]*100/ixx   #### we don't buy x % of the correct chanses\n",
    "print( f\"False prediction class 1 :{fp1} %\"+'#### we don\\'t buy x % of the correct chanses')\n",
    "trp0=True_prediction[True_prediction==0].shape[0]*100/ixx   #### it mean that 40 % of class 0 are predicted correctly\n",
    "trp1=True_prediction[True_prediction==1].shape[0]*100/ixx     #### the only buying correct of all\n",
    "print( f\"True prediction class 0 :{trp0} %\"+'#### it mean that 40 % of class 0 are predicted correctly')\n",
    "print( f\"True prediction class 1 :{trp1} %\"+'#### the only buying correct of all')\n",
    "print(f\"successful buy pct of unsuccessfull: {100*trp1/(trp1+fp1)}  %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(dt[:index_20pct,:-1], Y[:index_20pct]) #3-> 66.76 / 4 -> 65.75\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single AI crypto concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xdata_config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Imports and fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/pandas/core/arrays/masked.py:59: UserWarning: Pandas requires version '1.3.2' or newer of 'bottleneck' (version '1.2.1' currently installed).\n",
      "  from pandas.core import (\n",
      "2023-03-04 06:26:43.822329: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-04 06:26:43.822380: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-04 06:26:43.916476: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-04 06:26:45.946110: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-04 06:26:45.946342: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-04 06:26:45.946366: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from functions_module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.constraints import MaxNorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "from keras.models import load_model\n",
    "from keras.layers import BatchNormalization, Dense"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special list if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Binance_USDT_HALAL.index(\"ROSE/USDT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import date\n",
    "# TICKERS = \"../Binance-Fast-Trade-Bot/volatile_volume_\" + str(date.today()) + \".txt\"\n",
    "# VOLATILE_COINS=[line.strip() for line in open(TICKERS)]\n",
    "# PAIR_WITH=\"USDT\"\n",
    "# VOLATILE_USDT_PAIRS=[coin+\"/USDT\" for coin in VOLATILE_COINS]\n",
    "# VOLATILE_BUSD_PAIRS=[coin+\"/BUSD\" for coin in VOLATILE_COINS]\n",
    "# VOLATILE_USDT_PAIRS\n",
    "\n",
    "# coins_to_download=''\n",
    "# for coin in VOLATILE_COINS:\n",
    "#     coins_to_download=coins_to_download+\" \"+coin\n",
    "# f\"node database/ddargs.js {coins_to_download} {PAIR_WITH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coins_to_download=''\n",
    "# for coin in VOLATILE_COINS:\n",
    "#     coins_to_download=coins_to_download+\" \"+coin\n",
    "# os.system(f\"node database/ddargs.js {coins_to_download} {PAIR_WITH}\")#node database/ddargs.js ORN BUSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair_list = find_intersection(VOLATILE_USDT_PAIRS,Binance_USDT_HALAL)\n",
    "# #tf = '1m'\n",
    "# oldest_pair = \"BTC/USDT\"\n",
    "# if oldest_pair not in pair_list: pair_list.append(oldest_pair)\n",
    "# df_list1m = {}\n",
    "# df_list1d = {}\n",
    "# df_list1h = {}\n",
    "# df_list5m = {}\n",
    "# df_list15m = {}\n",
    "\n",
    "\n",
    "# for pair in pair_list:\n",
    "#     df = get_historical_from_db(ccxt.binance(), pair, '1m', path=\"./database/\")\n",
    "#     df_list1m[pair] = df.loc[:]\n",
    "\n",
    "# for pair in pair_list:\n",
    "#     df = get_historical_from_db(ccxt.binance(), pair, '1d', path=\"./database/\")\n",
    "#     df_list1d[pair] = df.loc[:]\n",
    "\n",
    "# for pair in pair_list:\n",
    "#     df = get_historical_from_db(ccxt.binance(), pair, '1h', path=\"./database/\")\n",
    "#     df_list1h[pair] = df.loc[:]\n",
    "\n",
    "# for pair in pair_list:\n",
    "#     df = get_historical_from_db(ccxt.binance(), pair, '5m', path=\"./database/\")\n",
    "#     df_list5m[pair] = df.loc[:]\n",
    "\n",
    "# for pair in pair_list:\n",
    "#     df = get_historical_from_db(\n",
    "#         ccxt.binance(), pair, '15m', path=\"./database/\")\n",
    "#     df_list15m[pair] = df.loc[:]\n",
    "# del(df)\n",
    "# df_list = df_list1m\n",
    "# prerr(\"Data load 100% use df_list1d[\\\"BTC/USDT\\\"] for exemple to access\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Pair</th>\n",
       "      <th>launch_week_stamp</th>\n",
       "      <th>launch_day_stamp</th>\n",
       "      <th>launch_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SNMBUSD</td>\n",
       "      <td>SNM/BUSD</td>\n",
       "      <td>1661126400000</td>\n",
       "      <td>1661472000000</td>\n",
       "      <td>2022-08-26 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>1502668800000</td>\n",
       "      <td>1502928000000</td>\n",
       "      <td>2017-08-17 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LUNAUSDT</td>\n",
       "      <td>LUNA/USDT</td>\n",
       "      <td>1597622400000</td>\n",
       "      <td>1597968000000</td>\n",
       "      <td>2020-08-21 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>ETH/USDT</td>\n",
       "      <td>1502668800000</td>\n",
       "      <td>1502928000000</td>\n",
       "      <td>2017-08-17 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GMTUSDT</td>\n",
       "      <td>GMT/USDT</td>\n",
       "      <td>1646611200000</td>\n",
       "      <td>1646784000000</td>\n",
       "      <td>2022-03-09 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>FIDAUSDT</td>\n",
       "      <td>FIDA/USDT</td>\n",
       "      <td>1632700800000</td>\n",
       "      <td>1632960000000</td>\n",
       "      <td>2021-09-30 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>XNOUSDT</td>\n",
       "      <td>XNO/USDT</td>\n",
       "      <td>1642982400000</td>\n",
       "      <td>1643328000000</td>\n",
       "      <td>2022-01-28 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>BTGUSDT</td>\n",
       "      <td>BTG/USDT</td>\n",
       "      <td>1618185600000</td>\n",
       "      <td>1618531200000</td>\n",
       "      <td>2021-04-16 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>GHSTUSDT</td>\n",
       "      <td>GHST/USDT</td>\n",
       "      <td>1629072000000</td>\n",
       "      <td>1629417600000</td>\n",
       "      <td>2021-08-20 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>EPSUSDT</td>\n",
       "      <td>EPS/USDT</td>\n",
       "      <td>1616976000000</td>\n",
       "      <td>1617321600000</td>\n",
       "      <td>2021-04-02 09:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       Pair  launch_week_stamp  launch_day_stamp  \\\n",
       "0     SNMBUSD   SNM/BUSD      1661126400000     1661472000000   \n",
       "1     BTCUSDT   BTC/USDT      1502668800000     1502928000000   \n",
       "2    LUNAUSDT  LUNA/USDT      1597622400000     1597968000000   \n",
       "3     ETHUSDT   ETH/USDT      1502668800000     1502928000000   \n",
       "4     GMTUSDT   GMT/USDT      1646611200000     1646784000000   \n",
       "..        ...        ...                ...               ...   \n",
       "107  FIDAUSDT  FIDA/USDT      1632700800000     1632960000000   \n",
       "108   XNOUSDT   XNO/USDT      1642982400000     1643328000000   \n",
       "109   BTGUSDT   BTG/USDT      1618185600000     1618531200000   \n",
       "110  GHSTUSDT  GHST/USDT      1629072000000     1629417600000   \n",
       "111   EPSUSDT   EPS/USDT      1616976000000     1617321600000   \n",
       "\n",
       "           launch_minute  \n",
       "0    2022-08-26 08:00:00  \n",
       "1    2017-08-17 04:00:00  \n",
       "2    2020-08-21 10:00:00  \n",
       "3    2017-08-17 04:00:00  \n",
       "4    2022-03-09 12:00:00  \n",
       "..                   ...  \n",
       "107  2021-09-30 12:00:00  \n",
       "108  2022-01-28 08:00:00  \n",
       "109  2021-04-16 07:00:00  \n",
       "110  2021-08-20 10:00:00  \n",
       "111  2021-04-02 09:00:00  \n",
       "\n",
       "[112 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chking import\n",
    "MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '/UltimeTradingBot/Data/BUY_TEST'\n",
      "Results dir: /UltimeTradingBot/Data/BUY_TEST\n"
     ]
    }
   ],
   "source": [
    "if BUY_MODE==\"BUY_ONLY\":\n",
    "    buy_function=buy_up_only\n",
    "elif BUY_MODE==\"BUY_UP\":\n",
    "    buy_function=buy_up\n",
    "elif  BUY_MODE==\"BUY_DIP\":\n",
    "    buy_function=buy_min_up\n",
    "elif  BUY_MODE==\"AFTER_DEPTH\":\n",
    "    buy_function=buy_after_depth\n",
    "elif  BUY_MODE==\"BUY_UP_CLOSE\":\n",
    "    buy_function=buy_up_close\n",
    "elif  BUY_MODE==\"AFTER_DEPTH_CLOSE\":\n",
    "    buy_function=buy_after_depth_close\n",
    "elif  BUY_MODE==\"BUY_TEST\":\n",
    "    buy_function=buy_test\n",
    "elif BUY_MODE==\"BUY_MIN_CLOSE\":\n",
    "    buy_function=buy_min_close\n",
    "elif  BUY_MODE==\"SELL_TEST\":\n",
    "    buy_function=sell_test\n",
    "elif  BUY_MODE==\"BUY_FIX\":\n",
    "    buy_function=buy_fix\n",
    "\n",
    "\n",
    "try:\n",
    "    os.mkdir(DATA_DIR, mode = 0o777)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "print(f\"Results dir: {DATA_DIR}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on: SNM/BUSD -->mini_expand : SNM/BUSD\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (156489, 287)\n",
      "df original shape buy mean : 5.131351085379803\n",
      "SNM/BUSD is processed -- 0/112\n",
      "working on: LUNA/USDT -->mini_expand : LUNA/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (953805, 287)\n",
      "df original shape buy mean : 2.4030069039269035\n",
      "LUNA/USDT is processed -- 1/112\n",
      "working on: GMT/USDT -->mini_expand : GMT/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (358605, 287)\n",
      "df original shape buy mean : 2.725282692656265\n",
      "GMT/USDT is processed -- 2/112\n",
      "working on: UST/USDT -->mini_expand : UST/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (180050, 287)\n",
      "df original shape buy mean : 0.23715634545959458\n",
      "UST/USDT is processed -- 3/112\n",
      "working on: SOL/USDT -->mini_expand : SOL/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (980042, 287)\n",
      "df original shape buy mean : 1.8833886710977694\n",
      "SOL/USDT is processed -- 4/112\n",
      "working on: APE/USDT -->mini_expand : APE/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (347087, 287)\n",
      "df original shape buy mean : 2.0827631112660514\n",
      "APE/USDT is processed -- 5/112\n",
      "working on: XRP/USDT -->mini_expand : XRP/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (980036, 287)\n",
      "df original shape buy mean : 1.3584194866311035\n",
      "XRP/USDT is processed -- 6/112\n",
      "working on: IDEX/USDT -->mini_expand : IDEX/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455090, 287)\n",
      "df original shape buy mean : 2.2540596365554064\n",
      "IDEX/USDT is processed -- 7/112\n",
      "working on: AVAX/USDT -->mini_expand : AVAX/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (980043, 287)\n",
      "df original shape buy mean : 2.282756981071239\n",
      "AVAX/USDT is processed -- 8/112\n",
      "working on: DOT/USDT -->mini_expand : DOT/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (980044, 287)\n",
      "df original shape buy mean : 1.3405520568464273\n",
      "DOT/USDT is processed -- 9/112\n",
      "working on: ADA/USDT -->mini_expand : ADA/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (980034, 287)\n",
      "df original shape buy mean : 1.2348551172714417\n",
      "ADA/USDT is processed -- 10/112\n",
      "working on: JASMY/USDT -->mini_expand : JASMY/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455092, 287)\n",
      "df original shape buy mean : 3.17144665254498\n",
      "JASMY/USDT is processed -- 11/112\n",
      "working on: TRX/USDT -->mini_expand : TRX/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455093, 287)\n",
      "df original shape buy mean : 0.42342993629873454\n",
      "TRX/USDT is processed -- 12/112\n",
      "working on: NEAR/USDT -->mini_expand : NEAR/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (980048, 287)\n",
      "df original shape buy mean : 2.293561131699672\n",
      "NEAR/USDT is processed -- 13/112\n",
      "working on: AXS/USDT -->mini_expand : AXS/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455094, 287)\n",
      "df original shape buy mean : 1.279296145411717\n",
      "AXS/USDT is processed -- 14/112\n",
      "working on: GAL/USDT -->mini_expand : GAL/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (276534, 287)\n",
      "df original shape buy mean : 2.2268509478038867\n",
      "GAL/USDT is processed -- 15/112\n",
      "working on: GALA/USDT -->mini_expand : GALA/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455096, 287)\n",
      "df original shape buy mean : 1.4645261659078523\n",
      "GALA/USDT is processed -- 16/112\n",
      "working on: SHIB/USDT -->mini_expand : SHIB/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455097, 287)\n",
      "df original shape buy mean : 1.1801879599294216\n",
      "SHIB/USDT is processed -- 17/112\n",
      "working on: ZIL/USDT -->mini_expand : ZIL/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455098, 287)\n",
      "df original shape buy mean : 1.359267674215224\n",
      "ZIL/USDT is processed -- 18/112\n",
      "working on: ENS/USDT -->mini_expand : ENS/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455098, 287)\n",
      "df original shape buy mean : 2.1476692932071773\n",
      "ENS/USDT is processed -- 19/112\n",
      "working on: DOGE/USDT -->mini_expand : DOGE/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (980040, 287)\n",
      "df original shape buy mean : 1.9814497367454391\n",
      "DOGE/USDT is processed -- 20/112\n",
      "working on: LTC/USDT -->mini_expand : LTC/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (980039, 287)\n",
      "df original shape buy mean : 1.002613161312968\n",
      "LTC/USDT is processed -- 21/112\n",
      "working on: MANA/USDT -->mini_expand : MANA/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (449670, 287)\n",
      "df original shape buy mean : 0.9925056152289456\n",
      "MANA/USDT is processed -- 22/112\n",
      "working on: DAR/USDT -->mini_expand : DAR/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455101, 287)\n",
      "df original shape buy mean : 2.371122014673666\n",
      "DAR/USDT is processed -- 23/112\n",
      "working on: WAVES/USDT -->mini_expand : WAVES/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455102, 287)\n",
      "df original shape buy mean : 1.8901257300561192\n",
      "WAVES/USDT is processed -- 24/112\n",
      "working on: LAZIO/USDT -->mini_expand : LAZIO/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455102, 287)\n",
      "df original shape buy mean : 3.2645428936809773\n",
      "LAZIO/USDT is processed -- 25/112\n",
      "working on: ALICE/USDT -->mini_expand : ALICE/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455103, 287)\n",
      "df original shape buy mean : 1.2649883652711584\n",
      "ALICE/USDT is processed -- 26/112\n",
      "working on: ROSE/USDT -->mini_expand : ROSE/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455103, 287)\n",
      "df original shape buy mean : 1.4519790025554655\n",
      "ROSE/USDT is processed -- 27/112\n",
      "working on: ZEC/USDT -->mini_expand : ZEC/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455104, 287)\n",
      "df original shape buy mean : 1.052726409787653\n",
      "ZEC/USDT is processed -- 28/112\n",
      "working on: ALGO/USDT -->mini_expand : ALGO/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455105, 287)\n",
      "df original shape buy mean : 0.8538688873996111\n",
      "ALGO/USDT is processed -- 29/112\n",
      "working on: GRT/USDT -->mini_expand : GRT/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455105, 287)\n",
      "df original shape buy mean : 1.2621263224970063\n",
      "GRT/USDT is processed -- 30/112\n",
      "working on: PSG/USDT -->mini_expand : PSG/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455106, 287)\n",
      "df original shape buy mean : 1.6822454549050112\n",
      "PSG/USDT is processed -- 31/112\n",
      "working on: SLP/USDT -->mini_expand : SLP/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455106, 287)\n",
      "df original shape buy mean : 4.882159321125188\n",
      "SLP/USDT is processed -- 32/112\n",
      "working on: EOS/USDT -->mini_expand : EOS/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455107, 287)\n",
      "df original shape buy mean : 0.6501767716163451\n",
      "EOS/USDT is processed -- 33/112\n",
      "working on: PORTO/USDT -->mini_expand : PORTO/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (449670, 287)\n",
      "df original shape buy mean : 2.9759601485533835\n",
      "PORTO/USDT is processed -- 34/112\n",
      "working on: ICP/USDT -->mini_expand : ICP/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455108, 287)\n",
      "df original shape buy mean : 1.3737398595498211\n",
      "ICP/USDT is processed -- 35/112\n",
      "working on: EGLD/USDT -->mini_expand : EGLD/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (980049, 287)\n",
      "df original shape buy mean : 1.5904306825475052\n",
      "EGLD/USDT is processed -- 36/112\n",
      "working on: XMR/USDT -->mini_expand : XMR/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455109, 287)\n",
      "df original shape buy mean : 0.6844514171330385\n",
      "XMR/USDT is processed -- 37/112\n",
      "working on: KDA/USDT -->mini_expand : KDA/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (355750, 287)\n",
      "df original shape buy mean : 2.123682361208714\n",
      "KDA/USDT is processed -- 38/112\n",
      "working on: ETC/USDT -->mini_expand : ETC/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455111, 287)\n",
      "df original shape buy mean : 1.2197024462164177\n",
      "ETC/USDT is processed -- 39/112\n",
      "working on: MBOX/USDT -->mini_expand : MBOX/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455111, 287)\n",
      "df original shape buy mean : 1.2669436686874191\n",
      "MBOX/USDT is processed -- 40/112\n",
      "working on: OGN/USDT -->mini_expand : OGN/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455112, 287)\n",
      "df original shape buy mean : 1.8290003339837226\n",
      "OGN/USDT is processed -- 41/112\n",
      "working on: AR/USDT -->mini_expand : AR/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455112, 287)\n",
      "df original shape buy mean : 1.7340786443776477\n",
      "AR/USDT is processed -- 42/112\n",
      "working on: GLMR/USDT -->mini_expand : GLMR/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (440713, 287)\n",
      "df original shape buy mean : 2.409277693192622\n",
      "GLMR/USDT is processed -- 43/112\n",
      "working on: LOKA/USDT -->mini_expand : LOKA/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (427754, 287)\n",
      "df original shape buy mean : 3.1225891517086923\n",
      "LOKA/USDT is processed -- 44/112\n",
      "working on: XLM/USDT -->mini_expand : XLM/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455114, 287)\n",
      "df original shape buy mean : 0.4269260009580017\n",
      "XLM/USDT is processed -- 45/112\n",
      "working on: MTL/USDT -->mini_expand : MTL/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455115, 287)\n",
      "df original shape buy mean : 1.44798567395054\n",
      "MTL/USDT is processed -- 46/112\n",
      "working on: SNX/USDT -->mini_expand : SNX/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455116, 287)\n",
      "df original shape buy mean : 1.7705376211778974\n",
      "SNX/USDT is processed -- 47/112\n",
      "working on: PYR/USDT -->mini_expand : PYR/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455116, 287)\n",
      "df original shape buy mean : 2.990666115891333\n",
      "PYR/USDT is processed -- 48/112\n",
      "working on: DASH/USDT -->mini_expand : DASH/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455117, 287)\n",
      "df original shape buy mean : 0.6468666298995643\n",
      "DASH/USDT is processed -- 49/112\n",
      "working on: CITY/USDT -->mini_expand : CITY/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (433170, 287)\n",
      "df original shape buy mean : 1.6393102015375027\n",
      "CITY/USDT is processed -- 50/112\n",
      "working on: ASTR/USDT -->mini_expand : ASTR/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (371598, 287)\n",
      "df original shape buy mean : 2.494362187094656\n",
      "ASTR/USDT is processed -- 51/112\n",
      "working on: IOTA/USDT -->mini_expand : IOTA/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455119, 287)\n",
      "df original shape buy mean : 0.6360973723355869\n",
      "IOTA/USDT is processed -- 52/112\n",
      "working on: ACM/USDT -->mini_expand : ACM/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (445170, 287)\n",
      "df original shape buy mean : 2.141429116966552\n",
      "ACM/USDT is processed -- 53/112\n",
      "working on: BAR/USDT -->mini_expand : BAR/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455120, 287)\n",
      "df original shape buy mean : 2.0700035155563365\n",
      "BAR/USDT is processed -- 54/112\n",
      "working on: JUV/USDT -->mini_expand : JUV/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455121, 287)\n",
      "df original shape buy mean : 2.0838414399687117\n",
      "JUV/USDT is processed -- 55/112\n",
      "working on: SYS/USDT -->mini_expand : SYS/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455121, 287)\n",
      "df original shape buy mean : 2.173048486007018\n",
      "SYS/USDT is processed -- 56/112\n",
      "working on: RVN/USDT -->mini_expand : RVN/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455122, 287)\n",
      "df original shape buy mean : 1.396109175122275\n",
      "RVN/USDT is processed -- 57/112\n",
      "working on: MBL/USDT -->mini_expand : MBL/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455123, 287)\n",
      "df original shape buy mean : 1.9691380132403766\n",
      "MBL/USDT is processed -- 58/112\n",
      "working on: REN/USDT -->mini_expand : REN/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455123, 287)\n",
      "df original shape buy mean : 1.4947607569821786\n",
      "REN/USDT is processed -- 59/112\n",
      "working on: JST/USDT -->mini_expand : JST/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455124, 287)\n",
      "df original shape buy mean : 0.8942617836018315\n",
      "JST/USDT is processed -- 60/112\n",
      "working on: OMG/USDT -->mini_expand : OMG/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455124, 287)\n",
      "df original shape buy mean : 0.8648192580483561\n",
      "OMG/USDT is processed -- 61/112\n",
      "working on: ATM/USDT -->mini_expand : ATM/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455125, 287)\n",
      "df original shape buy mean : 2.1605053556715186\n",
      "ATM/USDT is processed -- 62/112\n",
      "working on: XEC/USDT -->mini_expand : XEC/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455126, 287)\n",
      "df original shape buy mean : 1.17088454625752\n",
      "XEC/USDT is processed -- 63/112\n",
      "working on: STORJ/USDT -->mini_expand : STORJ/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455126, 287)\n",
      "df original shape buy mean : 1.3503952751545727\n",
      "STORJ/USDT is processed -- 64/112\n",
      "working on: ZRX/USDT -->mini_expand : ZRX/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455127, 287)\n",
      "df original shape buy mean : 1.2170229408494773\n",
      "ZRX/USDT is processed -- 65/112\n",
      "working on: SRM/USDT -->mini_expand : SRM/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455127, 287)\n",
      "df original shape buy mean : 1.022352002847557\n",
      "SRM/USDT is processed -- 66/112\n",
      "working on: ICX/USDT -->mini_expand : ICX/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455128, 287)\n",
      "df original shape buy mean : 1.0570652651561758\n",
      "ICX/USDT is processed -- 67/112\n",
      "working on: API3/USDT -->mini_expand : API3/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (426329, 287)\n",
      "df original shape buy mean : 2.295175791466215\n",
      "API3/USDT is processed -- 68/112\n",
      "working on: ONT/USDT -->mini_expand : ONT/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455129, 287)\n",
      "df original shape buy mean : 0.7200156439163402\n",
      "ONT/USDT is processed -- 69/112\n",
      "working on: SKL/USDT -->mini_expand : SKL/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455130, 287)\n",
      "df original shape buy mean : 1.5986641179443237\n",
      "SKL/USDT is processed -- 70/112\n",
      "working on: MULTI/USDT -->mini_expand : MULTI/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (318330, 287)\n",
      "df original shape buy mean : 1.2587566361951434\n",
      "MULTI/USDT is processed -- 71/112\n",
      "working on: QTUM/USDT -->mini_expand : QTUM/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455131, 287)\n",
      "df original shape buy mean : 0.7448404964724442\n",
      "QTUM/USDT is processed -- 72/112\n",
      "working on: COCOS/USDT -->mini_expand : COCOS/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455132, 287)\n",
      "df original shape buy mean : 1.682808503906559\n",
      "COCOS/USDT is processed -- 73/112\n",
      "working on: VOXEL/USDT -->mini_expand : VOXEL/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (444420, 287)\n",
      "df original shape buy mean : 2.701273570046353\n",
      "VOXEL/USDT is processed -- 74/112\n",
      "working on: HIVE/USDT -->mini_expand : HIVE/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455133, 287)\n",
      "df original shape buy mean : 1.4118949845429798\n",
      "HIVE/USDT is processed -- 75/112\n",
      "working on: KP3R/USDT -->mini_expand : KP3R/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455134, 287)\n",
      "df original shape buy mean : 2.517060909534335\n",
      "KP3R/USDT is processed -- 76/112\n",
      "working on: ATA/USDT -->mini_expand : ATA/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455134, 287)\n",
      "df original shape buy mean : 1.5127413025614436\n",
      "ATA/USDT is processed -- 77/112\n",
      "working on: STMX/USDT -->mini_expand : STMX/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455135, 287)\n",
      "df original shape buy mean : 1.2222747097015172\n",
      "STMX/USDT is processed -- 78/112\n",
      "working on: ADX/USDT -->mini_expand : ADX/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455136, 287)\n",
      "df original shape buy mean : 1.0548495394783097\n",
      "ADX/USDT is processed -- 79/112\n",
      "working on: HIGH/USDT -->mini_expand : HIGH/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455136, 287)\n",
      "df original shape buy mean : 2.912755747732546\n",
      "HIGH/USDT is processed -- 80/112\n",
      "working on: NULS/USDT -->mini_expand : NULS/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455137, 287)\n",
      "df original shape buy mean : 2.201754636516038\n",
      "NULS/USDT is processed -- 81/112\n",
      "working on: MLN/USDT -->mini_expand : MLN/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455137, 287)\n",
      "df original shape buy mean : 1.418254283874965\n",
      "MLN/USDT is processed -- 82/112\n",
      "working on: YGG/USDT -->mini_expand : YGG/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455138, 287)\n",
      "df original shape buy mean : 2.301719478487843\n",
      "YGG/USDT is processed -- 83/112\n",
      "working on: SC/USDT -->mini_expand : SC/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455139, 287)\n",
      "df original shape buy mean : 0.8839057958118288\n",
      "SC/USDT is processed -- 84/112\n",
      "working on: CKB/USDT -->mini_expand : CKB/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455139, 287)\n",
      "df original shape buy mean : 0.9522365694875631\n",
      "CKB/USDT is processed -- 85/112\n",
      "working on: TOMO/USDT -->mini_expand : TOMO/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455140, 287)\n",
      "df original shape buy mean : 1.1567869227051017\n",
      "TOMO/USDT is processed -- 86/112\n",
      "working on: STX/USDT -->mini_expand : STX/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455140, 287)\n",
      "df original shape buy mean : 1.2923496067144176\n",
      "STX/USDT is processed -- 87/112\n",
      "working on: FLUX/USDT -->mini_expand : FLUX/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455141, 287)\n",
      "df original shape buy mean : 2.372231901762311\n",
      "FLUX/USDT is processed -- 88/112\n",
      "working on: DNT/USDT -->mini_expand : DNT/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (416700, 287)\n",
      "df original shape buy mean : 1.9114470842332616\n",
      "DNT/USDT is processed -- 89/112\n",
      "working on: ORN/USDT -->mini_expand : ORN/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455142, 287)\n",
      "df original shape buy mean : 1.6386094889067588\n",
      "ORN/USDT is processed -- 90/112\n",
      "working on: PLA/USDT -->mini_expand : PLA/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455143, 287)\n",
      "df original shape buy mean : 1.6311357089969527\n",
      "PLA/USDT is processed -- 91/112\n",
      "working on: BADGER/USDT -->mini_expand : BADGER/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455143, 287)\n",
      "df original shape buy mean : 1.467890311396638\n",
      "BADGER/USDT is processed -- 92/112\n",
      "working on: DF/USDT -->mini_expand : DF/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455144, 287)\n",
      "df original shape buy mean : 2.1364667006485862\n",
      "DF/USDT is processed -- 93/112\n",
      "working on: MOB/USDT -->mini_expand : MOB/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (285225, 287)\n",
      "df original shape buy mean : 1.2204400035060041\n",
      "MOB/USDT is processed -- 94/112\n",
      "working on: LPT/USDT -->mini_expand : LPT/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455145, 287)\n",
      "df original shape buy mean : 1.0746025991716925\n",
      "LPT/USDT is processed -- 95/112\n",
      "working on: SCRT/USDT -->mini_expand : SCRT/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (426346, 287)\n",
      "df original shape buy mean : 1.0526661443991499\n",
      "SCRT/USDT is processed -- 96/112\n",
      "working on: RAD/USDT -->mini_expand : RAD/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (621579, 287)\n",
      "df original shape buy mean : 2.138907524224596\n",
      "RAD/USDT is processed -- 97/112\n",
      "working on: NMR/USDT -->mini_expand : NMR/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455147, 287)\n",
      "df original shape buy mean : 1.603438010137384\n",
      "NMR/USDT is processed -- 98/112\n",
      "working on: ELF/USDT -->mini_expand : ELF/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455148, 287)\n",
      "df original shape buy mean : 1.1932382433845694\n",
      "ELF/USDT is processed -- 99/112\n",
      "working on: TORN/USDT -->mini_expand : TORN/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (444420, 287)\n",
      "df original shape buy mean : 2.6495207236398\n",
      "TORN/USDT is processed -- 100/112\n",
      "working on: T/USDT -->mini_expand : T/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (375949, 287)\n",
      "df original shape buy mean : 1.1456341152656344\n",
      "T/USDT is processed -- 101/112\n",
      "working on: QUICK/USDT -->mini_expand : QUICK/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455150, 287)\n",
      "df original shape buy mean : 1.7341535757442599\n",
      "QUICK/USDT is processed -- 102/112\n",
      "working on: LSK/USDT -->mini_expand : LSK/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455150, 287)\n",
      "df original shape buy mean : 1.2483796550587718\n",
      "LSK/USDT is processed -- 103/112\n",
      "working on: FIDA/USDT -->mini_expand : FIDA/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455151, 287)\n",
      "df original shape buy mean : 1.9789037044848852\n",
      "FIDA/USDT is processed -- 104/112\n",
      "working on: XNO/USDT -->mini_expand : XNO/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (416272, 287)\n",
      "df original shape buy mean : 1.2917035015566745\n",
      "XNO/USDT is processed -- 105/112\n",
      "working on: BTG/USDT -->mini_expand : BTG/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (416700, 287)\n",
      "df original shape buy mean : 1.4934005279577633\n",
      "BTG/USDT is processed -- 106/112\n",
      "working on: GHST/USDT -->mini_expand : GHST/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (455153, 287)\n",
      "df original shape buy mean : 0.1691738821890661\n",
      "GHST/USDT is processed -- 107/112\n",
      "working on: EPS/USDT -->mini_expand : EPS/USDT\n",
      "---buy_after_depth--- Buy percent: 0.92% MaxForcastSize: 3\n",
      "---buy_after_depth--- no b\n",
      "---buy_after_depth--- no sell\n",
      "df original shape (174480, 287)\n",
      "df original shape buy mean : 2.4747822099954147\n",
      "EPS/USDT is processed -- 108/112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdf=pd.DataFrame()\n",
    "count=0\n",
    "row_numbers=30000\n",
    "for pair in pair_list:\n",
    "    if pair != \"BTC/USDT\" and pair != \"EUR/USDT\" and pair != \"ETH/USDT\" :\n",
    "        print(\"working on: \"+pair ,end=\" -->\")\n",
    "        try:\n",
    "            df=mini_expand4(pair=pair,i=0,j=len(df_list1m[pair]),window=WINDOW_SIZE,metadata=MetaData,buy_pourcent=BUY_PERCENT,sell_pourcent=SELL_PERCENT,buy_function=buy_function)\n",
    "            print(\"df original shape \"+str(df.shape))\n",
    "            print(f\"df original shape buy mean : {df.buy.mean()*100}\")\n",
    "            df=df.reset_index()\n",
    "            try:df.pop(\"num_index\")\n",
    "            except: pass\n",
    "            try:df.pop(\"index\")\n",
    "            except: pass\n",
    "            try:df.pop(\"date\")\n",
    "            except: pass\n",
    "            df=data_shufler(df)            \n",
    "            #df=data_chooser(df,weight=50,row_numbers=df.buy.sum()*2)\n",
    "            df=data_chooser50(df,row_numbers=row_numbers)\n",
    "            gc.collect()\n",
    "            df=data_cleanup(df)\n",
    "            df=df.dropna()\n",
    "            print(pair+f\" is processed -- {count}/{len(pair_list)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"error while processing {pair} {count}/{len(pair_list)}\")\n",
    "            print(e)\n",
    "        xdf=pd.concat([xdf,df],axis=0)\n",
    "        count+=1\n",
    "        del(df)\n",
    "        gc.collect()\n",
    "df=xdf\n",
    "del xdf\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>high-1</th>\n",
       "      <th>low-1</th>\n",
       "      <th>close-1</th>\n",
       "      <th>volume-1</th>\n",
       "      <th>high-2</th>\n",
       "      <th>low-2</th>\n",
       "      <th>close-2</th>\n",
       "      <th>volume-2</th>\n",
       "      <th>high-3</th>\n",
       "      <th>...</th>\n",
       "      <th>BTC_volume-6_5min</th>\n",
       "      <th>BTC_high-7_5min</th>\n",
       "      <th>BTC_low-7_5min</th>\n",
       "      <th>BTC_close-7_5min</th>\n",
       "      <th>BTC_volume-7_5min</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>lunch_day</th>\n",
       "      <th>buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071745</td>\n",
       "      <td>-0.001185</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>-0.000767</td>\n",
       "      <td>895505.000</td>\n",
       "      <td>-0.001045</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>476370.000</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>...</td>\n",
       "      <td>277.04986</td>\n",
       "      <td>-0.002340</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>-0.000979</td>\n",
       "      <td>300.78432</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>-621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136.627500</td>\n",
       "      <td>-0.001189</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>7122.590</td>\n",
       "      <td>-0.005215</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>11109.110</td>\n",
       "      <td>-0.006972</td>\n",
       "      <td>...</td>\n",
       "      <td>205.84605</td>\n",
       "      <td>-0.001670</td>\n",
       "      <td>-0.000603</td>\n",
       "      <td>-0.001006</td>\n",
       "      <td>116.04631</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>-223</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.540000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>103.200</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>...</td>\n",
       "      <td>207.76701</td>\n",
       "      <td>-0.000506</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>75.50422</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>-426</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.249700</td>\n",
       "      <td>-0.001201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3657.000</td>\n",
       "      <td>-0.003204</td>\n",
       "      <td>-0.003204</td>\n",
       "      <td>-0.003204</td>\n",
       "      <td>295.000</td>\n",
       "      <td>-0.002002</td>\n",
       "      <td>...</td>\n",
       "      <td>837.68351</td>\n",
       "      <td>-0.001559</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>-0.000383</td>\n",
       "      <td>936.75587</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>-968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.175000</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>60.649</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>...</td>\n",
       "      <td>263.20515</td>\n",
       "      <td>-0.002858</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>-0.002221</td>\n",
       "      <td>267.24030</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>55</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269995</th>\n",
       "      <td>1.737250</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>30.331</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>1729.862</td>\n",
       "      <td>0.004173</td>\n",
       "      <td>...</td>\n",
       "      <td>1026.12735</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>922.67987</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>-716</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269996</th>\n",
       "      <td>0.066055</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>614355.300</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>669702.800</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>...</td>\n",
       "      <td>1149.20125</td>\n",
       "      <td>-0.004634</td>\n",
       "      <td>-0.002019</td>\n",
       "      <td>-0.002697</td>\n",
       "      <td>1102.77453</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269997</th>\n",
       "      <td>15.060000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>166.720</td>\n",
       "      <td>-0.000664</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>345.550</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>...</td>\n",
       "      <td>14.79552</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>24.07747</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>-355</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269998</th>\n",
       "      <td>0.287675</td>\n",
       "      <td>-0.000782</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>916.000</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>693.000</td>\n",
       "      <td>0.001651</td>\n",
       "      <td>...</td>\n",
       "      <td>1083.89658</td>\n",
       "      <td>-0.001226</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>741.21722</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>59</td>\n",
       "      <td>580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269999</th>\n",
       "      <td>3.215000</td>\n",
       "      <td>-0.007776</td>\n",
       "      <td>-0.001555</td>\n",
       "      <td>-0.001555</td>\n",
       "      <td>5197.042</td>\n",
       "      <td>-0.010886</td>\n",
       "      <td>-0.004666</td>\n",
       "      <td>-0.010886</td>\n",
       "      <td>977.659</td>\n",
       "      <td>-0.007776</td>\n",
       "      <td>...</td>\n",
       "      <td>335.30084</td>\n",
       "      <td>-0.008227</td>\n",
       "      <td>-0.003527</td>\n",
       "      <td>-0.008189</td>\n",
       "      <td>274.22740</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>-695</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3270000 rows × 287 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              price    high-1     low-1   close-1    volume-1    high-2  \\\n",
       "0          0.071745 -0.001185  0.002160 -0.000767  895505.000 -0.001045   \n",
       "1        136.627500 -0.001189  0.002836  0.000274    7122.590 -0.005215   \n",
       "2          5.540000  0.000000  0.000000  0.000000       0.000  0.000000   \n",
       "3          0.249700 -0.001201  0.000000  0.000000    3657.000 -0.003204   \n",
       "4         60.175000 -0.000415 -0.000415 -0.000415       0.000 -0.000415   \n",
       "...             ...       ...       ...       ...         ...       ...   \n",
       "3269995    1.737250  0.002446  0.003022  0.003022      30.331  0.002446   \n",
       "3269996    0.066055 -0.000227  0.000227 -0.000076  614355.300 -0.000076   \n",
       "3269997   15.060000  0.000000  0.000664  0.000000     166.720 -0.000664   \n",
       "3269998    0.287675 -0.000782  0.000261  0.000261     916.000  0.000261   \n",
       "3269999    3.215000 -0.007776 -0.001555 -0.001555    5197.042 -0.010886   \n",
       "\n",
       "            low-2   close-2    volume-2    high-3  ...  BTC_volume-6_5min  \\\n",
       "0        0.001882  0.001603  476370.000  0.000209  ...          277.04986   \n",
       "1        0.002690  0.001738   11109.110 -0.006972  ...          205.84605   \n",
       "2        0.000000  0.000000     103.200  0.001805  ...          207.76701   \n",
       "3       -0.003204 -0.003204     295.000 -0.002002  ...          837.68351   \n",
       "4       -0.000415 -0.000415      60.649 -0.000415  ...          263.20515   \n",
       "...           ...       ...         ...       ...  ...                ...   \n",
       "3269995  0.005325  0.003022    1729.862  0.004173  ...         1026.12735   \n",
       "3269996  0.000378  0.000076  669702.800 -0.000227  ...         1149.20125   \n",
       "3269997  0.001992  0.000664     345.550  0.000664  ...           14.79552   \n",
       "3269998  0.000956  0.000261     693.000  0.001651  ...         1083.89658   \n",
       "3269999 -0.004666 -0.010886     977.659 -0.007776  ...          335.30084   \n",
       "\n",
       "         BTC_high-7_5min  BTC_low-7_5min  BTC_close-7_5min  BTC_volume-7_5min  \\\n",
       "0              -0.002340        0.000505         -0.000979          300.78432   \n",
       "1              -0.001670       -0.000603         -0.001006          116.04631   \n",
       "2              -0.000506        0.000401          0.000380           75.50422   \n",
       "3              -0.001559        0.000747         -0.000383          936.75587   \n",
       "4              -0.002858       -0.000553         -0.002221          267.24030   \n",
       "...                  ...             ...               ...                ...   \n",
       "3269995         0.000650        0.001402          0.000911          922.67987   \n",
       "3269996        -0.004634       -0.002019         -0.002697         1102.77453   \n",
       "3269997         0.000168        0.000684          0.000556           24.07747   \n",
       "3269998        -0.001226        0.000922          0.000400          741.21722   \n",
       "3269999        -0.008227       -0.003527         -0.008189          274.22740   \n",
       "\n",
       "         day  hour  minute  lunch_day  buy  \n",
       "0          5    12      27       -621    1  \n",
       "1          5     5      18       -223    1  \n",
       "2          6     2      47       -426    1  \n",
       "3          4    21      35       -968    0  \n",
       "4          7     7      55        286    0  \n",
       "...      ...   ...     ...        ...  ...  \n",
       "3269995    7    12      19       -716    1  \n",
       "3269996    5     1      49        569    0  \n",
       "3269997    7    13      23       -355    0  \n",
       "3269998    6    12      59        580    0  \n",
       "3269999    4    10      28       -695    1  \n",
       "\n",
       "[3270000 rows x 287 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.reset_index().drop(columns=\"num_index\")\n",
    "gc.collect()\n",
    "for i in range(1):\n",
    "    df = df.reindex(np.random.permutation(df.index)).reset_index().drop(columns=\"index\")\n",
    "    gc.collect()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather(f\"../Data/fea/w{WINDOW_SIZE}_buy{BUY_PERCENT}_forcasr{MAX_FORCAST_SIZE}min_{BUY_MODE}.fea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df choosen data shape(3270000, 287)\n",
      "pair: True\n",
      "654000\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print(\"df choosen data shape\"+str(df.shape))\n",
    "print(f\"pair: {(df.shape[0]/2)==df.buy.sum()}\")\n",
    "dt=df.to_numpy(dtype=np.float32)\n",
    "#dt=df.to_numpy()\n",
    "dt=np.nan_to_num(dt,nan=0)\n",
    "#dt=dt.astype(np.float32)\n",
    "dt=np.nan_to_num(dt, neginf=0) \n",
    "dt=np.nan_to_num(dt, posinf=0) \n",
    "\n",
    "index_20percent= int(0.2*len(dt[:,0]))\n",
    "print(index_20percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # feather loading\n",
    "# df=pd.read_feather(f\"../Data/fea/w{WINDOW_SIZE}_buy{BUY_PERCENT}_forcasr{MAX_FORCAST_SIZE}min_{BUY_MODE}.fea\")\n",
    "# dt=df.to_numpy(dtype=np.float32)\n",
    "# dt=fixdt(dt)\n",
    "# index_20percent= int(0.2*len(dt[:,0]))\n",
    "# gc.collect()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Normalized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 07:50:58.854986: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-04 07:50:58.856709: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-04 07:50:58.857432: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: abj-K93SV\n",
      "2023-03-04 07:50:58.857491: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: abj-K93SV\n",
      "2023-03-04 07:50:58.858097: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2023-03-04 07:50:58.860204: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 390.154.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 286)              1144      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 250)               71750     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 250)              1000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                5020      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,015\n",
      "Trainable params: 78,943\n",
      "Non-trainable params: 1,072\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_TEST/tp92_w7_max3min_Model_v5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 07:51:07.217916: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2992704000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6000\n",
      "1022/1022 [==============================] - 49s 47ms/step - loss: 0.4806 - accuracy: 0.7800 - val_loss: 0.4734 - val_accuracy: 0.7842\n",
      "Epoch 2/6000\n",
      "1022/1022 [==============================] - 44s 43ms/step - loss: 0.4639 - accuracy: 0.7900 - val_loss: 0.4697 - val_accuracy: 0.7869\n",
      "Epoch 3/6000\n",
      "1022/1022 [==============================] - 45s 44ms/step - loss: 0.4545 - accuracy: 0.7954 - val_loss: 0.4613 - val_accuracy: 0.7912\n",
      "Epoch 4/6000\n",
      "1022/1022 [==============================] - 47s 46ms/step - loss: 0.4474 - accuracy: 0.7993 - val_loss: 0.4581 - val_accuracy: 0.7939\n",
      "Epoch 5/6000\n",
      "1022/1022 [==============================] - 46s 45ms/step - loss: 0.4417 - accuracy: 0.8023 - val_loss: 0.4500 - val_accuracy: 0.7982\n",
      "Epoch 6/6000\n",
      "1022/1022 [==============================] - 47s 46ms/step - loss: 0.4368 - accuracy: 0.8050 - val_loss: 0.4495 - val_accuracy: 0.7986\n",
      "Epoch 7/6000\n",
      "1022/1022 [==============================] - 50s 49ms/step - loss: 0.4327 - accuracy: 0.8073 - val_loss: 0.4519 - val_accuracy: 0.7972\n",
      "Epoch 8/6000\n",
      "1022/1022 [==============================] - 54s 53ms/step - loss: 0.4293 - accuracy: 0.8087 - val_loss: 0.4486 - val_accuracy: 0.7993\n",
      "Epoch 9/6000\n",
      "1022/1022 [==============================] - 62s 60ms/step - loss: 0.4265 - accuracy: 0.8104 - val_loss: 0.4475 - val_accuracy: 0.8005\n",
      "Epoch 10/6000\n",
      "1022/1022 [==============================] - 74s 72ms/step - loss: 0.4238 - accuracy: 0.8117 - val_loss: 0.4440 - val_accuracy: 0.8022\n",
      "Epoch 11/6000\n",
      "1022/1022 [==============================] - 57s 56ms/step - loss: 0.4215 - accuracy: 0.8129 - val_loss: 0.4415 - val_accuracy: 0.8035\n",
      "Epoch 12/6000\n",
      "1022/1022 [==============================] - 65s 64ms/step - loss: 0.4194 - accuracy: 0.8139 - val_loss: 0.4379 - val_accuracy: 0.8044\n",
      "Epoch 13/6000\n",
      "1022/1022 [==============================] - 58s 57ms/step - loss: 0.4176 - accuracy: 0.8148 - val_loss: 0.4466 - val_accuracy: 0.8011\n",
      "Epoch 14/6000\n",
      "1022/1022 [==============================] - 62s 60ms/step - loss: 0.4160 - accuracy: 0.8157 - val_loss: 0.4457 - val_accuracy: 0.8012\n",
      "Epoch 15/6000\n",
      "1022/1022 [==============================] - 59s 58ms/step - loss: 0.4143 - accuracy: 0.8166 - val_loss: 0.4310 - val_accuracy: 0.8086\n",
      "Epoch 16/6000\n",
      "1022/1022 [==============================] - 59s 57ms/step - loss: 0.4128 - accuracy: 0.8172 - val_loss: 0.4501 - val_accuracy: 0.8001\n",
      "Epoch 17/6000\n",
      "1022/1022 [==============================] - 59s 58ms/step - loss: 0.4116 - accuracy: 0.8177 - val_loss: 0.4337 - val_accuracy: 0.8070\n",
      "Epoch 18/6000\n",
      "1022/1022 [==============================] - 57s 56ms/step - loss: 0.4103 - accuracy: 0.8183 - val_loss: 0.4447 - val_accuracy: 0.8031\n",
      "Epoch 19/6000\n",
      "1022/1022 [==============================] - 60s 59ms/step - loss: 0.4092 - accuracy: 0.8189 - val_loss: 0.4301 - val_accuracy: 0.8089\n",
      "Epoch 20/6000\n",
      "1022/1022 [==============================] - 59s 57ms/step - loss: 0.4080 - accuracy: 0.8195 - val_loss: 0.4330 - val_accuracy: 0.8081\n",
      "Epoch 21/6000\n",
      "1022/1022 [==============================] - 58s 57ms/step - loss: 0.4072 - accuracy: 0.8197 - val_loss: 0.4350 - val_accuracy: 0.8079\n",
      "Epoch 22/6000\n",
      "1022/1022 [==============================] - 60s 58ms/step - loss: 0.4063 - accuracy: 0.8201 - val_loss: 0.4402 - val_accuracy: 0.8044\n",
      "Epoch 23/6000\n",
      "1022/1022 [==============================] - 61s 59ms/step - loss: 0.4053 - accuracy: 0.8208 - val_loss: 0.4447 - val_accuracy: 0.8025\n",
      "Epoch 24/6000\n",
      "1022/1022 [==============================] - 58s 57ms/step - loss: 0.4045 - accuracy: 0.8212 - val_loss: 0.4285 - val_accuracy: 0.8099\n",
      "Epoch 25/6000\n",
      "1022/1022 [==============================] - 59s 57ms/step - loss: 0.4035 - accuracy: 0.8215 - val_loss: 0.4278 - val_accuracy: 0.8096\n",
      "Epoch 26/6000\n",
      "1022/1022 [==============================] - 58s 57ms/step - loss: 0.4030 - accuracy: 0.8218 - val_loss: 0.4438 - val_accuracy: 0.8038\n",
      "Epoch 27/6000\n",
      "1022/1022 [==============================] - 60s 58ms/step - loss: 0.4021 - accuracy: 0.8222 - val_loss: 0.4372 - val_accuracy: 0.8055\n",
      "Epoch 28/6000\n",
      "1022/1022 [==============================] - 59s 58ms/step - loss: 0.4014 - accuracy: 0.8225 - val_loss: 0.4333 - val_accuracy: 0.8072\n",
      "Epoch 29/6000\n",
      "1022/1022 [==============================] - 59s 58ms/step - loss: 0.4009 - accuracy: 0.8227 - val_loss: 0.4292 - val_accuracy: 0.8093\n",
      "Epoch 30/6000\n",
      "1022/1022 [==============================] - 58s 57ms/step - loss: 0.4004 - accuracy: 0.8229 - val_loss: 0.4296 - val_accuracy: 0.8092\n",
      "Epoch 31/6000\n",
      "1022/1022 [==============================] - 58s 57ms/step - loss: 0.3998 - accuracy: 0.8233 - val_loss: 0.4270 - val_accuracy: 0.8110\n",
      "Epoch 32/6000\n",
      "1022/1022 [==============================] - 59s 57ms/step - loss: 0.3988 - accuracy: 0.8236 - val_loss: 0.4263 - val_accuracy: 0.8108\n",
      "Epoch 33/6000\n",
      "1022/1022 [==============================] - 59s 58ms/step - loss: 0.3984 - accuracy: 0.8238 - val_loss: 0.4291 - val_accuracy: 0.8085\n",
      "Epoch 34/6000\n",
      "1022/1022 [==============================] - 58s 57ms/step - loss: 0.3979 - accuracy: 0.8242 - val_loss: 0.4246 - val_accuracy: 0.8115\n",
      "Epoch 35/6000\n",
      "1022/1022 [==============================] - 60s 59ms/step - loss: 0.3972 - accuracy: 0.8246 - val_loss: 0.4255 - val_accuracy: 0.8109\n",
      "Epoch 36/6000\n",
      "1022/1022 [==============================] - 63s 61ms/step - loss: 0.3968 - accuracy: 0.8247 - val_loss: 0.4313 - val_accuracy: 0.8076\n",
      "Epoch 37/6000\n",
      "1022/1022 [==============================] - 63s 62ms/step - loss: 0.3965 - accuracy: 0.8248 - val_loss: 0.4241 - val_accuracy: 0.8116\n",
      "Epoch 38/6000\n",
      "1022/1022 [==============================] - 68s 67ms/step - loss: 0.3960 - accuracy: 0.8253 - val_loss: 0.4245 - val_accuracy: 0.8119\n",
      "Epoch 39/6000\n",
      "1022/1022 [==============================] - 63s 61ms/step - loss: 0.3953 - accuracy: 0.8255 - val_loss: 0.4256 - val_accuracy: 0.8106\n",
      "Epoch 40/6000\n",
      "1022/1022 [==============================] - 63s 62ms/step - loss: 0.3949 - accuracy: 0.8256 - val_loss: 0.4258 - val_accuracy: 0.8110\n",
      "Epoch 41/6000\n",
      "1022/1022 [==============================] - 60s 59ms/step - loss: 0.3945 - accuracy: 0.8258 - val_loss: 0.4310 - val_accuracy: 0.8081\n",
      "Epoch 42/6000\n",
      "1022/1022 [==============================] - 61s 60ms/step - loss: 0.3942 - accuracy: 0.8259 - val_loss: 0.4416 - val_accuracy: 0.8037\n",
      "Epoch 43/6000\n",
      "1022/1022 [==============================] - 68s 67ms/step - loss: 0.3936 - accuracy: 0.8262 - val_loss: 0.4289 - val_accuracy: 0.8096\n",
      "Epoch 44/6000\n",
      "1022/1022 [==============================] - 73s 72ms/step - loss: 0.3932 - accuracy: 0.8265 - val_loss: 0.4323 - val_accuracy: 0.8081\n",
      "Epoch 45/6000\n",
      "1022/1022 [==============================] - 72s 70ms/step - loss: 0.3932 - accuracy: 0.8265 - val_loss: 0.4226 - val_accuracy: 0.8123\n",
      "Epoch 46/6000\n",
      "1022/1022 [==============================] - 67s 66ms/step - loss: 0.3924 - accuracy: 0.8269 - val_loss: 0.4222 - val_accuracy: 0.8128\n",
      "Epoch 47/6000\n",
      "1022/1022 [==============================] - 66s 65ms/step - loss: 0.3921 - accuracy: 0.8270 - val_loss: 0.4285 - val_accuracy: 0.8106\n",
      "Epoch 48/6000\n",
      "1022/1022 [==============================] - 71s 69ms/step - loss: 0.3918 - accuracy: 0.8271 - val_loss: 0.4267 - val_accuracy: 0.8106\n",
      "Epoch 49/6000\n",
      "1022/1022 [==============================] - 71s 69ms/step - loss: 0.3915 - accuracy: 0.8271 - val_loss: 0.4315 - val_accuracy: 0.8079\n",
      "Epoch 50/6000\n",
      "1022/1022 [==============================] - 70s 69ms/step - loss: 0.3911 - accuracy: 0.8276 - val_loss: 0.4206 - val_accuracy: 0.8137\n",
      "Epoch 51/6000\n",
      "1022/1022 [==============================] - 69s 68ms/step - loss: 0.3908 - accuracy: 0.8276 - val_loss: 0.4232 - val_accuracy: 0.8126\n",
      "Epoch 52/6000\n",
      "1022/1022 [==============================] - 63s 62ms/step - loss: 0.3903 - accuracy: 0.8278 - val_loss: 0.4217 - val_accuracy: 0.8132\n",
      "Epoch 53/6000\n",
      "1022/1022 [==============================] - 70s 69ms/step - loss: 0.3900 - accuracy: 0.8280 - val_loss: 0.4294 - val_accuracy: 0.8096\n",
      "Epoch 54/6000\n",
      "1022/1022 [==============================] - 70s 68ms/step - loss: 0.3898 - accuracy: 0.8281 - val_loss: 0.4299 - val_accuracy: 0.8094\n",
      "Epoch 55/6000\n",
      "1022/1022 [==============================] - 71s 69ms/step - loss: 0.3895 - accuracy: 0.8282 - val_loss: 0.4371 - val_accuracy: 0.8051\n",
      "Epoch 56/6000\n",
      "1022/1022 [==============================] - 70s 68ms/step - loss: 0.3890 - accuracy: 0.8283 - val_loss: 0.4201 - val_accuracy: 0.8139\n",
      "Epoch 57/6000\n",
      "1022/1022 [==============================] - 69s 68ms/step - loss: 0.3890 - accuracy: 0.8285 - val_loss: 0.4206 - val_accuracy: 0.8135\n",
      "Epoch 58/6000\n",
      "1022/1022 [==============================] - 69s 68ms/step - loss: 0.3885 - accuracy: 0.8287 - val_loss: 0.4355 - val_accuracy: 0.8065\n",
      "Epoch 59/6000\n",
      "1022/1022 [==============================] - 69s 67ms/step - loss: 0.3883 - accuracy: 0.8287 - val_loss: 0.4207 - val_accuracy: 0.8139\n",
      "Epoch 60/6000\n",
      "1022/1022 [==============================] - 76s 74ms/step - loss: 0.3879 - accuracy: 0.8289 - val_loss: 0.4222 - val_accuracy: 0.8129\n",
      "Epoch 61/6000\n",
      "1022/1022 [==============================] - 67s 66ms/step - loss: 0.3879 - accuracy: 0.8291 - val_loss: 0.4353 - val_accuracy: 0.8071\n",
      "Epoch 62/6000\n",
      "1022/1022 [==============================] - 68s 67ms/step - loss: 0.3875 - accuracy: 0.8293 - val_loss: 0.4219 - val_accuracy: 0.8135\n",
      "Epoch 63/6000\n",
      "1022/1022 [==============================] - 71s 69ms/step - loss: 0.3871 - accuracy: 0.8294 - val_loss: 0.4212 - val_accuracy: 0.8137\n",
      "Epoch 64/6000\n",
      "1022/1022 [==============================] - 76s 75ms/step - loss: 0.3871 - accuracy: 0.8294 - val_loss: 0.4197 - val_accuracy: 0.8143\n",
      "Epoch 65/6000\n",
      "1022/1022 [==============================] - 73s 71ms/step - loss: 0.3870 - accuracy: 0.8293 - val_loss: 0.4329 - val_accuracy: 0.8081\n",
      "Epoch 66/6000\n",
      "1022/1022 [==============================] - 68s 67ms/step - loss: 0.3866 - accuracy: 0.8297 - val_loss: 0.4342 - val_accuracy: 0.8077\n",
      "Epoch 67/6000\n",
      "1022/1022 [==============================] - 63s 61ms/step - loss: 0.3861 - accuracy: 0.8297 - val_loss: 0.4233 - val_accuracy: 0.8123\n",
      "Epoch 68/6000\n",
      "1022/1022 [==============================] - 60s 59ms/step - loss: 0.3860 - accuracy: 0.8300 - val_loss: 0.4347 - val_accuracy: 0.8069\n",
      "Epoch 69/6000\n",
      "1022/1022 [==============================] - 59s 58ms/step - loss: 0.3859 - accuracy: 0.8299 - val_loss: 0.4397 - val_accuracy: 0.8049\n",
      "Epoch 70/6000\n",
      "1022/1022 [==============================] - 59s 58ms/step - loss: 0.3856 - accuracy: 0.8300 - val_loss: 0.4216 - val_accuracy: 0.8132\n",
      "Epoch 71/6000\n",
      "1022/1022 [==============================] - 61s 60ms/step - loss: 0.3855 - accuracy: 0.8300 - val_loss: 0.4199 - val_accuracy: 0.8141\n",
      "Epoch 72/6000\n",
      "1022/1022 [==============================] - 72s 71ms/step - loss: 0.3851 - accuracy: 0.8302 - val_loss: 0.4294 - val_accuracy: 0.8095\n",
      "Epoch 73/6000\n",
      "1022/1022 [==============================] - 72s 71ms/step - loss: 0.3849 - accuracy: 0.8304 - val_loss: 0.4233 - val_accuracy: 0.8117\n",
      "Epoch 74/6000\n",
      "1022/1022 [==============================] - 70s 69ms/step - loss: 0.3849 - accuracy: 0.8304 - val_loss: 0.4352 - val_accuracy: 0.8054\n",
      "Epoch 75/6000\n",
      "1022/1022 [==============================] - 67s 66ms/step - loss: 0.3845 - accuracy: 0.8305 - val_loss: 0.4275 - val_accuracy: 0.8104\n",
      "Epoch 76/6000\n",
      "1022/1022 [==============================] - 70s 68ms/step - loss: 0.3843 - accuracy: 0.8307 - val_loss: 0.4197 - val_accuracy: 0.8145\n",
      "Epoch 77/6000\n",
      "1022/1022 [==============================] - 74s 72ms/step - loss: 0.3841 - accuracy: 0.8308 - val_loss: 0.4291 - val_accuracy: 0.8095\n",
      "Epoch 78/6000\n",
      "1022/1022 [==============================] - 71s 70ms/step - loss: 0.3838 - accuracy: 0.8308 - val_loss: 0.4225 - val_accuracy: 0.8133\n",
      "Epoch 79/6000\n",
      "1022/1022 [==============================] - 69s 68ms/step - loss: 0.3835 - accuracy: 0.8311 - val_loss: 0.4192 - val_accuracy: 0.8146\n",
      "Epoch 80/6000\n",
      "1022/1022 [==============================] - 68s 66ms/step - loss: 0.3836 - accuracy: 0.8311 - val_loss: 0.4223 - val_accuracy: 0.8129\n",
      "Epoch 81/6000\n",
      "1022/1022 [==============================] - 69s 67ms/step - loss: 0.3835 - accuracy: 0.8310 - val_loss: 0.4251 - val_accuracy: 0.8114\n",
      "Epoch 82/6000\n",
      "1022/1022 [==============================] - 71s 69ms/step - loss: 0.3830 - accuracy: 0.8313 - val_loss: 0.4188 - val_accuracy: 0.8149\n",
      "Epoch 83/6000\n",
      "1022/1022 [==============================] - 72s 71ms/step - loss: 0.3831 - accuracy: 0.8311 - val_loss: 0.4184 - val_accuracy: 0.8147\n",
      "Epoch 84/6000\n",
      "1022/1022 [==============================] - 65s 64ms/step - loss: 0.3828 - accuracy: 0.8314 - val_loss: 0.4198 - val_accuracy: 0.8142\n",
      "Epoch 85/6000\n",
      "1022/1022 [==============================] - 68s 66ms/step - loss: 0.3827 - accuracy: 0.8313 - val_loss: 0.4165 - val_accuracy: 0.8160\n",
      "Epoch 86/6000\n",
      "1022/1022 [==============================] - 71s 69ms/step - loss: 0.3823 - accuracy: 0.8314 - val_loss: 0.4223 - val_accuracy: 0.8135\n",
      "Epoch 87/6000\n",
      "1022/1022 [==============================] - 68s 67ms/step - loss: 0.3822 - accuracy: 0.8315 - val_loss: 0.4229 - val_accuracy: 0.8130\n",
      "Epoch 88/6000\n",
      "1022/1022 [==============================] - 69s 68ms/step - loss: 0.3821 - accuracy: 0.8316 - val_loss: 0.4196 - val_accuracy: 0.8149\n",
      "Epoch 89/6000\n",
      "1022/1022 [==============================] - 65s 63ms/step - loss: 0.3820 - accuracy: 0.8317 - val_loss: 0.4176 - val_accuracy: 0.8157\n",
      "Epoch 90/6000\n",
      "1022/1022 [==============================] - 72s 70ms/step - loss: 0.3818 - accuracy: 0.8317 - val_loss: 0.4244 - val_accuracy: 0.8122\n",
      "Epoch 91/6000\n",
      "1022/1022 [==============================] - 70s 69ms/step - loss: 0.3817 - accuracy: 0.8319 - val_loss: 0.4209 - val_accuracy: 0.8141\n",
      "Epoch 92/6000\n",
      "1022/1022 [==============================] - 70s 69ms/step - loss: 0.3816 - accuracy: 0.8318 - val_loss: 0.4249 - val_accuracy: 0.8118\n",
      "Epoch 93/6000\n",
      "1022/1022 [==============================] - 71s 70ms/step - loss: 0.3813 - accuracy: 0.8319 - val_loss: 0.4312 - val_accuracy: 0.8086\n",
      "Epoch 94/6000\n",
      "1022/1022 [==============================] - 68s 67ms/step - loss: 0.3811 - accuracy: 0.8320 - val_loss: 0.4362 - val_accuracy: 0.8064\n",
      "Epoch 95/6000\n",
      "1022/1022 [==============================] - 75s 73ms/step - loss: 0.3812 - accuracy: 0.8319 - val_loss: 0.4197 - val_accuracy: 0.8144\n",
      "Epoch 96/6000\n",
      "1022/1022 [==============================] - 69s 68ms/step - loss: 0.3809 - accuracy: 0.8322 - val_loss: 0.4252 - val_accuracy: 0.8114\n",
      "Epoch 97/6000\n",
      "1022/1022 [==============================] - 71s 69ms/step - loss: 0.3807 - accuracy: 0.8321 - val_loss: 0.4303 - val_accuracy: 0.8092\n",
      "Epoch 98/6000\n",
      "1022/1022 [==============================] - 64s 63ms/step - loss: 0.3804 - accuracy: 0.8323 - val_loss: 0.4256 - val_accuracy: 0.8112\n",
      "Epoch 99/6000\n",
      "1022/1022 [==============================] - 60s 59ms/step - loss: 0.3804 - accuracy: 0.8324 - val_loss: 0.4173 - val_accuracy: 0.8155\n",
      "Epoch 100/6000\n",
      "1022/1022 [==============================] - 60s 59ms/step - loss: 0.3800 - accuracy: 0.8326 - val_loss: 0.4373 - val_accuracy: 0.8058\n",
      "Epoch 100: early stopping\n",
      "##########################################################################\n",
      "------val_accuracy-----> 81.6 | 83.26 <----------accuracy----------\n",
      "/UltimeTradingBot/Data/BUY_TEST/tp92_w7_max3min_Norm_v5.json\n",
      "/UltimeTradingBot/Data/BUY_TEST/tp92_w7_max3min_Model_v5.h5\n",
      "save to: /UltimeTradingBot/Data/BUY_TEST/tp92_w7_max3min_Model_vInit.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Normalzed Model\n",
    "IN_DIM=dt.shape[1]-1\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(IN_DIM,)))\n",
    "model.add(Dense(int(250),activation='relu')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(20),activation='relu')) \n",
    "model.add(Dense(int(50),activation='relu')) \n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "print(model.summary())\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "callbacks_a = ModelCheckpoint(filepath =Model_FileName,monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "callbacks_b = EarlyStopping(monitor ='val_accuracy',mode='auto',patience=15,verbose=1)\n",
    "print(\"saving file in: \"+Model_FileName)\n",
    "history = model.fit(dt[index_20percent:, 0:-1],\n",
    "                dt[index_20percent:,-1],\n",
    "                validation_data=(dt[:index_20percent, :-1],dt[:index_20percent,-1]),\n",
    "                epochs=6000,\n",
    "                batch_size=256*10,\n",
    "                callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "print('##########################################################################')\n",
    "print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "print(Normalization_File)\n",
    "print(Model_FileName)\n",
    "model_init_file=Model_FileName.replace(f\"_v{VERSION}\", \"_vInit\")\n",
    "print(f\"save to: {model_init_file}\")\n",
    "model.save(model_init_file)\n",
    "model_init=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_init_file=Model_FileName.replace(f\"_v{VERSION}\", \"_vInit\")\n",
    "# print(f\"save to: {model_init_file}\")\n",
    "# model.save(model_init_file)\n",
    "# model_init=model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Model Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_2 (Batc  (None, 286)              1144      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 300)               86100     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 300)              1200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 300)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 200)              800       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 80)               320       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 80)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 80)               320       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 80)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 80)               320       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 80)               320       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 80)               320       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 20)                1620      \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 20)               80        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 194,765\n",
      "Trainable params: 192,353\n",
      "Non-trainable params: 2,412\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_TEST/tp92_w7_max3min_Model_v5.h5\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 09:38:29.084735: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2992704000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 170s 161ms/step - loss: 0.4886 - accuracy: 0.7755 - val_loss: 0.4828 - val_accuracy: 0.7772\n",
      "Epoch 2/500\n",
      "1022/1022 [==============================] - 165s 161ms/step - loss: 0.4760 - accuracy: 0.7828 - val_loss: 0.4727 - val_accuracy: 0.7844\n",
      "Epoch 3/500\n",
      "1022/1022 [==============================] - 164s 161ms/step - loss: 0.4697 - accuracy: 0.7866 - val_loss: 0.4675 - val_accuracy: 0.7882\n",
      "Epoch 4/500\n",
      "1022/1022 [==============================] - 163s 160ms/step - loss: 0.4631 - accuracy: 0.7906 - val_loss: 0.4607 - val_accuracy: 0.7925\n",
      "Epoch 5/500\n",
      "1022/1022 [==============================] - 167s 164ms/step - loss: 0.4569 - accuracy: 0.7942 - val_loss: 0.4575 - val_accuracy: 0.7941\n",
      "Epoch 6/500\n",
      "1022/1022 [==============================] - 161s 158ms/step - loss: 0.4513 - accuracy: 0.7973 - val_loss: 0.4507 - val_accuracy: 0.7979\n",
      "Epoch 7/500\n",
      "1022/1022 [==============================] - 163s 160ms/step - loss: 0.4464 - accuracy: 0.7999 - val_loss: 0.4488 - val_accuracy: 0.7983\n",
      "Epoch 8/500\n",
      "1022/1022 [==============================] - 165s 162ms/step - loss: 0.4423 - accuracy: 0.8019 - val_loss: 0.4497 - val_accuracy: 0.8002\n",
      "Epoch 9/500\n",
      "1022/1022 [==============================] - 169s 165ms/step - loss: 0.4388 - accuracy: 0.8037 - val_loss: 0.4466 - val_accuracy: 0.8008\n",
      "Epoch 10/500\n",
      "1022/1022 [==============================] - 165s 161ms/step - loss: 0.4357 - accuracy: 0.8051 - val_loss: 0.4563 - val_accuracy: 0.7946\n",
      "Epoch 11/500\n",
      "1022/1022 [==============================] - 163s 160ms/step - loss: 0.4331 - accuracy: 0.8069 - val_loss: 0.4378 - val_accuracy: 0.8042\n",
      "Epoch 12/500\n",
      "1022/1022 [==============================] - 164s 161ms/step - loss: 0.4306 - accuracy: 0.8079 - val_loss: 0.4362 - val_accuracy: 0.8055\n",
      "Epoch 13/500\n",
      "1022/1022 [==============================] - 165s 161ms/step - loss: 0.4287 - accuracy: 0.8089 - val_loss: 0.4452 - val_accuracy: 0.7999\n",
      "Epoch 14/500\n",
      "1022/1022 [==============================] - 165s 162ms/step - loss: 0.4266 - accuracy: 0.8100 - val_loss: 0.4294 - val_accuracy: 0.8075\n",
      "Epoch 15/500\n",
      "1022/1022 [==============================] - 162s 159ms/step - loss: 0.4250 - accuracy: 0.8107 - val_loss: 0.4314 - val_accuracy: 0.8075\n",
      "Epoch 16/500\n",
      "1022/1022 [==============================] - 163s 160ms/step - loss: 0.4236 - accuracy: 0.8118 - val_loss: 0.4433 - val_accuracy: 0.8039\n",
      "Epoch 17/500\n",
      "1022/1022 [==============================] - 161s 158ms/step - loss: 0.4224 - accuracy: 0.8122 - val_loss: 0.4380 - val_accuracy: 0.8038\n",
      "Epoch 18/500\n",
      "1022/1022 [==============================] - 163s 159ms/step - loss: 0.4211 - accuracy: 0.8127 - val_loss: 0.4355 - val_accuracy: 0.8039\n",
      "Epoch 19/500\n",
      "1022/1022 [==============================] - 163s 159ms/step - loss: 0.4202 - accuracy: 0.8134 - val_loss: 0.4346 - val_accuracy: 0.8047\n",
      "Epoch 20/500\n",
      "1022/1022 [==============================] - 168s 164ms/step - loss: 0.4187 - accuracy: 0.8140 - val_loss: 0.4275 - val_accuracy: 0.8088\n",
      "Epoch 21/500\n",
      "1022/1022 [==============================] - 165s 161ms/step - loss: 0.4178 - accuracy: 0.8144 - val_loss: 0.4232 - val_accuracy: 0.8118\n",
      "Epoch 22/500\n",
      "1022/1022 [==============================] - 164s 161ms/step - loss: 0.4169 - accuracy: 0.8147 - val_loss: 0.4313 - val_accuracy: 0.8084\n",
      "Epoch 23/500\n",
      "1022/1022 [==============================] - 163s 160ms/step - loss: 0.4157 - accuracy: 0.8154 - val_loss: 0.4327 - val_accuracy: 0.8056\n",
      "Epoch 24/500\n",
      "1022/1022 [==============================] - 162s 159ms/step - loss: 0.4149 - accuracy: 0.8157 - val_loss: 0.4227 - val_accuracy: 0.8112\n",
      "Epoch 25/500\n",
      "1022/1022 [==============================] - 165s 161ms/step - loss: 0.4142 - accuracy: 0.8161 - val_loss: 0.4218 - val_accuracy: 0.8118\n",
      "Epoch 26/500\n",
      "1022/1022 [==============================] - 164s 160ms/step - loss: 0.4133 - accuracy: 0.8166 - val_loss: 0.4207 - val_accuracy: 0.8112\n",
      "Epoch 27/500\n",
      "1022/1022 [==============================] - 166s 163ms/step - loss: 0.4127 - accuracy: 0.8168 - val_loss: 0.4304 - val_accuracy: 0.8069\n",
      "Epoch 28/500\n",
      "1022/1022 [==============================] - 163s 160ms/step - loss: 0.4120 - accuracy: 0.8171 - val_loss: 0.4248 - val_accuracy: 0.8089\n",
      "Epoch 29/500\n",
      "1022/1022 [==============================] - 166s 163ms/step - loss: 0.4113 - accuracy: 0.8174 - val_loss: 0.4168 - val_accuracy: 0.8162\n",
      "Epoch 30/500\n",
      "1022/1022 [==============================] - 164s 160ms/step - loss: 0.4108 - accuracy: 0.8177 - val_loss: 0.4373 - val_accuracy: 0.8044\n",
      "Epoch 31/500\n",
      "1022/1022 [==============================] - 164s 161ms/step - loss: 0.4105 - accuracy: 0.8177 - val_loss: 0.4199 - val_accuracy: 0.8140\n",
      "Epoch 32/500\n",
      "1022/1022 [==============================] - 165s 161ms/step - loss: 0.4096 - accuracy: 0.8184 - val_loss: 0.4332 - val_accuracy: 0.8054\n",
      "Epoch 33/500\n",
      "1022/1022 [==============================] - 163s 160ms/step - loss: 0.4089 - accuracy: 0.8185 - val_loss: 0.4224 - val_accuracy: 0.8101\n",
      "Epoch 34/500\n",
      "1022/1022 [==============================] - 163s 160ms/step - loss: 0.4085 - accuracy: 0.8189 - val_loss: 0.4182 - val_accuracy: 0.8129\n",
      "Epoch 35/500\n",
      "1022/1022 [==============================] - 163s 159ms/step - loss: 0.4079 - accuracy: 0.8192 - val_loss: 0.4203 - val_accuracy: 0.8120\n",
      "Epoch 35: early stopping\n",
      "/UltimeTradingBot/Data/BUY_TEST/tp92_w7_max3min_Model_VeryDeep.h5\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# Define the class weights\n",
    "class_weights = {0: 1., 1: 1.}\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "SizeTunner = 1\n",
    "IN_DIM = dt.shape[1] - 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(IN_DIM,)))\n",
    "model.add(Dense(int(300 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(200 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(80 * SizeTunner), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(20 * SizeTunner), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=Model_FileName, monitor='val_accuracy', save_best_only=True, save_weights=True),\n",
    "    EarlyStopping(monitor='val_accuracy', mode='auto', patience=6, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"saving file in: \" + Model_FileName)\n",
    "history = model.fit(dt[index_20percent:, :-1],\n",
    "                    dt[index_20percent:, -1],\n",
    "                    validation_data=(dt[:index_20percent, :-1], dt[:index_20percent, -1]),\n",
    "                    epochs=500,\n",
    "                    batch_size=256*10,\n",
    "                    callbacks=callbacks,\n",
    "                    class_weight=class_weights)\n",
    "\n",
    "verydeep_model_file=f'{DATA_DIR}/tp{int(BUY_PERCENT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+\"_VeryDeep.h5\"\n",
    "model.save(verydeep_model_file)\n",
    "print(verydeep_model_file)\n",
    "very_deep_model=load_model(f'{DATA_DIR}/tp{int(BUY_PERCENT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+\"_VeryDeep.h5\")\n",
    "#868/868 [==============================] - 30s 35ms/step - loss: 0.6078 - accuracy: 0.6664 - val_loss: 0.6107 - val_accuracy: 0.6639 >0.6646\n",
    "#Results after 380 min\n",
    "# Epoch 133/500\n",
    "# 347/347 [==============================] - 138s 398ms/step - loss: 0.5867 - accuracy: 0.6842 - val_loss: 0.5839 - val_accuracy: 0.6863\n",
    "# Epoch 134/500\n",
    "# 347/347 [==============================] - 137s 395ms/step - loss: 0.5865 - accuracy: 0.6843 - val_loss: 0.5845 - val_accuracy: 0.6861\n",
    "# Epoch 134: early stopping\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini_range_start=0\n",
    "# mini_range_stop=200000\n",
    "# model.evaluate(dt[mini_range_start:mini_range_stop,:-1],dt[mini_range_start:mini_range_stop,-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-  Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stats plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 11:14:26.441717: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3740880000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102188/102188 [==============================] - 367s 4ms/step\n",
      "Precent Mean: 44.825%\n",
      "Precent Mean: 0.203%\n",
      "ModelAccuracy: 81.586%\n",
      "True Win Predictions Mean of all: 38.206%\n",
      "XXX Loss Buy Mean of all: 6.619%\n",
      "Missed good deal off all: 11.794%\n",
      "Good Zero prediction Mean: 43.381%\n",
      "good fiability\n",
      "========= Win Ratio:85.23368655883993 ====================\n"
     ]
    }
   ],
   "source": [
    "USED_MODEL=very_deep_model\n",
    "#model_init=model\n",
    "#USED_MODEL=model_init#load_model(\"/UltimeTradingBot/Data/BUY_UP_CLOSE/tp60_w6_max3min_Model_GoodVeryDeep.h5\")\n",
    "Prediction_Note=USED_MODEL.predict( dt[:, 0:-1])\n",
    "prediction2=Prediction_Note.round()\n",
    "hp(prediction2[:,0].mean())\n",
    "PesemisticPrediction=(Prediction_Note[:,0]-0.49).round()\n",
    "hp(PesemisticPrediction.mean())\n",
    "Y=dt[:,-1].copy()\n",
    "Pred01=prediction2[:,-1]\n",
    "Original_Traget_Data=Y\n",
    "Predicted_Data=Pred01\n",
    "\n",
    "TruePred=((Original_Traget_Data==Predicted_Data)).copy()\n",
    "ModelAccuracy=hp(TruePred.mean(),\"ModelAccuracy\")\n",
    "\n",
    "TrueWinPred=((Predicted_Data==1) & (Original_Traget_Data==1) ).copy()\n",
    "TrueWinPred_Mean=hp(TrueWinPred.mean(),\"True Win Predictions Mean of all\")\n",
    "\n",
    "LossPred=((Predicted_Data==1) & (Original_Traget_Data==0) ).copy()\n",
    "LossPred_Mean=hp(LossPred.mean(),\"XXX Loss Buy Mean of all\")\n",
    "\n",
    "MissedDealPred=((Predicted_Data==0) & (Original_Traget_Data==1) ).copy()\n",
    "MissedDeal_Mean=hp(MissedDealPred.mean(),\"Missed good deal off all\")\n",
    "\n",
    "GoodZeroPred=((Predicted_Data==0) & (Original_Traget_Data==0) ).copy()\n",
    "GoodZero_Mean=hp(GoodZeroPred.mean(),\"Good Zero prediction Mean\")\n",
    "\n",
    "fiability=TrueWinPred_Mean + LossPred_Mean + MissedDeal_Mean + GoodZero_Mean\n",
    "if( fiability == 100):print(\"good fiability\")\n",
    "else: print(f\"check the fiability {fiability}\")\n",
    "\n",
    "winratio=TrueWinPred_Mean/(LossPred_Mean+TrueWinPred_Mean)\n",
    "print(f\"========= Win Ratio:{winratio*100} ====================\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANTI Retrain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_dt=dt[TruePred]\n",
    "# good_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bad_dt=dt[ np.logical_not(TruePred)]\n",
    "bad_dt=dt[Predicted_Data==1 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size is : 432894\n",
      "Precent Mean: 50.000%\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_11 (Bat  (None, 286)              1144      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 200)               57400     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 80)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 80)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 80)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110,745\n",
      "Trainable params: 109,133\n",
      "Non-trainable params: 1,612\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_TEST/tp92_w7_max3min_Model_v5.h5\n",
      "Epoch 1/500\n",
      "339/339 [==============================] - 16s 36ms/step - loss: 0.3363 - accuracy: 0.5880 - val_loss: 0.6851 - val_accuracy: 0.5789\n",
      "Epoch 2/500\n",
      "339/339 [==============================] - 14s 42ms/step - loss: 0.3305 - accuracy: 0.6072 - val_loss: 0.6606 - val_accuracy: 0.6140\n",
      "Epoch 3/500\n",
      "339/339 [==============================] - 15s 44ms/step - loss: 0.3288 - accuracy: 0.6114 - val_loss: 0.6482 - val_accuracy: 0.6140\n",
      "Epoch 4/500\n",
      "339/339 [==============================] - 14s 41ms/step - loss: 0.3275 - accuracy: 0.6156 - val_loss: 0.6598 - val_accuracy: 0.6140\n",
      "Epoch 5/500\n",
      "339/339 [==============================] - 14s 41ms/step - loss: 0.3264 - accuracy: 0.6183 - val_loss: 0.6803 - val_accuracy: 0.6140\n",
      "Epoch 6/500\n",
      "339/339 [==============================] - 14s 42ms/step - loss: 0.3254 - accuracy: 0.6204 - val_loss: 0.6442 - val_accuracy: 0.6491\n",
      "Epoch 7/500\n",
      "339/339 [==============================] - 14s 43ms/step - loss: 0.3243 - accuracy: 0.6233 - val_loss: 0.6590 - val_accuracy: 0.5965\n",
      "Epoch 8/500\n",
      "339/339 [==============================] - 14s 41ms/step - loss: 0.3233 - accuracy: 0.6243 - val_loss: 0.6557 - val_accuracy: 0.5789\n",
      "Epoch 9/500\n",
      "339/339 [==============================] - 14s 41ms/step - loss: 0.3222 - accuracy: 0.6278 - val_loss: 0.6323 - val_accuracy: 0.5789\n",
      "Epoch 10/500\n",
      "339/339 [==============================] - 15s 43ms/step - loss: 0.3213 - accuracy: 0.6306 - val_loss: 0.6601 - val_accuracy: 0.6491\n",
      "Epoch 11/500\n",
      "339/339 [==============================] - 14s 42ms/step - loss: 0.3203 - accuracy: 0.6321 - val_loss: 0.6344 - val_accuracy: 0.6491\n",
      "Epoch 12/500\n",
      "339/339 [==============================] - 14s 41ms/step - loss: 0.3193 - accuracy: 0.6341 - val_loss: 0.6478 - val_accuracy: 0.6140\n",
      "Epoch 13/500\n",
      "339/339 [==============================] - 14s 41ms/step - loss: 0.3183 - accuracy: 0.6357 - val_loss: 0.6388 - val_accuracy: 0.6491\n",
      "Epoch 14/500\n",
      "339/339 [==============================] - 15s 44ms/step - loss: 0.3175 - accuracy: 0.6378 - val_loss: 0.6495 - val_accuracy: 0.5965\n",
      "Epoch 15/500\n",
      "339/339 [==============================] - 14s 41ms/step - loss: 0.3165 - accuracy: 0.6397 - val_loss: 0.6545 - val_accuracy: 0.5965\n",
      "Epoch 16/500\n",
      "339/339 [==============================] - 14s 42ms/step - loss: 0.3156 - accuracy: 0.6419 - val_loss: 0.6380 - val_accuracy: 0.5789\n",
      "Epoch 17/500\n",
      "339/339 [==============================] - 15s 44ms/step - loss: 0.3147 - accuracy: 0.6431 - val_loss: 0.6491 - val_accuracy: 0.5965\n",
      "Epoch 18/500\n",
      "339/339 [==============================] - 15s 44ms/step - loss: 0.3142 - accuracy: 0.6437 - val_loss: 0.6342 - val_accuracy: 0.6491\n",
      "Epoch 19/500\n",
      "339/339 [==============================] - 14s 41ms/step - loss: 0.3132 - accuracy: 0.6462 - val_loss: 0.6362 - val_accuracy: 0.6491\n",
      "Epoch 20/500\n",
      "339/339 [==============================] - 16s 47ms/step - loss: 0.3126 - accuracy: 0.6475 - val_loss: 0.6410 - val_accuracy: 0.6491\n",
      "Epoch 21/500\n",
      "339/339 [==============================] - 17s 50ms/step - loss: 0.3118 - accuracy: 0.6483 - val_loss: 0.6148 - val_accuracy: 0.6667\n",
      "Epoch 22/500\n",
      "339/339 [==============================] - 15s 44ms/step - loss: 0.3113 - accuracy: 0.6495 - val_loss: 0.6229 - val_accuracy: 0.6491\n",
      "Epoch 23/500\n",
      "339/339 [==============================] - 14s 42ms/step - loss: 0.3105 - accuracy: 0.6527 - val_loss: 0.6487 - val_accuracy: 0.6140\n",
      "Epoch 24/500\n",
      "339/339 [==============================] - 15s 44ms/step - loss: 0.3100 - accuracy: 0.6533 - val_loss: 0.6183 - val_accuracy: 0.6316\n",
      "Epoch 25/500\n",
      "339/339 [==============================] - 15s 43ms/step - loss: 0.3095 - accuracy: 0.6535 - val_loss: 0.6259 - val_accuracy: 0.6140\n",
      "Epoch 26/500\n",
      "339/339 [==============================] - 14s 43ms/step - loss: 0.3089 - accuracy: 0.6546 - val_loss: 0.6349 - val_accuracy: 0.6316\n",
      "Epoch 27/500\n",
      "339/339 [==============================] - 14s 42ms/step - loss: 0.3083 - accuracy: 0.6566 - val_loss: 0.6247 - val_accuracy: 0.6491\n",
      "Epoch 28/500\n",
      "339/339 [==============================] - 16s 46ms/step - loss: 0.3078 - accuracy: 0.6572 - val_loss: 0.6441 - val_accuracy: 0.6491\n",
      "Epoch 29/500\n",
      "339/339 [==============================] - 14s 42ms/step - loss: 0.3074 - accuracy: 0.6580 - val_loss: 0.6368 - val_accuracy: 0.6316\n",
      "Epoch 30/500\n",
      "339/339 [==============================] - 15s 43ms/step - loss: 0.3067 - accuracy: 0.6585 - val_loss: 0.6302 - val_accuracy: 0.6316\n",
      "Epoch 31/500\n",
      "339/339 [==============================] - 16s 46ms/step - loss: 0.3065 - accuracy: 0.6589 - val_loss: 0.6051 - val_accuracy: 0.6491\n",
      "Epoch 32/500\n",
      "339/339 [==============================] - 15s 44ms/step - loss: 0.3060 - accuracy: 0.6605 - val_loss: 0.6385 - val_accuracy: 0.6491\n",
      "Epoch 33/500\n",
      "339/339 [==============================] - 15s 43ms/step - loss: 0.3055 - accuracy: 0.6614 - val_loss: 0.6240 - val_accuracy: 0.6316\n",
      "Epoch 34/500\n",
      "339/339 [==============================] - 14s 43ms/step - loss: 0.3052 - accuracy: 0.6614 - val_loss: 0.6346 - val_accuracy: 0.6140\n",
      "Epoch 35/500\n",
      "339/339 [==============================] - 16s 47ms/step - loss: 0.3046 - accuracy: 0.6633 - val_loss: 0.6264 - val_accuracy: 0.6316\n",
      "Epoch 36/500\n",
      "339/339 [==============================] - 14s 43ms/step - loss: 0.3041 - accuracy: 0.6639 - val_loss: 0.6459 - val_accuracy: 0.6140\n",
      "Epoch 37/500\n",
      "339/339 [==============================] - 15s 43ms/step - loss: 0.3039 - accuracy: 0.6644 - val_loss: 0.6144 - val_accuracy: 0.6667\n",
      "Epoch 37: early stopping\n",
      "/UltimeTradingBot/Data/BUY_TEST/tp92_w7_max3min_Anti-Model_v2.h5\n"
     ]
    }
   ],
   "source": [
    "#Anti prediction\n",
    "\n",
    "BadONE=bad_dt[bad_dt[:,-1]==0]\n",
    "TrueOne=bad_dt[bad_dt[:,-1]==1][:BadONE.shape[0]]\n",
    "AntiPrediction_DT=np.concatenate((BadONE,TrueOne),axis=0)\n",
    "np.random.shuffle(AntiPrediction_DT)\n",
    "\n",
    "retrain_dt=AntiPrediction_DT\n",
    "print(f\"Dataset Size is : {retrain_dt.shape[0]}\")\n",
    "class_1_weight=hp(retrain_dt[:,-1].mean())/100\n",
    "\n",
    "import gc\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# Define the class weights\n",
    "index_20percent=int(retrain_dt.shape[1]*0.2)\n",
    "\n",
    "class_weights = {0: 1-class_1_weight, 1: class_1_weight}\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "SizeTunner = 1\n",
    "IN_DIM = retrain_dt.shape[1] - 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(IN_DIM,)))\n",
    "model.add(Dense(int(200 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(Dense(int(80 * SizeTunner), activation='relu'))\n",
    "model.add(Dense(int(20 * SizeTunner), activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=Model_FileName, monitor='val_accuracy', save_best_only=True, save_weights=True),\n",
    "    EarlyStopping(monitor='val_accuracy', mode='auto', patience=16, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"saving file in: \" + Model_FileName)\n",
    "history = model.fit(retrain_dt[index_20percent:, :-1],\n",
    "                    retrain_dt[index_20percent:, -1],\n",
    "                    validation_data=(retrain_dt[:index_20percent, :-1], retrain_dt[:index_20percent, -1]),\n",
    "                    epochs=500,\n",
    "                    batch_size=256*5,\n",
    "                    callbacks=callbacks,\n",
    "                    class_weight=class_weights)\n",
    "\n",
    "#868/868 [==============================] - 30s 35ms/step - loss: 0.6078 - accuracy: 0.6664 - val_loss: 0.6107 - val_accuracy: 0.6639 >0.6646\n",
    "#Results after 380 min\n",
    "# Epoch 133/500\n",
    "# 347/347 [==============================] - 138s 398ms/step - loss: 0.5867 - accuracy: 0.6842 - val_loss: 0.5839 - val_accuracy: 0.6863\n",
    "# Epoch 134/500\n",
    "# 347/347 [==============================] - 137s 395ms/step - loss: 0.5865 - accuracy: 0.6843 - val_loss: 0.5845 - val_accuracy: 0.6861\n",
    "# Epoch 134: early stopping\n",
    "justgood_good_model=model\n",
    "justgood_good_model_wheretosave=f'{DATA_DIR}/tp{int(BUY_PERCENT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Anti-Model_v2.h5'\n",
    "justgood_good_model.save(justgood_good_model_wheretosave)\n",
    "print(justgood_good_model_wheretosave)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# True PredONly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_17 (Bat  (None, 286)              1144      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 200)               57400     \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 80)                0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110,745\n",
      "Trainable params: 109,133\n",
      "Non-trainable params: 1,612\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_TEST/tp92_w7_max3min_Model_v5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 11:30:55.833205: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3740814792 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2555/2555 [==============================] - 117s 43ms/step - loss: 0.1582 - accuracy: 0.8579 - val_loss: 0.2607 - val_accuracy: 0.8246\n",
      "Epoch 2/500\n",
      "2555/2555 [==============================] - 114s 45ms/step - loss: 0.1447 - accuracy: 0.8721 - val_loss: 0.2221 - val_accuracy: 0.9123\n",
      "Epoch 3/500\n",
      "2555/2555 [==============================] - 112s 44ms/step - loss: 0.1368 - accuracy: 0.8804 - val_loss: 0.2343 - val_accuracy: 0.8772\n",
      "Epoch 4/500\n",
      "2555/2555 [==============================] - 113s 44ms/step - loss: 0.1320 - accuracy: 0.8849 - val_loss: 0.2291 - val_accuracy: 0.8947\n",
      "Epoch 5/500\n",
      "2555/2555 [==============================] - 113s 44ms/step - loss: 0.1290 - accuracy: 0.8882 - val_loss: 0.2126 - val_accuracy: 0.8772\n",
      "Epoch 6/500\n",
      "2555/2555 [==============================] - 115s 45ms/step - loss: 0.1267 - accuracy: 0.8902 - val_loss: 0.2127 - val_accuracy: 0.9298\n",
      "Epoch 7/500\n",
      "2555/2555 [==============================] - 114s 45ms/step - loss: 0.1251 - accuracy: 0.8917 - val_loss: 0.2199 - val_accuracy: 0.8772\n",
      "Epoch 8/500\n",
      "2555/2555 [==============================] - 114s 44ms/step - loss: 0.1238 - accuracy: 0.8931 - val_loss: 0.2230 - val_accuracy: 0.8772\n",
      "Epoch 9/500\n",
      "2555/2555 [==============================] - 117s 46ms/step - loss: 0.1226 - accuracy: 0.8943 - val_loss: 0.2214 - val_accuracy: 0.8947\n",
      "Epoch 10/500\n",
      "2555/2555 [==============================] - 115s 45ms/step - loss: 0.1218 - accuracy: 0.8951 - val_loss: 0.2313 - val_accuracy: 0.8947\n",
      "Epoch 11/500\n",
      "2555/2555 [==============================] - 115s 45ms/step - loss: 0.1210 - accuracy: 0.8962 - val_loss: 0.2351 - val_accuracy: 0.8596\n",
      "Epoch 12/500\n",
      "2555/2555 [==============================] - 114s 45ms/step - loss: 0.1205 - accuracy: 0.8961 - val_loss: 0.2269 - val_accuracy: 0.8947\n",
      "Epoch 13/500\n",
      "2555/2555 [==============================] - 114s 45ms/step - loss: 0.1199 - accuracy: 0.8968 - val_loss: 0.2105 - val_accuracy: 0.8772\n",
      "Epoch 14/500\n",
      "2555/2555 [==============================] - 115s 45ms/step - loss: 0.1194 - accuracy: 0.8971 - val_loss: 0.2139 - val_accuracy: 0.8947\n",
      "Epoch 15/500\n",
      "2555/2555 [==============================] - 114s 45ms/step - loss: 0.1190 - accuracy: 0.8975 - val_loss: 0.2243 - val_accuracy: 0.9123\n",
      "Epoch 16/500\n",
      "2555/2555 [==============================] - 115s 45ms/step - loss: 0.1185 - accuracy: 0.8981 - val_loss: 0.2230 - val_accuracy: 0.8947\n",
      "Epoch 17/500\n",
      "2555/2555 [==============================] - 114s 44ms/step - loss: 0.1181 - accuracy: 0.8985 - val_loss: 0.2171 - val_accuracy: 0.8947\n",
      "Epoch 18/500\n",
      "2555/2555 [==============================] - 115s 45ms/step - loss: 0.1177 - accuracy: 0.8987 - val_loss: 0.2102 - val_accuracy: 0.8947\n",
      "Epoch 19/500\n",
      "2555/2555 [==============================] - 117s 46ms/step - loss: 0.1175 - accuracy: 0.8992 - val_loss: 0.2136 - val_accuracy: 0.9123\n",
      "Epoch 20/500\n",
      "2555/2555 [==============================] - 116s 45ms/step - loss: 0.1173 - accuracy: 0.8993 - val_loss: 0.2059 - val_accuracy: 0.8947\n",
      "Epoch 21/500\n",
      "2555/2555 [==============================] - 115s 45ms/step - loss: 0.1169 - accuracy: 0.8993 - val_loss: 0.1931 - val_accuracy: 0.9298\n",
      "Epoch 22/500\n",
      "2555/2555 [==============================] - 114s 45ms/step - loss: 0.1167 - accuracy: 0.8998 - val_loss: 0.2250 - val_accuracy: 0.8772\n",
      "Epoch 22: early stopping\n",
      "/UltimeTradingBot/Data/BUY_TEST/tp92_w7_max3min_Model_true_win_model_Re1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 12:13:09.941534: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3740880000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102188/102188 [==============================] - 320s 3ms/step\n",
      "ModelAccuracy: 79.374%\n",
      "True Win Predictions Mean of all: 34.654%\n",
      "XXX Loss Buy Mean of all: 5.279%\n",
      "Missed good deal off all: 15.346%\n",
      "Good Zero prediction Mean: 44.721%\n",
      "good fiability\n",
      "========= Win Ratio:86.78035709813938 ====================\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_23 (Bat  (None, 286)              1144      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 200)               57400     \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110,745\n",
      "Trainable params: 109,133\n",
      "Non-trainable params: 1,612\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_TEST/tp92_w7_max3min_Model_v5.h5\n",
      "Epoch 1/500\n",
      "2555/2555 [==============================] - 109s 41ms/step - loss: 0.1356 - accuracy: 0.8762 - val_loss: 0.2379 - val_accuracy: 0.8772\n",
      "Epoch 2/500\n",
      "2555/2555 [==============================] - 108s 42ms/step - loss: 0.1195 - accuracy: 0.8942 - val_loss: 0.2765 - val_accuracy: 0.8596\n",
      "Epoch 3/500\n",
      "2555/2555 [==============================] - 110s 43ms/step - loss: 0.1109 - accuracy: 0.9037 - val_loss: 0.2212 - val_accuracy: 0.8772\n",
      "Epoch 4/500\n",
      "2555/2555 [==============================] - 115s 45ms/step - loss: 0.1065 - accuracy: 0.9084 - val_loss: 0.2297 - val_accuracy: 0.8772\n",
      "Epoch 5/500\n",
      "2555/2555 [==============================] - 112s 44ms/step - loss: 0.1035 - accuracy: 0.9112 - val_loss: 0.2091 - val_accuracy: 0.8772\n",
      "Epoch 6/500\n",
      "2555/2555 [==============================] - 113s 44ms/step - loss: 0.1018 - accuracy: 0.9132 - val_loss: 0.2177 - val_accuracy: 0.8772\n",
      "Epoch 7/500\n",
      "2555/2555 [==============================] - 113s 44ms/step - loss: 0.1003 - accuracy: 0.9147 - val_loss: 0.2328 - val_accuracy: 0.8596\n",
      "Epoch 8/500\n",
      "2555/2555 [==============================] - 116s 45ms/step - loss: 0.0992 - accuracy: 0.9159 - val_loss: 0.2364 - val_accuracy: 0.8596\n",
      "Epoch 9/500\n",
      "2555/2555 [==============================] - 114s 45ms/step - loss: 0.0983 - accuracy: 0.9164 - val_loss: 0.2425 - val_accuracy: 0.8596\n",
      "Epoch 10/500\n",
      "2555/2555 [==============================] - 114s 45ms/step - loss: 0.0976 - accuracy: 0.9176 - val_loss: 0.2271 - val_accuracy: 0.8596\n",
      "Epoch 11/500\n",
      "2555/2555 [==============================] - 114s 45ms/step - loss: 0.0969 - accuracy: 0.9183 - val_loss: 0.2239 - val_accuracy: 0.8772\n",
      "Epoch 12/500\n",
      "2555/2555 [==============================] - 115s 45ms/step - loss: 0.0963 - accuracy: 0.9192 - val_loss: 0.2104 - val_accuracy: 0.8772\n",
      "Epoch 13/500\n",
      "2555/2555 [==============================] - 114s 45ms/step - loss: 0.0959 - accuracy: 0.9196 - val_loss: 0.2093 - val_accuracy: 0.8772\n",
      "Epoch 14/500\n",
      "2555/2555 [==============================] - 113s 44ms/step - loss: 0.0954 - accuracy: 0.9195 - val_loss: 0.2287 - val_accuracy: 0.8772\n",
      "Epoch 15/500\n",
      "2555/2555 [==============================] - 117s 46ms/step - loss: 0.0951 - accuracy: 0.9201 - val_loss: 0.2154 - val_accuracy: 0.8772\n",
      "Epoch 16/500\n",
      "2555/2555 [==============================] - 114s 45ms/step - loss: 0.0947 - accuracy: 0.9205 - val_loss: 0.2185 - val_accuracy: 0.8947\n",
      "Epoch 17/500\n",
      "2555/2555 [==============================] - 122s 48ms/step - loss: 0.0944 - accuracy: 0.9205 - val_loss: 0.2161 - val_accuracy: 0.8596\n",
      "Epoch 18/500\n",
      "2555/2555 [==============================] - 136s 53ms/step - loss: 0.0940 - accuracy: 0.9210 - val_loss: 0.2099 - val_accuracy: 0.9123\n",
      "Epoch 19/500\n",
      "2555/2555 [==============================] - 137s 54ms/step - loss: 0.0938 - accuracy: 0.9211 - val_loss: 0.2135 - val_accuracy: 0.8947\n",
      "Epoch 20/500\n",
      "2555/2555 [==============================] - 129s 50ms/step - loss: 0.0935 - accuracy: 0.9216 - val_loss: 0.2075 - val_accuracy: 0.8947\n",
      "Epoch 21/500\n",
      "2555/2555 [==============================] - 134s 53ms/step - loss: 0.0933 - accuracy: 0.9215 - val_loss: 0.2205 - val_accuracy: 0.8772\n",
      "Epoch 22/500\n",
      "2555/2555 [==============================] - 134s 52ms/step - loss: 0.0932 - accuracy: 0.9215 - val_loss: 0.2158 - val_accuracy: 0.8947\n",
      "Epoch 23/500\n",
      "2555/2555 [==============================] - 139s 55ms/step - loss: 0.0929 - accuracy: 0.9219 - val_loss: 0.2214 - val_accuracy: 0.8947\n",
      "Epoch 24/500\n",
      "2555/2555 [==============================] - 142s 55ms/step - loss: 0.0928 - accuracy: 0.9220 - val_loss: 0.2063 - val_accuracy: 0.8772\n",
      "Epoch 25/500\n",
      "2555/2555 [==============================] - 138s 54ms/step - loss: 0.0926 - accuracy: 0.9222 - val_loss: 0.2151 - val_accuracy: 0.8596\n",
      "Epoch 26/500\n",
      "2555/2555 [==============================] - 142s 55ms/step - loss: 0.0924 - accuracy: 0.9217 - val_loss: 0.2240 - val_accuracy: 0.8772\n",
      "Epoch 27/500\n",
      "2555/2555 [==============================] - 138s 54ms/step - loss: 0.0923 - accuracy: 0.9221 - val_loss: 0.2310 - val_accuracy: 0.8947\n",
      "Epoch 28/500\n",
      "2555/2555 [==============================] - 138s 54ms/step - loss: 0.0920 - accuracy: 0.9221 - val_loss: 0.2153 - val_accuracy: 0.8947\n",
      "Epoch 29/500\n",
      "2555/2555 [==============================] - 134s 52ms/step - loss: 0.0919 - accuracy: 0.9228 - val_loss: 0.2156 - val_accuracy: 0.8947\n",
      "Epoch 30/500\n",
      "2555/2555 [==============================] - 131s 51ms/step - loss: 0.0918 - accuracy: 0.9228 - val_loss: 0.2171 - val_accuracy: 0.8947\n",
      "Epoch 31/500\n",
      "2555/2555 [==============================] - 139s 54ms/step - loss: 0.0917 - accuracy: 0.9220 - val_loss: 0.2195 - val_accuracy: 0.8947\n",
      "Epoch 32/500\n",
      "2555/2555 [==============================] - 121s 47ms/step - loss: 0.0915 - accuracy: 0.9227 - val_loss: 0.2444 - val_accuracy: 0.8596\n",
      "Epoch 33/500\n",
      "2555/2555 [==============================] - 119s 47ms/step - loss: 0.0914 - accuracy: 0.9232 - val_loss: 0.2434 - val_accuracy: 0.8421\n",
      "Epoch 34/500\n",
      "2555/2555 [==============================] - 116s 45ms/step - loss: 0.0913 - accuracy: 0.9232 - val_loss: 0.2219 - val_accuracy: 0.8772\n",
      "Epoch 34: early stopping\n",
      "/UltimeTradingBot/Data/BUY_TEST/tp92_w7_max3min_Model_true_win_model_Re2.h5\n",
      "102188/102188 [==============================] - 302s 3ms/step\n",
      "ModelAccuracy: 76.992%\n",
      "True Win Predictions Mean of all: 30.867%\n",
      "XXX Loss Buy Mean of all: 3.874%\n",
      "Missed good deal off all: 19.133%\n",
      "Good Zero prediction Mean: 46.126%\n",
      "good fiability\n",
      "========= Win Ratio:88.84891050919663 ====================\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_29 (Bat  (None, 286)              1144      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 200)               57400     \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110,745\n",
      "Trainable params: 109,133\n",
      "Non-trainable params: 1,612\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_TEST/tp92_w7_max3min_Model_v5.h5\n",
      "Epoch 1/500\n",
      "2555/2555 [==============================] - 129s 49ms/step - loss: 0.1185 - accuracy: 0.8842 - val_loss: 0.1929 - val_accuracy: 0.9298\n",
      "Epoch 2/500\n",
      "2555/2555 [==============================] - 136s 53ms/step - loss: 0.1019 - accuracy: 0.9046 - val_loss: 0.1647 - val_accuracy: 0.9298\n",
      "Epoch 3/500\n",
      "2555/2555 [==============================] - 139s 54ms/step - loss: 0.0940 - accuracy: 0.9148 - val_loss: 0.1791 - val_accuracy: 0.9474\n",
      "Epoch 4/500\n",
      "2555/2555 [==============================] - 138s 54ms/step - loss: 0.0900 - accuracy: 0.9197 - val_loss: 0.1630 - val_accuracy: 0.9474\n",
      "Epoch 5/500\n",
      "2555/2555 [==============================] - 145s 57ms/step - loss: 0.0873 - accuracy: 0.9227 - val_loss: 0.1550 - val_accuracy: 0.9474\n",
      "Epoch 6/500\n",
      "2555/2555 [==============================] - 137s 54ms/step - loss: 0.0855 - accuracy: 0.9248 - val_loss: 0.1597 - val_accuracy: 0.9474\n",
      "Epoch 7/500\n",
      "2555/2555 [==============================] - 140s 55ms/step - loss: 0.0839 - accuracy: 0.9265 - val_loss: 0.1629 - val_accuracy: 0.9474\n",
      "Epoch 8/500\n",
      "2555/2555 [==============================] - 139s 54ms/step - loss: 0.0830 - accuracy: 0.9277 - val_loss: 0.1631 - val_accuracy: 0.9474\n",
      "Epoch 9/500\n",
      "2555/2555 [==============================] - 140s 55ms/step - loss: 0.0820 - accuracy: 0.9285 - val_loss: 0.1629 - val_accuracy: 0.9474\n",
      "Epoch 10/500\n",
      "2555/2555 [==============================] - 140s 55ms/step - loss: 0.0813 - accuracy: 0.9294 - val_loss: 0.1616 - val_accuracy: 0.9474\n",
      "Epoch 11/500\n",
      "2555/2555 [==============================] - 141s 55ms/step - loss: 0.0808 - accuracy: 0.9300 - val_loss: 0.1932 - val_accuracy: 0.9123\n",
      "Epoch 12/500\n",
      "2555/2555 [==============================] - 140s 55ms/step - loss: 0.0802 - accuracy: 0.9304 - val_loss: 0.1608 - val_accuracy: 0.9298\n",
      "Epoch 13/500\n",
      "2555/2555 [==============================] - 142s 56ms/step - loss: 0.0796 - accuracy: 0.9309 - val_loss: 0.1530 - val_accuracy: 0.9298\n",
      "Epoch 14/500\n",
      "2555/2555 [==============================] - 141s 55ms/step - loss: 0.0793 - accuracy: 0.9313 - val_loss: 0.1655 - val_accuracy: 0.9298\n",
      "Epoch 15/500\n",
      "2555/2555 [==============================] - 139s 54ms/step - loss: 0.0790 - accuracy: 0.9315 - val_loss: 0.1837 - val_accuracy: 0.9298\n",
      "Epoch 16/500\n",
      "2555/2555 [==============================] - 142s 56ms/step - loss: 0.0786 - accuracy: 0.9320 - val_loss: 0.1471 - val_accuracy: 0.9474\n",
      "Epoch 17/500\n",
      "2555/2555 [==============================] - 141s 55ms/step - loss: 0.0782 - accuracy: 0.9326 - val_loss: 0.1849 - val_accuracy: 0.9298\n",
      "Epoch 18/500\n",
      "2555/2555 [==============================] - 140s 55ms/step - loss: 0.0780 - accuracy: 0.9333 - val_loss: 0.1745 - val_accuracy: 0.9298\n",
      "Epoch 19/500\n",
      "2555/2555 [==============================] - 140s 55ms/step - loss: 0.0777 - accuracy: 0.9334 - val_loss: 0.2100 - val_accuracy: 0.8947\n",
      "Epoch 19: early stopping\n",
      "/UltimeTradingBot/Data/BUY_TEST/tp92_w7_max3min_Model_true_win_model_Re3.h5\n",
      "102188/102188 [==============================] - 308s 3ms/step\n",
      "ModelAccuracy: 72.866%\n",
      "True Win Predictions Mean of all: 25.570%\n",
      "XXX Loss Buy Mean of all: 2.704%\n",
      "Missed good deal off all: 24.430%\n",
      "Good Zero prediction Mean: 47.296%\n",
      "good fiability\n",
      "========= Win Ratio:90.43644337553937 ====================\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_35 (Bat  (None, 286)              1144      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 200)               57400     \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110,745\n",
      "Trainable params: 109,133\n",
      "Non-trainable params: 1,612\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_TEST/tp92_w7_max3min_Model_v5.h5\n",
      "Epoch 1/500\n",
      "2555/2555 [==============================] - 141s 52ms/step - loss: 0.0964 - accuracy: 0.8911 - val_loss: 0.1494 - val_accuracy: 0.9474\n",
      "Epoch 2/500\n",
      "2555/2555 [==============================] - 131s 51ms/step - loss: 0.0795 - accuracy: 0.9157 - val_loss: 0.1277 - val_accuracy: 0.9649\n",
      "Epoch 3/500\n",
      "2555/2555 [==============================] - 136s 53ms/step - loss: 0.0722 - accuracy: 0.9266 - val_loss: 0.1152 - val_accuracy: 0.9825\n",
      "Epoch 4/500\n",
      "2555/2555 [==============================] - 141s 55ms/step - loss: 0.0688 - accuracy: 0.9317 - val_loss: 0.1065 - val_accuracy: 0.9649\n",
      "Epoch 5/500\n",
      "2555/2555 [==============================] - 140s 55ms/step - loss: 0.0666 - accuracy: 0.9344 - val_loss: 0.1103 - val_accuracy: 0.9649\n",
      "Epoch 6/500\n",
      "2555/2555 [==============================] - 135s 53ms/step - loss: 0.0652 - accuracy: 0.9363 - val_loss: 0.0908 - val_accuracy: 0.9649\n",
      "Epoch 7/500\n",
      "2555/2555 [==============================] - 139s 55ms/step - loss: 0.0639 - accuracy: 0.9381 - val_loss: 0.0912 - val_accuracy: 0.9825\n",
      "Epoch 8/500\n",
      "2555/2555 [==============================] - 135s 53ms/step - loss: 0.0631 - accuracy: 0.9392 - val_loss: 0.0877 - val_accuracy: 0.9825\n",
      "Epoch 9/500\n",
      "2555/2555 [==============================] - 142s 56ms/step - loss: 0.0623 - accuracy: 0.9404 - val_loss: 0.0906 - val_accuracy: 0.9825\n",
      "Epoch 10/500\n",
      "2555/2555 [==============================] - 139s 54ms/step - loss: 0.0617 - accuracy: 0.9411 - val_loss: 0.0924 - val_accuracy: 0.9825\n",
      "Epoch 11/500\n",
      "2555/2555 [==============================] - 136s 53ms/step - loss: 0.0613 - accuracy: 0.9416 - val_loss: 0.0950 - val_accuracy: 0.9825\n",
      "Epoch 12/500\n",
      "2555/2555 [==============================] - 139s 54ms/step - loss: 0.0608 - accuracy: 0.9425 - val_loss: 0.0966 - val_accuracy: 0.9649\n",
      "Epoch 13/500\n",
      "2555/2555 [==============================] - 141s 55ms/step - loss: 0.0604 - accuracy: 0.9427 - val_loss: 0.0934 - val_accuracy: 0.9825\n",
      "Epoch 14/500\n",
      "2555/2555 [==============================] - 139s 54ms/step - loss: 0.0601 - accuracy: 0.9432 - val_loss: 0.0925 - val_accuracy: 0.9649\n",
      "Epoch 15/500\n",
      "2555/2555 [==============================] - 139s 54ms/step - loss: 0.0598 - accuracy: 0.9435 - val_loss: 0.0843 - val_accuracy: 0.9649\n",
      "Epoch 16/500\n",
      "2555/2555 [==============================] - 139s 54ms/step - loss: 0.0596 - accuracy: 0.9438 - val_loss: 0.0953 - val_accuracy: 0.9474\n",
      "Epoch 17/500\n",
      "2555/2555 [==============================] - 120s 47ms/step - loss: 0.0592 - accuracy: 0.9440 - val_loss: 0.0897 - val_accuracy: 0.9649\n",
      "Epoch 18/500\n",
      "2555/2555 [==============================] - 117s 46ms/step - loss: 0.0590 - accuracy: 0.9446 - val_loss: 0.0893 - val_accuracy: 0.9649\n",
      "Epoch 19/500\n",
      "2555/2555 [==============================] - 115s 45ms/step - loss: 0.0588 - accuracy: 0.9450 - val_loss: 0.0890 - val_accuracy: 0.9649\n",
      "Epoch 19: early stopping\n",
      "/UltimeTradingBot/Data/BUY_TEST/tp92_w7_max3min_Model_true_win_model_Re4.h5\n",
      "102188/102188 [==============================] - 321s 3ms/step\n",
      "ModelAccuracy: 70.825%\n",
      "True Win Predictions Mean of all: 23.099%\n",
      "XXX Loss Buy Mean of all: 2.274%\n",
      "Missed good deal off all: 26.901%\n",
      "Good Zero prediction Mean: 47.726%\n",
      "good fiability\n",
      "========= Win Ratio:91.03771725850312 ====================\n"
     ]
    }
   ],
   "source": [
    "#Change retaindt\n",
    "for rrr in range(1,5):\n",
    "    retrain_dt=dt\n",
    "    class_1_weight=TrueWinPred.mean()\n",
    "\n",
    "    import gc\n",
    "    from keras.layers import Dense\n",
    "    from keras.models import Sequential\n",
    "    from keras.optimizers import Nadam\n",
    "    from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "    # Define the class weights\n",
    "    index_20percent=int(retrain_dt.shape[1]*0.2)\n",
    "    class_weights = {0: 1-class_1_weight, 1: class_1_weight}\n",
    "    gc.collect()\n",
    "\n",
    "    SizeTunner = 1\n",
    "    IN_DIM = retrain_dt.shape[1] - 1\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(IN_DIM,)))\n",
    "    model.add(Dense(int(200 * SizeTunner), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    model.add(Dense(int(80 * SizeTunner), activation='relu'))\n",
    "    model.add(Dense(int(20 * SizeTunner), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(filepath=Model_FileName, monitor='val_accuracy', save_best_only=True, save_weights=True),\n",
    "        EarlyStopping(monitor='val_accuracy', mode='auto', patience=16, verbose=1)\n",
    "    ]\n",
    "\n",
    "    print(\"saving file in: \" + Model_FileName)\n",
    "    history = model.fit(retrain_dt[index_20percent:, :-1],\n",
    "                        TrueWinPred[index_20percent:],\n",
    "                        validation_data=(retrain_dt[:index_20percent, :-1], TrueWinPred[:index_20percent]),\n",
    "                        epochs=500,\n",
    "                        batch_size=256*5,\n",
    "                        callbacks=callbacks,\n",
    "                        class_weight=class_weights)\n",
    "\n",
    "    #868/868 [==============================] - 30s 35ms/step - loss: 0.6078 - accuracy: 0.6664 - val_loss: 0.6107 - val_accuracy: 0.6639 >0.6646\n",
    "    #Results after 380 min\n",
    "    # Epoch 133/500\n",
    "    # 347/347 [==============================] - 138s 398ms/step - loss: 0.5867 - accuracy: 0.6842 - val_loss: 0.5839 - val_accuracy: 0.6863\n",
    "    # Epoch 134/500\n",
    "    # 347/347 [==============================] - 137s 395ms/step - loss: 0.5865 - accuracy: 0.6843 - val_loss: 0.5845 - val_accuracy: 0.6861\n",
    "    # Epoch 134: early stopping\n",
    "\n",
    "    true_win_model=model\n",
    "    wheretosave=f'{DATA_DIR}/tp{int(BUY_PERCENT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+f\"_true_win_model_Re{rrr}.h5\"\n",
    "    true_win_model.save(wheretosave)\n",
    "    print(wheretosave)\n",
    "    USED_MODEL=true_win_model\n",
    "    bad_Prediction_Note=USED_MODEL.predict( dt[:, 0:-1])\n",
    "    Pred02=bad_Prediction_Note.round()\n",
    "    Original_Traget_Data=Y\n",
    "    Predicted_Data=Pred02[:,0]\n",
    "\n",
    "    BadTruePred=(Original_Traget_Data==Predicted_Data).copy()\n",
    "    BadModelAccuracy=hp(BadTruePred.mean(),\"ModelAccuracy\")\n",
    "\n",
    "    BadTrueWinPred=((Predicted_Data==1) & (Original_Traget_Data==1) ).copy()\n",
    "    BadTrueWinPred_Mean=hp(BadTrueWinPred.mean(),\"True Win Predictions Mean of all\")\n",
    "\n",
    "    BadLossPred=((Predicted_Data==1) & (Original_Traget_Data==0) ).copy()\n",
    "    BadLossPred_Mean=hp(BadLossPred.mean(),\"XXX Loss Buy Mean of all\")\n",
    "\n",
    "    BadMissedDealPred=((Predicted_Data==0) & (Original_Traget_Data==1) ).copy()\n",
    "    BadMissedDeal_Mean=hp(BadMissedDealPred.mean(),\"Missed good deal off all\")\n",
    "\n",
    "    BadGoodZeroPred=((Predicted_Data==0) & (Original_Traget_Data==0) ).copy()\n",
    "    BadGoodZero_Mean=hp(BadGoodZeroPred.mean(),\"Good Zero prediction Mean\")\n",
    "\n",
    "    fiability=BadTrueWinPred_Mean + BadLossPred_Mean + BadMissedDeal_Mean + BadGoodZero_Mean\n",
    "    if( fiability == 100):print(\"good fiability\")\n",
    "    else: print(f\"check the fiability {fiability}\")\n",
    "    winratio=BadTrueWinPred_Mean/(BadLossPred_Mean+BadTrueWinPred_Mean)\n",
    "    print(f\"========= Win Ratio:{winratio*100} ====================\")\n",
    "    ## for retraining again\n",
    "    TrueWinPred=BadTrueWinPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/UltimeTradingBot/Data/BUY_TEST/tp92_w7_max3min_Model_GoodVeryDeep_v2.h5\n"
     ]
    }
   ],
   "source": [
    "very_deep_good_model=model\n",
    "wheretosave=f'{DATA_DIR}/tp{int(BUY_PERCENT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+\"_GoodVeryDeep_v2.h5\"\n",
    "very_deep_good_model.save(wheretosave)\n",
    "print(wheretosave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_deep_bad_model=model\n",
    "very_deep_bad_model.save(f'{DATA_DIR}/tp{int(BUY_PERCENT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+\"_BadVeryDeep_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test On special coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buy_fix(df,buy_pourcent=BUY_PERCENT,sell_pourcent=SELL_PERCENT,window=3):\n",
    "    try:\n",
    "        window=3\n",
    "        #buy_pourcent=0.43\n",
    "        print (f\"---fixed buy--- Buy percent: {buy_pourcent}% MaxForcastSize: {window}\")\n",
    "        mino=buy_pourcent*0.01\n",
    "        maxo=-sell_pourcent*0.01\n",
    "        codep1='df[\"buy\"]=((('\n",
    "        for i in range(1,window):\n",
    "            codep1=codep1+'df[\"high\"].shift(periods='+str(-i)+', freq=None, axis=0, fill_value=None)-df[\"close\"])/df[\"close\"] >=mino )| (('\n",
    "        codep2='df[\"high\"].shift(periods='+str(-window)+', freq=None, axis=0, fill_value=None)-df[\"close\"])/df[\"close\"] >=mino)).replace({False: 0, True: 1})'\n",
    "        code=codep1+codep2\n",
    "        prerr(code)\n",
    "        exec(code)\n",
    "        window=3\n",
    "        df['ismin1'] = np.where(\n",
    "        df['close'] <= df.shift(-window-1).rolling(2*window)['high'].min(), 1,\n",
    "       0\n",
    "        )\n",
    "        window=5\n",
    "        df['ismin2'] = np.where(\n",
    "        df['close'] <= df.shift(-window-1).rolling(2*window)['high'].min(), 1,\n",
    "       0\n",
    "        )\n",
    "        window=7\n",
    "        df['ismin3'] = np.where(\n",
    "        df['close'] <= df.shift(-window-1).rolling(2*window)['high'].min(), 1,\n",
    "       0\n",
    "        )\n",
    "        window=10\n",
    "        df['ismin4'] = np.where(\n",
    "        df['close'] <= df.shift(-window-1).rolling(2*window)['high'].min(), 1,\n",
    "       0\n",
    "        )\n",
    "        window=15\n",
    "        df['ismin5'] = np.where(\n",
    "        df['close'] <= df.shift(-window-1).rolling(2*window)['high'].min(), 1,\n",
    "       0\n",
    "        )\n",
    "        window=20\n",
    "        df['ismin6'] = np.where(\n",
    "        df['close'] <= df.shift(-window-1).rolling(2*window)['high'].min(), 1,\n",
    "       0\n",
    "        )\n",
    "        df['ismin']=((df['ismin1']==1) | (df['ismin2']==1) | (df['ismin3'] == 1) |(df['ismin4']==1) |(df['ismin5'])| (df['ismin6']==1))\n",
    "        df[\"buy\"]=((df['buy']==1 ) & (df['ismin']==1)).replace({False: 0, True: 1})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error buy only\")\n",
    "        print(e)\n",
    "    try:df.pop(\"b\")\n",
    "    except:print(\"---fixed buy--- no b\")\n",
    "    try:\n",
    "        df.pop(\"ismin\")\n",
    "        df.pop(\"ismin1\")\n",
    "        df.pop(\"ismin2\")\n",
    "        df.pop(\"ismin3\")\n",
    "        df.pop(\"ismin4\")\n",
    "        df.pop(\"ismin5\")\n",
    "        df.pop(\"ismin6\")\n",
    "    except:print(\"---fixed buy--- no sell\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ismin6</th>\n",
       "      <th>ismin5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-03-09 12:05:00</th>\n",
       "      <td>0.15982</td>\n",
       "      <td>0.15987</td>\n",
       "      <td>0.14438</td>\n",
       "      <td>0.14606</td>\n",
       "      <td>38045060.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-09 12:06:00</th>\n",
       "      <td>0.14600</td>\n",
       "      <td>0.15155</td>\n",
       "      <td>0.14600</td>\n",
       "      <td>0.14785</td>\n",
       "      <td>24581951.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-09 12:08:00</th>\n",
       "      <td>0.15417</td>\n",
       "      <td>0.15474</td>\n",
       "      <td>0.14831</td>\n",
       "      <td>0.15005</td>\n",
       "      <td>16364039.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-09 12:09:00</th>\n",
       "      <td>0.15006</td>\n",
       "      <td>0.15250</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.15186</td>\n",
       "      <td>9285695.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-09 12:13:00</th>\n",
       "      <td>0.15318</td>\n",
       "      <td>0.15333</td>\n",
       "      <td>0.14980</td>\n",
       "      <td>0.14982</td>\n",
       "      <td>8410420.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-20 00:24:00</th>\n",
       "      <td>0.41090</td>\n",
       "      <td>0.41140</td>\n",
       "      <td>0.41090</td>\n",
       "      <td>0.41130</td>\n",
       "      <td>5878.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-20 00:27:00</th>\n",
       "      <td>0.41140</td>\n",
       "      <td>0.41140</td>\n",
       "      <td>0.41070</td>\n",
       "      <td>0.41130</td>\n",
       "      <td>21240.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-20 00:28:00</th>\n",
       "      <td>0.41130</td>\n",
       "      <td>0.41150</td>\n",
       "      <td>0.41130</td>\n",
       "      <td>0.41140</td>\n",
       "      <td>1916.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-20 00:31:00</th>\n",
       "      <td>0.41180</td>\n",
       "      <td>0.41180</td>\n",
       "      <td>0.41140</td>\n",
       "      <td>0.41180</td>\n",
       "      <td>18531.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-20 00:35:00</th>\n",
       "      <td>0.41270</td>\n",
       "      <td>0.41360</td>\n",
       "      <td>0.41240</td>\n",
       "      <td>0.41240</td>\n",
       "      <td>34193.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147405 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open     high      low    close      volume  ismin6  \\\n",
       "date                                                                          \n",
       "2022-03-09 12:05:00  0.15982  0.15987  0.14438  0.14606  38045060.1       1   \n",
       "2022-03-09 12:06:00  0.14600  0.15155  0.14600  0.14785  24581951.4       1   \n",
       "2022-03-09 12:08:00  0.15417  0.15474  0.14831  0.15005  16364039.8       1   \n",
       "2022-03-09 12:09:00  0.15006  0.15250  0.14900  0.15186   9285695.0       1   \n",
       "2022-03-09 12:13:00  0.15318  0.15333  0.14980  0.14982   8410420.8       1   \n",
       "...                      ...      ...      ...      ...         ...     ...   \n",
       "2022-11-20 00:24:00  0.41090  0.41140  0.41090  0.41130      5878.4       1   \n",
       "2022-11-20 00:27:00  0.41140  0.41140  0.41070  0.41130     21240.7       1   \n",
       "2022-11-20 00:28:00  0.41130  0.41150  0.41130  0.41140      1916.1       1   \n",
       "2022-11-20 00:31:00  0.41180  0.41180  0.41140  0.41180     18531.0       1   \n",
       "2022-11-20 00:35:00  0.41270  0.41360  0.41240  0.41240     34193.3       1   \n",
       "\n",
       "                     ismin5  \n",
       "date                         \n",
       "2022-03-09 12:05:00       0  \n",
       "2022-03-09 12:06:00       0  \n",
       "2022-03-09 12:08:00       0  \n",
       "2022-03-09 12:09:00       0  \n",
       "2022-03-09 12:13:00       1  \n",
       "...                     ...  \n",
       "2022-11-20 00:24:00       0  \n",
       "2022-11-20 00:27:00       0  \n",
       "2022-11-20 00:28:00       0  \n",
       "2022-11-20 00:31:00       0  \n",
       "2022-11-20 00:35:00       0  \n",
       "\n",
       "[147405 rows x 7 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df[\"ismin6\"]==1) | (df[\"ismin5\"]==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini_expand : GMT/USDT\n",
      "---fixed buy--- Buy percent: 0.4% MaxForcastSize: 3\n",
      "---fixed buy--- no b\n",
      "False\n",
      "False\n",
      "Buy mean percent: 11.653%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11207/11207 [==============================] - 34s 3ms/step\n",
      "ModelAccuracy: 85.029%\n",
      "True Win Predictions Mean of all: 3.528%\n",
      "XXX Loss Buy Mean of all: 6.846%\n",
      "Missed good deal off all: 8.125%\n",
      "Good Zero prediction Mean: 81.501%\n",
      "good fiability\n",
      "========= Win Ratio:34.0080971659919 %====================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Generate Data\n",
    "BAD_PERIOD_START=\"2022-08-30\"\n",
    "BAD_PERIOD_END=\"2022-11-22\"\n",
    "pair_to_test=\"GMT/USDT\"\n",
    "MAX_FORCAST_SIZE=5\n",
    "USED_MODEL=very_deep_good_model#true_win_model#model_init #model_good_x3 #very_deep_good_model 16/1.7\n",
    "\n",
    "\n",
    "loc_start=0\n",
    "loc_end=1000000\n",
    "\n",
    "\n",
    "i_start=71000\n",
    "i_end=i_start+200\n",
    "\n",
    "# loc_start=df_list1m[pair_to_test].index.get_loc(pd.to_datetime(BAD_PERIOD_START))\n",
    "# loc_end=df_list1m[pair_to_test].index.get_loc(pd.to_datetime(BAD_PERIOD_END))\n",
    "\n",
    "\n",
    "OnePair_DF=mini_expand4(        pair=pair_to_test,\n",
    "                                i=loc_start,j=loc_end,\n",
    "                                window=WINDOW_SIZE,\n",
    "                                metadata=MetaData,\n",
    "                                high_weight=1,\n",
    "                                buy_pourcent=0.55,\n",
    "                                sell_pourcent=SELL_PERCENT,\n",
    "                                buy_function=buy_fix#buy_test\n",
    "                        )\n",
    "OnePair_DT=OnePair_DF.to_numpy()\n",
    "gc.collect()\n",
    "OnePair_DT=fixdt(OnePair_DT)\n",
    "print(OnePair_DT[0,0] == OnePair_DF.iloc[0,0])\n",
    "print(OnePair_DT[5,5] == OnePair_DF.iloc[5,5])\n",
    "hp(OnePair_DF.buy.mean(),\"Buy mean percent\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0, 10, 500)\n",
    "dashes = [10, 5, 100, 5]  # 10 points on, 5 off, 100 on, 5 off\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot(OnePair_DF.index[i_start:i_end], OnePair_DF.price[i_start:i_end], '-', linewidth=1,\n",
    "                 label='Dashes set retroactively')\n",
    "line1.set_dashes(dashes)\n",
    "plt.plot(OnePair_DF[i_start:i_end][OnePair_DF.buy[i_start:i_end]==1].index, OnePair_DF[i_start:i_end][OnePair_DF.buy[i_start:i_end]==1].price, 'ro')\n",
    "\n",
    "\n",
    "ax.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "OnePair_PredNote=USED_MODEL.predict( OnePair_DT[:, 0:-1])\n",
    "OnePair_Pred=OnePair_PredNote.round()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "Original_Traget_Data=OnePair_DT[:,-1]\n",
    "Predicted_Data=OnePair_Pred[:,0]\n",
    "gc.collect()\n",
    "TruePred=(Original_Traget_Data==Predicted_Data).copy()\n",
    "ModelAccuracy=hp(TruePred.mean(),\"ModelAccuracy\")\n",
    "gc.collect()\n",
    "TrueWinPred=((Predicted_Data==1) & (Original_Traget_Data==1) ).copy()\n",
    "TrueWinPred_Mean=hp(TrueWinPred.mean(),\"True Win Predictions Mean of all\")\n",
    "gc.collect()\n",
    "LossPred=((Predicted_Data==1) & (Original_Traget_Data==0) ).copy()\n",
    "LossPred_Mean=hp(LossPred.mean(),\"XXX Loss Buy Mean of all\")\n",
    "gc.collect()\n",
    "\n",
    "MissedDealPred=((Predicted_Data==0) & (Original_Traget_Data==1) ).copy()\n",
    "MissedDeal_Mean=hp(MissedDealPred.mean(),\"Missed good deal off all\")\n",
    "gc.collect()\n",
    "\n",
    "GoodZeroPred=((Predicted_Data==0) & (Original_Traget_Data==0) ).copy()\n",
    "GoodZero_Mean=hp(GoodZeroPred.mean(),\"Good Zero prediction Mean\")\n",
    "gc.collect()\n",
    "\n",
    "fiability=TrueWinPred_Mean + LossPred_Mean + MissedDeal_Mean + GoodZero_Mean\n",
    "if( fiability == 100):print(\"good fiability\")\n",
    "else: print(f\"check the fiability {fiability}\")\n",
    "winratio=TrueWinPred_Mean/(LossPred_Mean+TrueWinPred_Mean)\n",
    "\n",
    "print(f\"========= Win Ratio:{winratio*100} %====================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PREDICTION_TO_TEST=Predicted_Data\n",
    "\n",
    "x = np.linspace(0, 10, 500)\n",
    "dashes = [10, 5, 100, 5]  # 10 points on, 5 off, 100 on, 5 off\n",
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot(OnePair_DF.index[i_start:i_end], OnePair_DF.price[i_start:i_end], '-', linewidth=1,\n",
    "                 label='price')\n",
    "line1.set_dashes(dashes)\n",
    "plt.plot(OnePair_DF[i_start:i_end][PREDICTION_TO_TEST[i_start:i_end]==1].index, OnePair_DF[i_start:i_end][PREDICTION_TO_TEST[i_start:i_end]==1].price, 'ro')\n",
    "\n",
    "\n",
    "ax.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Good_Prediction_Note' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Good_Prediction_Note=very_deep_good_model.predict( XX)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# Bad_Prediction_Note=very_deep_bad_model.predict( XX)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# Initial_Pred_Note=model_init.predict( XX)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m Predicted_Data\u001b[39m=\u001b[39mOnePair_Pred[:\u001b[39m300000\u001b[39m,\u001b[39m0\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m goodp\u001b[39m=\u001b[39m(Good_Prediction_Note\u001b[39m-\u001b[39mprecision)\u001b[39m.\u001b[39mround()\n\u001b[1;32m      9\u001b[0m \u001b[39m# badp=(Bad_Prediction_Note).round()\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# initp=Initial_Pred_Note.round()\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[39m# Original_Traget_Data=YY\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[39m#Predicted_Data=((goodp==badp|initp==goodp))[:,0]\u001b[39;00m\n\u001b[1;32m     15\u001b[0m Predicted_Data\u001b[39m=\u001b[39m(goodp)[:,\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Good_Prediction_Note' is not defined"
     ]
    }
   ],
   "source": [
    "XX=OnePair_DT[:100000,:-1]\n",
    "YY=OnePair_DT[:100000,-1]\n",
    "precision=0.0\n",
    "# Good_Prediction_Note=very_deep_good_model.predict( XX)\n",
    "# Bad_Prediction_Note=very_deep_bad_model.predict( XX)\n",
    "# Initial_Pred_Note=model_init.predict( XX)\n",
    "Predicted_Data=OnePair_Pred[:300000,0]\n",
    "goodp=(Good_Prediction_Note-precision).round()\n",
    "# badp=(Bad_Prediction_Note).round()\n",
    "# initp=Initial_Pred_Note.round()\n",
    "\n",
    "# Original_Traget_Data=YY\n",
    "\n",
    "#Predicted_Data=((goodp==badp|initp==goodp))[:,0]\n",
    "Predicted_Data=(goodp)[:,0]\n",
    "\n",
    "GoodTruePred=(Original_Traget_Data==Predicted_Data).copy()\n",
    "GoodModelAccuracy=hp(GoodTruePred.mean(),\"ModelAccuracy\")\n",
    "\n",
    "GoodTrueWinPred=((Predicted_Data==1) & (Original_Traget_Data==1) ).copy()\n",
    "GoodTrueWinPred_Mean=hp(GoodTrueWinPred.mean(),\"True Win Predictions Mean of all\")\n",
    "\n",
    "GoodLossPred=((Predicted_Data==1) & (Original_Traget_Data==0) ).copy()\n",
    "GoodLossPred_Mean=hp(GoodLossPred.mean(),\"XXX Loss Buy Mean of all\")\n",
    "\n",
    "GoodMissedDealPred=((Predicted_Data==0) & (Original_Traget_Data==1) ).copy()\n",
    "GoodMissedDeal_Mean=hp(GoodMissedDealPred.mean(),\"Missed good deal off all\")\n",
    "\n",
    "GoodGoodZeroPred=((Predicted_Data==0) & (Original_Traget_Data==0) ).copy()\n",
    "GoodGoodZero_Mean=hp(GoodGoodZeroPred.mean(),\"Good Zero prediction Mean\")\n",
    "\n",
    "winratio=GoodTrueWinPred_Mean/(GoodTrueWinPred_Mean+GoodLossPred_Mean)\n",
    "fiability=GoodTrueWinPred_Mean + GoodLossPred_Mean + GoodMissedDeal_Mean + GoodGoodZero_Mean\n",
    "if( fiability == 100):print(\"good fiability\")\n",
    "else: print(f\"check the fiability {fiability}\")\n",
    "print(f\"========= Win Ratio:{winratio*100} ====================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction(XX,YY,USEDMODEL)\n",
    "XX=OnePair_DT[:100000,:-1]\n",
    "YY=OnePair_DT[:100000,-1]\n",
    "\n",
    "# Good_Prediction_Note=very_deep_good_model.predict( XX)\n",
    "# Bad_Prediction_Note=very_deep_bad_model.predict( XX)\n",
    "# Initial_Pred_Note=model_init.predict( XX)\n",
    "goodp=(Good_Prediction_Note-precision).round()\n",
    "# badp=(Bad_Prediction_Note).round()\n",
    "# initp=Initial_Pred_Note.round()\n",
    "\n",
    "# Original_Traget_Data=YY\n",
    "\n",
    "#Predicted_Data=((goodp==badp|initp==goodp))[:,0]\n",
    "Predicted_Data=(goodp)[:,0]\n",
    "\n",
    "GoodTruePred=(Original_Traget_Data==Predicted_Data).copy()\n",
    "GoodModelAccuracy=hp(GoodTruePred.mean(),\"ModelAccuracy\")\n",
    "\n",
    "GoodTrueWinPred=((Predicted_Data==1) & (Original_Traget_Data==1) ).copy()\n",
    "GoodTrueWinPred_Mean=hp(GoodTrueWinPred.mean(),\"True Win Predictions Mean of all\")\n",
    "\n",
    "GoodLossPred=((Predicted_Data==1) & (Original_Traget_Data==0) ).copy()\n",
    "GoodLossPred_Mean=hp(GoodLossPred.mean(),\"XXX Loss Buy Mean of all\")\n",
    "\n",
    "GoodMissedDealPred=((Predicted_Data==0) & (Original_Traget_Data==1) ).copy()\n",
    "GoodMissedDeal_Mean=hp(GoodMissedDealPred.mean(),\"Missed good deal off all\")\n",
    "\n",
    "GoodGoodZeroPred=((Predicted_Data==0) & (Original_Traget_Data==0) ).copy()\n",
    "GoodGoodZero_Mean=hp(GoodGoodZeroPred.mean(),\"Good Zero prediction Mean\")\n",
    "\n",
    "winratio=GoodTrueWinPred_Mean/(GoodTrueWinPred_Mean+GoodLossPred_Mean)\n",
    "fiability=GoodTrueWinPred_Mean + GoodLossPred_Mean + GoodMissedDeal_Mean + GoodGoodZero_Mean\n",
    "if( fiability == 100):print(\"good fiability\")\n",
    "else: print(f\"check the fiability {fiability}\")\n",
    "print(f\"========= Win Ratio:{winratio*100} ====================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

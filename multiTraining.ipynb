{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single AI crypto concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xdata_config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Imports and fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.constraints import MaxNorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "from keras.models import load_model\n",
    "from keras.layers import BatchNormalization, Dense"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special list if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Binance_USDT_HALAL.index(\"ROSE/USDT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import date\n",
    "# TICKERS = \"../Binance-Fast-Trade-Bot/volatile_volume_\" + str(date.today()) + \".txt\"\n",
    "# VOLATILE_COINS=[line.strip() for line in open(TICKERS)]\n",
    "# PAIR_WITH=\"USDT\"\n",
    "# VOLATILE_USDT_PAIRS=[coin+\"/USDT\" for coin in VOLATILE_COINS]\n",
    "# VOLATILE_BUSD_PAIRS=[coin+\"/BUSD\" for coin in VOLATILE_COINS]\n",
    "# VOLATILE_USDT_PAIRS\n",
    "\n",
    "# coins_to_download=''\n",
    "# for coin in VOLATILE_COINS:\n",
    "#     coins_to_download=coins_to_download+\" \"+coin\n",
    "# f\"node database/ddargs.js {coins_to_download} {PAIR_WITH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coins_to_download=''\n",
    "# for coin in VOLATILE_COINS:\n",
    "#     coins_to_download=coins_to_download+\" \"+coin\n",
    "# os.system(f\"node database/ddargs.js {coins_to_download} {PAIR_WITH}\")#node database/ddargs.js ORN BUSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair_list = find_intersection(VOLATILE_USDT_PAIRS,Binance_USDT_HALAL)\n",
    "# #tf = '1m'\n",
    "# oldest_pair = \"BTC/USDT\"\n",
    "# if oldest_pair not in pair_list: pair_list.append(oldest_pair)\n",
    "# df_list1m = {}\n",
    "# df_list1d = {}\n",
    "# df_list1h = {}\n",
    "# df_list5m = {}\n",
    "# df_list15m = {}\n",
    "\n",
    "\n",
    "# for pair in pair_list:\n",
    "#     df = get_historical_from_db(ccxt.binance(), pair, '1m', path=\"./database/\")\n",
    "#     df_list1m[pair] = df.loc[:]\n",
    "\n",
    "# for pair in pair_list:\n",
    "#     df = get_historical_from_db(ccxt.binance(), pair, '1d', path=\"./database/\")\n",
    "#     df_list1d[pair] = df.loc[:]\n",
    "\n",
    "# for pair in pair_list:\n",
    "#     df = get_historical_from_db(ccxt.binance(), pair, '1h', path=\"./database/\")\n",
    "#     df_list1h[pair] = df.loc[:]\n",
    "\n",
    "# for pair in pair_list:\n",
    "#     df = get_historical_from_db(ccxt.binance(), pair, '5m', path=\"./database/\")\n",
    "#     df_list5m[pair] = df.loc[:]\n",
    "\n",
    "# for pair in pair_list:\n",
    "#     df = get_historical_from_db(\n",
    "#         ccxt.binance(), pair, '15m', path=\"./database/\")\n",
    "#     df_list15m[pair] = df.loc[:]\n",
    "# del(df)\n",
    "# df_list = df_list1m\n",
    "# prerr(\"Data load 100% use df_list1d[\\\"BTC/USDT\\\"] for exemple to access\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Pair</th>\n",
       "      <th>launch_week_stamp</th>\n",
       "      <th>launch_day_stamp</th>\n",
       "      <th>launch_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SNMBUSD</td>\n",
       "      <td>SNM/BUSD</td>\n",
       "      <td>1661126400000</td>\n",
       "      <td>1661472000000</td>\n",
       "      <td>2022-08-26 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>BTC/USDT</td>\n",
       "      <td>1502668800000</td>\n",
       "      <td>1502928000000</td>\n",
       "      <td>2017-08-17 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LUNAUSDT</td>\n",
       "      <td>LUNA/USDT</td>\n",
       "      <td>1597622400000</td>\n",
       "      <td>1597968000000</td>\n",
       "      <td>2020-08-21 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>ETH/USDT</td>\n",
       "      <td>1502668800000</td>\n",
       "      <td>1502928000000</td>\n",
       "      <td>2017-08-17 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GMTUSDT</td>\n",
       "      <td>GMT/USDT</td>\n",
       "      <td>1646611200000</td>\n",
       "      <td>1646784000000</td>\n",
       "      <td>2022-03-09 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>FIDAUSDT</td>\n",
       "      <td>FIDA/USDT</td>\n",
       "      <td>1632700800000</td>\n",
       "      <td>1632960000000</td>\n",
       "      <td>2021-09-30 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>XNOUSDT</td>\n",
       "      <td>XNO/USDT</td>\n",
       "      <td>1642982400000</td>\n",
       "      <td>1643328000000</td>\n",
       "      <td>2022-01-28 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>BTGUSDT</td>\n",
       "      <td>BTG/USDT</td>\n",
       "      <td>1618185600000</td>\n",
       "      <td>1618531200000</td>\n",
       "      <td>2021-04-16 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>GHSTUSDT</td>\n",
       "      <td>GHST/USDT</td>\n",
       "      <td>1629072000000</td>\n",
       "      <td>1629417600000</td>\n",
       "      <td>2021-08-20 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>EPSUSDT</td>\n",
       "      <td>EPS/USDT</td>\n",
       "      <td>1616976000000</td>\n",
       "      <td>1617321600000</td>\n",
       "      <td>2021-04-02 09:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       Pair  launch_week_stamp  launch_day_stamp  \\\n",
       "0     SNMBUSD   SNM/BUSD      1661126400000     1661472000000   \n",
       "1     BTCUSDT   BTC/USDT      1502668800000     1502928000000   \n",
       "2    LUNAUSDT  LUNA/USDT      1597622400000     1597968000000   \n",
       "3     ETHUSDT   ETH/USDT      1502668800000     1502928000000   \n",
       "4     GMTUSDT   GMT/USDT      1646611200000     1646784000000   \n",
       "..        ...        ...                ...               ...   \n",
       "107  FIDAUSDT  FIDA/USDT      1632700800000     1632960000000   \n",
       "108   XNOUSDT   XNO/USDT      1642982400000     1643328000000   \n",
       "109   BTGUSDT   BTG/USDT      1618185600000     1618531200000   \n",
       "110  GHSTUSDT  GHST/USDT      1629072000000     1629417600000   \n",
       "111   EPSUSDT   EPS/USDT      1616976000000     1617321600000   \n",
       "\n",
       "           launch_minute  \n",
       "0    2022-08-26 08:00:00  \n",
       "1    2017-08-17 04:00:00  \n",
       "2    2020-08-21 10:00:00  \n",
       "3    2017-08-17 04:00:00  \n",
       "4    2022-03-09 12:00:00  \n",
       "..                   ...  \n",
       "107  2021-09-30 12:00:00  \n",
       "108  2022-01-28 08:00:00  \n",
       "109  2021-04-16 07:00:00  \n",
       "110  2021-08-20 10:00:00  \n",
       "111  2021-04-02 09:00:00  \n",
       "\n",
       "[112 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chking import\n",
    "MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '/UltimeTradingBot/Data/BUY_OPTIMAL'\n",
      "Results dir: /UltimeTradingBot/Data/BUY_OPTIMAL\n"
     ]
    }
   ],
   "source": [
    "if BUY_MODE==\"BUY_ONLY\":\n",
    "    buy_function=buy_up_only\n",
    "elif BUY_MODE==\"BUY_UP\":\n",
    "    buy_function=buy_up\n",
    "elif  BUY_MODE==\"BUY_DIP\":\n",
    "    buy_function=buy_min_up\n",
    "elif  BUY_MODE==\"AFTER_DEPTH\":\n",
    "    buy_function=buy_after_depth\n",
    "elif  BUY_MODE==\"BUY_UP_CLOSE\":\n",
    "    buy_function=buy_up_close\n",
    "elif  BUY_MODE==\"AFTER_DEPTH_CLOSE\":\n",
    "    buy_function=buy_after_depth_close\n",
    "elif  BUY_MODE==\"BUY_TEST\":\n",
    "    buy_function=buy_test\n",
    "elif BUY_MODE==\"BUY_MIN_CLOSE\":\n",
    "    buy_function=buy_min_close\n",
    "elif  BUY_MODE==\"SELL_TEST\":\n",
    "    buy_function=sell_test\n",
    "elif  BUY_MODE==\"BUY_FIX\":\n",
    "    buy_function=buy_fix\n",
    "elif  BUY_MODE==\"BUY_OPTIMAL\":\n",
    "    buy_function=buy_optimal\n",
    "\n",
    "\n",
    "try:\n",
    "    os.mkdir(DATA_DIR, mode = 0o777)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "print(f\"Results dir: {DATA_DIR}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on: SNM/BUSD -->mini_expand : SNM/BUSD\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (156489, 287)\n",
      "df original shape buy mean : 28.00452427966183\n",
      "SNM/BUSD is processed -- 0/112\n",
      "working on: LUNA/USDT -->mini_expand : LUNA/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (953805, 287)\n",
      "df original shape buy mean : 21.56090605522093\n",
      "LUNA/USDT is processed -- 1/112\n",
      "working on: GMT/USDT -->mini_expand : GMT/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (358605, 287)\n",
      "df original shape buy mean : 20.414941230601915\n",
      "GMT/USDT is processed -- 2/112\n",
      "working on: UST/USDT -->mini_expand : UST/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (180050, 287)\n",
      "df original shape buy mean : 1.4307136906414883\n",
      "UST/USDT is processed -- 3/112\n",
      "working on: SOL/USDT -->mini_expand : SOL/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (980042, 287)\n",
      "df original shape buy mean : 19.501307086839134\n",
      "SOL/USDT is processed -- 4/112\n",
      "working on: APE/USDT -->mini_expand : APE/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (347087, 287)\n",
      "df original shape buy mean : 19.864183907781047\n",
      "APE/USDT is processed -- 5/112\n",
      "working on: XRP/USDT -->mini_expand : XRP/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (980036, 287)\n",
      "df original shape buy mean : 13.429812782387584\n",
      "XRP/USDT is processed -- 6/112\n",
      "working on: IDEX/USDT -->mini_expand : IDEX/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455090, 287)\n",
      "df original shape buy mean : 16.117691006174603\n",
      "IDEX/USDT is processed -- 7/112\n",
      "working on: AVAX/USDT -->mini_expand : AVAX/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (980043, 287)\n",
      "df original shape buy mean : 21.925364499312785\n",
      "AVAX/USDT is processed -- 8/112\n",
      "working on: DOT/USDT -->mini_expand : DOT/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (980044, 287)\n",
      "df original shape buy mean : 17.540538996208333\n",
      "DOT/USDT is processed -- 9/112\n",
      "working on: ADA/USDT -->mini_expand : ADA/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (980034, 287)\n",
      "df original shape buy mean : 14.852750006632423\n",
      "ADA/USDT is processed -- 10/112\n",
      "working on: JASMY/USDT -->mini_expand : JASMY/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455092, 287)\n",
      "df original shape buy mean : 26.143065577949077\n",
      "JASMY/USDT is processed -- 11/112\n",
      "working on: TRX/USDT -->mini_expand : TRX/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455093, 287)\n",
      "df original shape buy mean : 4.80033751343132\n",
      "TRX/USDT is processed -- 12/112\n",
      "working on: NEAR/USDT -->mini_expand : NEAR/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (980048, 287)\n",
      "df original shape buy mean : 21.98606598860464\n",
      "NEAR/USDT is processed -- 13/112\n",
      "working on: AXS/USDT -->mini_expand : AXS/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455094, 287)\n",
      "df original shape buy mean : 14.6974031738498\n",
      "AXS/USDT is processed -- 14/112\n",
      "working on: GAL/USDT -->mini_expand : GAL/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (276534, 287)\n",
      "df original shape buy mean : 20.18413648954559\n",
      "GAL/USDT is processed -- 15/112\n",
      "working on: GALA/USDT -->mini_expand : GALA/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455096, 287)\n",
      "df original shape buy mean : 16.540905655070578\n",
      "GALA/USDT is processed -- 16/112\n",
      "working on: SHIB/USDT -->mini_expand : SHIB/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455097, 287)\n",
      "df original shape buy mean : 12.819904328088297\n",
      "SHIB/USDT is processed -- 17/112\n",
      "working on: ZIL/USDT -->mini_expand : ZIL/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455098, 287)\n",
      "df original shape buy mean : 14.302413985559154\n",
      "ZIL/USDT is processed -- 18/112\n",
      "working on: ENS/USDT -->mini_expand : ENS/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455098, 287)\n",
      "df original shape buy mean : 21.562169027330377\n",
      "ENS/USDT is processed -- 19/112\n",
      "working on: DOGE/USDT -->mini_expand : DOGE/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (980040, 287)\n",
      "df original shape buy mean : 16.18280886494429\n",
      "DOGE/USDT is processed -- 20/112\n",
      "working on: LTC/USDT -->mini_expand : LTC/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (980039, 287)\n",
      "df original shape buy mean : 13.23375906469028\n",
      "LTC/USDT is processed -- 21/112\n",
      "working on: MANA/USDT -->mini_expand : MANA/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (449670, 287)\n",
      "df original shape buy mean : 12.445348811350545\n",
      "MANA/USDT is processed -- 22/112\n",
      "working on: DAR/USDT -->mini_expand : DAR/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455101, 287)\n",
      "df original shape buy mean : 18.865043144269077\n",
      "DAR/USDT is processed -- 23/112\n",
      "working on: WAVES/USDT -->mini_expand : WAVES/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455102, 287)\n",
      "df original shape buy mean : 17.58550830363303\n",
      "WAVES/USDT is processed -- 24/112\n",
      "working on: LAZIO/USDT -->mini_expand : LAZIO/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455102, 287)\n",
      "df original shape buy mean : 19.95179102706646\n",
      "LAZIO/USDT is processed -- 25/112\n",
      "working on: ALICE/USDT -->mini_expand : ALICE/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455103, 287)\n",
      "df original shape buy mean : 15.607016433642496\n",
      "ALICE/USDT is processed -- 26/112\n",
      "working on: ROSE/USDT -->mini_expand : ROSE/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455103, 287)\n",
      "df original shape buy mean : 17.50021423721663\n",
      "ROSE/USDT is processed -- 27/112\n",
      "working on: ZEC/USDT -->mini_expand : ZEC/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455104, 287)\n",
      "df original shape buy mean : 14.123365208831387\n",
      "ZEC/USDT is processed -- 28/112\n",
      "working on: ALGO/USDT -->mini_expand : ALGO/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455105, 287)\n",
      "df original shape buy mean : 12.720580964832292\n",
      "ALGO/USDT is processed -- 29/112\n",
      "working on: GRT/USDT -->mini_expand : GRT/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455105, 287)\n",
      "df original shape buy mean : 15.87941244328232\n",
      "GRT/USDT is processed -- 30/112\n",
      "working on: PSG/USDT -->mini_expand : PSG/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455106, 287)\n",
      "df original shape buy mean : 14.536173990235243\n",
      "PSG/USDT is processed -- 31/112\n",
      "working on: SLP/USDT -->mini_expand : SLP/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455106, 287)\n",
      "df original shape buy mean : 31.510461299125918\n",
      "SLP/USDT is processed -- 32/112\n",
      "working on: EOS/USDT -->mini_expand : EOS/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455107, 287)\n",
      "df original shape buy mean : 9.648500242800045\n",
      "EOS/USDT is processed -- 33/112\n",
      "working on: PORTO/USDT -->mini_expand : PORTO/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (449670, 287)\n",
      "df original shape buy mean : 19.113127404541107\n",
      "PORTO/USDT is processed -- 34/112\n",
      "working on: ICP/USDT -->mini_expand : ICP/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455108, 287)\n",
      "df original shape buy mean : 15.854698225476152\n",
      "ICP/USDT is processed -- 35/112\n",
      "working on: EGLD/USDT -->mini_expand : EGLD/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (980049, 287)\n",
      "df original shape buy mean : 18.300411510036742\n",
      "EGLD/USDT is processed -- 36/112\n",
      "working on: XMR/USDT -->mini_expand : XMR/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455109, 287)\n",
      "df original shape buy mean : 10.316869145633243\n",
      "XMR/USDT is processed -- 37/112\n",
      "working on: KDA/USDT -->mini_expand : KDA/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (355750, 287)\n",
      "df original shape buy mean : 15.74673225579761\n",
      "KDA/USDT is processed -- 38/112\n",
      "working on: ETC/USDT -->mini_expand : ETC/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455111, 287)\n",
      "df original shape buy mean : 13.565262100894069\n",
      "ETC/USDT is processed -- 39/112\n",
      "working on: MBOX/USDT -->mini_expand : MBOX/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455111, 287)\n",
      "df original shape buy mean : 13.322903643287024\n",
      "MBOX/USDT is processed -- 40/112\n",
      "working on: OGN/USDT -->mini_expand : OGN/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455112, 287)\n",
      "df original shape buy mean : 17.811439821406598\n",
      "OGN/USDT is processed -- 41/112\n",
      "working on: AR/USDT -->mini_expand : AR/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455112, 287)\n",
      "df original shape buy mean : 18.81251208493733\n",
      "AR/USDT is processed -- 42/112\n",
      "working on: GLMR/USDT -->mini_expand : GLMR/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (440713, 287)\n",
      "df original shape buy mean : 19.218402906199728\n",
      "GLMR/USDT is processed -- 43/112\n",
      "working on: LOKA/USDT -->mini_expand : LOKA/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (427754, 287)\n",
      "df original shape buy mean : 19.254992355419237\n",
      "LOKA/USDT is processed -- 44/112\n",
      "working on: XLM/USDT -->mini_expand : XLM/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455114, 287)\n",
      "df original shape buy mean : 7.97580386452625\n",
      "XLM/USDT is processed -- 45/112\n",
      "working on: MTL/USDT -->mini_expand : MTL/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455115, 287)\n",
      "df original shape buy mean : 14.46403656218758\n",
      "MTL/USDT is processed -- 46/112\n",
      "working on: SNX/USDT -->mini_expand : SNX/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455116, 287)\n",
      "df original shape buy mean : 18.85101820195291\n",
      "SNX/USDT is processed -- 47/112\n",
      "working on: PYR/USDT -->mini_expand : PYR/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455116, 287)\n",
      "df original shape buy mean : 24.985278478453846\n",
      "PYR/USDT is processed -- 48/112\n",
      "working on: DASH/USDT -->mini_expand : DASH/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455117, 287)\n",
      "df original shape buy mean : 12.409995671442728\n",
      "DASH/USDT is processed -- 49/112\n",
      "working on: CITY/USDT -->mini_expand : CITY/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (433170, 287)\n",
      "df original shape buy mean : 14.717085670752821\n",
      "CITY/USDT is processed -- 50/112\n",
      "working on: ASTR/USDT -->mini_expand : ASTR/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (371598, 287)\n",
      "df original shape buy mean : 20.29962486342768\n",
      "ASTR/USDT is processed -- 51/112\n",
      "working on: IOTA/USDT -->mini_expand : IOTA/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455119, 287)\n",
      "df original shape buy mean : 10.642491304472017\n",
      "IOTA/USDT is processed -- 52/112\n",
      "working on: ACM/USDT -->mini_expand : ACM/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (445170, 287)\n",
      "df original shape buy mean : 15.836646674304196\n",
      "ACM/USDT is processed -- 53/112\n",
      "working on: BAR/USDT -->mini_expand : BAR/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455120, 287)\n",
      "df original shape buy mean : 17.628976973105996\n",
      "BAR/USDT is processed -- 54/112\n",
      "working on: JUV/USDT -->mini_expand : JUV/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455121, 287)\n",
      "df original shape buy mean : 16.008490049898818\n",
      "JUV/USDT is processed -- 55/112\n",
      "working on: SYS/USDT -->mini_expand : SYS/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455121, 287)\n",
      "df original shape buy mean : 16.87705027893681\n",
      "SYS/USDT is processed -- 56/112\n",
      "working on: RVN/USDT -->mini_expand : RVN/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455122, 287)\n",
      "df original shape buy mean : 15.575164461397165\n",
      "RVN/USDT is processed -- 57/112\n",
      "working on: MBL/USDT -->mini_expand : MBL/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455123, 287)\n",
      "df original shape buy mean : 14.139694104670605\n",
      "MBL/USDT is processed -- 58/112\n",
      "working on: REN/USDT -->mini_expand : REN/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455123, 287)\n",
      "df original shape buy mean : 17.95097149561767\n",
      "REN/USDT is processed -- 59/112\n",
      "working on: JST/USDT -->mini_expand : JST/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455124, 287)\n",
      "df original shape buy mean : 8.650609504223025\n",
      "JST/USDT is processed -- 60/112\n",
      "working on: OMG/USDT -->mini_expand : OMG/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455124, 287)\n",
      "df original shape buy mean : 12.821560717518743\n",
      "OMG/USDT is processed -- 61/112\n",
      "working on: ATM/USDT -->mini_expand : ATM/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455125, 287)\n",
      "df original shape buy mean : 17.152210931062896\n",
      "ATM/USDT is processed -- 62/112\n",
      "working on: XEC/USDT -->mini_expand : XEC/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455126, 287)\n",
      "df original shape buy mean : 12.604421632690727\n",
      "XEC/USDT is processed -- 63/112\n",
      "working on: STORJ/USDT -->mini_expand : STORJ/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455126, 287)\n",
      "df original shape buy mean : 15.618971449664487\n",
      "STORJ/USDT is processed -- 64/112\n",
      "working on: ZRX/USDT -->mini_expand : ZRX/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455127, 287)\n",
      "df original shape buy mean : 13.823833787052845\n",
      "ZRX/USDT is processed -- 65/112\n",
      "working on: SRM/USDT -->mini_expand : SRM/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455127, 287)\n",
      "df original shape buy mean : 12.05927136821151\n",
      "SRM/USDT is processed -- 66/112\n",
      "working on: ICX/USDT -->mini_expand : ICX/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455128, 287)\n",
      "df original shape buy mean : 13.700321667750611\n",
      "ICX/USDT is processed -- 67/112\n",
      "working on: API3/USDT -->mini_expand : API3/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (426329, 287)\n",
      "df original shape buy mean : 19.885112202078677\n",
      "API3/USDT is processed -- 68/112\n",
      "working on: ONT/USDT -->mini_expand : ONT/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455129, 287)\n",
      "df original shape buy mean : 10.251818715133512\n",
      "ONT/USDT is processed -- 69/112\n",
      "working on: SKL/USDT -->mini_expand : SKL/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455130, 287)\n",
      "df original shape buy mean : 18.483290488431876\n",
      "SKL/USDT is processed -- 70/112\n",
      "working on: MULTI/USDT -->mini_expand : MULTI/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (318330, 287)\n",
      "df original shape buy mean : 11.550592152797412\n",
      "MULTI/USDT is processed -- 71/112\n",
      "working on: QTUM/USDT -->mini_expand : QTUM/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455131, 287)\n",
      "df original shape buy mean : 11.157446976804481\n",
      "QTUM/USDT is processed -- 72/112\n",
      "working on: COCOS/USDT -->mini_expand : COCOS/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455132, 287)\n",
      "df original shape buy mean : 12.842867563695807\n",
      "COCOS/USDT is processed -- 73/112\n",
      "working on: VOXEL/USDT -->mini_expand : VOXEL/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (444420, 287)\n",
      "df original shape buy mean : 18.42671346924081\n",
      "VOXEL/USDT is processed -- 74/112\n",
      "working on: HIVE/USDT -->mini_expand : HIVE/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455133, 287)\n",
      "df original shape buy mean : 12.329582781296896\n",
      "HIVE/USDT is processed -- 75/112\n",
      "working on: KP3R/USDT -->mini_expand : KP3R/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455134, 287)\n",
      "df original shape buy mean : 19.477999885747934\n",
      "KP3R/USDT is processed -- 76/112\n",
      "working on: ATA/USDT -->mini_expand : ATA/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455134, 287)\n",
      "df original shape buy mean : 16.26971397434602\n",
      "ATA/USDT is processed -- 77/112\n",
      "working on: STMX/USDT -->mini_expand : STMX/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455135, 287)\n",
      "df original shape buy mean : 13.932349742384128\n",
      "STMX/USDT is processed -- 78/112\n",
      "working on: ADX/USDT -->mini_expand : ADX/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455136, 287)\n",
      "df original shape buy mean : 7.842271321099627\n",
      "ADX/USDT is processed -- 79/112\n",
      "working on: HIGH/USDT -->mini_expand : HIGH/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455136, 287)\n",
      "df original shape buy mean : 25.07624094776067\n",
      "HIGH/USDT is processed -- 80/112\n",
      "working on: NULS/USDT -->mini_expand : NULS/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455137, 287)\n",
      "df original shape buy mean : 16.280592437002486\n",
      "NULS/USDT is processed -- 81/112\n",
      "working on: MLN/USDT -->mini_expand : MLN/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455137, 287)\n",
      "df original shape buy mean : 12.080098959214478\n",
      "MLN/USDT is processed -- 82/112\n",
      "working on: YGG/USDT -->mini_expand : YGG/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455138, 287)\n",
      "df original shape buy mean : 20.260228765780926\n",
      "YGG/USDT is processed -- 83/112\n",
      "working on: SC/USDT -->mini_expand : SC/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455139, 287)\n",
      "df original shape buy mean : 12.497061337305746\n",
      "SC/USDT is processed -- 84/112\n",
      "working on: CKB/USDT -->mini_expand : CKB/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455139, 287)\n",
      "df original shape buy mean : 11.697305658271429\n",
      "CKB/USDT is processed -- 85/112\n",
      "working on: TOMO/USDT -->mini_expand : TOMO/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455140, 287)\n",
      "df original shape buy mean : 15.194665377685986\n",
      "TOMO/USDT is processed -- 86/112\n",
      "working on: STX/USDT -->mini_expand : STX/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455140, 287)\n",
      "df original shape buy mean : 14.798743243837063\n",
      "STX/USDT is processed -- 87/112\n",
      "working on: FLUX/USDT -->mini_expand : FLUX/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455141, 287)\n",
      "df original shape buy mean : 19.287429609725336\n",
      "FLUX/USDT is processed -- 88/112\n",
      "working on: DNT/USDT -->mini_expand : DNT/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (416700, 287)\n",
      "df original shape buy mean : 16.34749220062395\n",
      "DNT/USDT is processed -- 89/112\n",
      "working on: ORN/USDT -->mini_expand : ORN/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455142, 287)\n",
      "df original shape buy mean : 12.544656392949893\n",
      "ORN/USDT is processed -- 90/112\n",
      "working on: PLA/USDT -->mini_expand : PLA/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455143, 287)\n",
      "df original shape buy mean : 14.663303621059756\n",
      "PLA/USDT is processed -- 91/112\n",
      "working on: BADGER/USDT -->mini_expand : BADGER/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455143, 287)\n",
      "df original shape buy mean : 15.468105628340984\n",
      "BADGER/USDT is processed -- 92/112\n",
      "working on: DF/USDT -->mini_expand : DF/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455144, 287)\n",
      "df original shape buy mean : 17.09524897614821\n",
      "DF/USDT is processed -- 93/112\n",
      "working on: MOB/USDT -->mini_expand : MOB/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (285225, 287)\n",
      "df original shape buy mean : 9.447629064773425\n",
      "MOB/USDT is processed -- 94/112\n",
      "working on: LPT/USDT -->mini_expand : LPT/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455145, 287)\n",
      "df original shape buy mean : 14.522844368278239\n",
      "LPT/USDT is processed -- 95/112\n",
      "working on: SCRT/USDT -->mini_expand : SCRT/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (426346, 287)\n",
      "df original shape buy mean : 11.020391888278533\n",
      "SCRT/USDT is processed -- 96/112\n",
      "working on: RAD/USDT -->mini_expand : RAD/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (621579, 287)\n",
      "df original shape buy mean : 14.48037980691111\n",
      "RAD/USDT is processed -- 97/112\n",
      "working on: NMR/USDT -->mini_expand : NMR/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455147, 287)\n",
      "df original shape buy mean : 11.909119471291692\n",
      "NMR/USDT is processed -- 98/112\n",
      "working on: ELF/USDT -->mini_expand : ELF/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455148, 287)\n",
      "df original shape buy mean : 9.19590990183413\n",
      "ELF/USDT is processed -- 99/112\n",
      "working on: TORN/USDT -->mini_expand : TORN/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (444420, 287)\n",
      "df original shape buy mean : 19.484721659691285\n",
      "TORN/USDT is processed -- 100/112\n",
      "working on: T/USDT -->mini_expand : T/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (375949, 287)\n",
      "df original shape buy mean : 12.597719371510497\n",
      "T/USDT is processed -- 101/112\n",
      "working on: QUICK/USDT -->mini_expand : QUICK/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455150, 287)\n",
      "df original shape buy mean : 13.72404701746677\n",
      "QUICK/USDT is processed -- 102/112\n",
      "working on: LSK/USDT -->mini_expand : LSK/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455150, 287)\n",
      "df original shape buy mean : 10.814896188069866\n",
      "LSK/USDT is processed -- 103/112\n",
      "working on: FIDA/USDT -->mini_expand : FIDA/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455151, 287)\n",
      "df original shape buy mean : 14.192652548275186\n",
      "FIDA/USDT is processed -- 104/112\n",
      "working on: XNO/USDT -->mini_expand : XNO/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (416272, 287)\n",
      "df original shape buy mean : 10.652169735173157\n",
      "XNO/USDT is processed -- 105/112\n",
      "working on: BTG/USDT -->mini_expand : BTG/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (416700, 287)\n",
      "df original shape buy mean : 11.752099832013439\n",
      "BTG/USDT is processed -- 106/112\n",
      "working on: GHST/USDT -->mini_expand : GHST/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (455153, 287)\n",
      "df original shape buy mean : 2.3862305642278527\n",
      "GHST/USDT is processed -- 107/112\n",
      "working on: EPS/USDT -->mini_expand : EPS/USDT\n",
      "after mark = : 1\n",
      "optimalbuy buy maximum forcast size=7 at 0.4% of the current price \n",
      "df original shape (174480, 287)\n",
      "df original shape buy mean : 19.85900962861073\n",
      "EPS/USDT is processed -- 108/112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdf=pd.DataFrame()\n",
    "count=0\n",
    "row_numbers=30000\n",
    "for pair in pair_list:\n",
    "    if pair != \"BTC/USDT\" and pair != \"EUR/USDT\" and pair != \"ETH/USDT\" :\n",
    "        print(\"working on: \"+pair ,end=\" -->\")\n",
    "        try:\n",
    "            df=mini_expand4(pair=pair,i=0,j=len(df_list1m[pair]),window=WINDOW_SIZE,metadata=MetaData,buy_pourcent=BUY_PERCENT,sell_pourcent=SELL_PERCENT,buy_function=buy_function)\n",
    "            print(\"df original shape \"+str(df.shape))\n",
    "            print(f\"df original shape buy mean : {df.buy.mean()*100}\")\n",
    "            df=df.reset_index()\n",
    "            try:df.pop(\"num_index\")\n",
    "            except: pass\n",
    "            try:df.pop(\"index\")\n",
    "            except: pass\n",
    "            try:df.pop(\"date\")\n",
    "            except: pass\n",
    "            df=data_shufler(df)            \n",
    "            #df=data_chooser(df,weight=50,row_numbers=df.buy.sum()*2)\n",
    "            df=data_chooser50(df,row_numbers=row_numbers)\n",
    "            gc.collect()\n",
    "            df=data_cleanup(df)\n",
    "            df=df.dropna()\n",
    "            print(pair+f\" is processed -- {count}/{len(pair_list)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"error while processing {pair} {count}/{len(pair_list)}\")\n",
    "            print(e)\n",
    "        xdf=pd.concat([xdf,df],axis=0)\n",
    "        count+=1\n",
    "        del(df)\n",
    "        gc.collect()\n",
    "df=xdf\n",
    "del xdf\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>high-1</th>\n",
       "      <th>low-1</th>\n",
       "      <th>close-1</th>\n",
       "      <th>volume-1</th>\n",
       "      <th>high-2</th>\n",
       "      <th>low-2</th>\n",
       "      <th>close-2</th>\n",
       "      <th>volume-2</th>\n",
       "      <th>high-3</th>\n",
       "      <th>...</th>\n",
       "      <th>BTC_volume-6_5min</th>\n",
       "      <th>BTC_high-7_5min</th>\n",
       "      <th>BTC_low-7_5min</th>\n",
       "      <th>BTC_close-7_5min</th>\n",
       "      <th>BTC_volume-7_5min</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>lunch_day</th>\n",
       "      <th>buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.28560</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>...</td>\n",
       "      <td>358.52991</td>\n",
       "      <td>-0.001288</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>535.53108</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>-713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.58510</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>914.600</td>\n",
       "      <td>-0.000513</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>1572.300</td>\n",
       "      <td>-0.001538</td>\n",
       "      <td>...</td>\n",
       "      <td>2654.91991</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>0.007678</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>2515.92199</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>-750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.32180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>27299.000</td>\n",
       "      <td>-0.003729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101327.000</td>\n",
       "      <td>-0.004972</td>\n",
       "      <td>...</td>\n",
       "      <td>46.32448</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>121.04474</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2984.000</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>...</td>\n",
       "      <td>636.14099</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>803.22086</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>-335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.15325</td>\n",
       "      <td>-0.002936</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>-0.002936</td>\n",
       "      <td>357272.000</td>\n",
       "      <td>-0.001631</td>\n",
       "      <td>0.003589</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>380972.000</td>\n",
       "      <td>-0.002936</td>\n",
       "      <td>...</td>\n",
       "      <td>679.98041</td>\n",
       "      <td>0.011074</td>\n",
       "      <td>0.018675</td>\n",
       "      <td>0.012257</td>\n",
       "      <td>567.94489</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269995</th>\n",
       "      <td>4.93000</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>428.164</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>140.069</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>...</td>\n",
       "      <td>191.30447</td>\n",
       "      <td>-0.007470</td>\n",
       "      <td>-0.003197</td>\n",
       "      <td>-0.005333</td>\n",
       "      <td>375.83644</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>-695</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269996</th>\n",
       "      <td>0.09905</td>\n",
       "      <td>-0.002524</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>154146.500</td>\n",
       "      <td>-0.000505</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>17808.600</td>\n",
       "      <td>-0.000505</td>\n",
       "      <td>...</td>\n",
       "      <td>343.19869</td>\n",
       "      <td>-0.010316</td>\n",
       "      <td>-0.003280</td>\n",
       "      <td>-0.009001</td>\n",
       "      <td>496.36454</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>-789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269997</th>\n",
       "      <td>1.53050</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>192.200</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>9420.400</td>\n",
       "      <td>-0.001633</td>\n",
       "      <td>...</td>\n",
       "      <td>428.73711</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>396.71690</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269998</th>\n",
       "      <td>18.33000</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>103.590</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>25.170</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>...</td>\n",
       "      <td>721.70305</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>604.53291</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269999</th>\n",
       "      <td>2.32150</td>\n",
       "      <td>-0.002369</td>\n",
       "      <td>-0.000646</td>\n",
       "      <td>-0.000646</td>\n",
       "      <td>1567.450</td>\n",
       "      <td>-0.002800</td>\n",
       "      <td>-0.002369</td>\n",
       "      <td>-0.002369</td>\n",
       "      <td>448.240</td>\n",
       "      <td>-0.004092</td>\n",
       "      <td>...</td>\n",
       "      <td>1711.89172</td>\n",
       "      <td>-0.005306</td>\n",
       "      <td>-0.002587</td>\n",
       "      <td>-0.005046</td>\n",
       "      <td>496.11230</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>-439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3270000 rows Ã— 287 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            price    high-1     low-1   close-1    volume-1    high-2  \\\n",
       "0         0.28560  0.001751  0.001751  0.001751       0.000  0.001751   \n",
       "1         0.58510  0.000342  0.000684  0.000342     914.600 -0.000513   \n",
       "2         0.32180  0.000000  0.001243  0.000622   27299.000 -0.003729   \n",
       "3         0.03833  0.000000  0.000000  0.000000       0.000  0.000000   \n",
       "4         0.15325 -0.002936  0.001631 -0.002936  357272.000 -0.001631   \n",
       "...           ...       ...       ...       ...         ...       ...   \n",
       "3269995   4.93000 -0.002028  0.002028  0.000000     428.164  0.002028   \n",
       "3269996   0.09905 -0.002524  0.000505  0.000505  154146.500 -0.000505   \n",
       "3269997   1.53050  0.000327  0.000980  0.000327     192.200 -0.000327   \n",
       "3269998  18.33000 -0.000546 -0.000546 -0.000546     103.590 -0.000546   \n",
       "3269999   2.32150 -0.002369 -0.000646 -0.000646    1567.450 -0.002800   \n",
       "\n",
       "            low-2   close-2    volume-2    high-3  ...  BTC_volume-6_5min  \\\n",
       "0        0.001751  0.001751       0.000  0.001751  ...          358.52991   \n",
       "1        0.000855  0.000342    1572.300 -0.001538  ...         2654.91991   \n",
       "2        0.000000  0.000000  101327.000 -0.004972  ...           46.32448   \n",
       "3        0.000261  0.000000    2984.000  0.000522  ...          636.14099   \n",
       "4        0.003589  0.001631  380972.000 -0.002936  ...          679.98041   \n",
       "...           ...       ...         ...       ...  ...                ...   \n",
       "3269995  0.002028  0.002028     140.069 -0.002028  ...          191.30447   \n",
       "3269996  0.000505  0.000505   17808.600 -0.000505  ...          343.19869   \n",
       "3269997  0.001633  0.000980    9420.400 -0.001633  ...          428.73711   \n",
       "3269998 -0.000546 -0.000546      25.170 -0.000546  ...          721.70305   \n",
       "3269999 -0.002369 -0.002369     448.240 -0.004092  ...         1711.89172   \n",
       "\n",
       "         BTC_high-7_5min  BTC_low-7_5min  BTC_close-7_5min  BTC_volume-7_5min  \\\n",
       "0              -0.001288        0.000484         -0.000240          535.53108   \n",
       "1              -0.000205        0.007678          0.003162         2515.92199   \n",
       "2               0.002513        0.004689          0.002913          121.04474   \n",
       "3              -0.000237        0.000992          0.000803          803.22086   \n",
       "4               0.011074        0.018675          0.012257          567.94489   \n",
       "...                  ...             ...               ...                ...   \n",
       "3269995        -0.007470       -0.003197         -0.005333          375.83644   \n",
       "3269996        -0.010316       -0.003280         -0.009001          496.36454   \n",
       "3269997         0.001549        0.002416          0.002297          396.71690   \n",
       "3269998         0.000289        0.002000          0.000582          604.53291   \n",
       "3269999        -0.005306       -0.002587         -0.005046          496.11230   \n",
       "\n",
       "         day  hour  minute  lunch_day  buy  \n",
       "0          6    18      31       -713    0  \n",
       "1          5     4      47       -750    0  \n",
       "2          3     1       6       -351    0  \n",
       "3          6    10      11       -335    1  \n",
       "4          2     6       9        580    1  \n",
       "...      ...   ...     ...        ...  ...  \n",
       "3269995    1    19      39       -695    0  \n",
       "3269996    3    11      45       -789    1  \n",
       "3269997    6    12      36        583    1  \n",
       "3269998    7     1      13       -265    1  \n",
       "3269999    1    14       0       -439    1  \n",
       "\n",
       "[3270000 rows x 287 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.reset_index().drop(columns=\"num_index\")\n",
    "gc.collect()\n",
    "for i in range(1):\n",
    "    df = df.reindex(np.random.permutation(df.index)).reset_index().drop(columns=\"index\")\n",
    "    gc.collect()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather(f\"../Data/fea/w{WINDOW_SIZE}_buy{BUY_PERCENT}_forcasr{MAX_FORCAST_SIZE}min_{BUY_MODE}.fea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df choosen data shape(3270000, 287)\n",
      "pair: True\n",
      "654000\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print(\"df choosen data shape\"+str(df.shape))\n",
    "print(f\"pair: {(df.shape[0]/2)==df.buy.sum()}\")\n",
    "dt=df.to_numpy(dtype=np.float32)\n",
    "#dt=df.to_numpy()\n",
    "dt=np.nan_to_num(dt,nan=0)\n",
    "#dt=dt.astype(np.float32)\n",
    "dt=np.nan_to_num(dt, neginf=0) \n",
    "dt=np.nan_to_num(dt, posinf=0) \n",
    "\n",
    "index_20percent= int(0.2*len(dt[:,0]))\n",
    "print(index_20percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # feather loading\n",
    "# df=pd.read_feather(f\"../Data/fea/w{WINDOW_SIZE}_buy{BUY_PERCENT}_forcasr{MAX_FORCAST_SIZE}min_{BUY_MODE}.fea\")\n",
    "# dt=df.to_numpy(dtype=np.float32)\n",
    "# dt=fixdt(dt)\n",
    "# index_20percent= int(0.2*len(dt[:,0]))\n",
    "# gc.collect()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Normalized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 18:07:52.943930: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-09 18:07:52.945895: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-09 18:07:52.946806: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: abj-K93SV\n",
      "2023-03-09 18:07:52.946885: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: abj-K93SV\n",
      "2023-03-09 18:07:52.947562: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2023-03-09 18:07:52.949598: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 390.154.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 286)              1144      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 250)               71750     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 250)              1000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                5020      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,015\n",
      "Trainable params: 78,943\n",
      "Non-trainable params: 1,072\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/BUY_OPTIMAL/tp40_w7_max7min_Model_v5.h5\n",
      "Epoch 1/6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 18:08:01.168159: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2992704000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 58s 55ms/step - loss: 0.5881 - accuracy: 0.6867 - val_loss: 0.5836 - val_accuracy: 0.6919\n",
      "Epoch 2/6000\n",
      "1022/1022 [==============================] - 58s 57ms/step - loss: 0.5785 - accuracy: 0.6954 - val_loss: 0.5789 - val_accuracy: 0.6954\n",
      "Epoch 3/6000\n",
      "1022/1022 [==============================] - 59s 58ms/step - loss: 0.5743 - accuracy: 0.6987 - val_loss: 0.5777 - val_accuracy: 0.6968\n",
      "Epoch 4/6000\n",
      "1022/1022 [==============================] - 59s 58ms/step - loss: 0.5704 - accuracy: 0.7020 - val_loss: 0.5741 - val_accuracy: 0.7001\n",
      "Epoch 5/6000\n",
      "1022/1022 [==============================] - 62s 60ms/step - loss: 0.5668 - accuracy: 0.7050 - val_loss: 0.5724 - val_accuracy: 0.7016\n",
      "Epoch 6/6000\n",
      "1022/1022 [==============================] - 62s 61ms/step - loss: 0.5635 - accuracy: 0.7079 - val_loss: 0.5706 - val_accuracy: 0.7031\n",
      "Epoch 7/6000\n",
      "1022/1022 [==============================] - 59s 58ms/step - loss: 0.5602 - accuracy: 0.7103 - val_loss: 0.5694 - val_accuracy: 0.7040\n",
      "Epoch 8/6000\n",
      "1022/1022 [==============================] - 61s 59ms/step - loss: 0.5572 - accuracy: 0.7131 - val_loss: 0.5654 - val_accuracy: 0.7072\n",
      "Epoch 9/6000\n",
      "1022/1022 [==============================] - 64s 63ms/step - loss: 0.5547 - accuracy: 0.7150 - val_loss: 0.5639 - val_accuracy: 0.7087\n",
      "Epoch 10/6000\n",
      "1022/1022 [==============================] - 60s 59ms/step - loss: 0.5520 - accuracy: 0.7171 - val_loss: 0.5602 - val_accuracy: 0.7121\n",
      "Epoch 11/6000\n",
      "1022/1022 [==============================] - 61s 60ms/step - loss: 0.5498 - accuracy: 0.7189 - val_loss: 0.5646 - val_accuracy: 0.7091\n",
      "Epoch 12/6000\n",
      "1022/1022 [==============================] - 60s 59ms/step - loss: 0.5477 - accuracy: 0.7206 - val_loss: 0.5597 - val_accuracy: 0.7126\n",
      "Epoch 13/6000\n",
      "1022/1022 [==============================] - 61s 60ms/step - loss: 0.5459 - accuracy: 0.7218 - val_loss: 0.5677 - val_accuracy: 0.7079\n",
      "Epoch 14/6000\n",
      "1022/1022 [==============================] - 62s 61ms/step - loss: 0.5440 - accuracy: 0.7236 - val_loss: 0.5545 - val_accuracy: 0.7163\n",
      "Epoch 15/6000\n",
      "1022/1022 [==============================] - 61s 60ms/step - loss: 0.5422 - accuracy: 0.7247 - val_loss: 0.5569 - val_accuracy: 0.7149\n",
      "Epoch 16/6000\n",
      "1022/1022 [==============================] - 60s 58ms/step - loss: 0.5409 - accuracy: 0.7258 - val_loss: 0.5575 - val_accuracy: 0.7154\n",
      "Epoch 17/6000\n",
      "1022/1022 [==============================] - 61s 59ms/step - loss: 0.5393 - accuracy: 0.7268 - val_loss: 0.5527 - val_accuracy: 0.7177\n",
      "Epoch 18/6000\n",
      "1022/1022 [==============================] - 63s 61ms/step - loss: 0.5379 - accuracy: 0.7278 - val_loss: 0.5546 - val_accuracy: 0.7173\n",
      "Epoch 19/6000\n",
      "1022/1022 [==============================] - 63s 61ms/step - loss: 0.5365 - accuracy: 0.7288 - val_loss: 0.5554 - val_accuracy: 0.7169\n",
      "Epoch 20/6000\n",
      "1022/1022 [==============================] - 61s 60ms/step - loss: 0.5353 - accuracy: 0.7300 - val_loss: 0.5526 - val_accuracy: 0.7192\n",
      "Epoch 21/6000\n",
      "1022/1022 [==============================] - 62s 61ms/step - loss: 0.5341 - accuracy: 0.7306 - val_loss: 0.5508 - val_accuracy: 0.7192\n",
      "Epoch 22/6000\n",
      "1022/1022 [==============================] - 63s 62ms/step - loss: 0.5332 - accuracy: 0.7313 - val_loss: 0.5499 - val_accuracy: 0.7203\n",
      "Epoch 23/6000\n",
      "1022/1022 [==============================] - 60s 59ms/step - loss: 0.5319 - accuracy: 0.7322 - val_loss: 0.5532 - val_accuracy: 0.7194\n",
      "Epoch 24/6000\n",
      "1022/1022 [==============================] - 61s 60ms/step - loss: 0.5311 - accuracy: 0.7328 - val_loss: 0.5487 - val_accuracy: 0.7207\n",
      "Epoch 25/6000\n",
      "1022/1022 [==============================] - 60s 59ms/step - loss: 0.5301 - accuracy: 0.7337 - val_loss: 0.5457 - val_accuracy: 0.7234\n",
      "Epoch 26/6000\n",
      "1022/1022 [==============================] - 61s 60ms/step - loss: 0.5291 - accuracy: 0.7343 - val_loss: 0.5491 - val_accuracy: 0.7212\n",
      "Epoch 27/6000\n",
      "1022/1022 [==============================] - 62s 60ms/step - loss: 0.5284 - accuracy: 0.7348 - val_loss: 0.5531 - val_accuracy: 0.7190\n",
      "Epoch 28/6000\n",
      "1022/1022 [==============================] - 62s 61ms/step - loss: 0.5277 - accuracy: 0.7352 - val_loss: 0.5463 - val_accuracy: 0.7236\n",
      "Epoch 29/6000\n",
      "1022/1022 [==============================] - 64s 62ms/step - loss: 0.5269 - accuracy: 0.7360 - val_loss: 0.5450 - val_accuracy: 0.7238\n",
      "Epoch 30/6000\n",
      "1022/1022 [==============================] - 64s 62ms/step - loss: 0.5262 - accuracy: 0.7365 - val_loss: 0.5529 - val_accuracy: 0.7190\n",
      "Epoch 31/6000\n",
      "1022/1022 [==============================] - 104s 101ms/step - loss: 0.5254 - accuracy: 0.7370 - val_loss: 0.5430 - val_accuracy: 0.7255\n",
      "Epoch 32/6000\n",
      "1022/1022 [==============================] - 116s 113ms/step - loss: 0.5249 - accuracy: 0.7376 - val_loss: 0.5447 - val_accuracy: 0.7249\n",
      "Epoch 33/6000\n",
      "1022/1022 [==============================] - 114s 112ms/step - loss: 0.5240 - accuracy: 0.7382 - val_loss: 0.5425 - val_accuracy: 0.7257\n",
      "Epoch 34/6000\n",
      "1022/1022 [==============================] - 114s 111ms/step - loss: 0.5235 - accuracy: 0.7384 - val_loss: 0.5418 - val_accuracy: 0.7264\n",
      "Epoch 35/6000\n",
      "1022/1022 [==============================] - 114s 111ms/step - loss: 0.5228 - accuracy: 0.7389 - val_loss: 0.5417 - val_accuracy: 0.7267\n",
      "Epoch 36/6000\n",
      "1022/1022 [==============================] - 113s 111ms/step - loss: 0.5220 - accuracy: 0.7395 - val_loss: 0.5450 - val_accuracy: 0.7251\n",
      "Epoch 37/6000\n",
      "1022/1022 [==============================] - 116s 114ms/step - loss: 0.5216 - accuracy: 0.7395 - val_loss: 0.5401 - val_accuracy: 0.7275\n",
      "Epoch 38/6000\n",
      "1022/1022 [==============================] - 114s 111ms/step - loss: 0.5212 - accuracy: 0.7402 - val_loss: 0.5403 - val_accuracy: 0.7277\n",
      "Epoch 39/6000\n",
      "1022/1022 [==============================] - 114s 112ms/step - loss: 0.5206 - accuracy: 0.7404 - val_loss: 0.5461 - val_accuracy: 0.7242\n",
      "Epoch 40/6000\n",
      "1022/1022 [==============================] - 117s 114ms/step - loss: 0.5200 - accuracy: 0.7408 - val_loss: 0.5397 - val_accuracy: 0.7287\n",
      "Epoch 41/6000\n",
      "1022/1022 [==============================] - 114s 112ms/step - loss: 0.5196 - accuracy: 0.7412 - val_loss: 0.5404 - val_accuracy: 0.7287\n",
      "Epoch 42/6000\n",
      "1022/1022 [==============================] - 114s 112ms/step - loss: 0.5190 - accuracy: 0.7416 - val_loss: 0.5445 - val_accuracy: 0.7254\n",
      "Epoch 43/6000\n",
      "1022/1022 [==============================] - 114s 111ms/step - loss: 0.5186 - accuracy: 0.7418 - val_loss: 0.5474 - val_accuracy: 0.7240\n",
      "Epoch 44/6000\n",
      "1022/1022 [==============================] - 116s 114ms/step - loss: 0.5180 - accuracy: 0.7420 - val_loss: 0.5410 - val_accuracy: 0.7279\n",
      "Epoch 45/6000\n",
      "1022/1022 [==============================] - 116s 113ms/step - loss: 0.5176 - accuracy: 0.7427 - val_loss: 0.5411 - val_accuracy: 0.7283\n",
      "Epoch 46/6000\n",
      "1022/1022 [==============================] - 115s 112ms/step - loss: 0.5172 - accuracy: 0.7430 - val_loss: 0.5394 - val_accuracy: 0.7292\n",
      "Epoch 47/6000\n",
      "1022/1022 [==============================] - 119s 116ms/step - loss: 0.5168 - accuracy: 0.7431 - val_loss: 0.5449 - val_accuracy: 0.7258\n",
      "Epoch 48/6000\n",
      "1022/1022 [==============================] - 133s 131ms/step - loss: 0.5165 - accuracy: 0.7433 - val_loss: 0.5449 - val_accuracy: 0.7261\n",
      "Epoch 49/6000\n",
      "1022/1022 [==============================] - 132s 129ms/step - loss: 0.5157 - accuracy: 0.7438 - val_loss: 0.5401 - val_accuracy: 0.7284\n",
      "Epoch 50/6000\n",
      "1022/1022 [==============================] - 136s 133ms/step - loss: 0.5155 - accuracy: 0.7440 - val_loss: 0.5420 - val_accuracy: 0.7274\n",
      "Epoch 51/6000\n",
      "1022/1022 [==============================] - 132s 129ms/step - loss: 0.5152 - accuracy: 0.7442 - val_loss: 0.5431 - val_accuracy: 0.7263\n",
      "Epoch 52/6000\n",
      "1022/1022 [==============================] - 139s 136ms/step - loss: 0.5149 - accuracy: 0.7444 - val_loss: 0.5377 - val_accuracy: 0.7298\n",
      "Epoch 53/6000\n",
      "1022/1022 [==============================] - 136s 133ms/step - loss: 0.5146 - accuracy: 0.7445 - val_loss: 0.5437 - val_accuracy: 0.7266\n",
      "Epoch 54/6000\n",
      "1022/1022 [==============================] - 133s 130ms/step - loss: 0.5141 - accuracy: 0.7452 - val_loss: 0.5393 - val_accuracy: 0.7282\n",
      "Epoch 55/6000\n",
      "1022/1022 [==============================] - 131s 129ms/step - loss: 0.5138 - accuracy: 0.7450 - val_loss: 0.5385 - val_accuracy: 0.7302\n",
      "Epoch 56/6000\n",
      "1022/1022 [==============================] - 131s 128ms/step - loss: 0.5134 - accuracy: 0.7455 - val_loss: 0.5405 - val_accuracy: 0.7287\n",
      "Epoch 57/6000\n",
      "1022/1022 [==============================] - 133s 131ms/step - loss: 0.5130 - accuracy: 0.7456 - val_loss: 0.5396 - val_accuracy: 0.7289\n",
      "Epoch 58/6000\n",
      "1022/1022 [==============================] - 131s 128ms/step - loss: 0.5129 - accuracy: 0.7459 - val_loss: 0.5398 - val_accuracy: 0.7288\n",
      "Epoch 59/6000\n",
      "1022/1022 [==============================] - 137s 134ms/step - loss: 0.5124 - accuracy: 0.7463 - val_loss: 0.5418 - val_accuracy: 0.7285\n",
      "Epoch 60/6000\n",
      "1022/1022 [==============================] - 133s 130ms/step - loss: 0.5121 - accuracy: 0.7461 - val_loss: 0.5407 - val_accuracy: 0.7288\n",
      "Epoch 61/6000\n",
      "1022/1022 [==============================] - 155s 151ms/step - loss: 0.5117 - accuracy: 0.7467 - val_loss: 0.5335 - val_accuracy: 0.7328\n",
      "Epoch 62/6000\n",
      "1022/1022 [==============================] - 137s 134ms/step - loss: 0.5115 - accuracy: 0.7469 - val_loss: 0.5404 - val_accuracy: 0.7286\n",
      "Epoch 63/6000\n",
      "1022/1022 [==============================] - 133s 130ms/step - loss: 0.5112 - accuracy: 0.7471 - val_loss: 0.5354 - val_accuracy: 0.7324\n",
      "Epoch 64/6000\n",
      "1022/1022 [==============================] - 132s 129ms/step - loss: 0.5110 - accuracy: 0.7472 - val_loss: 0.5334 - val_accuracy: 0.7324\n",
      "Epoch 65/6000\n",
      "1022/1022 [==============================] - 160s 156ms/step - loss: 0.5107 - accuracy: 0.7473 - val_loss: 0.5372 - val_accuracy: 0.7311\n",
      "Epoch 66/6000\n",
      "1022/1022 [==============================] - 157s 154ms/step - loss: 0.5103 - accuracy: 0.7474 - val_loss: 0.5364 - val_accuracy: 0.7317\n",
      "Epoch 67/6000\n",
      "1022/1022 [==============================] - 158s 154ms/step - loss: 0.5099 - accuracy: 0.7478 - val_loss: 0.5406 - val_accuracy: 0.7291\n",
      "Epoch 68/6000\n",
      "1022/1022 [==============================] - 152s 149ms/step - loss: 0.5098 - accuracy: 0.7477 - val_loss: 0.5373 - val_accuracy: 0.7307\n",
      "Epoch 69/6000\n",
      "1022/1022 [==============================] - 152s 149ms/step - loss: 0.5096 - accuracy: 0.7482 - val_loss: 0.5426 - val_accuracy: 0.7276\n",
      "Epoch 70/6000\n",
      "1022/1022 [==============================] - 164s 160ms/step - loss: 0.5095 - accuracy: 0.7482 - val_loss: 0.5348 - val_accuracy: 0.7330\n",
      "Epoch 71/6000\n",
      "1022/1022 [==============================] - 155s 152ms/step - loss: 0.5090 - accuracy: 0.7485 - val_loss: 0.5449 - val_accuracy: 0.7266\n",
      "Epoch 72/6000\n",
      "1022/1022 [==============================] - 152s 149ms/step - loss: 0.5089 - accuracy: 0.7485 - val_loss: 0.5333 - val_accuracy: 0.7338\n",
      "Epoch 73/6000\n",
      "1022/1022 [==============================] - 153s 150ms/step - loss: 0.5086 - accuracy: 0.7485 - val_loss: 0.5365 - val_accuracy: 0.7319\n",
      "Epoch 74/6000\n",
      "1022/1022 [==============================] - 155s 152ms/step - loss: 0.5083 - accuracy: 0.7488 - val_loss: 0.5324 - val_accuracy: 0.7338\n",
      "Epoch 75/6000\n",
      "1022/1022 [==============================] - 158s 154ms/step - loss: 0.5081 - accuracy: 0.7490 - val_loss: 0.5338 - val_accuracy: 0.7326\n",
      "Epoch 76/6000\n",
      "1022/1022 [==============================] - 153s 149ms/step - loss: 0.5080 - accuracy: 0.7491 - val_loss: 0.5325 - val_accuracy: 0.7336\n",
      "Epoch 77/6000\n",
      "1022/1022 [==============================] - 152s 149ms/step - loss: 0.5077 - accuracy: 0.7494 - val_loss: 0.5423 - val_accuracy: 0.7283\n",
      "Epoch 78/6000\n",
      "1022/1022 [==============================] - 153s 150ms/step - loss: 0.5075 - accuracy: 0.7493 - val_loss: 0.5336 - val_accuracy: 0.7333\n",
      "Epoch 79/6000\n",
      "1022/1022 [==============================] - 156s 153ms/step - loss: 0.5073 - accuracy: 0.7494 - val_loss: 0.5315 - val_accuracy: 0.7344\n",
      "Epoch 80/6000\n",
      "1022/1022 [==============================] - 152s 149ms/step - loss: 0.5072 - accuracy: 0.7497 - val_loss: 0.5326 - val_accuracy: 0.7338\n",
      "Epoch 81/6000\n",
      "1022/1022 [==============================] - 160s 157ms/step - loss: 0.5070 - accuracy: 0.7500 - val_loss: 0.5328 - val_accuracy: 0.7337\n",
      "Epoch 82/6000\n",
      "1022/1022 [==============================] - 151s 148ms/step - loss: 0.5066 - accuracy: 0.7499 - val_loss: 0.5347 - val_accuracy: 0.7330\n",
      "Epoch 83/6000\n",
      "1022/1022 [==============================] - 153s 150ms/step - loss: 0.5064 - accuracy: 0.7502 - val_loss: 0.5390 - val_accuracy: 0.7302\n",
      "Epoch 84/6000\n",
      "1022/1022 [==============================] - 153s 150ms/step - loss: 0.5061 - accuracy: 0.7502 - val_loss: 0.5312 - val_accuracy: 0.7348\n",
      "Epoch 85/6000\n",
      "1022/1022 [==============================] - 153s 150ms/step - loss: 0.5060 - accuracy: 0.7505 - val_loss: 0.5377 - val_accuracy: 0.7308\n",
      "Epoch 86/6000\n",
      "1022/1022 [==============================] - 159s 156ms/step - loss: 0.5059 - accuracy: 0.7504 - val_loss: 0.5319 - val_accuracy: 0.7349\n",
      "Epoch 87/6000\n",
      "1022/1022 [==============================] - 202s 197ms/step - loss: 0.5057 - accuracy: 0.7506 - val_loss: 0.5354 - val_accuracy: 0.7331\n",
      "Epoch 88/6000\n",
      "1022/1022 [==============================] - 183s 179ms/step - loss: 0.5057 - accuracy: 0.7507 - val_loss: 0.5385 - val_accuracy: 0.7299\n",
      "Epoch 89/6000\n",
      "1022/1022 [==============================] - 178s 174ms/step - loss: 0.5055 - accuracy: 0.7507 - val_loss: 0.5345 - val_accuracy: 0.7330\n",
      "Epoch 90/6000\n",
      "1022/1022 [==============================] - 180s 176ms/step - loss: 0.5051 - accuracy: 0.7509 - val_loss: 0.5376 - val_accuracy: 0.7305\n",
      "Epoch 91/6000\n",
      "1022/1022 [==============================] - 191s 186ms/step - loss: 0.5049 - accuracy: 0.7510 - val_loss: 0.5302 - val_accuracy: 0.7357\n",
      "Epoch 92/6000\n",
      "1022/1022 [==============================] - 196s 192ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5350 - val_accuracy: 0.7331\n",
      "Epoch 93/6000\n",
      "1022/1022 [==============================] - 187s 183ms/step - loss: 0.5046 - accuracy: 0.7514 - val_loss: 0.5352 - val_accuracy: 0.7337\n",
      "Epoch 94/6000\n",
      "1022/1022 [==============================] - 179s 175ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.5336 - val_accuracy: 0.7337\n",
      "Epoch 95/6000\n",
      "1022/1022 [==============================] - 180s 176ms/step - loss: 0.5046 - accuracy: 0.7513 - val_loss: 0.5382 - val_accuracy: 0.7311\n",
      "Epoch 96/6000\n",
      "1022/1022 [==============================] - 195s 190ms/step - loss: 0.5041 - accuracy: 0.7516 - val_loss: 0.5338 - val_accuracy: 0.7338\n",
      "Epoch 97/6000\n",
      "1022/1022 [==============================] - 165s 161ms/step - loss: 0.5039 - accuracy: 0.7516 - val_loss: 0.5322 - val_accuracy: 0.7338\n",
      "Epoch 98/6000\n",
      "1022/1022 [==============================] - 152s 149ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5310 - val_accuracy: 0.7358\n",
      "Epoch 99/6000\n",
      "1022/1022 [==============================] - 149s 146ms/step - loss: 0.5037 - accuracy: 0.7521 - val_loss: 0.5386 - val_accuracy: 0.7303\n",
      "Epoch 100/6000\n",
      "1022/1022 [==============================] - 149s 146ms/step - loss: 0.5036 - accuracy: 0.7521 - val_loss: 0.5345 - val_accuracy: 0.7339\n",
      "Epoch 101/6000\n",
      "1022/1022 [==============================] - 149s 146ms/step - loss: 0.5033 - accuracy: 0.7522 - val_loss: 0.5354 - val_accuracy: 0.7332\n",
      "Epoch 102/6000\n",
      "1022/1022 [==============================] - 152s 149ms/step - loss: 0.5032 - accuracy: 0.7523 - val_loss: 0.5290 - val_accuracy: 0.7364\n",
      "Epoch 103/6000\n",
      "1022/1022 [==============================] - 152s 148ms/step - loss: 0.5031 - accuracy: 0.7523 - val_loss: 0.5308 - val_accuracy: 0.7357\n",
      "Epoch 104/6000\n",
      "1022/1022 [==============================] - 151s 148ms/step - loss: 0.5029 - accuracy: 0.7526 - val_loss: 0.5333 - val_accuracy: 0.7340\n",
      "Epoch 105/6000\n",
      "1022/1022 [==============================] - 151s 148ms/step - loss: 0.5029 - accuracy: 0.7525 - val_loss: 0.5313 - val_accuracy: 0.7355\n",
      "Epoch 106/6000\n",
      "1022/1022 [==============================] - 152s 148ms/step - loss: 0.5024 - accuracy: 0.7528 - val_loss: 0.5328 - val_accuracy: 0.7352\n",
      "Epoch 107/6000\n",
      "1022/1022 [==============================] - 152s 149ms/step - loss: 0.5025 - accuracy: 0.7526 - val_loss: 0.5315 - val_accuracy: 0.7347\n",
      "Epoch 108/6000\n",
      "1022/1022 [==============================] - 163s 159ms/step - loss: 0.5024 - accuracy: 0.7527 - val_loss: 0.5317 - val_accuracy: 0.7350\n",
      "Epoch 109/6000\n",
      "1022/1022 [==============================] - 151s 148ms/step - loss: 0.5023 - accuracy: 0.7526 - val_loss: 0.5342 - val_accuracy: 0.7338\n",
      "Epoch 110/6000\n",
      "1022/1022 [==============================] - 163s 159ms/step - loss: 0.5020 - accuracy: 0.7531 - val_loss: 0.5302 - val_accuracy: 0.7364\n",
      "Epoch 111/6000\n",
      "1022/1022 [==============================] - 264s 259ms/step - loss: 0.5018 - accuracy: 0.7534 - val_loss: 0.5288 - val_accuracy: 0.7364\n",
      "Epoch 112/6000\n",
      "1022/1022 [==============================] - 277s 271ms/step - loss: 0.5017 - accuracy: 0.7534 - val_loss: 0.5359 - val_accuracy: 0.7327\n",
      "Epoch 113/6000\n",
      "1022/1022 [==============================] - 196s 192ms/step - loss: 0.5016 - accuracy: 0.7533 - val_loss: 0.5287 - val_accuracy: 0.7375\n",
      "Epoch 114/6000\n",
      "1022/1022 [==============================] - 166s 163ms/step - loss: 0.5015 - accuracy: 0.7532 - val_loss: 0.5329 - val_accuracy: 0.7347\n",
      "Epoch 115/6000\n",
      "1022/1022 [==============================] - 151s 148ms/step - loss: 0.5015 - accuracy: 0.7533 - val_loss: 0.5282 - val_accuracy: 0.7375\n",
      "Epoch 116/6000\n",
      "1022/1022 [==============================] - 155s 152ms/step - loss: 0.5015 - accuracy: 0.7534 - val_loss: 0.5309 - val_accuracy: 0.7355\n",
      "Epoch 117/6000\n",
      "1022/1022 [==============================] - 157s 154ms/step - loss: 0.5012 - accuracy: 0.7535 - val_loss: 0.5334 - val_accuracy: 0.7340\n",
      "Epoch 118/6000\n",
      "1022/1022 [==============================] - 195s 191ms/step - loss: 0.5011 - accuracy: 0.7537 - val_loss: 0.5299 - val_accuracy: 0.7372\n",
      "Epoch 119/6000\n",
      "1022/1022 [==============================] - 183s 179ms/step - loss: 0.5010 - accuracy: 0.7535 - val_loss: 0.5331 - val_accuracy: 0.7345\n",
      "Epoch 120/6000\n",
      "1022/1022 [==============================] - 177s 174ms/step - loss: 0.5007 - accuracy: 0.7537 - val_loss: 0.5337 - val_accuracy: 0.7352\n",
      "Epoch 121/6000\n",
      "1022/1022 [==============================] - 176s 172ms/step - loss: 0.5006 - accuracy: 0.7539 - val_loss: 0.5292 - val_accuracy: 0.7361\n",
      "Epoch 122/6000\n",
      "1022/1022 [==============================] - 159s 155ms/step - loss: 0.5007 - accuracy: 0.7539 - val_loss: 0.5318 - val_accuracy: 0.7349\n",
      "Epoch 123/6000\n",
      "1022/1022 [==============================] - 168s 164ms/step - loss: 0.5005 - accuracy: 0.7540 - val_loss: 0.5309 - val_accuracy: 0.7363\n",
      "Epoch 124/6000\n",
      "1022/1022 [==============================] - 203s 199ms/step - loss: 0.5006 - accuracy: 0.7538 - val_loss: 0.5307 - val_accuracy: 0.7358\n",
      "Epoch 125/6000\n",
      "1022/1022 [==============================] - 196s 192ms/step - loss: 0.5001 - accuracy: 0.7541 - val_loss: 0.5322 - val_accuracy: 0.7346\n",
      "Epoch 126/6000\n",
      "1022/1022 [==============================] - 186s 182ms/step - loss: 0.5001 - accuracy: 0.7543 - val_loss: 0.5340 - val_accuracy: 0.7341\n",
      "Epoch 127/6000\n",
      "1022/1022 [==============================] - 167s 163ms/step - loss: 0.5001 - accuracy: 0.7544 - val_loss: 0.5356 - val_accuracy: 0.7333\n",
      "Epoch 128/6000\n",
      "1022/1022 [==============================] - 152s 149ms/step - loss: 0.5000 - accuracy: 0.7543 - val_loss: 0.5296 - val_accuracy: 0.7371\n",
      "Epoch 128: early stopping\n",
      "##########################################################################\n",
      "------val_accuracy-----> 73.75 | 75.44 <----------accuracy----------\n",
      "/UltimeTradingBot/Data/BUY_OPTIMAL/tp40_w7_max7min_Norm_v5.json\n",
      "/UltimeTradingBot/Data/BUY_OPTIMAL/tp40_w7_max7min_Model_v5.h5\n",
      "save to: /UltimeTradingBot/Data/BUY_OPTIMAL/tp40_w7_max7min_Model_vInit.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Normalzed Model\n",
    "IN_DIM=dt.shape[1]-1\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(IN_DIM,)))\n",
    "model.add(Dense(int(250),activation='relu')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(20),activation='relu')) \n",
    "model.add(Dense(int(50),activation='relu')) \n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "print(model.summary())\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "callbacks_a = ModelCheckpoint(filepath =Model_FileName,monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "callbacks_b = EarlyStopping(monitor ='val_accuracy',mode='auto',patience=15,verbose=1)\n",
    "print(\"saving file in: \"+Model_FileName)\n",
    "history = model.fit(dt[index_20percent:, 0:-1],\n",
    "                dt[index_20percent:,-1],\n",
    "                validation_data=(dt[:index_20percent, :-1],dt[:index_20percent,-1]),\n",
    "                epochs=6000,\n",
    "                batch_size=256*10,\n",
    "                callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "print('##########################################################################')\n",
    "print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "print(Normalization_File)\n",
    "print(Model_FileName)\n",
    "model_init_file=Model_FileName.replace(f\"_v{VERSION}\", \"_vInit\")\n",
    "print(f\"save to: {model_init_file}\")\n",
    "model.save(model_init_file)\n",
    "model_init=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_init_file=Model_FileName.replace(f\"_v{VERSION}\", \"_vInit\")\n",
    "# print(f\"save to: {model_init_file}\")\n",
    "# model.save(model_init_file)\n",
    "# model_init=model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Model Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 432s 423ms/step - loss: 0.5274 - accuracy: 0.7354 - val_loss: 0.5316 - val_accuracy: 0.7355\n",
      "Epoch 54/500\n",
      "1022/1022 [==============================] - 437s 428ms/step - loss: 0.5271 - accuracy: 0.7352 - val_loss: 0.5300 - val_accuracy: 0.7357\n",
      "Epoch 55/500\n",
      "1022/1022 [==============================] - 422s 413ms/step - loss: 0.5270 - accuracy: 0.7357 - val_loss: 0.5314 - val_accuracy: 0.7341\n",
      "Epoch 56/500\n",
      "1022/1022 [==============================] - 424s 415ms/step - loss: 0.5266 - accuracy: 0.7360 - val_loss: 0.5253 - val_accuracy: 0.7391\n",
      "Epoch 57/500\n",
      "1022/1022 [==============================] - 439s 430ms/step - loss: 0.5261 - accuracy: 0.7365 - val_loss: 0.5303 - val_accuracy: 0.7342\n",
      "Epoch 58/500\n",
      "1022/1022 [==============================] - 494s 483ms/step - loss: 0.5259 - accuracy: 0.7364 - val_loss: 0.5345 - val_accuracy: 0.7296\n",
      "Epoch 59/500\n",
      "1022/1022 [==============================] - 457s 447ms/step - loss: 0.5258 - accuracy: 0.7365 - val_loss: 0.5352 - val_accuracy: 0.7348\n",
      "Epoch 60/500\n",
      "1022/1022 [==============================] - 552s 540ms/step - loss: 0.5253 - accuracy: 0.7368 - val_loss: 0.5299 - val_accuracy: 0.7343\n",
      "Epoch 61/500\n",
      "1022/1022 [==============================] - 421s 412ms/step - loss: 0.5249 - accuracy: 0.7372 - val_loss: 0.5313 - val_accuracy: 0.7311\n",
      "Epoch 62/500\n",
      "1022/1022 [==============================] - 424s 415ms/step - loss: 0.5248 - accuracy: 0.7373 - val_loss: 0.5294 - val_accuracy: 0.7361\n",
      "Epoch 62: early stopping\n",
      "/UltimeTradingBot/Data/BUY_OPTIMAL/tp40_w7_max7min_Model_VeryDeep.h5\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# Define the class weights\n",
    "class_weights = {0: 1., 1: 1.}\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "SizeTunner = 1\n",
    "IN_DIM = dt.shape[1] - 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(IN_DIM,)))\n",
    "model.add(Dense(int(300 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(200 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(80 * SizeTunner), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(20 * SizeTunner), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=Model_FileName, monitor='val_accuracy', save_best_only=True, save_weights=True),\n",
    "    EarlyStopping(monitor='val_accuracy', mode='auto', patience=6, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"saving file in: \" + Model_FileName)\n",
    "history = model.fit(dt[index_20percent:, :-1],\n",
    "                    dt[index_20percent:, -1],\n",
    "                    validation_data=(dt[:index_20percent, :-1], dt[:index_20percent, -1]),\n",
    "                    epochs=500,\n",
    "                    batch_size=256*10,\n",
    "                    callbacks=callbacks,\n",
    "                    class_weight=class_weights)\n",
    "\n",
    "verydeep_model_file=f'{DATA_DIR}/tp{int(BUY_PERCENT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+\"_VeryDeep.h5\"\n",
    "model.save(verydeep_model_file)\n",
    "print(verydeep_model_file)\n",
    "very_deep_model=load_model(f'{DATA_DIR}/tp{int(BUY_PERCENT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+\"_VeryDeep.h5\")\n",
    "#868/868 [==============================] - 30s 35ms/step - loss: 0.6078 - accuracy: 0.6664 - val_loss: 0.6107 - val_accuracy: 0.6639 >0.6646\n",
    "#Results after 380 min\n",
    "# Epoch 133/500\n",
    "# 347/347 [==============================] - 138s 398ms/step - loss: 0.5867 - accuracy: 0.6842 - val_loss: 0.5839 - val_accuracy: 0.6863\n",
    "# Epoch 134/500\n",
    "# 347/347 [==============================] - 137s 395ms/step - loss: 0.5865 - accuracy: 0.6843 - val_loss: 0.5845 - val_accuracy: 0.6861\n",
    "# Epoch 134: early stopping\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Binary Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BinaryQuantization' from 'tensorflow.keras.layers.experimental.preprocessing' (/usr/local/lib/python3.9/dist-packages/keras/api/_v2/keras/layers/experimental/preprocessing/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [47], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m to_categorical\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvis_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_model\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m BinaryQuantization\n\u001b[1;32m     12\u001b[0m \u001b[39m# Define the class weights\u001b[39;00m\n\u001b[1;32m     13\u001b[0m class_weights \u001b[39m=\u001b[39m {\u001b[39m0\u001b[39m: \u001b[39m1.\u001b[39m, \u001b[39m1\u001b[39m: \u001b[39m1.\u001b[39m}\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'BinaryQuantization' from 'tensorflow.keras.layers.experimental.preprocessing' (/usr/local/lib/python3.9/dist-packages/keras/api/_v2/keras/layers/experimental/preprocessing/__init__.py)"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.layers.experimental.preprocessing import BinaryQuantization\n",
    "\n",
    "# Define the class weights\n",
    "class_weights = {0: 1., 1: 1.}\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "SizeTunner = 1\n",
    "IN_DIM = dt.shape[1] - 1\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(BinaryQuantization(input_shape=(IN_DIM,)))\n",
    "\n",
    "model.add(Dense(int(300 * SizeTunner)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(BinaryQuantization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(200 * SizeTunner)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(BinaryQuantization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(BinaryQuantization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(BinaryQuantization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(BinaryQuantization())\n",
    "model.add(Dense(int(80 * SizeTunner)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(BinaryQuantization())\n",
    "model.add(Dense(int(80 * SizeTunner)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(BinaryQuantization())\n",
    "model.add(Dense(int(20 * SizeTunner)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(BinaryQuantization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=Model_FileName, monitor='val_accuracy', save_best_only=True, save_weights=True),\n",
    "    EarlyStopping(monitor='val_accuracy', mode='auto', patience=6, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"saving file in: \" + Model_FileName)\n",
    "history = model.fit(dt[index_20percent:, :-1],\n",
    "                    dt[index_20percent:, -1],\n",
    "                    validation_data=(dt[:index_20percent, :-1], dt[:index_20percent, -1]),\n",
    "                    epochs=500,\n",
    "                    batch_size=256*10,\n",
    "                    callbacks=callbacks,\n",
    "                    class_weight=class_weights)\n",
    "# Save the model\n",
    "binary_model_file=f'{DATA_DIR}/tp{int(BUY_PERCENT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+\"_BINARY.h5\"\n",
    "model.save(binary_model_file)\n",
    "binary_model_file=tf.keras.models.load_model(binary_model_file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini_range_start=0\n",
    "# mini_range_stop=200000\n",
    "# model.evaluate(dt[mini_range_start:mini_range_stop,:-1],dt[mini_range_start:mini_range_stop,-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-  Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stats plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USED_MODEL=very_deep_model\n",
    "#model_init=model\n",
    "#USED_MODEL=model_init#load_model(\"/UltimeTradingBot/Data/BUY_UP_CLOSE/tp60_w6_max3min_Model_GoodVeryDeep.h5\")\n",
    "Prediction_Note=USED_MODEL.predict( dt[:, 0:-1])\n",
    "prediction2=Prediction_Note.round()\n",
    "hp(prediction2[:,0].mean())\n",
    "PesemisticPrediction=(Prediction_Note[:,0]-0.49).round()\n",
    "hp(PesemisticPrediction.mean())\n",
    "Y=dt[:,-1].copy()\n",
    "Pred01=prediction2[:,-1]\n",
    "Original_Traget_Data=Y\n",
    "Predicted_Data=Pred01\n",
    "\n",
    "TruePred=((Original_Traget_Data==Predicted_Data)).copy()\n",
    "ModelAccuracy=hp(TruePred.mean(),\"ModelAccuracy\")\n",
    "\n",
    "TrueWinPred=((Predicted_Data==1) & (Original_Traget_Data==1) ).copy()\n",
    "TrueWinPred_Mean=hp(TrueWinPred.mean(),\"True Win Predictions Mean of all\")\n",
    "\n",
    "LossPred=((Predicted_Data==1) & (Original_Traget_Data==0) ).copy()\n",
    "LossPred_Mean=hp(LossPred.mean(),\"XXX Loss Buy Mean of all\")\n",
    "\n",
    "MissedDealPred=((Predicted_Data==0) & (Original_Traget_Data==1) ).copy()\n",
    "MissedDeal_Mean=hp(MissedDealPred.mean(),\"Missed good deal off all\")\n",
    "\n",
    "GoodZeroPred=((Predicted_Data==0) & (Original_Traget_Data==0) ).copy()\n",
    "GoodZero_Mean=hp(GoodZeroPred.mean(),\"Good Zero prediction Mean\")\n",
    "\n",
    "fiability=TrueWinPred_Mean + LossPred_Mean + MissedDeal_Mean + GoodZero_Mean\n",
    "if( fiability == 100):print(\"good fiability\")\n",
    "else: print(f\"check the fiability {fiability}\")\n",
    "\n",
    "winratio=TrueWinPred_Mean/(LossPred_Mean+TrueWinPred_Mean)\n",
    "print(f\"========= Win Ratio:{winratio*100} ====================\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANTI Retrain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_dt=dt[TruePred]\n",
    "# good_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bad_dt=dt[ np.logical_not(TruePred)]\n",
    "bad_dt=dt[Predicted_Data==1 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anti prediction\n",
    "\n",
    "BadONE=bad_dt[bad_dt[:,-1]==0]\n",
    "TrueOne=bad_dt[bad_dt[:,-1]==1][:BadONE.shape[0]]\n",
    "AntiPrediction_DT=np.concatenate((BadONE,TrueOne),axis=0)\n",
    "np.random.shuffle(AntiPrediction_DT)\n",
    "\n",
    "retrain_dt=AntiPrediction_DT\n",
    "print(f\"Dataset Size is : {retrain_dt.shape[0]}\")\n",
    "class_1_weight=hp(retrain_dt[:,-1].mean())/100\n",
    "\n",
    "import gc\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# Define the class weights\n",
    "index_20percent=int(retrain_dt.shape[1]*0.2)\n",
    "\n",
    "class_weights = {0: 1-class_1_weight, 1: class_1_weight}\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "SizeTunner = 1\n",
    "IN_DIM = retrain_dt.shape[1] - 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(IN_DIM,)))\n",
    "model.add(Dense(int(200 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(Dense(int(80 * SizeTunner), activation='relu'))\n",
    "model.add(Dense(int(20 * SizeTunner), activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=Model_FileName, monitor='loss', save_best_only=True, save_weights=True),\n",
    "    EarlyStopping(monitor='loss', mode='auto', patience=20, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"saving file in: \" + Model_FileName)\n",
    "history = model.fit(retrain_dt[index_20percent:, :-1],\n",
    "                    retrain_dt[index_20percent:, -1],\n",
    "                    validation_data=(retrain_dt[:index_20percent, :-1], retrain_dt[:index_20percent, -1]),\n",
    "                    epochs=500,\n",
    "                    batch_size=256*5,\n",
    "                    callbacks=callbacks,\n",
    "                    class_weight=class_weights)\n",
    "\n",
    "#868/868 [==============================] - 30s 35ms/step - loss: 0.6078 - accuracy: 0.6664 - val_loss: 0.6107 - val_accuracy: 0.6639 >0.6646\n",
    "#Results after 380 min\n",
    "# Epoch 133/500\n",
    "# 347/347 [==============================] - 138s 398ms/step - loss: 0.5867 - accuracy: 0.6842 - val_loss: 0.5839 - val_accuracy: 0.6863\n",
    "# Epoch 134/500\n",
    "# 347/347 [==============================] - 137s 395ms/step - loss: 0.5865 - accuracy: 0.6843 - val_loss: 0.5845 - val_accuracy: 0.6861\n",
    "# Epoch 134: early stopping\n",
    "justgood_good_model=model\n",
    "justgood_good_model_wheretosave=f'{DATA_DIR}/tp{int(BUY_PERCENT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Anti-Model_v2.h5'\n",
    "justgood_good_model.save(justgood_good_model_wheretosave)\n",
    "print(justgood_good_model_wheretosave)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# True PredONly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change retaindt\n",
    "for rrr in range(1,7):\n",
    "    retrain_dt=dt\n",
    "    class_1_weight=TrueWinPred.mean()\n",
    "\n",
    "    import gc\n",
    "    from keras.layers import Dense\n",
    "    from keras.models import Sequential\n",
    "    from keras.optimizers import Nadam\n",
    "    from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "    # Define the class weights\n",
    "    index_20percent=int(retrain_dt.shape[1]*0.2)\n",
    "    class_weights = {0: 1-class_1_weight, 1: class_1_weight}\n",
    "    gc.collect()\n",
    "\n",
    "    SizeTunner = 1\n",
    "    IN_DIM = retrain_dt.shape[1] - 1\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(IN_DIM,)))\n",
    "    model.add(Dense(int(200 * SizeTunner), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    # model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    model.add(Dense(int(80 * SizeTunner), activation='relu'))\n",
    "    model.add(Dense(int(20 * SizeTunner), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(filepath=Model_FileName, monitor='val_accuracy', save_best_only=True, save_weights=True),\n",
    "        EarlyStopping(monitor='val_accuracy', mode='auto', patience=16, verbose=1)\n",
    "    ]\n",
    "\n",
    "    print(\"saving file in: \" + Model_FileName)\n",
    "    history = model.fit(retrain_dt[index_20percent:, :-1],\n",
    "                        TrueWinPred[index_20percent:],\n",
    "                        validation_data=(retrain_dt[:index_20percent, :-1], TrueWinPred[:index_20percent]),\n",
    "                        epochs=500,\n",
    "                        batch_size=256*5,\n",
    "                        callbacks=callbacks,\n",
    "                        class_weight=class_weights)\n",
    "\n",
    "    #868/868 [==============================] - 30s 35ms/step - loss: 0.6078 - accuracy: 0.6664 - val_loss: 0.6107 - val_accuracy: 0.6639 >0.6646\n",
    "    #Results after 380 min\n",
    "    # Epoch 133/500\n",
    "    # 347/347 [==============================] - 138s 398ms/step - loss: 0.5867 - accuracy: 0.6842 - val_loss: 0.5839 - val_accuracy: 0.6863\n",
    "    # Epoch 134/500\n",
    "    # 347/347 [==============================] - 137s 395ms/step - loss: 0.5865 - accuracy: 0.6843 - val_loss: 0.5845 - val_accuracy: 0.6861\n",
    "    # Epoch 134: early stopping\n",
    "\n",
    "    true_win_model=model\n",
    "    wheretosave=f'{DATA_DIR}/tp{int(BUY_PERCENT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+f\"_true_win_model_Re{rrr}.h5\"\n",
    "    true_win_model.save(wheretosave)\n",
    "    print(wheretosave)\n",
    "    USED_MODEL=true_win_model\n",
    "    bad_Prediction_Note=USED_MODEL.predict( dt[:, 0:-1])\n",
    "    Pred02=bad_Prediction_Note.round()\n",
    "    Original_Traget_Data=Y\n",
    "    Predicted_Data=Pred02[:,0]\n",
    "\n",
    "    BadTruePred=(Original_Traget_Data==Predicted_Data).copy()\n",
    "    BadModelAccuracy=hp(BadTruePred.mean(),\"ModelAccuracy\")\n",
    "\n",
    "    BadTrueWinPred=((Predicted_Data==1) & (Original_Traget_Data==1) ).copy()\n",
    "    BadTrueWinPred_Mean=hp(BadTrueWinPred.mean(),\"True Win Predictions Mean of all\")\n",
    "\n",
    "    BadLossPred=((Predicted_Data==1) & (Original_Traget_Data==0) ).copy()\n",
    "    BadLossPred_Mean=hp(BadLossPred.mean(),\"XXX Loss Buy Mean of all\")\n",
    "\n",
    "    BadMissedDealPred=((Predicted_Data==0) & (Original_Traget_Data==1) ).copy()\n",
    "    BadMissedDeal_Mean=hp(BadMissedDealPred.mean(),\"Missed good deal off all\")\n",
    "\n",
    "    BadGoodZeroPred=((Predicted_Data==0) & (Original_Traget_Data==0) ).copy()\n",
    "    BadGoodZero_Mean=hp(BadGoodZeroPred.mean(),\"Good Zero prediction Mean\")\n",
    "\n",
    "    fiability=BadTrueWinPred_Mean + BadLossPred_Mean + BadMissedDeal_Mean + BadGoodZero_Mean\n",
    "    if( fiability == 100):print(\"good fiability\")\n",
    "    else: print(f\"check the fiability {fiability}\")\n",
    "    winratio=BadTrueWinPred_Mean/(BadLossPred_Mean+BadTrueWinPred_Mean)\n",
    "    print(f\"========= Win Ratio:{winratio*100} ====================\")\n",
    "    ## for retraining again\n",
    "    TrueWinPred=BadTrueWinPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_deep_good_model=model\n",
    "wheretosave=f'{DATA_DIR}/tp{int(BUY_PERCENT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+\"_GoodVeryDeep_v2.h5\"\n",
    "very_deep_good_model.save(wheretosave)\n",
    "print(wheretosave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_deep_bad_model=model\n",
    "very_deep_bad_model.save(f'{DATA_DIR}/tp{int(BUY_PERCENT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+\"_BadVeryDeep_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test On special coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Data\n",
    "BAD_PERIOD_START=\"2022-08-30\"\n",
    "BAD_PERIOD_END=\"2022-11-22\"\n",
    "pair_to_test=\"GMT/USDT\"\n",
    "MAX_FORCAST_SIZE=5\n",
    "USED_MODEL=very_deep_good_model#true_win_model#model_init #model_good_x3 #very_deep_good_model 16/1.7\n",
    "\n",
    "\n",
    "loc_start=0\n",
    "loc_end=1000000\n",
    "\n",
    "\n",
    "i_start=71000\n",
    "i_end=i_start+200\n",
    "\n",
    "# loc_start=df_list1m[pair_to_test].index.get_loc(pd.to_datetime(BAD_PERIOD_START))\n",
    "# loc_end=df_list1m[pair_to_test].index.get_loc(pd.to_datetime(BAD_PERIOD_END))\n",
    "\n",
    "\n",
    "OnePair_DF=mini_expand4(        pair=pair_to_test,\n",
    "                                i=loc_start,j=loc_end,\n",
    "                                window=WINDOW_SIZE,\n",
    "                                metadata=MetaData,\n",
    "                                high_weight=1,\n",
    "                                buy_pourcent=0.55,\n",
    "                                sell_pourcent=SELL_PERCENT,\n",
    "                                buy_function=buy_fix#buy_test\n",
    "                        )\n",
    "OnePair_DT=OnePair_DF.to_numpy()\n",
    "gc.collect()\n",
    "OnePair_DT=fixdt(OnePair_DT)\n",
    "print(OnePair_DT[0,0] == OnePair_DF.iloc[0,0])\n",
    "print(OnePair_DT[5,5] == OnePair_DF.iloc[5,5])\n",
    "hp(OnePair_DF.buy.mean(),\"Buy mean percent\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0, 10, 500)\n",
    "dashes = [10, 5, 100, 5]  # 10 points on, 5 off, 100 on, 5 off\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot(OnePair_DF.index[i_start:i_end], OnePair_DF.price[i_start:i_end], '-', linewidth=1,\n",
    "                 label='Dashes set retroactively')\n",
    "line1.set_dashes(dashes)\n",
    "plt.plot(OnePair_DF[i_start:i_end][OnePair_DF.buy[i_start:i_end]==1].index, OnePair_DF[i_start:i_end][OnePair_DF.buy[i_start:i_end]==1].price, 'ro')\n",
    "\n",
    "\n",
    "ax.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "OnePair_PredNote=USED_MODEL.predict( OnePair_DT[:, 0:-1])\n",
    "OnePair_Pred=OnePair_PredNote.round()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "Original_Traget_Data=OnePair_DT[:,-1]\n",
    "Predicted_Data=OnePair_Pred[:,0]\n",
    "gc.collect()\n",
    "TruePred=(Original_Traget_Data==Predicted_Data).copy()\n",
    "ModelAccuracy=hp(TruePred.mean(),\"ModelAccuracy\")\n",
    "gc.collect()\n",
    "TrueWinPred=((Predicted_Data==1) & (Original_Traget_Data==1) ).copy()\n",
    "TrueWinPred_Mean=hp(TrueWinPred.mean(),\"True Win Predictions Mean of all\")\n",
    "gc.collect()\n",
    "LossPred=((Predicted_Data==1) & (Original_Traget_Data==0) ).copy()\n",
    "LossPred_Mean=hp(LossPred.mean(),\"XXX Loss Buy Mean of all\")\n",
    "gc.collect()\n",
    "\n",
    "MissedDealPred=((Predicted_Data==0) & (Original_Traget_Data==1) ).copy()\n",
    "MissedDeal_Mean=hp(MissedDealPred.mean(),\"Missed good deal off all\")\n",
    "gc.collect()\n",
    "\n",
    "GoodZeroPred=((Predicted_Data==0) & (Original_Traget_Data==0) ).copy()\n",
    "GoodZero_Mean=hp(GoodZeroPred.mean(),\"Good Zero prediction Mean\")\n",
    "gc.collect()\n",
    "\n",
    "fiability=TrueWinPred_Mean + LossPred_Mean + MissedDeal_Mean + GoodZero_Mean\n",
    "if( fiability == 100):print(\"good fiability\")\n",
    "else: print(f\"check the fiability {fiability}\")\n",
    "winratio=TrueWinPred_Mean/(LossPred_Mean+TrueWinPred_Mean)\n",
    "\n",
    "print(f\"========= Win Ratio:{winratio*100} %====================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PREDICTION_TO_TEST=Predicted_Data\n",
    "\n",
    "x = np.linspace(0, 10, 500)\n",
    "dashes = [10, 5, 100, 5]  # 10 points on, 5 off, 100 on, 5 off\n",
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot(OnePair_DF.index[i_start:i_end], OnePair_DF.price[i_start:i_end], '-', linewidth=1,\n",
    "                 label='price')\n",
    "line1.set_dashes(dashes)\n",
    "plt.plot(OnePair_DF[i_start:i_end][PREDICTION_TO_TEST[i_start:i_end]==1].index, OnePair_DF[i_start:i_end][PREDICTION_TO_TEST[i_start:i_end]==1].price, 'ro')\n",
    "\n",
    "\n",
    "ax.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX=OnePair_DT[:100000,:-1]\n",
    "YY=OnePair_DT[:100000,-1]\n",
    "precision=0.0\n",
    "# Good_Prediction_Note=very_deep_good_model.predict( XX)\n",
    "# Bad_Prediction_Note=very_deep_bad_model.predict( XX)\n",
    "# Initial_Pred_Note=model_init.predict( XX)\n",
    "Predicted_Data=OnePair_Pred[:300000,0]\n",
    "goodp=(Good_Prediction_Note-precision).round()\n",
    "# badp=(Bad_Prediction_Note).round()\n",
    "# initp=Initial_Pred_Note.round()\n",
    "\n",
    "# Original_Traget_Data=YY\n",
    "\n",
    "#Predicted_Data=((goodp==badp|initp==goodp))[:,0]\n",
    "Predicted_Data=(goodp)[:,0]\n",
    "\n",
    "GoodTruePred=(Original_Traget_Data==Predicted_Data).copy()\n",
    "GoodModelAccuracy=hp(GoodTruePred.mean(),\"ModelAccuracy\")\n",
    "\n",
    "GoodTrueWinPred=((Predicted_Data==1) & (Original_Traget_Data==1) ).copy()\n",
    "GoodTrueWinPred_Mean=hp(GoodTrueWinPred.mean(),\"True Win Predictions Mean of all\")\n",
    "\n",
    "GoodLossPred=((Predicted_Data==1) & (Original_Traget_Data==0) ).copy()\n",
    "GoodLossPred_Mean=hp(GoodLossPred.mean(),\"XXX Loss Buy Mean of all\")\n",
    "\n",
    "GoodMissedDealPred=((Predicted_Data==0) & (Original_Traget_Data==1) ).copy()\n",
    "GoodMissedDeal_Mean=hp(GoodMissedDealPred.mean(),\"Missed good deal off all\")\n",
    "\n",
    "GoodGoodZeroPred=((Predicted_Data==0) & (Original_Traget_Data==0) ).copy()\n",
    "GoodGoodZero_Mean=hp(GoodGoodZeroPred.mean(),\"Good Zero prediction Mean\")\n",
    "\n",
    "winratio=GoodTrueWinPred_Mean/(GoodTrueWinPred_Mean+GoodLossPred_Mean)\n",
    "fiability=GoodTrueWinPred_Mean + GoodLossPred_Mean + GoodMissedDeal_Mean + GoodGoodZero_Mean\n",
    "if( fiability == 100):print(\"good fiability\")\n",
    "else: print(f\"check the fiability {fiability}\")\n",
    "print(f\"========= Win Ratio:{winratio*100} ====================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction(XX,YY,USEDMODEL)\n",
    "XX=OnePair_DT[:100000,:-1]\n",
    "YY=OnePair_DT[:100000,-1]\n",
    "\n",
    "# Good_Prediction_Note=very_deep_good_model.predict( XX)\n",
    "# Bad_Prediction_Note=very_deep_bad_model.predict( XX)\n",
    "# Initial_Pred_Note=model_init.predict( XX)\n",
    "goodp=(Good_Prediction_Note-precision).round()\n",
    "# badp=(Bad_Prediction_Note).round()\n",
    "# initp=Initial_Pred_Note.round()\n",
    "\n",
    "# Original_Traget_Data=YY\n",
    "\n",
    "#Predicted_Data=((goodp==badp|initp==goodp))[:,0]\n",
    "Predicted_Data=(goodp)[:,0]\n",
    "\n",
    "GoodTruePred=(Original_Traget_Data==Predicted_Data).copy()\n",
    "GoodModelAccuracy=hp(GoodTruePred.mean(),\"ModelAccuracy\")\n",
    "\n",
    "GoodTrueWinPred=((Predicted_Data==1) & (Original_Traget_Data==1) ).copy()\n",
    "GoodTrueWinPred_Mean=hp(GoodTrueWinPred.mean(),\"True Win Predictions Mean of all\")\n",
    "\n",
    "GoodLossPred=((Predicted_Data==1) & (Original_Traget_Data==0) ).copy()\n",
    "GoodLossPred_Mean=hp(GoodLossPred.mean(),\"XXX Loss Buy Mean of all\")\n",
    "\n",
    "GoodMissedDealPred=((Predicted_Data==0) & (Original_Traget_Data==1) ).copy()\n",
    "GoodMissedDeal_Mean=hp(GoodMissedDealPred.mean(),\"Missed good deal off all\")\n",
    "\n",
    "GoodGoodZeroPred=((Predicted_Data==0) & (Original_Traget_Data==0) ).copy()\n",
    "GoodGoodZero_Mean=hp(GoodGoodZeroPred.mean(),\"Good Zero prediction Mean\")\n",
    "\n",
    "winratio=GoodTrueWinPred_Mean/(GoodTrueWinPred_Mean+GoodLossPred_Mean)\n",
    "fiability=GoodTrueWinPred_Mean + GoodLossPred_Mean + GoodMissedDeal_Mean + GoodGoodZero_Mean\n",
    "if( fiability == 100):print(\"good fiability\")\n",
    "else: print(f\"check the fiability {fiability}\")\n",
    "print(f\"========= Win Ratio:{winratio*100} ====================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a Keras model using numpy without loading all the data into memory at once, you can use the fit_generator method of the Sequential or Model class.\n",
    "\n",
    "First, you can create a custom data generator function that yields batches of data on the fly. This function can use pandas to load a subset of the data from the feather file into memory, transform it using numpy, and then yield the transformed batch.\n",
    "\n",
    "You can then use the fit_generator method to train your Keras model on the generated batches of data. This method takes as input the data generator function, the number of steps per epoch (i.e., the number of batches to yield in each epoch), and the number of epochs to train for.\n",
    "\n",
    "Here is some sample code to get you started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xdata_config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32m../Data/fea/w5_buy0.21.fea\u001b[0m*\n"
     ]
    }
   ],
   "source": [
    "ls ../Data/fea/w5_buy0.21.fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_feather() got an unexpected keyword argument 'chunksize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m feather_file\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../Data/fea/w5_buy0.21.fea\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_feather(feather_file, chunksize\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: read_feather() got an unexpected keyword argument 'chunksize'"
     ]
    }
   ],
   "source": [
    "feather_file=\"../Data/fea/w5_buy0.21.fea\"\n",
    "\n",
    "df = pd.read_feather(feather_file, chunksize=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/pandas/core/arrays/masked.py:59: UserWarning: Pandas requires version '1.3.2' or newer of 'bottleneck' (version '1.2.1' currently installed).\n",
      "  from pandas.core import (\n",
      "2023-02-14 20:50:00.692873: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-14 20:50:00.692906: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-14 20:50:00.777577: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-14 20:50:02.157293: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-14 20:50:02.157514: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-14 20:50:02.157528: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-14 20:50:03.484309: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-14 20:50:03.484671: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-14 20:50:03.484766: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: abj-K93SV\n",
      "2023-02-14 20:50:03.484788: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: abj-K93SV\n",
      "2023-02-14 20:50:03.484843: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2023-02-14 20:50:03.484889: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 390.154.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'input_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m# Create Keras model\u001b[39;00m\n\u001b[1;32m     16\u001b[0m model \u001b[39m=\u001b[39m Sequential()\n\u001b[0;32m---> 17\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m64\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, input_dim\u001b[39m=\u001b[39minput_dim))\n\u001b[1;32m     18\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     20\u001b[0m \u001b[39m# Compile the model\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_dim' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "feather_file=\"../Data/fea/w5_buy0.21.fea\"\n",
    "# Define data generator function\n",
    "def data_generator(feather_file, batch_size):\n",
    "    while True:\n",
    "        df = pd.read_feather(feather_file, chunksize=batch_size)\n",
    "        for chunk in df:\n",
    "            X = np.array(chunk.drop(['target'], axis=1))  # Assuming 'target' is the name of the target column\n",
    "            y = np.array(chunk['target'])\n",
    "            yield X, y\n",
    "\n",
    "# Create Keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=X.shape))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using the data generator\n",
    "model.fit_generator(data_generator(feather_file='my_data.feather', batch_size=32), \n",
    "                    steps_per_epoch=100, epochs=10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the data_generator function loads the feather file in chunks of size batch_size and yields each chunk as a pair of X and y arrays. The fit_generator method then uses this function to train the Keras model for 10 epochs, with 100 batches per epoch.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

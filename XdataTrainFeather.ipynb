{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/UltimeTradingBot/Crypto_backtest_tools\n",
      "/UltimeTradingBot/Data/tp70_w14_max7min_Model_v1.hdf5\n",
      "/UltimeTradingBot/Data/tp70_w14_max7min_Norm_v1.json\n"
     ]
    }
   ],
   "source": [
    "%cd '/UltimeTradingBot/Crypto_backtest_tools'\n",
    "WINDOW_SIZE=14\n",
    "BUY_PCT=0.7\n",
    "SELL_PCT=0.4\n",
    "MAX_FORCAST_SIZE=7\n",
    "VERSION=1\n",
    "TESTING_MOD=False\n",
    "UPGRAD_MOD=False\n",
    "JUST_IMPORT_DATA=False\n",
    "#Normalization_File='w15_NoVol_Normalization.json'\n",
    "#Model_FileName='w15_NoVol_XcryptoAi_model.hdf5'\n",
    "ALLHIST_FILE='Results_history.json'\n",
    "DATA_DIR='/UltimeTradingBot/Data/'\n",
    "FIRST_NORM_FLAG=True\n",
    "DATA_DIR='/UltimeTradingBot/Data'\n",
    "Normalization_File=f'{DATA_DIR}/tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Norm_v{VERSION}.json'\n",
    "Model_FileName=f'{DATA_DIR}/tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model_v{VERSION}.hdf5'\n",
    "DATA_FILE=f'{DATA_DIR}/CSV/tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Data_v{VERSION}.csv'\n",
    "REMOTE_DATA_FILE=f'/gdrive/+DATA+/tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Data_v{VERSION}.csv.zip'\n",
    "METAINFO=f\"tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min\"\n",
    "window=WINDOW_SIZE\n",
    "NORM_FILE=Normalization_File\n",
    "MODEL_FILE=Model_FileName\n",
    "Px=40\n",
    "BUFFER_SIZE=250000*Px\n",
    "SAMPLE_SIZE=5000*Px\n",
    "ModelTest=\"/UltimeTradingBot/Data/tp200_w10_max20min_Model_v2.h5\"\n",
    "\n",
    "#DATA_FILE=DATA_DIR+'w'+str(WINDOW_SIZE)+'_EXTData.csv'\n",
    "print(MODEL_FILE)\n",
    "print(NORM_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Today_list=['FIDA/USDT',\n",
    " 'LAZIO/USDT',\n",
    " 'SRM/USDT',\n",
    " 'GMT/USDT',\n",
    " 'SOL/USDT',\n",
    " 'ALGO/USDT',\n",
    " 'DOGE/USDT',\n",
    " 'GALA/USDT',\n",
    " 'ETH/USDT',\n",
    " 'APE/USDT',\n",
    " 'SHIB/USDT',\n",
    " 'AVAX/USDT',\n",
    " 'ADA/USDT',\n",
    " 'NEAR/USDT',\n",
    " 'DOT/USDT',\n",
    " 'LTC/USDT',\n",
    " 'XMR/USDT',\n",
    " 'XRP/USDT',\n",
    " 'ETC/USDT',\n",
    " 'TRX/USDT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/UltimeTradingBot/Crypto_backtest_tools\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/pandas/core/arrays/masked.py:59: UserWarning: Pandas requires version '1.3.2' or newer of 'bottleneck' (version '1.2.1' currently installed).\n",
      "  from pandas.core import (\n",
      "2022-11-24 22:27:54.005857: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-24 22:27:54.005911: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-24 22:27:54.073517: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-24 22:27:55.487704: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-24 22:27:55.487892: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-24 22:27:55.487917: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('/UltimeTradingBot/Crypto_backtest_tools')\n",
    "%cd /UltimeTradingBot/Crypto_backtest_tools\n",
    "from utilities.get_data import get_historical_from_db\n",
    "from utilities.backtesting import basic_single_asset_backtest, plot_wallet_vs_asset, get_metrics\n",
    "import pandas as pd\n",
    "import ccxt\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "#import ta\n",
    "import numpy as np\n",
    "import gc\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from utilities.backtesting import plot_wallet_vs_asset, get_metrics, get_n_columns, basic_multi_asset_backtest, plot_sharpe_evolution, plot_bar_by_month\n",
    "#from utilities.custom_indicators import SuperTrend\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import gc\n",
    "gc.collect()    \n",
    "import ccxt\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense \n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "PRERR=False\n",
    "def prerr(err):\n",
    "    if PRERR:\n",
    "        print(\"\\033[0;31m Error in \"+str(sys._getframe().f_code.co_name) +\" \\033[0;33m\"+str(err))\n",
    "\n",
    "PDEBUG=True\n",
    "def pdebug(err):\n",
    "    if PDEBUG:\n",
    "        print(\"\\033[0;31m Error in \"+str(sys._getframe().f_code.co_name) +\" \\033[0;33m\"+str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usefull Global and Config Vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "Binance_USDT_HALAL = [\n",
    "    \"LUNA/USDT\",\n",
    "    \"ETH/USDT\",\n",
    "    \"GMT/USDT\",\n",
    "    \"SOL/USDT\",\n",
    "    \"LTC/USDT\",\n",
    "    \"APE/USDT\",\n",
    "    \"XRP/USDT\",\n",
    "    \"ICP/USDT\",\n",
    "    \"IDEX/USDT\",\n",
    "    \"AVAX/USDT\",\n",
    "    \"DOT/USDT\",\n",
    "    \"ROSE/USDT\",\n",
    "    \"ADA/USDT\",\n",
    "    \"JASMY/USDT\",\n",
    "    \"GAL/USDT\",\n",
    "    \"GALA/USDT\",\n",
    "    \"SHIB/USDT\",\n",
    "    \"WAVES/USDT\",\n",
    "    \"DOGE/USDT\",\n",
    "    \"AR/USDT\",\n",
    "    \"GLMR/USDT\",\n",
    "    \"LOKA/USDT\",\n",
    "    \"XLM/USDT\",\n",
    "    \"MTL/USDT\",\n",
    "    \"SNX/USDT\",\n",
    "    \"PYR/USDT\",\n",
    "    \"DASH/USDT\",\n",
    "    \"BTC/USDT\",\n",
    "    \"TRX/USDT\",\n",
    "    \"NEAR/USDT\",\n",
    "    \"AXS/USDT\",\n",
    "    \"ZIL/USDT\",\n",
    "    \"UST/USDT\",\n",
    "    \"ENS/USDT\",\n",
    "    \"MANA/USDT\",\n",
    "    \"DAR/USDT\",\n",
    "    \"LAZIO/USDT\",\n",
    "    \"ALICE/USDT\",\n",
    "    \"ZEC/USDT\",\n",
    "    \"ALGO/USDT\",\n",
    "    \"GRT/USDT\",\n",
    "    \"PSG/USDT\",\n",
    "    \"SLP/USDT\",\n",
    "    \"EOS/USDT\",\n",
    "    \"PORTO/USDT\",\n",
    "    \"EGLD/USDT\",\n",
    "    \"XMR/USDT\",\n",
    "    \"KDA/USDT\",\n",
    "    \"ETC/USDT\",\n",
    "    \"MBOX/USDT\",\n",
    "    \"OGN/USDT\",\n",
    "    \"CITY/USDT\",\n",
    "    \"ASTR/USDT\",\n",
    "    \"IOTA/USDT\",\n",
    "    \"ACM/USDT\",\n",
    "    \"BAR/USDT\",\n",
    "    \"JUV/USDT\",\n",
    "    \"SYS/USDT\",\n",
    "    \"RVN/USDT\",\n",
    "    \"MBL/USDT\",\n",
    "    \"REN/USDT\",\n",
    "    \"JST/USDT\",\n",
    "    \"OMG/USDT\",\n",
    "    \"ATM/USDT\",\n",
    "    \"XEC/USDT\",\n",
    "    \"STORJ/USDT\",\n",
    "    \"ZRX/USDT\",\n",
    "    \"SRM/USDT\",\n",
    "    \"ICX/USDT\",\n",
    "    \"API3/USDT\",\n",
    "    \"ONT/USDT\",\n",
    "    \"SKL/USDT\",\n",
    "    \"MULTI/USDT\",\n",
    "    \"QTUM/USDT\",\n",
    "    \"COCOS/USDT\",\n",
    "    \"VOXEL/USDT\",\n",
    "    \"HIVE/USDT\",\n",
    "    \"KP3R/USDT\",\n",
    "    \"ATA/USDT\",\n",
    "    \"STMX/USDT\",\n",
    "    \"ADX/USDT\",\n",
    "    \"HIGH/USDT\",\n",
    "    \"NULS/USDT\",\n",
    "    \"MLN/USDT\",\n",
    "    \"YGG/USDT\",\n",
    "    \"SC/USDT\",\n",
    "    \"CKB/USDT\",\n",
    "    \"TOMO/USDT\",\n",
    "    \"STX/USDT\",\n",
    "    \"FLUX/USDT\",\n",
    "    \"DNT/USDT\",\n",
    "    \"ORN/USDT\",\n",
    "    \"PLA/USDT\",\n",
    "    \"BADGER/USDT\",\n",
    "    \"DF/USDT\",\n",
    "    \"MOB/USDT\",\n",
    "    \"LPT/USDT\",\n",
    "    \"SCRT/USDT\",\n",
    "    \"RAD/USDT\",\n",
    "    \"NMR/USDT\",\n",
    "    \"ELF/USDT\",\n",
    "    \"TORN/USDT\",\n",
    "    \"T/USDT\",\n",
    "    \"QUICK/USDT\",\n",
    "    \"LSK/USDT\",\n",
    "    \"FIDA/USDT\",\n",
    "    \"XNO/USDT\",\n",
    "    \"BTG/USDT\",\n",
    "    \"GHST/USDT\",\n",
    "    \"EPS/USDT\"\n",
    "]\n",
    "\n",
    "pair_list = Binance_USDT_HALAL\n",
    "#tf = '1m'\n",
    "oldest_pair = \"BTC/USDT\"\n",
    "df_list1m = {}\n",
    "df_list1d = {}\n",
    "df_list1h = {}\n",
    "df_list5m = {}\n",
    "df_list15m = {}\n",
    "\n",
    "\n",
    "for pair in pair_list:\n",
    "    df = get_historical_from_db(ccxt.binance(), pair, '1m', path=\"./database/\")\n",
    "    df_list1m[pair] = df.loc[:]\n",
    "\n",
    "for pair in pair_list:\n",
    "    df = get_historical_from_db(ccxt.binance(), pair, '1d', path=\"./database/\")\n",
    "    df_list1d[pair] = df.loc[:]\n",
    "\n",
    "for pair in pair_list:\n",
    "    df = get_historical_from_db(ccxt.binance(), pair, '1h', path=\"./database/\")\n",
    "    df_list1h[pair] = df.loc[:]\n",
    "\n",
    "for pair in pair_list:\n",
    "    df = get_historical_from_db(ccxt.binance(), pair, '5m', path=\"./database/\")\n",
    "    df_list5m[pair] = df.loc[:]\n",
    "\n",
    "for pair in pair_list:\n",
    "    df = get_historical_from_db(\n",
    "        ccxt.binance(), pair, '15m', path=\"./database/\")\n",
    "    df_list15m[pair] = df.loc[:]\n",
    "del(df)\n",
    "df_list = df_list1m\n",
    "prerr(\"Data load 100% use df_list1d[\\\"BTC/USDT\\\"] for exemple to access\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_list1m[\"BTC/USDT\"].iloc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validated Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Binance First Candle Finders\n",
    "Creslin\n",
    "\n",
    "Get list of all IDs on binance\n",
    "Returns the first candle / launch timestamp to the minute for each\n",
    "'''\n",
    "import urllib.request\n",
    "import json\n",
    "import ccxt\n",
    "\n",
    "def all_ids():\n",
    "    # load all markets from binance into a list\n",
    "    id = 'binance'\n",
    "    exchange_found = id in ccxt.exchanges\n",
    "    if exchange_found:\n",
    "        exchange = getattr(ccxt, id)({})\n",
    "        markets = exchange.load_markets()\n",
    "        tuples = list(ccxt.Exchange.keysort(markets).items())\n",
    "\n",
    "        ids = []\n",
    "        for (k, v) in tuples:\n",
    "            ids.append(v['id'])\n",
    "\n",
    "        return ids\n",
    "\n",
    "def give_first_kline_open_stamp(interval, symbol, start_ts=1499990400000):\n",
    "        '''\n",
    "        Returns the first kline from an interval and start timestamp and symbol\n",
    "        :param interval:  1w, 1d, 1m etc - the bar length to query\n",
    "        :param symbol:    BTCUSDT or LTCBTC etc\n",
    "        :param start_ts:  Timestamp in miliseconds to start the query from\n",
    "        :return:          The first open candle timestamp\n",
    "        '''\n",
    "\n",
    "        url_stub = \"http://api.binance.com/api/v1/klines?interval=\"\n",
    "\n",
    "        #/api/v1/klines?interval=1m&startTime=1536349500000&symbol=ETCBNB\n",
    "        addInterval   = url_stub     + str(interval) + \"&\"\n",
    "        addStarttime  = addInterval   + \"startTime=\"  + str(start_ts) + \"&\"\n",
    "        addSymbol     = addStarttime + \"symbol=\"     + str(symbol)\n",
    "        url_to_get = addSymbol\n",
    "\n",
    "        kline_data = urllib.request.urlopen(url_to_get).read().decode(\"utf-8\")\n",
    "        kline_data = json.loads(kline_data)\n",
    "\n",
    "        return kline_data[0][0]\n",
    "\n",
    "\n",
    "# Get list of all IDs on binance\n",
    "def get_crypto_metadata(pair_list):\n",
    "    Binance_USDT_HALAL=pair_list\n",
    "    ids = []\n",
    "    #ids = all_ids()\n",
    "    for halalpair in Binance_USDT_HALAL:\n",
    "    #    print( halalpair.replace('/',''))\n",
    "        ids.append(halalpair.replace('/',''))\n",
    "    #print(ids)\n",
    "    MetaData=pd.DataFrame(ids)\n",
    "    MetaData[\"Pair\"]=Binance_USDT_HALAL\n",
    "    counters=0\n",
    "    for this_id in ids:\n",
    "        '''\n",
    "        Find launch Week of symbol, start at Binance launch date 2017-07-14 (1499990400000)\n",
    "        Find launch Day of symbol in week\n",
    "        Find launch minute of symbol in day\n",
    "        '''\n",
    "\n",
    "        symbol_launch_week_stamp   = give_first_kline_open_stamp('1w', this_id, 1499990400000 )\n",
    "        symbol_launch_day_stamp    = give_first_kline_open_stamp('1d', this_id, symbol_launch_week_stamp)\n",
    "        symbol_launch_minute_stamp = give_first_kline_open_stamp('1m', this_id, symbol_launch_day_stamp)\n",
    "        MetaData.loc[counters,\"launch_week_stamp\"]=str(symbol_launch_week_stamp)\n",
    "        MetaData.loc[counters,\"launch_day_stamp\"]=str(symbol_launch_day_stamp)\n",
    "        MetaData.loc[counters,\"launch_minute\"]=pd.to_datetime(symbol_launch_minute_stamp, unit='ms')\n",
    "\n",
    "        counters += 1\n",
    "\n",
    "        #print(\"Week stamp\", symbol_launch_week_stamp)\n",
    "        #print(\"Day  stamp\", symbol_launch_day_stamp)\n",
    "        #print(\"Min  stamp\", symbol_launch_minute_stamp)\n",
    "\n",
    "        print(this_id, \"launched\", symbol_launch_minute_stamp )\n",
    "    return MetaData\n",
    "    #print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    MetaData = pd.read_csv(\"../Data/MetaData.csv\",index_col=0)\n",
    "except:\n",
    "    MetaData=get_crypto_metadata(Binance_USDT_HALAL)\n",
    "    MetaData.to_csv(\"../Data/MetaData.csv\")\n",
    "#allok = pd.read_csv('D:/+DATA+/allok_w15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "#MetaData.to_csv(\"D:\\+DATA+\\MetaData.csv\")\n",
    "pair_list=Binance_USDT_HALAL\n",
    "window=WINDOW_SIZE\n",
    "buy_weight=50\n",
    "sample_size=10000\n",
    "min_days=MAX_FORCAST_SIZE\n",
    "buffer_size=100000\n",
    "#MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def expand_row(dataframe, window=2):\n",
    "    df = dataframe.copy()\n",
    "    for i in range(1, window+1):\n",
    "        df[\"high\"+str(i)] = df[\"high\"][i:]\n",
    "        df[\"low\"+str(i)] = df[\"low\"][i:]\n",
    "        df[\"open\"+str(i)] = df[\"open\"][i:]\n",
    "        df[\"close\"+str(i)] = df[\"close\"][i:]\n",
    "        df[\"volume\"+str(i)] = df[\"volume\"][i:]\n",
    "    return df\n",
    "\n",
    "def justlast_remover(df):\n",
    "    justlast=[\"BTC_open\",\"BTC_low\",\"BTC_close\",\"open\",\"low\",\"close\"]\n",
    "    for key in df.keys():\n",
    "        #key.find(\"-1\") != -1 and key.find(\"open-1\") == -1) or\n",
    "        if ( key.find(\"close\") != -1 ):\n",
    "            justlast.append(key)\n",
    "    df=df.drop(columns=justlast)\n",
    "    return df\n",
    "\n",
    "def expand_previous(dataframe, window=10):\n",
    "    df = dataframe.copy()\n",
    "    if window >= len(df):\n",
    "        for i in range(1, window+1):\n",
    "            df.loc[window:len(df),\"high-\"+str(i)]=None\n",
    "            df.loc[window:len(df),\"low-\"+str(i)]=None\n",
    "            #df.loc[window:len(df),\"open-\"+str(i)]=None            \n",
    "            df.loc[window:len(df),\"close-\"+str(i)]=None            \n",
    "            df.loc[window:len(df),\"volume-\"+str(i)]=None\n",
    "        window=len(df)\n",
    "\n",
    "    for i in range(1, window+1):\n",
    "        try:\n",
    "            df.loc[window:len(df),\"high-\"+str(i)]=None\n",
    "            df[\"high-\"+str(i)].iloc[window:len(df)]=df[\"high\"][window-i:len(df)-i].to_list()\n",
    "\n",
    "            df.loc[window:len(df),\"low-\"+str(i)]=None\n",
    "            df[\"low-\"+str(i)].iloc[window:len(df)]=df[\"low\"][window-i:len(df)-i].to_list()\n",
    "\n",
    "            # df.loc[window:len(df),\"open-\"+str(i)]=None\n",
    "            # df[\"open-\"+str(i)].iloc[window:len(df)]=df[\"open\"][window-i:len(df)-i].to_list()           \n",
    "            \n",
    "            df.loc[window:len(df),\"close-\"+str(i)]=None\n",
    "            df[\"close-\"+str(i)].iloc[window:len(df)]=df[\"close\"][window-i:len(df)-i].to_list()            \n",
    "            \n",
    "            df.loc[window:len(df),\"volume-\"+str(i)]=None\n",
    "            df[\"volume-\"+str(i)].iloc[window:len(df)]=df[\"volume\"][window-i:len(df)-i].to_list()\n",
    "            \n",
    "            # df[\"high-\"+str(i)][i:] = df[\"high\"][i-1:]\n",
    "            # df[\"low-\"+str(i)][i:] = df[\"low\"][i-1:]\n",
    "            # df[\"open-\"+str(i)][i:] = df[\"open\"][i-1:]\n",
    "            # df[\"close-\"+str(i)][i:] = df[\"close\"][i-1:]\n",
    "            # df[\"volume-\"+str(i)][i:] = df[\"volume\"][i-1:]\n",
    "        except:\n",
    "            prerr(\"Error in     expand_previous: \" +str(i))\n",
    "    if window >= len(df): return df       \n",
    "    return df.iloc[window:]\n",
    "\n",
    "def expand_previous_org(dataframe, window=10):\n",
    "    df = dataframe.copy()\n",
    "    if window >= len(df):\n",
    "        for i in range(1, window+1):\n",
    "            df.loc[window:len(df),\"high-\"+str(i)]=None\n",
    "            df.loc[window:len(df),\"low-\"+str(i)]=None\n",
    "            df.loc[window:len(df),\"open-\"+str(i)]=None            \n",
    "            df.loc[window:len(df),\"close-\"+str(i)]=None            \n",
    "            df.loc[window:len(df),\"volume-\"+str(i)]=None\n",
    "        window=len(df)\n",
    "\n",
    "    for i in range(1, window+1):\n",
    "        try:\n",
    "            df.loc[window:len(df),\"high-\"+str(i)]=None\n",
    "            df[\"high-\"+str(i)].iloc[window:len(df)]=df[\"high\"][window-i:len(df)-i].to_list()\n",
    "\n",
    "            df.loc[window:len(df),\"low-\"+str(i)]=None\n",
    "            df[\"low-\"+str(i)].iloc[window:len(df)]=df[\"low\"][window-i:len(df)-i].to_list()\n",
    "\n",
    "            df.loc[window:len(df),\"open-\"+str(i)]=None\n",
    "            df[\"open-\"+str(i)].iloc[window:len(df)]=df[\"open\"][window-i:len(df)-i].to_list()           \n",
    "            \n",
    "            df.loc[window:len(df),\"close-\"+str(i)]=None\n",
    "            df[\"close-\"+str(i)].iloc[window:len(df)]=df[\"close\"][window-i:len(df)-i].to_list()            \n",
    "            \n",
    "            df.loc[window:len(df),\"volume-\"+str(i)]=None\n",
    "            df[\"volume-\"+str(i)].iloc[window:len(df)]=df[\"volume\"][window-i:len(df)-i].to_list()\n",
    "            \n",
    "            # df[\"high-\"+str(i)][i:] = df[\"high\"][i-1:]\n",
    "            # df[\"low-\"+str(i)][i:] = df[\"low\"][i-1:]\n",
    "            # df[\"open-\"+str(i)][i:] = df[\"open\"][i-1:]\n",
    "            # df[\"close-\"+str(i)][i:] = df[\"close\"][i-1:]\n",
    "            # df[\"volume-\"+str(i)][i:] = df[\"volume\"][i-1:]\n",
    "        except:\n",
    "            prerr(\"Error in     expand_previous: \" +str(i))\n",
    "    if window >= len(df): return df       \n",
    "    return df.iloc[window:]\n",
    "\n",
    "\n",
    "def expand_previous_err(dataframe, window=10):\n",
    "    df = dataframe.copy()\n",
    "    if window >= len(df):\n",
    "        for i in range(1, window+1):\n",
    "            df.loc[window:len(df),\"high-\"+str(i)]=None\n",
    "            df.loc[window:len(df),\"low-\"+str(i)]=None\n",
    "            df.loc[window:len(df),\"open-\"+str(i)]=None            \n",
    "            df.loc[window:len(df),\"close-\"+str(i)]=None            \n",
    "            df.loc[window:len(df),\"volume-\"+str(i)]=None\n",
    "        window=len(df)\n",
    "\n",
    "    for i in range(1, window+1):\n",
    "            df.loc[window:len(df),\"high-\"+str(i)]=None\n",
    "            df[\"high-\"+str(i)].iloc[window:len(df)]=df[\"high\"][window-i:len(df)-i]\n",
    "\n",
    "            df.loc[window:len(df),\"low-\"+str(i)]=None\n",
    "            df[\"low-\"+str(i)].iloc[window:len(df)]=df[\"low\"][window-i:len(df)-i]\n",
    "\n",
    "            df.loc[window:len(df),\"open-\"+str(i)]=None\n",
    "            df[\"open-\"+str(i)].iloc[window:len(df)]=df[\"open\"][window-i:len(df)-i]            \n",
    "            \n",
    "            df.loc[window:len(df),\"close-\"+str(i)]=None\n",
    "            df[\"close-\"+str(i)].iloc[window:len(df)]=df[\"close\"][window-i:len(df)-i]            \n",
    "            \n",
    "            df.loc[window:len(df),\"volume-\"+str(i)]=None\n",
    "            df[\"volume-\"+str(i)].iloc[window:len(df)]=df[\"volume\"][window-i:len(df)-i]\n",
    "            \n",
    "            # df[\"high-\"+str(i)][i:] = df[\"high\"][i-1:]\n",
    "            # df[\"low-\"+str(i)][i:] = df[\"low\"][i-1:]\n",
    "            # df[\"open-\"+str(i)][i:] = df[\"open\"][i-1:]\n",
    "            # df[\"close-\"+str(i)][i:] = df[\"close\"][i-1:]\n",
    "            # df[\"volume-\"+str(i)][i:] = df[\"volume\"][i-1:]\n",
    "    if window >= len(df):\n",
    "        return df\n",
    "    return df.iloc[window:]\n",
    "\n",
    "def expand_timeframe(df_minutes,df_hours, window=2):\n",
    "    dfm = df_minutes.copy()\n",
    "    for j in range(1, window+1):\n",
    "        for i in df_hours[dfm.iloc[0].name:].index:\n",
    "        #prerr(str(i))\n",
    "            try:\n",
    "                dfm.loc[pd.date_range(str(i), periods=60, freq=\"min\"),\"high_1h-\"+str(j)]= df_hours[str(i-pd.Timedelta(str(j)+\" hour\"))]['high']\n",
    "                dfm.loc[pd.date_range(str(i), periods=60, freq=\"min\"),\"low_1h-\"+str(j)]= df_hours[str(i-pd.Timedelta(str(j)+\" hour\"))]['low']\n",
    "                dfm.loc[pd.date_range(str(i), periods=60, freq=\"min\"),\"open_1h-\"+str(j)]= df_hours[str(i-pd.Timedelta(str(j)+\" hour\"))]['open']\n",
    "                dfm.loc[pd.date_range(str(i), periods=60, freq=\"min\"),\"close_1h-\"+str(j)]= df_hours[str(i-pd.Timedelta(str(j)+\" hour\"))]['close']\n",
    "            except:\n",
    "                prerr(\"Error Merging: \"+str(i))\n",
    "    \n",
    "    return dfm\n",
    "\n",
    "\n",
    "def float_or_not(var):\n",
    "    try:\n",
    "        x=float(var)\n",
    "    except:\n",
    "        x=None\n",
    "    return x\n",
    "\n",
    "def expand_to_1h(df_1m,df_1h, window=2):\n",
    "    dfm = df_1m.copy()\n",
    "    index_start=df_1h.index.intersection(dfm.index.round(freq='H'))\n",
    "    for i in index_start:\n",
    "        for j in range(1, window+1):\n",
    "            # try:    \n",
    "                timefragment=dfm.index.intersection(pd.date_range(str(i), periods=60, freq=\"min\"))\n",
    "                dfm.loc[timefragment,\"high_1h-\"+str(j)]=float_or_not(df_1h.loc[str(i-pd.Timedelta(str(j)+\" hour\"))]['high'])\n",
    "                dfm.loc[timefragment,\"low_1h-\"+str(j)]=float_or_not(df_1h.loc[str(i-pd.Timedelta(str(j)+\" hour\"))]['low'])\n",
    "                dfm.loc[timefragment,\"open_1h-\"+str(j)]=float_or_not(df_1h.loc[str(i-pd.Timedelta(str(j)+\" hour\"))]['open'])\n",
    "                dfm.loc[timefragment,\"close_1h-\"+str(j)]=float_or_not(df_1h.loc[str(i-pd.Timedelta(str(j)+\" hour\"))]['close'])\n",
    "            # except:\n",
    "            #     prerr(\"error fonction \"str(i))\n",
    "    return dfm\n",
    "\n",
    "def expand_to_4h(df_1m,df_4h, window=2):\n",
    "    dfm = df_1m.copy()\n",
    "    #index_start=df_1h[str(dfm.iloc[0].name.round(freq='H')):].index.intersection(dfm.index)\n",
    "    index_start=df_4h.index.intersection(dfm.index.round(freq='4H'))\n",
    "    for i in index_start:\n",
    "        for j in range(1, window+1):\n",
    "            # try:    \n",
    "                timefragment=dfm.index.intersection(pd.date_range(str(i), periods=4*60, freq=\"min\"))\n",
    "                dfm.loc[timefragment,\"high_4h-\"+str(j)]=float_or_not(df_4h.loc[str(i-pd.Timedelta(str(j*4)+\" hour\"))]['high'])\n",
    "                dfm.loc[timefragment,\"low_4h-\"+str(j)]= float_or_not(df_4h.loc[str(i-pd.Timedelta(str(j*4)+\" hour\"))]['low'])\n",
    "                dfm.loc[timefragment,\"open_4h-\"+str(j)]= float_or_not(df_4h.loc[str(i-pd.Timedelta(str(j*4)+\" hour\"))]['open'])\n",
    "                dfm.loc[timefragment,\"close_4h-\"+str(j)]= float_or_not(df_4h.loc[str(i-pd.Timedelta(str(j*4)+\" hour\"))]['close'])\n",
    "            # except:\n",
    "            #     prerr(\"error fonction \"str(i))\n",
    "    return dfm\n",
    "\n",
    "def expand_to_1d(df_1m,df_1d, window=2,time_suffix=\"1d\"):\n",
    "    dfm = df_1m.copy()\n",
    "    index_start=df_1d.index.intersection(dfm.index.round(freq='1d'))\n",
    "    for i in index_start:\n",
    "        for j in range(1, window+1):\n",
    "            # try:    \n",
    "                prerr(i)\n",
    "                timefragment=dfm.index.intersection(pd.date_range(str(i), periods=24*60, freq=\"min\"))\n",
    "                dfm.loc[timefragment,\"high_\"+time_suffix+\"-\"+str(j)]=float_or_not(df_1d.loc[str(i-pd.Timedelta(str(j)+\" day\"))]['high'])\n",
    "                dfm.loc[timefragment,\"low_\"+time_suffix+\"-\"+str(j)]= float_or_not(df_1d.loc[str(i-pd.Timedelta(str(j)+\" day\"))]['low'])\n",
    "                dfm.loc[timefragment,\"open_\"+time_suffix+\"-\"+str(j)]= float_or_not(df_1d.loc[str(i-pd.Timedelta(str(j)+\" day\"))]['open'])\n",
    "                dfm.loc[timefragment,\"close_\"+time_suffix+\"-\"+str(j)]= float_or_not(df_1d.loc[str(i-pd.Timedelta(str(j)+\" day\"))]['close'])\n",
    "            # except:\n",
    "            #     prerr(\"error fonction \"str(i))\n",
    "    return dfm\n",
    "\n",
    "def expand_to_5m(df_1m,df_5m, window=2,time_suffix=\"5m\"):\n",
    "    dfm = df_1m.copy()\n",
    "    index_start=df_5m.index.intersection(dfm.index.round(freq='5 min'))\n",
    "    for i in index_start:\n",
    "        for j in range(1, window+1):\n",
    "            # try:    \n",
    "                \n",
    "                timefragment=dfm.index.intersection(pd.date_range(str(i), periods=5, freq=\"min\"))\n",
    "                dfm.loc[timefragment,\"high_\"+time_suffix+\"-\"+str(j)]=float_or_not(df_5m.loc[str(i-pd.Timedelta(str(j*5)+\" min\"))]['high'])\n",
    "                dfm.loc[timefragment,\"low_\"+time_suffix+\"-\"+str(j)]= float_or_not(df_5m.loc[str(i-pd.Timedelta(str(j*5)+\" min\"))]['low'])\n",
    "                dfm.loc[timefragment,\"open_\"+time_suffix+\"-\"+str(j)]= float_or_not(df_5m.loc[str(i-pd.Timedelta(str(j*5)+\" min\"))]['open'])\n",
    "                dfm.loc[timefragment,\"close_\"+time_suffix+\"-\"+str(j)]= float_or_not(df_5m.loc[str(i-pd.Timedelta(str(j*5)+\" min\"))]['close'])\n",
    "            # except:\n",
    "            #     prerr(\"error fonction \"str(i))\n",
    "    return dfm\n",
    "\n",
    "\n",
    "def expand_to_15m(df_1m,df_15m, window=2,time_suffix=\"15m\"):\n",
    "    dfm = df_1m.copy()\n",
    "    index_start=df_15m.index.intersection(dfm.index.round(freq='5 min'))\n",
    "    for i in index_start:\n",
    "        for j in range(1, window+1):    \n",
    "            # try:    \n",
    "                timefragment=dfm.index.intersection(pd.date_range(str(i), periods=15, freq=\"min\"))\n",
    "                dfm.loc[timefragment,\"high_\"+time_suffix+\"-\"+str(j)]=float_or_not(df_15m.loc[str(i-pd.Timedelta(str(j*15)+\" min\"))]['high'])\n",
    "                dfm.loc[timefragment,\"low_\"+time_suffix+\"-\"+str(j)]= float_or_not(df_15m.loc[str(i-pd.Timedelta(str(j*15)+\" min\"))]['low'])\n",
    "                dfm.loc[timefragment,\"open_\"+time_suffix+\"-\"+str(j)]= float_or_not(df_15m.loc[str(i-pd.Timedelta(str(j*15)+\" min\"))]['open'])\n",
    "                dfm.loc[timefragment,\"close_\"+time_suffix+\"-\"+str(j)]= float_or_not(df_15m.loc[str(i-pd.Timedelta(str(j*15)+\" min\"))]['close'])\n",
    "            # except:\n",
    "            #     prerr(\"error fonction \"str(i))\n",
    "    return dfm\n",
    "\n",
    "def rapid1d_expand(df1m,df1d,window=2):\n",
    "    d1min=df1m.copy()\n",
    "    d1day=df1d.loc[\n",
    "    d1min.index[0].round(freq='1d')-pd.Timedelta(str(window)+' day'):\n",
    "    d1min.index[len(d1min)-1].round(freq='1d')+pd.Timedelta('1 day')\n",
    "    ].copy()\n",
    "    d1day_pre=expand_previous(d1day,window)\n",
    "    d1day_pre=d1day_pre.drop(columns=['open', 'low','close','high','volume'])\n",
    "    d1day_pre=d1day_pre.add_suffix(\"_day\")\n",
    "    d1min=pd.merge_asof(\n",
    "        d1min, d1day_pre, on=None, left_on=None, right_on=None, left_index=True, \n",
    "        right_index=True, by=None, left_by=None, right_by=None, \n",
    "        suffixes=('', '_day'),\n",
    "        tolerance=pd.Timedelta('1 day'), allow_exact_matches=True, direction='backward')\n",
    "    return d1min\n",
    "\n",
    "def rapid1h_expand(df1m,df1h,window=2):\n",
    "    d1min=df1m.copy()\n",
    "    d1hour=df1h.loc[\n",
    "    d1min.index[0].round(freq='H')-pd.Timedelta(str(window)+' hour'):\n",
    "    d1min.index[len(d1min)-1].round(freq='H')+pd.Timedelta('1 hour')\n",
    "    ].copy()\n",
    "    d1hour_pre=expand_previous(d1hour,window)\n",
    "    d1hour_pre=d1hour_pre.drop(columns=['open', 'low','close','high','volume'])\n",
    "    d1hour_pre=d1hour_pre.add_suffix(\"_hour\")\n",
    "    d1min=pd.merge_asof(\n",
    "    d1min, d1hour_pre, on=None, left_on=None, right_on=None, left_index=True, \n",
    "    right_index=True, by=None, left_by=None, right_by=None, \n",
    "    suffixes=('', '_hour'),\n",
    "    tolerance=pd.Timedelta('1 hour'), allow_exact_matches=True, direction='backward')\n",
    "    return d1min\n",
    "\n",
    "\n",
    "def rapid5m_expand(df1m,df5m,window=2):\n",
    "    d1min=df1m.copy()\n",
    "    d5min=df5m.loc[\n",
    "    d1min.index[0].round(freq='5 min')-pd.Timedelta(str(window*5+10)+' min'):\n",
    "    d1min.index[len(d1min)-1].round(freq='5 min')+pd.Timedelta('5 min')\n",
    "    ].copy()\n",
    "    d5min_pre=expand_previous(d5min,window)\n",
    "    d5min_pre=d5min_pre.drop(columns=['open', 'low','close','high','volume'])\n",
    "    d5min_pre=d5min_pre.add_suffix(\"_5min\")\n",
    "    d1min=pd.merge_asof(\n",
    "    d1min, d5min_pre, on=None, left_on=None, right_on=None, left_index=True, \n",
    "    right_index=True, by=None, left_by=None, right_by=None, \n",
    "    suffixes=('', '_5min'),\n",
    "    tolerance=pd.Timedelta('5 min'), allow_exact_matches=True, direction='backward')\n",
    "    return d1min\n",
    "\n",
    "def rapid15m_expand(df1m,df15m,window=2):\n",
    "    d1min=df1m.copy()\n",
    "    d15min=df15m.loc[\n",
    "    d1min.index[0].round(freq='15 min')-pd.Timedelta(str(window*15+30)+' min'):\n",
    "    d1min.index[len(d1min)-1].round(freq='15 min')+pd.Timedelta('15 min')\n",
    "    ].copy()\n",
    "    d15min_pre=expand_previous(d15min,window)\n",
    "    d15min_pre=d15min_pre.drop(columns=['open', 'low','close','high','volume'])\n",
    "    d15min_pre=d15min_pre.add_suffix(\"_15min\")\n",
    "    d1min=pd.merge_asof(\n",
    "    d1min, d15min_pre, on=None, left_on=None, right_on=None, left_index=True, \n",
    "    right_index=True, by=None, left_by=None, right_by=None, \n",
    "    suffixes=('', '_15min'),\n",
    "    tolerance=pd.Timedelta('15 min'), allow_exact_matches=True, direction='backward')\n",
    "    return d1min\n",
    "\n",
    "\n",
    "def full_expand(df1m,df5m,df15m,df1h,df1d,window=10):\n",
    "    d1min=df1m.copy()\n",
    "    d1min=expand_previous(d1min,window=window).drop(columns=[\"volume\"])\n",
    "    d1min=rapid1d_expand(d1min,df1d,window)\n",
    "    d1min=rapid1h_expand(d1min,df1h,window)\n",
    "    d1min=rapid15m_expand(d1min,df15m,window)\n",
    "    d1min=rapid5m_expand(d1min,df5m,window)\n",
    "    return d1min\n",
    "\n",
    "def full_expand_org(df1m,df5m,df15m,df1h,df1d,window=10):\n",
    "    d1min=df1m.copy()\n",
    "    d1min=expand_previous(d1min,window=window)\n",
    "    d1min=rapid1d_expand(d1min,df1d,window)\n",
    "    d1min=rapid1h_expand(d1min,df1h,window)\n",
    "    d1min=rapid15m_expand(d1min,df15m,window)\n",
    "    d1min=rapid5m_expand(d1min,df5m,window)\n",
    "    return d1min\n",
    "\n",
    "\n",
    "def day_expand(data_full):\n",
    "    ser = pd.to_datetime(pd.Series(data_full.index))\n",
    "    data_full[\"day\"]=ser.dt.isocalendar().day.values\n",
    "    data_full[\"hour\"]=ser.dt.hour.values\n",
    "    data_full[\"minute\"]=ser.dt.minute.values\n",
    "\n",
    "# merging\n",
    "def pair_btc(pair=\"LTC/USDT\",window=2):\n",
    "    Pair_Full=full_expand(df_list1m[pair],df_list5m[pair],df_list15m[pair],df_list1h[pair],df_list1d[pair],window)\n",
    "    BTC_Full=full_expand(\n",
    "        df_list1m[\"BTC/USDT\"].loc[df_list1m[pair].iloc[0].name:\n",
    "        df_list1m[pair].iloc[len(df_list1m[pair])-1].name],\n",
    "        df_list5m[\"BTC/USDT\"],df_list15m[\"BTC/USDT\"],df_list1h[\"BTC/USDT\"],df_list1d[\"BTC/USDT\"],window)   \n",
    "    BTC_Full=BTC_Full.add_prefix(\"BTC_\")\n",
    "    Merged=pd.merge(Pair_Full, BTC_Full, left_index=True, how='outer',\n",
    "            right_index=True, suffixes=('', ''))\n",
    "    day_expand(Merged)\n",
    "    return Merged\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def buy_results(df,min_pct=BUY_PCT):\n",
    "    mino=min_pct*0.01\n",
    "    df[\"buy\"]=(\n",
    "        ((df[\"high\"].shift(periods=1, freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino )| ((\n",
    "          df[\"high\"].shift(periods=2, freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino )| ((\n",
    "          df[\"high\"].shift(periods=3, freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino)\n",
    "    ).replace({False: 0, True: 1}) \n",
    " \n",
    "def buy_results_gen(df,min_pct=BUY_PCT,window=3):\n",
    "    mino=min_pct*0.01\n",
    "    codep1='df[\"buy\"]=((('\n",
    "    for i in range(1,window):\n",
    "        codep1=codep1+'df[\"high\"].shift(periods='+str(i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino )| (('\n",
    "    codep2='df[\"high\"].shift(periods='+str(window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino)).replace({False: 0, True: 1})'\n",
    "    code=codep1+codep2\n",
    "    print(code)\n",
    "    exec(code)\n",
    "\n",
    "def buy_sell(df,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=3):\n",
    "    mino=BUY_PCT*0.01\n",
    "    maxo=-SELL_PCT*0.01\n",
    "    codep1='df[\"buy\"]=((('\n",
    "    for i in range(1,window):\n",
    "        codep1=codep1+'df[\"high\"].shift(periods='+str(i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino )| (('\n",
    "    codep2='df[\"high\"].shift(periods='+str(window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino)).replace({False: 0, True: 1})'\n",
    "    code=codep1+codep2\n",
    "    prerr(code)\n",
    "    exec(code)\n",
    "    codep1='df[\"sell\"]=((df[\"buy\"]==0)&(( '\n",
    "    for i in range(1,window):\n",
    "        codep1=codep1+'df[\"high\"].shift(periods='+str(i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] <=maxo )& (('\n",
    "    codep2='df[\"high\"].shift(periods='+str(window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] <=maxo )).replace({False: 0, True: 1})'\n",
    "    code=codep1+codep2\n",
    "    prerr(code)\n",
    "    exec(code)\n",
    "    df[\"bs\"]=((df['buy']==1 ) & (df['sell']==0)).replace({False: 0, True: 1})\n",
    "\n",
    "def buy_only(df,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=3):\n",
    "    mino=BUY_PCT*0.01\n",
    "    maxo=-SELL_PCT*0.01\n",
    "    codep1='df[\"buy\"]=((('\n",
    "    for i in range(1,window):\n",
    "        codep1=codep1+'df[\"high\"].shift(periods='+str(i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino )| (('\n",
    "    codep2='df[\"high\"].shift(periods='+str(window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino)).replace({False: 0, True: 1})'\n",
    "    code=codep1+codep2\n",
    "    prerr(code)\n",
    "    exec(code)\n",
    "    # codep1='df[\"sell\"]=((df[\"buy\"]==0)&(( '\n",
    "    # for i in range(1,window):\n",
    "    #     codep1=codep1+'df[\"high\"].shift(periods='+str(i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] <=maxo )& (('\n",
    "    # codep2='df[\"high\"].shift(periods='+str(window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] <=maxo )).replace({False: 0, True: 1})'\n",
    "    # code=codep1+codep2\n",
    "    # prerr(code)\n",
    "    # exec(code)\n",
    "    # df[\"bs\"]=((df['buy']==1 ) & (df['sell']==0)).replace({False: 0, True: 1})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def Meta_expand(data_full,metadt,pair):\n",
    "    data_full[\"lunch_day\"]=int(-(pd.to_datetime(metadt[metadt[\"Pair\"] == pair][\"launch_minute\"])-pd.Timestamp('2020-01-01 00:00:00.000000')).dt.days)\n",
    "\n",
    "def mini_expand(pair=\"LTC/USDT\",i=0,j=10000,window=2):\n",
    "    Pair_Full=full_expand(df_list1m[pair].iloc[i:j],df_list5m[pair],df_list15m[pair],df_list1h[pair],df_list1d[pair],window)\n",
    "    BTC_Full=full_expand(\n",
    "        df_list1m[\"BTC/USDT\"].loc[Pair_Full.iloc[0].name-pd.Timedelta(str(window-1) +\" min\"):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        df_list5m[\"BTC/USDT\"],\n",
    "        df_list15m[\"BTC/USDT\"],\n",
    "        df_list1h[\"BTC/USDT\"],\n",
    "        df_list1d[\"BTC/USDT\"],\n",
    "        window)   \n",
    "    BTC_Full=BTC_Full.add_prefix(\"BTC_\")\n",
    "    Merged=pd.merge(Pair_Full, BTC_Full, left_index=True, how='left',\n",
    "            right_index=True, suffixes=('', ''))\n",
    "    day_expand(Merged)\n",
    "    return Merged\n",
    "\n",
    "def mini_expand2(pair=\"LTC/USDT\",i=0,j=10000,window=2,metadata=MetaData):\n",
    "    Pair_Full=full_expand(df_list1m[pair].iloc[i:j],df_list5m[pair],df_list15m[pair],df_list1h[pair],df_list1d[pair],window)\n",
    "    BTC_Full=full_expand(\n",
    "        df_list1m[\"BTC/USDT\"].loc[Pair_Full.iloc[0].name-pd.Timedelta(str(window-1) +\" min\"):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        df_list5m[\"BTC/USDT\"],\n",
    "        df_list15m[\"BTC/USDT\"],\n",
    "        df_list1h[\"BTC/USDT\"],\n",
    "        df_list1d[\"BTC/USDT\"],\n",
    "        window)   \n",
    "    BTC_Full=BTC_Full.add_prefix(\"BTC_\")\n",
    "    Merged=pd.merge(Pair_Full, BTC_Full, left_index=True, how='left',\n",
    "            right_index=True, suffixes=('', ''))\n",
    "    day_expand(Merged)\n",
    "    Meta_expand(Merged,metadata,pair)\n",
    "    buy_sell(Merged,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=7)\n",
    "    return Merged\n",
    "\n",
    "def mini_expand3(pair=\"LTC/USDT\",i=0,j=10000,window=2,metadata=MetaData,high_weight=3):\n",
    "    Pair_Full=full_expand(df_list1m[pair].iloc[i:j],df_list5m[pair],df_list15m[pair],df_list1h[pair],df_list1d[pair],window)\n",
    "    BTC_Full=full_expand(\n",
    "        df_list1m[\"BTC/USDT\"].loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" d\")).round(freq='1 min'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        df_list5m[\"BTC/USDT\"],#.loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" d\")).round(freq='5 min'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        df_list15m[\"BTC/USDT\"],#.loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" day\")).round(freq='15 min'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        df_list1h[\"BTC/USDT\"],#.loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" day\")).round(freq='1 H'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        df_list1d[\"BTC/USDT\"],#.loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" day\")).round(freq='1 d'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        window)   \n",
    "    BTC_Full=BTC_Full.add_prefix(\"BTC_\")\n",
    "    # Merged=pd.merge(Pair_Full, BTC_Full, left_index=True, how='left',\n",
    "    #         right_index=True, suffixes=('', ''))\n",
    "    Merged=pd.merge(Pair_Full, BTC_Full, left_index=True, how='inner',\n",
    "            right_index=True, suffixes=('', ''))\n",
    "    day_expand(Merged)\n",
    "    Meta_expand(Merged,metadata,pair)\n",
    "    #buy_sell(Merged,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=MAX_FORCAST_SIZE)\n",
    "    buy_only(Merged,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=MAX_FORCAST_SIZE)\n",
    "    Merged[\"high\"]=(Merged[\"open\"]+high_weight*Merged[\"high\"]+Merged[\"low\"]+Merged[\"close\"])/(3+high_weight)\n",
    "    Merged.rename(columns={\"high\":\"price\"},inplace = True)\n",
    "    Merged[\"BTC_high\"]=(Merged[\"BTC_open\"]+high_weight*Merged[\"BTC_high\"]+Merged[\"BTC_low\"]+Merged[\"BTC_close\"])/(3+high_weight)\n",
    "    Merged.rename(columns={\"BTC_high\":\"BTC_price\"},inplace = True)\n",
    "    Merged=Merged.drop(columns=[\"BTC_open\",\"BTC_low\",\"BTC_close\",\"open\",\"low\",\"close\"])\n",
    "    # Merged=justlast_remover(Merged)\n",
    "    for key in Merged.keys():\n",
    "        if key.find(\"BTC\")!=-1 and (key.find(\"open\")!=-1 or\n",
    "        key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "            Merged[key]=(Merged[\"BTC_price\"]-Merged[key])/Merged[\"BTC_price\"]\n",
    "        if key.find(\"BTC\")==-1 and (key.find(\"open\")!=-1 or\n",
    "        key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "            Merged[key]=(Merged[\"price\"]-Merged[key])/Merged[\"price\"]\n",
    "    return Merged\n",
    "\n",
    "def mini_expand3old(pair=\"LTC/USDT\",i=0,j=10000,window=2,metadata=MetaData,high_weight=3):\n",
    "    Pair_Full=full_expand(df_list1m[pair].iloc[i:j],df_list5m[pair],df_list15m[pair],df_list1h[pair],df_list1d[pair],window)\n",
    "    BTC_Full=full_expand(\n",
    "        df_list1m[\"BTC/USDT\"].loc[Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" min\"):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        df_list5m[\"BTC/USDT\"],\n",
    "        df_list15m[\"BTC/USDT\"],\n",
    "        df_list1h[\"BTC/USDT\"],\n",
    "        df_list1d[\"BTC/USDT\"],\n",
    "        window)   \n",
    "    BTC_Full=BTC_Full.add_prefix(\"BTC_\")\n",
    "    Merged=pd.merge(Pair_Full, BTC_Full, left_index=True, how='left',\n",
    "            right_index=True, suffixes=('', ''))\n",
    "    day_expand(Merged)\n",
    "    Meta_expand(Merged,metadata,pair)\n",
    "    buy_sell(Merged,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=MAX_FORCAST_SIZE)\n",
    "    Merged[\"high\"]=(Merged[\"open\"]+high_weight*Merged[\"high\"]+Merged[\"low\"]+Merged[\"close\"])/(3+high_weight)\n",
    "    Merged.rename(columns={\"high\":\"price\"},inplace = True)\n",
    "    Merged[\"BTC_high\"]=(Merged[\"BTC_open\"]+high_weight*Merged[\"BTC_high\"]+Merged[\"BTC_low\"]+Merged[\"BTC_close\"])/(3+high_weight)\n",
    "    Merged.rename(columns={\"BTC_high\":\"BTC_price\"},inplace = True)\n",
    "    # Merged=Merged.drop(columns=[\"BTC_open\",\"BTC_low\",\"BTC_close\",\"open\",\"low\",\"close\"])\n",
    "    Merged=justlast_remover(Merged)\n",
    "\n",
    "    for key in Merged.keys():\n",
    "        if key.find(\"BTC\")!=-1 and (key.find(\"open\")!=-1 or\n",
    "        key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "            Merged[key]=(Merged[\"BTC_price\"]-Merged[key])/Merged[\"BTC_price\"]\n",
    "        if key.find(\"BTC\")==-1 and (key.find(\"open\")!=-1 or\n",
    "        key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "            Merged[key]=(Merged[\"price\"]-Merged[key])/Merged[\"price\"]\n",
    "    return Merged\n",
    "\n",
    "\n",
    "\n",
    "def slow_expand(pair=\"LTC/USDT\",i=0,j=100000,window=3):\n",
    "    df=mini_expand(pair=pair,i=i,j=j,window=window)\n",
    "    for mx in range(1,int(len(df_list1m[pair])/j)+1) :\n",
    "        df=pd.concat([df,\n",
    "        mini_expand(pair=pair,\n",
    "        i=(mx*j)-window,\n",
    "        j=(mx+1)*j,\n",
    "        window=window)],axis=0)\n",
    "    return df\n",
    "\n",
    "def pair_data_gen(pair=\"LTC/USDT\",i=0,j=100000,window=3,metadata=MetaData):\n",
    "    df=mini_expand3(pair=pair,i=i,j=j,window=window,metadata=metadata)\n",
    "    for mx in range(1,int(len(df_list1m[pair])/j)+1) :\n",
    "        df=pd.concat([df,\n",
    "        mini_expand3(pair=pair,\n",
    "        i=(mx*j)-window,\n",
    "        j=(mx+1)*j,\n",
    "        window=window,metadata=metadata)],axis=0)\n",
    "        # Meta_expand(df,metadata,pair)\n",
    "        # buy_sell(df,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=7)\n",
    "        #print(\"loop \"+str(mx)+\"--> size of df: \"+str(len(df)))\n",
    "    return df\n",
    "\n",
    "###\n",
    "\n",
    "def data_is_enough(df,days=10,window=10):\n",
    "    if days <= window:\n",
    "        return df[~df.isnull().any(axis=1) |(df[\"open-\"+str(days)+\"_day\"].isnull() & ~df[\"open-\"+str(window-1)+\"_hour\"].isnull()  & ~df[\"open-\"+str(window-1)+\"_5min\"].isnull() & ~df[\"open-\"+str(days-1)+\"_day\"].isnull())]\n",
    "    else:\n",
    "        prerr(\"number of days must be equal or lower than window\")\n",
    "        return df\n",
    "\n",
    "def data_cleanup(df):\n",
    "    return df.dropna()\n",
    "    #return df[~df.isnull().any(axis=1)]\n",
    "    \n",
    "def data_shufler2(df):\n",
    "    return df.sample(frac=1).reset_index()\n",
    "    \n",
    "def data_shufler(df):\n",
    "    x = len(df)\n",
    "    df[\"num_index\"] = range(0, x, 1)\n",
    "    df.set_index(df['num_index'], inplace=True)\n",
    "    df = df.reindex(np.random.permutation(df.index))\n",
    "    try:df= df.drop(\"num_index\",axis=1)\n",
    "    except:pass\n",
    "    #df = df.reindex(np.random.permutation(df.index))\n",
    "    return df\n",
    "    \n",
    "def data_np_shufler(df):\n",
    "    df = shuffle(df)\n",
    "    #df = df.reindex(np.random.permutation(df.index))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def data_chooser(df,weight=50,row_numbers=100000):\n",
    "    df=data_shufler(df)\n",
    "    if row_numbers>=len(df):\n",
    "        row_numbers=len(df)\n",
    "    df=pd.concat([df[df[\"buy\"]==1].iloc[:int(row_numbers*weight*0.01)],\n",
    "                 df[df[\"buy\"]==0].iloc[:int(row_numbers*(100-weight)*0.01)]])\n",
    "    df=data_shufler(df)\n",
    "    return df\n",
    "    \n",
    "\n",
    "def data_looper(pair_list=Binance_USDT_HALAL,window=15,buy_weight=50,sample_size=100000,min_days=10,buffer_size=100000):\n",
    "    xdf=pd.DataFrame()\n",
    "    for pair in pair_list:\n",
    "        if pair != \"BTC/USDT\":\n",
    "            print(\"working on: \"+pair)\n",
    "            df=pair_data_gen(pair=pair,i=0,j=buffer_size,window=window)\n",
    "            gc.collect()\n",
    "\n",
    "            df=data_is_enough(df,days=min_days,window=window)\n",
    "            gc.collect()\n",
    "\n",
    "            df=data_chooser(df,weight=buy_weight,row_numbers=sample_size)\n",
    "            gc.collect()\n",
    "\n",
    "            print(pair+\" is processed\")\n",
    "            xdf=pd.concat([xdf,df],axis=0)\n",
    "            del(df)\n",
    "            gc.collect()\n",
    "        else:\n",
    "            print(\"ignore BTC\")\n",
    "    return xdf\n",
    "\n",
    "def data_looper_fast(pair_list=Binance_USDT_HALAL,window=15,buy_weight=50,sample_size=100000,min_days=10,buffer_size=100000):\n",
    "    xdf=pd.DataFrame()\n",
    "    count=0\n",
    "    for pair in pair_list:\n",
    "        if pair != \"BTC/USDT\":\n",
    "            print(\"working on: \"+pair ,end=\" -->\")\n",
    "            try:\n",
    "                df=pair_data_gen(pair=pair,i=0,j=buffer_size,window=window)\n",
    "                gc.collect()\n",
    "                count+=1\n",
    "                # df=data_is_enough(df,days=min_days,window=window)\n",
    "                # gc.collect()\n",
    "                df.reindex(np.random.permutation(df.index))\n",
    "                df=data_chooser(df,weight=buy_weight,row_numbers=sample_size)\n",
    "                gc.collect()\n",
    "\n",
    "                df=data_cleanup(df)\n",
    "                print(pair+\" is processed\")\n",
    "            except:\n",
    "                print(f\"error while processing {pair} {count}/{len(pair_list)}\")\n",
    "            xdf=pd.concat([xdf,df],axis=0)\n",
    "            del(df)\n",
    "            gc.collect()\n",
    "        else:\n",
    "            print(\"ignore BTC\")\n",
    "            \n",
    "    return xdf\n",
    "\n",
    "def volume_cleaner(df):\n",
    "    VolRemover=[\"volume\",\"volume-1\",\"BTC_volume\",\"BTC_volume-1\"]\n",
    "    for key in df.keys():\n",
    "        if key.find(\"volume-1_\") != -1 :\n",
    "            VolRemover.append(key)\n",
    "    df=df.drop(columns=VolRemover)\n",
    "    return df\n",
    "    \n",
    "Normalization=None\n",
    "def normalize(dataset,file=Normalization_File):\n",
    "    global Normalization\n",
    "    try:\n",
    "        N=Normalization\n",
    "    except:\n",
    "        Normalization=None\n",
    "    if(Normalization==None):\n",
    "        #print('Loading normalization from file')\n",
    "        with open(file) as json_file:\n",
    "            Normalization = json.load(json_file)\n",
    "    else:\n",
    "        #print('normalization is loaded')\n",
    "        pass\n",
    "\n",
    "    mean=np.array(Normalization[\"mean\"])\n",
    "    std=np.array(Normalization[\"std\"])\n",
    "    dataset -= mean \n",
    "    dataset /= std\n",
    "    return(dataset)\n",
    "\n",
    "\n",
    "\n",
    "# Costumaize buy condition here\n",
    "def buy_up(df,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=3):\n",
    "    try:\n",
    "        \n",
    "        print (f\"---buy_simple_up--- Buy pct: {BUY_PCT}%\")\n",
    "        print (f\"---buy_only--- Max time window: {window}%\")\n",
    "        mino=BUY_PCT*0.01\n",
    "        maxo=-SELL_PCT*0.01\n",
    "        codep1='df[\"buy\"]=((('\n",
    "        for i in range(1,window):\n",
    "            codep1=codep1+'df[\"high\"].shift(periods='+str(-i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino )| (('\n",
    "        codep2='df[\"high\"].shift(periods='+str(-window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino)).replace({False: 0, True: 1})'\n",
    "        code=codep1+codep2\n",
    "        prerr(code)\n",
    "        exec(code)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error buy only\")\n",
    "        print(e)\n",
    "    try:df.pop(\"b\")\n",
    "    except:print(\"---buy_only--- no b\")\n",
    "    try:df.pop(\"sell\")\n",
    "    except:print(\"---buy_only--- no sell\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Costumaize buy condition here\n",
    "def buy_min_up(df,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=3):\n",
    "    try:\n",
    "        \n",
    "        print (f\"---buy_min_up--- Buy pct: {BUY_PCT}%\")\n",
    "        mino=BUY_PCT*0.01\n",
    "        maxo=-SELL_PCT*0.01\n",
    "        codep1='df[\"buy\"]=((('\n",
    "        for i in range(1,window):\n",
    "            codep1=codep1+'df[\"high\"].shift(periods='+str(-i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino )| (('\n",
    "        codep2='df[\"high\"].shift(periods='+str(-window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino)).replace({False: 0, True: 1})'\n",
    "        code=codep1+codep2\n",
    "        prerr(code)\n",
    "        exec(code)\n",
    "\n",
    "        df['ismin'] = np.where(\n",
    "        df['high'] <= df.shift(-window-1).rolling(2*window)['high'].min(), 1,\n",
    "       0\n",
    "        )\n",
    "        df[\"buy\"]=((df['buy']==1 ) & (df['ismin']==1)).replace({False: 0, True: 1})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error buy only\")\n",
    "        print(e)\n",
    "    try:df.pop(\"b\")\n",
    "    except:print(\"---buy_only--- no b\")\n",
    "    try:df.pop(\"ismin\")\n",
    "    except:print(\"---buy_only--- no sell\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def buy_the_dip(df,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=3):\n",
    "    try:\n",
    "        \n",
    "        print (f\"---buy_min_up--- Buy pct: {BUY_PCT}%\")\n",
    "        mino=BUY_PCT*0.01\n",
    "        maxo=-SELL_PCT*0.01\n",
    "        codep1='df[\"buy\"]=((('\n",
    "        for i in range(1,window):\n",
    "            codep1=codep1+'df[\"high\"].shift(periods='+str(-i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino )| (('\n",
    "        codep2='df[\"high\"].shift(periods='+str(-window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino)).replace({False: 0, True: 1})'\n",
    "        code=codep1+codep2\n",
    "        prerr(code)\n",
    "        exec(code)\n",
    "\n",
    "        df['ismin'] = np.where(\n",
    "        df['high'] <= df.shift(-window-1).rolling(2*window)['high'].min(), 1,\n",
    "       0\n",
    "        )\n",
    "        df[\"buy\"]=((df['buy']==1 ) & (df['ismin']==1)).replace({False: 0, True: 1})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error buy only\")\n",
    "        print(e)\n",
    "    try:df.pop(\"b\")\n",
    "    except:print(\"---buy_only--- no b\")\n",
    "    try:df.pop(\"ismin\")\n",
    "    except:print(\"---buy_only--- no sell\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def mini_expand3(pair=\"GMT/USDT\",i=0,j=10000,window=2,metadata=MetaData,high_weight=1,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT):\n",
    "    Pair_Full=full_expand(df_list1m[pair].iloc[i:j],df_list5m[pair],df_list15m[pair],df_list1h[pair],df_list1d[pair],window)\n",
    "    BTC_Full=full_expand(\n",
    "        df_list1m[\"BTC/USDT\"].loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" d\")).round(freq='1 min'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        df_list5m[\"BTC/USDT\"],#.loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" d\")).round(freq='5 min'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        df_list15m[\"BTC/USDT\"],#.loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" day\")).round(freq='15 min'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        df_list1h[\"BTC/USDT\"],#.loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" day\")).round(freq='1 H'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        df_list1d[\"BTC/USDT\"],#.loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" day\")).round(freq='1 d'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        window)   \n",
    "    BTC_Full=BTC_Full.add_prefix(\"BTC_\")\n",
    "    # Merged=pd.merge(Pair_Full, BTC_Full, left_index=True, how='left',\n",
    "    #         right_index=True, suffixes=('', ''))\n",
    "    Merged=pd.merge(Pair_Full, BTC_Full, left_index=True, how='inner',\n",
    "            right_index=True, suffixes=('', ''))\n",
    "    day_expand(Merged)\n",
    "    Meta_expand(Merged,metadata,pair)\n",
    "    #buy_sell(Merged,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=MAX_FORCAST_SIZE)\n",
    "    buy_function(Merged,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=MAX_FORCAST_SIZE)\n",
    "    Merged[\"high\"]=(Merged[\"open\"]+high_weight*Merged[\"high\"]+Merged[\"low\"]+Merged[\"close\"])/(3+high_weight)\n",
    "    Merged.rename(columns={\"high\":\"price\"},inplace = True)\n",
    "    Merged[\"BTC_high\"]=(Merged[\"BTC_open\"]+high_weight*Merged[\"BTC_high\"]+Merged[\"BTC_low\"]+Merged[\"BTC_close\"])/(3+high_weight)\n",
    "    Merged.rename(columns={\"BTC_high\":\"BTC_price\"},inplace = True)\n",
    "    Merged=Merged.drop(columns=[\"BTC_open\",\"BTC_low\",\"BTC_close\",\"open\",\"low\",\"close\"])\n",
    "    # Merged=justlast_remover(Merged)\n",
    "    for key in Merged.keys():\n",
    "        if key.find(\"BTC\")!=-1 and (key.find(\"open\")!=-1 or\n",
    "        key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "            Merged[key]=(Merged[\"BTC_price\"]-Merged[key])/Merged[\"BTC_price\"]\n",
    "        if key.find(\"BTC\")==-1 and (key.find(\"open\")!=-1 or\n",
    "        key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "            Merged[key]=(Merged[\"price\"]-Merged[key])/Merged[\"price\"]\n",
    "    Merged=Merged.dropna()\n",
    "    return Merged\n",
    "\n",
    "def mini_expand4_btc(i=0,j=10000,window=2,metadata=MetaData,high_weight=1,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT):\n",
    "    pair=\"BTC/USDT\"\n",
    "    Pair_Full=full_expand(df_list1m[pair].iloc[i:j],df_list5m[pair],df_list15m[pair],df_list1h[pair],df_list1d[pair],window)\n",
    "    \n",
    "    # Merged=pd.merge(Pair_Full, BTC_Full, left_index=True, how='left',\n",
    "    #         right_index=True, suffixes=('', ''))\n",
    "    Merged=Pair_Full\n",
    "    day_expand(Merged)\n",
    "    Meta_expand(Merged,metadata,pair)\n",
    "    #buy_sell(Merged,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=MAX_FORCAST_SIZE)\n",
    "    buy_function(Merged,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=MAX_FORCAST_SIZE)\n",
    "    Merged[\"high\"]=(Merged[\"open\"]+high_weight*Merged[\"high\"]+Merged[\"low\"]+Merged[\"close\"])/(3+high_weight)\n",
    "    Merged.rename(columns={\"high\":\"price\"},inplace = True)\n",
    "\n",
    "    Merged=Merged.drop(columns=[\"open\",\"low\",\"close\"])\n",
    "    # Merged=justlast_remover(Merged)\n",
    "    for key in Merged.keys():\n",
    "        if  (key.find(\"open\")!=-1 or\n",
    "        key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "            Merged[key]=(Merged[\"price\"]-Merged[key])/Merged[\"price\"]\n",
    "    Merged=Merged.dropna()\n",
    "    return Merged\n",
    "\n",
    "def data_chooser50(df,row_numbers=100000):\n",
    "    \n",
    "    df=data_shufler(df)\n",
    "    if row_numbers>=len(df):\n",
    "        row_numbers=len(df)\n",
    "    halfrows=int(row_numbers/2)\n",
    "    dfbuy=df[df[\"buy\"]==1].iloc[:halfrows]\n",
    "    while(dfbuy.shape[0]<halfrows):\n",
    "        dfbuy=pd.concat([dfbuy,dfbuy]).iloc[:halfrows]\n",
    "    dfnob=df[df[\"buy\"]==0].iloc[:halfrows]\n",
    "    df=pd.concat([dfbuy,\n",
    "                 dfnob])\n",
    "    df=data_shufler(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## buy or sell mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Costumaize buy condition here\n",
    "def buy_only(df,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=3):\n",
    "    try:\n",
    "        \n",
    "        ## test param\n",
    "        #BUY_PCT=1\n",
    "        window=15\n",
    "        print (f\"---buy_only--- Buy pct: {BUY_PCT}%\")\n",
    "        mino=BUY_PCT*0.01\n",
    "        maxo=-SELL_PCT*0.01\n",
    "        codep1='df[\"b\"]=((('\n",
    "        for i in range(1,window):\n",
    "            codep1=codep1+'df[\"high\"].shift(periods='+str(-i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino )| (('\n",
    "        codep2='df[\"high\"].shift(periods='+str(-window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino)).replace({False: 0, True: 1})'\n",
    "        code=codep1+codep2\n",
    "        prerr(code)\n",
    "        exec(code)\n",
    "\n",
    "\n",
    "##################### debug ###############33\n",
    "        strcomment='''\n",
    "        codep1='df[\"b5\"]=((('\n",
    "        for i in range(1,5):\n",
    "            codep1=codep1+'df[\"high\"].shift(periods='+str(-i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino )| (('\n",
    "        codep2='df[\"high\"].shift(periods='+str(-window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino)).replace({False: 0, True: 1})'\n",
    "        code=codep1+codep2\n",
    "        prerr(code)\n",
    "        exec(code)\n",
    "\n",
    "\n",
    "\n",
    "        codep1='df[\"b10\"]=((('\n",
    "        for i in range(1,10):\n",
    "            codep1=codep1+'df[\"high\"].shift(periods='+str(-i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino )| (('\n",
    "        codep2='df[\"high\"].shift(periods='+str(-window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino)).replace({False: 0, True: 1})'\n",
    "        code=codep1+codep2\n",
    "        prerr(code)\n",
    "        exec(code)\n",
    "\n",
    "        codep1='df[\"b15\"]=((('\n",
    "        for i in range(1,15):\n",
    "            codep1=codep1+'df[\"high\"].shift(periods='+str(-i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino )| (('\n",
    "        codep2='df[\"high\"].shift(periods='+str(-window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino)).replace({False: 0, True: 1})'\n",
    "        code=codep1+codep2\n",
    "        prerr(code)\n",
    "        exec(code)\n",
    "\n",
    "\n",
    "        mino=BUY_PCT*0.01\n",
    "        maxo=-SELL_PCT*0.01\n",
    "        codep1='df[\"b30\"]=((('\n",
    "        for i in range(1,30):\n",
    "            codep1=codep1+'df[\"high\"].shift(periods='+str(-i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino )| (('\n",
    "        codep2='df[\"high\"].shift(periods='+str(-window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino)).replace({False: 0, True: 1})'\n",
    "        code=codep1+codep2\n",
    "        prerr(code)\n",
    "        exec(code)\n",
    "\n",
    "\n",
    "        mino=BUY_PCT*0.01\n",
    "        maxo=-SELL_PCT*0.01\n",
    "        codep1='df[\"b60\"]=((('\n",
    "        for i in range(1,60):\n",
    "            codep1=codep1+'df[\"high\"].shift(periods='+str(-i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino )| (('\n",
    "        codep2='df[\"high\"].shift(periods='+str(-window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino)).replace({False: 0, True: 1})'\n",
    "        code=codep1+codep2\n",
    "        prerr(code)\n",
    "        exec(code)\n",
    "\n",
    "        mino=BUY_PCT*0.01\n",
    "        maxo=-SELL_PCT*0.01\n",
    "        codep1='df[\"b180\"]=((('\n",
    "        for i in range(1,180):\n",
    "            codep1=codep1+'df[\"high\"].shift(periods='+str(-i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino )| (('\n",
    "        codep2='df[\"high\"].shift(periods='+str(-window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino)).replace({False: 0, True: 1})'\n",
    "        code=codep1+codep2\n",
    "        prerr(code)\n",
    "        exec(code)\n",
    "    \n",
    "        '''#####\n",
    "\n",
    "        # codep1='df[\"b5p\"]=((('\n",
    "        # for i in range(1,window+5):\n",
    "        #     codep1=codep1+'df[\"high\"].shift(periods='+str(-i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=0.005 )| (('\n",
    "        # codep2='df[\"high\"].shift(periods='+str(-window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=0.005)).replace({False: 0, True: 1})'\n",
    "        # code=codep1+codep2\n",
    "        # prerr(code)\n",
    "        # exec(code)\n",
    "\n",
    "        # codep1='df[\"b9p\"]=((('\n",
    "        # for i in range(1,window+9):\n",
    "        #     codep1=codep1+'df[\"high\"].shift(periods='+str(-i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=0.009 )| (('\n",
    "        # codep2='df[\"high\"].shift(periods='+str(-window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=0.009)).replace({False: 0, True: 1})'\n",
    "        # code=codep1+codep2\n",
    "        # prerr(code)\n",
    "        # exec(code)\n",
    "\n",
    "        # codep1='df[\"b15p\"]=((('\n",
    "        # for i in range(1,window+15):\n",
    "        #     codep1=codep1+'df[\"high\"].shift(periods='+str(-i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=0.015 )| (('\n",
    "        # codep2='df[\"high\"].shift(periods='+str(-window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=0.015)).replace({False: 0, True: 1})'\n",
    "        # code=codep1+codep2\n",
    "        # prerr(code)\n",
    "        # exec(code)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # codep1='df[\"sell\"]=((( '\n",
    "        # for i in range(1,window):\n",
    "        #     codep1=codep1+'df[\"low\"].shift(periods='+str(-i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] <=maxo )& (('\n",
    "        # codep2='df[\"low\"].shift(periods='+str(-window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] <=maxo )).replace({False: 0, True: 1})'\n",
    "        # code=codep1+codep2\n",
    "        # prerr(code)\n",
    "        # exec(code)\n",
    "\n",
    "        # df[\"buy\"]=((df['b']==1 ) & (df['sell']==0)).replace({False: 0, True: 1})\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #df.pop(\"b\")\n",
    "        #df.pop(\"sell\")\n",
    "        \n",
    "        \n",
    "        # df[\"f1\"]=(df[\"high\"].shift(periods=-1, freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"]\n",
    "        # df[\"f2\"]=(df[\"high\"].shift(periods=-2, freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"]\n",
    "        # df[\"f15_p\"]=df[\"high-1_15min\"].shift(periods=-2, freq=None, axis=0, fill_value=None)\n",
    "        # df[\"fh_p\"]=df[\"high-1_hour\"].shift(periods=-2, freq=None, axis=0, fill_value=None)\n",
    "\n",
    "        # df['signal'] = np.where(\n",
    "        # df['high'] >= df.shift(1).rolling(window)['high'].min(), 1,\n",
    "        # np.where(\n",
    "        #     df['low'] >= df.shift(1).rolling(window)['low'].min(), -1,\n",
    "        #     0\n",
    "        # )\n",
    "        # )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #     df['ismin'] = np.where(\n",
    "    #     df['high'] <= df.shift(-window-1).rolling(2*window)['high'].min(), 1,\n",
    "    #    0\n",
    "    #     )\n",
    "    #     df[\"buy\"]=((df['buy']==1 ) & (df['ismin']==1)).replace({False: 0, True: 1})\n",
    "    #     df.pop(\"b\")\n",
    "    #     df.pop(\"ismin\")\n",
    "\n",
    "        \n",
    "\n",
    "    #     df['ismax'] = np.where(\n",
    "    #     df['low'] >= df.shift(1).rolling(window)['low'].min(), 1,\n",
    "    #    0\n",
    "    #     )\n",
    "        \n",
    "        \n",
    "        codep1='df[\"sell\"]=((( '\n",
    "        for i in range(1,window):\n",
    "            codep1=codep1+'df[\"low\"].shift(periods='+str(-i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] <=maxo ) | (('\n",
    "        codep2='df[\"low\"].shift(periods='+str(-window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] <=maxo )).replace({False: 0, True: 1})'\n",
    "        code=codep1+codep2\n",
    "        prerr(code)\n",
    "        exec(code)\n",
    "\n",
    "        df[\"buy\"]=((df['b']==1 ) & (df['sell']==0)).replace({False: 0, True: 1})\n",
    "        \n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error buy only\")\n",
    "        print(e)\n",
    "    p=df.pop(\"b\")\n",
    "    p=df.pop(\"sell\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_only=buy_min_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE=10\n",
    "BUY_PCT=1.2\n",
    "SELL_PCT=0.2\n",
    "MAX_FORCAST_SIZE=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dddd=pd.DataFrame()\n",
    "for pair in [\"GMT/USDT\",\"XRP/USDT\",\"RVN/USDT\",\"ETC/USDT\",\"LUNA/USDT\",\"APE/USDT\",\"ETH/USDT\",\"DOGE/USDT\"]:\n",
    "    print( f'===  {pair}  === ')\n",
    "    dtest=mini_expand3(pair=pair,i=0,j=len(df_list1m[pair]),window=1,metadata=MetaData)\n",
    "    #print(f\"  - {BUY_PCT}% / {MAX_FORCAST_SIZE}min ==b 0.27%=> \" +str({dtest[\"buy\"].mean()*100}))\n",
    "\n",
    "    print(f\"  - {MAX_FORCAST_SIZE}min ==buy {BUY_PCT}%=> \" +str( format(float(dtest[\"buy\"].mean()*100) ,\".2f\")))\n",
    "    #print(f\"  - {MAX_FORCAST_SIZE}min ==sell {SELL_PCT}%=> \" +str( format(float(dtest[\"sell\"].mean()*100) ,\".2f\")))\n",
    "\n",
    "\n",
    "    dddd=pd.concat([dtest,dddd],axis=0)\n",
    "\n",
    "\n",
    "print( f'=== ALL === ')\n",
    "  \n",
    "#print(f\"  - {MAX_FORCAST_SIZE}min ==b {SELL_PCT}%=> \" +str(format(float(dddd[\"sell\"].mean()*100), \".2f\")))\n",
    "print(f\"  - final buy dessision {MAX_FORCAST_SIZE}min  -  {BUY_PCT}% => \" + str( format(float(dddd[\"buy\"].mean()*100), \".2f\")))\n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "    # print(f\"  - 0.9% / 11min => \" +str( {dtest[\"b9p\"].mean()*100}))\n",
    "    # print(f\"  - 0.5% / 7min => \" +str( {dtest[\"b5p\"].mean()*100}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dddd.buy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair='ETH/USDT'\n",
    "pt=mini_expand3(pair,i=0,j=int(len(df_list1m[pair])/2),window=10,metadata=MetaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.delete(dt, dt[:,1], axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buyy=pt.pop(\"buy\")\n",
    "bb=pt.pop(\"b\")\n",
    "bprice=pt.pop(\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=pt.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=(dt[:,-1]-1)*(-1)\n",
    "dt[:,-1]=Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model \n",
    "model2=load_model(\"../dontbuy_model_w10_noprice_p1.2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predo=(model2.predict( tf.convert_to_tensor(np.nan_to_num(dt[:, 0:-1],copy=False,nan=0) ,dtype=tf.float32))).round().transpose()[0]\n",
    "False_prediction=dt[:,-1][(predo!=Y[:])]\n",
    "True_prediction=dt[:,-1][(predo==Y[:])]\n",
    "fp0=False_prediction[False_prediction==0].shape[0]*100/dt.shape[0] #### it mean that 11.73 of the 0 class are wrong the buyed witch lead the losses\n",
    "print( f\"Prediction mean :{predo.mean()*100} %\"+'#### the colose to 50 the better')\n",
    "print( f\"False prediction class 0 :{fp0} %\"+'#### it mean that x of the 0 class are wrong the buyed witch lead the losses')\n",
    "fp1=False_prediction[False_prediction==1].shape[0]*100/dt.shape[0]   #### we don't buy x % of the correct chanses\n",
    "print( f\"False prediction class 1 :{fp1} %\"+'#### we don\\'t buy x % of the correct chanses')\n",
    "trp0=True_prediction[True_prediction==0].shape[0]*100/dt.shape[0]   #### it mean that 40 % of class 0 are predicted correctly\n",
    "trp1=True_prediction[True_prediction==1].shape[0]*100/dt.shape[0]     #### the only buying correct of all\n",
    "print( f\"True prediction class 0 :{trp0} %\"+'#### it mean that 40 % of class 0 are predicted correctly')\n",
    "print( f\"True prediction class 1 :{trp1} %\"+'#### the only buying correct of all')\n",
    "print(f\"successful buy pct of unsuccessfull: {100*trp1/(trp1+fp1)}  %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.sell=(pt.sell-1)*(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price=pt.pop(\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=pt.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model2=load_model(\"../dontbuy_model_w10_noprice_p1.2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## garbage test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "etc=mini_expand3(pair=\"BTC/USDT\",i=0,j=500000,window=8,metadata=MetaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "etc.buy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc_np=etc.iloc[:,0:-10].reset_index().reset_index().drop(columns=\"date\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan_to_num(etc_np)\n",
    "\n",
    "etc_np=tf.convert_to_tensor(etc_np, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.load_model(Model_FileName)\n",
    "etc[\"prediction\"]=model.predict(etc_np).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc[(etc.b60==0)&(etc.prediction==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(etc.iloc[:2,0:-11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Data genration Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if  False:\n",
    "    ww=WINDOW_SIZE\n",
    "    gc.collect()\n",
    "    df=data_looper_fast(pair_list=Binance_USDT_HALAL,window=WINDOW_SIZE,buy_weight=50,sample_size=SAMPLE_SIZE,min_days=0,buffer_size=BUFFER_SIZE)\n",
    "    # Test Data:\n",
    "    # df=data_looper_fast(pair_list=Binance_USDT_HALAL[50:80],window=WINDOW_SIZE,buy_weight=10,sample_size=SAMPLE_SIZE*3,min_days=0,buffer_size=BUFFER_SIZE)\n",
    "    gc.collect()\n",
    "    #df=volume_cleaner(df)\n",
    "    #df=data_shufler(df)\n",
    "    #df=df.reindex(np.random.permutation(df.index))\n",
    "    #df=df.reindex(np.random.permutation(df.index))\n",
    "    time.sleep(3)\n",
    "    gc.collect()\n",
    "    print('################### reindexing and shufling ###############')\n",
    "    df=df.reset_index().drop(columns=\"num_index\")\n",
    "    gc.collect()\n",
    "    for i in range(1):\n",
    "        df = df.reindex(np.random.permutation(df.index)).reset_index().drop(columns=\"index\")\n",
    "        gc.collect()\n",
    "    print('################### Cleaning Null values ###############')\n",
    "    df=df.dropna()\n",
    "    print(df)\n",
    "# else:\n",
    "#     if TESTING_MOD:\n",
    "#         df_testing=data_looper_fast(pair_list=Binance_USDT_HALAL[70:90],window=WINDOW_SIZE,buy_weight=10,sample_size=SAMPLE_SIZE,min_days=0,buffer_size=BUFFER_SIZE)\n",
    "#         df_testing=df_testing[~df_testing.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_only=buy_min_up\n",
    "buy_function=buy_min_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on: FIDA/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "FIDA/USDT is processed -- 1/20\n",
      "working on: LAZIO/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "LAZIO/USDT is processed -- 2/20\n",
      "working on: SRM/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "SRM/USDT is processed -- 3/20\n",
      "working on: GMT/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "GMT/USDT is processed -- 4/20\n",
      "working on: SOL/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "SOL/USDT is processed -- 5/20\n",
      "working on: ALGO/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "ALGO/USDT is processed -- 6/20\n",
      "working on: DOGE/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "DOGE/USDT is processed -- 7/20\n",
      "working on: GALA/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "GALA/USDT is processed -- 8/20\n",
      "working on: ETH/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "ETH/USDT is processed -- 9/20\n",
      "working on: APE/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "APE/USDT is processed -- 10/20\n",
      "working on: SHIB/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "SHIB/USDT is processed -- 11/20\n",
      "working on: AVAX/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "AVAX/USDT is processed -- 12/20\n",
      "working on: ADA/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "ADA/USDT is processed -- 13/20\n",
      "working on: NEAR/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "NEAR/USDT is processed -- 14/20\n",
      "working on: DOT/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "DOT/USDT is processed -- 15/20\n",
      "working on: LTC/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "LTC/USDT is processed -- 16/20\n",
      "working on: XMR/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "XMR/USDT is processed -- 17/20\n",
      "working on: XRP/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "XRP/USDT is processed -- 18/20\n",
      "working on: ETC/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "ETC/USDT is processed -- 19/20\n",
      "working on: TRX/USDT -->---buy_min_up--- Buy pct: 0.7%\n",
      "---buy_only--- no b\n",
      "TRX/USDT is processed -- 20/20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pair_list=Binance_USDT_HALAL[:]\n",
    "pair_list=Today_list\n",
    "window=WINDOW_SIZE\n",
    "buy_weight=50\n",
    "sample_size=200000\n",
    "min_days=1\n",
    "buffer_size=BUFFER_SIZE\n",
    "xdf=pd.DataFrame()\n",
    "count=0\n",
    "for pair in pair_list:\n",
    "    if pair != \"BTC/USDT\":\n",
    "        print(\"working on: \"+pair ,end=\" -->\")\n",
    "        try:\n",
    "            df=mini_expand3(pair=pair,i=0,j=len(df_list1m[pair]),window=window,metadata=MetaData)\n",
    "            gc.collect()\n",
    "            count+=1\n",
    "            df=df.reset_index()\n",
    "            try:df.pop(\"num_index\")\n",
    "            except: pass\n",
    "            try:df.pop(\"index\")\n",
    "            except: pass\n",
    "            try:df.pop(\"date\")\n",
    "            except: pass\n",
    "            df=data_shufler(df)            \n",
    "            #df=data_chooser(df,weight=buy_weight,row_numbers=sample_size)\n",
    "            df=data_chooser50(df,row_numbers=sample_size)\n",
    "            gc.collect()\n",
    "            df=data_cleanup(df)\n",
    "            print(pair+f\" is processed -- {count}/{len(pair_list)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"error while processing {pair} {count}/{len(pair_list)}\")\n",
    "            print(e)\n",
    "        xdf=pd.concat([xdf,df],axis=0)\n",
    "        del(df)\n",
    "        gc.collect()\n",
    "df=xdf\n",
    "del xdf\n",
    "for i in range(1):\n",
    "    try:df=df.reset_index() \n",
    "    except: pass\n",
    "    try:df.pop(\"num_index\")\n",
    "    except: pass\n",
    "    try:df.pop(\"index\")\n",
    "    except: pass\n",
    "    df=df.reset_index()    \n",
    "    gc.collect()\n",
    "    df = df.reindex(np.random.permutation(df.index))\n",
    "    try:df.pop(\"index\")\n",
    "    except: pass\n",
    "    gc.collect()\n",
    "    df=df.reset_index()\n",
    "try:df.pop(\"index\")\n",
    "except: pass\n",
    "    \n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather(f\"../Data/fea/w{WINDOW_SIZE}_buy{BUY_PCT}_top20.fea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>high-1</th>\n",
       "      <th>low-1</th>\n",
       "      <th>close-1</th>\n",
       "      <th>volume-1</th>\n",
       "      <th>high-2</th>\n",
       "      <th>low-2</th>\n",
       "      <th>close-2</th>\n",
       "      <th>volume-2</th>\n",
       "      <th>high-3</th>\n",
       "      <th>...</th>\n",
       "      <th>BTC_volume-13_5min</th>\n",
       "      <th>BTC_high-14_5min</th>\n",
       "      <th>BTC_low-14_5min</th>\n",
       "      <th>BTC_close-14_5min</th>\n",
       "      <th>BTC_volume-14_5min</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>lunch_day</th>\n",
       "      <th>buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.638100</td>\n",
       "      <td>-0.001258</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>-0.000410</td>\n",
       "      <td>8909.82</td>\n",
       "      <td>-0.001760</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>5797.300</td>\n",
       "      <td>-0.002619</td>\n",
       "      <td>...</td>\n",
       "      <td>369.654907</td>\n",
       "      <td>-0.021497</td>\n",
       "      <td>-0.017269</td>\n",
       "      <td>-0.018561</td>\n",
       "      <td>225.932195</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>45</td>\n",
       "      <td>-230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233.800000</td>\n",
       "      <td>-0.003849</td>\n",
       "      <td>-0.000855</td>\n",
       "      <td>-0.000855</td>\n",
       "      <td>114.04</td>\n",
       "      <td>-0.005133</td>\n",
       "      <td>-0.002994</td>\n",
       "      <td>-0.004277</td>\n",
       "      <td>64.265</td>\n",
       "      <td>-0.005560</td>\n",
       "      <td>...</td>\n",
       "      <td>244.020580</td>\n",
       "      <td>-0.012957</td>\n",
       "      <td>-0.008183</td>\n",
       "      <td>-0.009748</td>\n",
       "      <td>558.243530</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>59</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.263375</td>\n",
       "      <td>-0.001128</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>87059.30</td>\n",
       "      <td>-0.001286</td>\n",
       "      <td>-0.000495</td>\n",
       "      <td>-0.001207</td>\n",
       "      <td>109894.580</td>\n",
       "      <td>-0.001761</td>\n",
       "      <td>...</td>\n",
       "      <td>77.915299</td>\n",
       "      <td>-0.003592</td>\n",
       "      <td>-0.002367</td>\n",
       "      <td>-0.002964</td>\n",
       "      <td>74.226148</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>607</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.278900</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>105.76</td>\n",
       "      <td>-0.000301</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>1185.970</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>...</td>\n",
       "      <td>291.346011</td>\n",
       "      <td>-0.006224</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.001244</td>\n",
       "      <td>371.678945</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>-265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.780825</td>\n",
       "      <td>-0.003170</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>-0.001377</td>\n",
       "      <td>1275787.00</td>\n",
       "      <td>-0.004066</td>\n",
       "      <td>-0.001249</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>678601.000</td>\n",
       "      <td>-0.008293</td>\n",
       "      <td>...</td>\n",
       "      <td>338.421930</td>\n",
       "      <td>-0.012598</td>\n",
       "      <td>-0.005345</td>\n",
       "      <td>-0.009181</td>\n",
       "      <td>686.120470</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>49</td>\n",
       "      <td>607</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999995</th>\n",
       "      <td>2.301000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.80</td>\n",
       "      <td>-0.001304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>536.200</td>\n",
       "      <td>-0.001738</td>\n",
       "      <td>...</td>\n",
       "      <td>77.646980</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>41.462980</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>-638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999996</th>\n",
       "      <td>28.405000</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>298.49</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>91.220</td>\n",
       "      <td>-0.000528</td>\n",
       "      <td>...</td>\n",
       "      <td>1323.643860</td>\n",
       "      <td>-0.006168</td>\n",
       "      <td>-0.001640</td>\n",
       "      <td>-0.005767</td>\n",
       "      <td>1309.775770</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>568</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999997</th>\n",
       "      <td>0.212448</td>\n",
       "      <td>-0.006413</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>3018143.10</td>\n",
       "      <td>-0.006131</td>\n",
       "      <td>-0.002930</td>\n",
       "      <td>-0.003307</td>\n",
       "      <td>1683141.300</td>\n",
       "      <td>-0.005754</td>\n",
       "      <td>...</td>\n",
       "      <td>737.769290</td>\n",
       "      <td>-0.008741</td>\n",
       "      <td>-0.004976</td>\n",
       "      <td>-0.006435</td>\n",
       "      <td>278.594914</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999998</th>\n",
       "      <td>1.820000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>213.50</td>\n",
       "      <td>-0.001099</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>2398.100</td>\n",
       "      <td>-0.001648</td>\n",
       "      <td>...</td>\n",
       "      <td>431.858480</td>\n",
       "      <td>-0.015975</td>\n",
       "      <td>-0.014766</td>\n",
       "      <td>-0.015774</td>\n",
       "      <td>86.781380</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>57</td>\n",
       "      <td>-223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999999</th>\n",
       "      <td>0.396409</td>\n",
       "      <td>-0.000639</td>\n",
       "      <td>0.003265</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>5230108.00</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>0.003439</td>\n",
       "      <td>0.002323</td>\n",
       "      <td>7030003.000</td>\n",
       "      <td>-0.006535</td>\n",
       "      <td>...</td>\n",
       "      <td>278.472315</td>\n",
       "      <td>0.003106</td>\n",
       "      <td>0.005254</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>263.826298</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>58</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000000 rows × 567 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              price    high-1     low-1   close-1    volume-1    high-2  \\\n",
       "0         33.638100 -0.001258  0.001724 -0.000410     8909.82 -0.001760   \n",
       "1        233.800000 -0.003849 -0.000855 -0.000855      114.04 -0.005133   \n",
       "2          1.263375 -0.001128  0.000455  0.000455    87059.30 -0.001286   \n",
       "3         13.278900  0.001092  0.001130  0.001130      105.76 -0.000301   \n",
       "4          0.780825 -0.003170  0.000160 -0.001377  1275787.00 -0.004066   \n",
       "...             ...       ...       ...       ...         ...       ...   \n",
       "3999995    2.301000  0.000000  0.000000  0.000000       19.80 -0.001304   \n",
       "3999996   28.405000 -0.000176  0.000528  0.000176      298.49 -0.000176   \n",
       "3999997    0.212448 -0.006413  0.002483  0.001871  3018143.10 -0.006131   \n",
       "3999998    1.820000  0.000000  0.000000  0.000000      213.50 -0.001099   \n",
       "3999999    0.396409 -0.000639  0.003265  0.001544  5230108.00 -0.002529   \n",
       "\n",
       "            low-2   close-2     volume-2    high-3  ...  BTC_volume-13_5min  \\\n",
       "0        0.001338  0.001338     5797.300 -0.002619  ...          369.654907   \n",
       "1       -0.002994 -0.004277       64.265 -0.005560  ...          244.020580   \n",
       "2       -0.000495 -0.001207   109894.580 -0.001761  ...           77.915299   \n",
       "3        0.001604  0.000806     1185.970  0.001416  ...          291.346011   \n",
       "4       -0.001249 -0.002529   678601.000 -0.008293  ...          338.421930   \n",
       "...           ...       ...          ...       ...  ...                 ...   \n",
       "3999995  0.000000  0.000000      536.200 -0.001738  ...           77.646980   \n",
       "3999996 -0.000176 -0.000176       91.220 -0.000528  ...         1323.643860   \n",
       "3999997 -0.002930 -0.003307  1683141.300 -0.005754  ...          737.769290   \n",
       "3999998  0.000549  0.000549     2398.100 -0.001648  ...          431.858480   \n",
       "3999999  0.003439  0.002323  7030003.000 -0.006535  ...          278.472315   \n",
       "\n",
       "         BTC_high-14_5min  BTC_low-14_5min  BTC_close-14_5min  \\\n",
       "0               -0.021497        -0.017269          -0.018561   \n",
       "1               -0.012957        -0.008183          -0.009748   \n",
       "2               -0.003592        -0.002367          -0.002964   \n",
       "3               -0.006224         0.000029          -0.001244   \n",
       "4               -0.012598        -0.005345          -0.009181   \n",
       "...                   ...              ...                ...   \n",
       "3999995         -0.000158         0.001438           0.001058   \n",
       "3999996         -0.006168        -0.001640          -0.005767   \n",
       "3999997         -0.008741        -0.004976          -0.006435   \n",
       "3999998         -0.015975        -0.014766          -0.015774   \n",
       "3999999          0.003106         0.005254           0.004176   \n",
       "\n",
       "         BTC_volume-14_5min  day  hour  minute  lunch_day  buy  \n",
       "0                225.932195    3    19      45       -230    1  \n",
       "1                558.243530    2    14      59        292    1  \n",
       "2                 74.226148    6     3      24        607    1  \n",
       "3                371.678945    2    21      25       -265    0  \n",
       "4                686.120470    6     9      49        607    1  \n",
       "...                     ...  ...   ...     ...        ...  ...  \n",
       "3999995           41.462980    1     6      43       -638    1  \n",
       "3999996         1309.775770    4     5      19        568    0  \n",
       "3999997          278.594914    3     9       5        180    1  \n",
       "3999998           86.781380    7    10      57       -223    0  \n",
       "3999999          263.826298    2    11      58        180    0  \n",
       "\n",
       "[4000000 rows x 567 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:del df\n",
    "except:pass\n",
    "gc.collect()\n",
    "pair_list=Binance_USDT_HALAL[55:]\n",
    "window=WINDOW_SIZE\n",
    "buy_weight=50\n",
    "sample_size=50000\n",
    "min_days=1\n",
    "buffer_size=BUFFER_SIZE\n",
    "xdf=pd.DataFrame()\n",
    "count=0\n",
    "for pair in pair_list:\n",
    "    if pair != \"BTC/USDT\":\n",
    "        print(\"working on: \"+pair ,end=\" -->\")\n",
    "        try:\n",
    "            df=mini_expand3(pair=pair,i=0,j=len(df_list1m[pair]),window=window,metadata=MetaData)\n",
    "            gc.collect()\n",
    "            count+=1\n",
    "            df=df.reset_index()\n",
    "            try:df.pop(\"num_index\")\n",
    "            except: pass\n",
    "            try:df.pop(\"index\")\n",
    "            except: pass\n",
    "            try:df.pop(\"date\")\n",
    "            except: pass\n",
    "            df=data_shufler(df)            \n",
    "            df=data_chooser(df,weight=buy_weight,row_numbers=sample_size)\n",
    "            gc.collect()\n",
    "            df=data_cleanup(df)\n",
    "            print(pair+f\" is processed -- {count}/{len(pair_list)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"error while processing {pair} {count}/{len(pair_list)}\")\n",
    "            print(e)\n",
    "        xdf=pd.concat([xdf,df],axis=0)\n",
    "        del(df)\n",
    "        gc.collect()\n",
    "df=xdf\n",
    "del xdf\n",
    "for i in range(1):\n",
    "    try:df=df.reset_index() \n",
    "    except: pass\n",
    "    try:df.pop(\"num_index\")\n",
    "    except: pass\n",
    "    try:df.pop(\"index\")\n",
    "    except: pass\n",
    "    df=df.reset_index()    \n",
    "    gc.collect()\n",
    "    df = df.reindex(np.random.permutation(df.index))\n",
    "    try:df.pop(\"index\")\n",
    "    except: pass\n",
    "    gc.collect()\n",
    "    df=df.reset_index()\n",
    "try:df.pop(\"index\")\n",
    "except: pass\n",
    "    \n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather(f\"../Data/fea/w{WINDOW_SIZE}_buy{BUY_PCT}_p2.fea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_feather(f\"../Data/fea/w{WINDOW_SIZE}_buy{BUY_PCT}_p1.fea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_feather(f\"../Data/fea/w{WINDOW_SIZE}_buy{BUY_PCT}_p2.fea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather(f\"../Data/fea/w{WINDOW_SIZE}_buy{BUY_PCT}_full.fea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_feather(f\"../Data/fea/w{WINDOW_SIZE}_buy{BUY_PCT}_full.fea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_fea(file=f\"../Data/fea/w{WINDOW_SIZE}_buy{BUY_PCT}_full.fea\",nrows=2000000,srows=0):\n",
    "    return pd.read_feather(file).drop(columns=[\"index\",\"price\"])[srows:nrows+srows].copy()\n",
    "dt=get_from_fea(file=f\"../Data/fea/w{WINDOW_SIZE}_buy{BUY_PCT}_full.fea\",nrows=500000,srows=0).to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"../Data/np/w{WINDOW_SIZE}_buy{BUY_PCT}_full_normalized.npy\",dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=np.load(f\"../Data/np/w{WINDOW_SIZE}_buy{BUY_PCT}_full_normalized.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan_to_num(dt, copy=False, nan=0.0, posinf=None, neginf=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pop(\"index\")\n",
    "prices=df.pop(\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if  not JUST_IMPORT_DATA:\n",
    "    print(\"saveing the file\")\n",
    "    df.to_csv(DATA_FILE+\"buy07.csv\",index=False)\n",
    "    # dffull=df\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[111:121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.buy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if JUST_IMPORT_DATA:\n",
    "    df=pd.read_csv(DATA_FILE,nrows=20000)\n",
    "    # df=dffull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.price==4724.285]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest=mini_expand3(pair=\"ETH/USDT\",i=0,j=len(df_list1m[\"ETH/USDT\"]),window=1,metadata=MetaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest[dtest.price==4724.285]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mread_feather(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../Data/fea/w\u001b[39m\u001b[39m{\u001b[39;00mWINDOW_SIZE\u001b[39m}\u001b[39;00m\u001b[39m_buy\u001b[39m\u001b[39m{\u001b[39;00mBUY_PCT\u001b[39m}\u001b[39;00m\u001b[39m_p1.fea\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m:\u001b[39m1000000\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#get million\n",
    "df=pd.read_feather(f\"../Data/fea/w{WINDOW_SIZE}_buy{BUY_PCT}_p1.fea\").iloc[0:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.buy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=pd.read_csv(DATA_FILE).dropna().drop(columns=\"price\").to_numpy() # no price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgY=dt[:,-1].copy()\n",
    "dt[:,-1]=(dt[:,-1]-1)*(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing impoted DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# starting numpy process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert Pandas DataFrame to numpy object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>high-1</th>\n",
       "      <th>low-1</th>\n",
       "      <th>close-1</th>\n",
       "      <th>volume-1</th>\n",
       "      <th>high-2</th>\n",
       "      <th>low-2</th>\n",
       "      <th>close-2</th>\n",
       "      <th>volume-2</th>\n",
       "      <th>high-3</th>\n",
       "      <th>...</th>\n",
       "      <th>BTC_volume-19_5min</th>\n",
       "      <th>BTC_high-20_5min</th>\n",
       "      <th>BTC_low-20_5min</th>\n",
       "      <th>BTC_close-20_5min</th>\n",
       "      <th>BTC_volume-20_5min</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>lunch_day</th>\n",
       "      <th>buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.856650</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>7.075000e+03</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>6.567000e+03</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>...</td>\n",
       "      <td>75.501360</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.006425</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>160.631160</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>43</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452640</td>\n",
       "      <td>-0.000685</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>5.516207e+05</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>5.749362e+05</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>...</td>\n",
       "      <td>1011.854175</td>\n",
       "      <td>-0.015560</td>\n",
       "      <td>-0.006021</td>\n",
       "      <td>-0.008398</td>\n",
       "      <td>730.219717</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>607</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.001003</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.001003</td>\n",
       "      <td>1.642836e+09</td>\n",
       "      <td>-0.001805</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>6.850947e+09</td>\n",
       "      <td>-0.001805</td>\n",
       "      <td>...</td>\n",
       "      <td>1234.202230</td>\n",
       "      <td>0.035991</td>\n",
       "      <td>0.037419</td>\n",
       "      <td>0.036334</td>\n",
       "      <td>1007.333300</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>-495</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.902500</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0.010736</td>\n",
       "      <td>0.003526</td>\n",
       "      <td>1.876218e+04</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.010422</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>2.632938e+04</td>\n",
       "      <td>0.008855</td>\n",
       "      <td>...</td>\n",
       "      <td>49.747880</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>86.928420</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.625000</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.017792</td>\n",
       "      <td>0.004164</td>\n",
       "      <td>2.191216e+04</td>\n",
       "      <td>0.015773</td>\n",
       "      <td>0.020820</td>\n",
       "      <td>0.018044</td>\n",
       "      <td>1.580669e+04</td>\n",
       "      <td>0.012997</td>\n",
       "      <td>...</td>\n",
       "      <td>880.209830</td>\n",
       "      <td>0.035458</td>\n",
       "      <td>0.040096</td>\n",
       "      <td>0.037497</td>\n",
       "      <td>1071.196420</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999995</th>\n",
       "      <td>17.957500</td>\n",
       "      <td>-0.000696</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>5.508070e+03</td>\n",
       "      <td>-0.001253</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>-0.000696</td>\n",
       "      <td>2.673300e+03</td>\n",
       "      <td>-0.001810</td>\n",
       "      <td>...</td>\n",
       "      <td>96.706150</td>\n",
       "      <td>0.006012</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>0.008204</td>\n",
       "      <td>178.457930</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>59</td>\n",
       "      <td>-230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999996</th>\n",
       "      <td>0.076268</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000295</td>\n",
       "      <td>7.742913e+05</td>\n",
       "      <td>-0.001082</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>-0.000688</td>\n",
       "      <td>6.907103e+05</td>\n",
       "      <td>-0.000951</td>\n",
       "      <td>...</td>\n",
       "      <td>77.699260</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>94.640930</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999997</th>\n",
       "      <td>84.100000</td>\n",
       "      <td>-0.000595</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>1.053710e+03</td>\n",
       "      <td>-0.004162</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>1.376390e+03</td>\n",
       "      <td>-0.004518</td>\n",
       "      <td>...</td>\n",
       "      <td>103.893520</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>-0.003503</td>\n",
       "      <td>-0.003913</td>\n",
       "      <td>73.789250</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>-265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999998</th>\n",
       "      <td>0.941350</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>5.158400e+04</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>1.143630e+05</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>...</td>\n",
       "      <td>184.198520</td>\n",
       "      <td>-0.002911</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>-0.001858</td>\n",
       "      <td>541.940310</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>59</td>\n",
       "      <td>607</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999999</th>\n",
       "      <td>8.359325</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>-0.000499</td>\n",
       "      <td>1.391893e+04</td>\n",
       "      <td>-0.004698</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>-0.003717</td>\n",
       "      <td>2.238999e+04</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>...</td>\n",
       "      <td>106.783550</td>\n",
       "      <td>0.007819</td>\n",
       "      <td>0.009892</td>\n",
       "      <td>0.009669</td>\n",
       "      <td>59.859600</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>-806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000000 rows × 807 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             price    high-1     low-1   close-1      volume-1    high-2  \\\n",
       "0         0.856650 -0.000292  0.000642  0.000642  7.075000e+03 -0.000058   \n",
       "1         0.452640 -0.000685  0.002695 -0.000243  5.516207e+05  0.000972   \n",
       "2         0.000012 -0.001003 -0.000201 -0.001003  1.642836e+09 -0.001805   \n",
       "3        31.902500  0.002586  0.010736  0.003526  1.876218e+04  0.001959   \n",
       "4        39.625000  0.003407  0.017792  0.004164  2.191216e+04  0.015773   \n",
       "...            ...       ...       ...       ...           ...       ...   \n",
       "1999995  17.957500 -0.000696  0.000418  0.000418  5.508070e+03 -0.001253   \n",
       "1999996   0.076268 -0.000819 -0.000033 -0.000295  7.742913e+05 -0.001082   \n",
       "1999997  84.100000 -0.000595  0.001427  0.000238  1.053710e+03 -0.004162   \n",
       "1999998   0.941350  0.000266  0.000584  0.000478  5.158400e+04  0.000372   \n",
       "1999999   8.359325 -0.004005  0.000493 -0.000499  1.391893e+04 -0.004698   \n",
       "\n",
       "            low-2   close-2      volume-2    high-3  ...  BTC_volume-19_5min  \\\n",
       "0        0.001576  0.000058  6.567000e+03  0.001809  ...           75.501360   \n",
       "1        0.002342  0.001657  5.749362e+05  0.000773  ...         1011.854175   \n",
       "2       -0.000201 -0.000201  6.850947e+09 -0.001805  ...         1234.202230   \n",
       "3        0.010422  0.004153  2.632938e+04  0.008855  ...           49.747880   \n",
       "4        0.020820  0.018044  1.580669e+04  0.012997  ...          880.209830   \n",
       "...           ...       ...           ...       ...  ...                 ...   \n",
       "1999995 -0.000139 -0.000696  2.673300e+03 -0.001810  ...           96.706150   \n",
       "1999996 -0.000426 -0.000688  6.907103e+05 -0.000951  ...           77.699260   \n",
       "1999997  0.000476  0.000476  1.376390e+03 -0.004518  ...          103.893520   \n",
       "1999998  0.000797  0.000372  1.143630e+05 -0.000266  ...          184.198520   \n",
       "1999999  0.000793 -0.003717  2.238999e+04 -0.012055  ...          106.783550   \n",
       "\n",
       "         BTC_high-20_5min  BTC_low-20_5min  BTC_close-20_5min  \\\n",
       "0                0.002548         0.006425           0.002889   \n",
       "1               -0.015560        -0.006021          -0.008398   \n",
       "2                0.035991         0.037419           0.036334   \n",
       "3                0.001623         0.002420           0.002100   \n",
       "4                0.035458         0.040096           0.037497   \n",
       "...                   ...              ...                ...   \n",
       "1999995          0.006012         0.009575           0.008204   \n",
       "1999996         -0.000113         0.001077           0.000488   \n",
       "1999997         -0.005110        -0.003503          -0.003913   \n",
       "1999998         -0.002911         0.002923          -0.001858   \n",
       "1999999          0.007819         0.009892           0.009669   \n",
       "\n",
       "         BTC_volume-20_5min  day  hour  minute  lunch_day  buy  \n",
       "0                160.631160    6    20      43        193    1  \n",
       "1                730.219717    5     1      59        607    0  \n",
       "2               1007.333300    5     4       8       -495    1  \n",
       "3                 86.928420    6    16      18        568    1  \n",
       "4               1071.196420    4    16      16        568    1  \n",
       "...                     ...  ...   ...     ...        ...  ...  \n",
       "1999995          178.457930    5    19      59       -230    1  \n",
       "1999996           94.640930    6     8       2        569    0  \n",
       "1999997           73.789250    4    21       5       -265    1  \n",
       "1999998          541.940310    7    11      59        607    1  \n",
       "1999999           59.859600    6    22      21       -806    1  \n",
       "\n",
       "[2000000 rows x 807 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Half Mem\n",
    "gc.collect()\n",
    "df1=df.iloc[0:int(df.shape[0]/2)].copy()\n",
    "del df\n",
    "gc.collect()\n",
    "df=df1\n",
    "del df1\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>high-1</th>\n",
       "      <th>low-1</th>\n",
       "      <th>close-1</th>\n",
       "      <th>volume-1</th>\n",
       "      <th>high-2</th>\n",
       "      <th>low-2</th>\n",
       "      <th>close-2</th>\n",
       "      <th>volume-2</th>\n",
       "      <th>high-3</th>\n",
       "      <th>...</th>\n",
       "      <th>BTC_volume-19_5min</th>\n",
       "      <th>BTC_high-20_5min</th>\n",
       "      <th>BTC_low-20_5min</th>\n",
       "      <th>BTC_close-20_5min</th>\n",
       "      <th>BTC_volume-20_5min</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>lunch_day</th>\n",
       "      <th>buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.856650</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>7.075000e+03</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>6.567000e+03</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>...</td>\n",
       "      <td>75.501360</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.006425</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>160.631160</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>43</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452640</td>\n",
       "      <td>-0.000685</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>5.516207e+05</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>5.749362e+05</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>...</td>\n",
       "      <td>1011.854175</td>\n",
       "      <td>-0.015560</td>\n",
       "      <td>-0.006021</td>\n",
       "      <td>-0.008398</td>\n",
       "      <td>730.219717</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>607</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.001003</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.001003</td>\n",
       "      <td>1.642836e+09</td>\n",
       "      <td>-0.001805</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>6.850947e+09</td>\n",
       "      <td>-0.001805</td>\n",
       "      <td>...</td>\n",
       "      <td>1234.202230</td>\n",
       "      <td>0.035991</td>\n",
       "      <td>0.037419</td>\n",
       "      <td>0.036334</td>\n",
       "      <td>1007.333300</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>-495</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.902500</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0.010736</td>\n",
       "      <td>0.003526</td>\n",
       "      <td>1.876218e+04</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.010422</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>2.632938e+04</td>\n",
       "      <td>0.008855</td>\n",
       "      <td>...</td>\n",
       "      <td>49.747880</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>86.928420</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.625000</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.017792</td>\n",
       "      <td>0.004164</td>\n",
       "      <td>2.191216e+04</td>\n",
       "      <td>0.015773</td>\n",
       "      <td>0.020820</td>\n",
       "      <td>0.018044</td>\n",
       "      <td>1.580669e+04</td>\n",
       "      <td>0.012997</td>\n",
       "      <td>...</td>\n",
       "      <td>880.209830</td>\n",
       "      <td>0.035458</td>\n",
       "      <td>0.040096</td>\n",
       "      <td>0.037497</td>\n",
       "      <td>1071.196420</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>2.065600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>353.441190</td>\n",
       "      <td>-0.010529</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>-0.003927</td>\n",
       "      <td>356.812900</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>-659</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>9.912500</td>\n",
       "      <td>-0.001765</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>3.753540e+03</td>\n",
       "      <td>-0.000757</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>-0.000757</td>\n",
       "      <td>7.223620e+03</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>...</td>\n",
       "      <td>210.169590</td>\n",
       "      <td>-0.002107</td>\n",
       "      <td>-0.000320</td>\n",
       "      <td>-0.001696</td>\n",
       "      <td>290.994820</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>-230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>2346.682500</td>\n",
       "      <td>-0.000732</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>6.663301e+02</td>\n",
       "      <td>-0.000860</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>7.391517e+02</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>...</td>\n",
       "      <td>274.115476</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.006587</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>304.990715</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>0.577600</td>\n",
       "      <td>-0.004155</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>-0.001039</td>\n",
       "      <td>3.134340e+05</td>\n",
       "      <td>-0.005367</td>\n",
       "      <td>-0.003289</td>\n",
       "      <td>-0.004155</td>\n",
       "      <td>1.216820e+05</td>\n",
       "      <td>-0.006406</td>\n",
       "      <td>...</td>\n",
       "      <td>333.970960</td>\n",
       "      <td>-0.001192</td>\n",
       "      <td>0.010657</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>517.451700</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>40</td>\n",
       "      <td>607</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>1541.620000</td>\n",
       "      <td>0.007901</td>\n",
       "      <td>0.017774</td>\n",
       "      <td>0.008076</td>\n",
       "      <td>1.051681e+04</td>\n",
       "      <td>0.004294</td>\n",
       "      <td>0.027309</td>\n",
       "      <td>0.014991</td>\n",
       "      <td>1.775649e+04</td>\n",
       "      <td>0.026706</td>\n",
       "      <td>...</td>\n",
       "      <td>1380.385580</td>\n",
       "      <td>0.011408</td>\n",
       "      <td>0.013492</td>\n",
       "      <td>0.012502</td>\n",
       "      <td>1072.652350</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 807 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              price    high-1     low-1   close-1      volume-1    high-2  \\\n",
       "0          0.856650 -0.000292  0.000642  0.000642  7.075000e+03 -0.000058   \n",
       "1          0.452640 -0.000685  0.002695 -0.000243  5.516207e+05  0.000972   \n",
       "2          0.000012 -0.001003 -0.000201 -0.001003  1.642836e+09 -0.001805   \n",
       "3         31.902500  0.002586  0.010736  0.003526  1.876218e+04  0.001959   \n",
       "4         39.625000  0.003407  0.017792  0.004164  2.191216e+04  0.015773   \n",
       "...             ...       ...       ...       ...           ...       ...   \n",
       "499995     2.065600  0.000000  0.000000  0.000000  0.000000e+00  0.000000   \n",
       "499996     9.912500 -0.001765  0.001261  0.000252  3.753540e+03 -0.000757   \n",
       "499997  2346.682500 -0.000732  0.000466  0.000368  6.663301e+02 -0.000860   \n",
       "499998     0.577600 -0.004155  0.001039 -0.001039  3.134340e+05 -0.005367   \n",
       "499999  1541.620000  0.007901  0.017774  0.008076  1.051681e+04  0.004294   \n",
       "\n",
       "           low-2   close-2      volume-2    high-3  ...  BTC_volume-19_5min  \\\n",
       "0       0.001576  0.000058  6.567000e+03  0.001809  ...           75.501360   \n",
       "1       0.002342  0.001657  5.749362e+05  0.000773  ...         1011.854175   \n",
       "2      -0.000201 -0.000201  6.850947e+09 -0.001805  ...         1234.202230   \n",
       "3       0.010422  0.004153  2.632938e+04  0.008855  ...           49.747880   \n",
       "4       0.020820  0.018044  1.580669e+04  0.012997  ...          880.209830   \n",
       "...          ...       ...           ...       ...  ...                 ...   \n",
       "499995  0.000000  0.000000  0.000000e+00  0.000000  ...          353.441190   \n",
       "499996  0.002270 -0.000757  7.223620e+03  0.001261  ...          210.169590   \n",
       "499997  0.000551  0.000039  7.391517e+02 -0.001767  ...          274.115476   \n",
       "499998 -0.003289 -0.004155  1.216820e+05 -0.006406  ...          333.970960   \n",
       "499999  0.027309  0.014991  1.775649e+04  0.026706  ...         1380.385580   \n",
       "\n",
       "        BTC_high-20_5min  BTC_low-20_5min  BTC_close-20_5min  \\\n",
       "0               0.002548         0.006425           0.002889   \n",
       "1              -0.015560        -0.006021          -0.008398   \n",
       "2               0.035991         0.037419           0.036334   \n",
       "3               0.001623         0.002420           0.002100   \n",
       "4               0.035458         0.040096           0.037497   \n",
       "...                  ...              ...                ...   \n",
       "499995         -0.010529        -0.003584          -0.003927   \n",
       "499996         -0.002107        -0.000320          -0.001696   \n",
       "499997          0.002639         0.006587           0.004717   \n",
       "499998         -0.001192         0.010657           0.002109   \n",
       "499999          0.011408         0.013492           0.012502   \n",
       "\n",
       "        BTC_volume-20_5min  day  hour  minute  lunch_day  buy  \n",
       "0               160.631160    6    20      43        193    1  \n",
       "1               730.219717    5     1      59        607    0  \n",
       "2              1007.333300    5     4       8       -495    1  \n",
       "3                86.928420    6    16      18        568    1  \n",
       "4              1071.196420    4    16      16        568    1  \n",
       "...                    ...  ...   ...     ...        ...  ...  \n",
       "499995          356.812900    5    22      30       -659    1  \n",
       "499996          290.994820    3    17      17       -230    0  \n",
       "499997          304.990715    1     6       7        867    1  \n",
       "499998          517.451700    6    19      40        607    1  \n",
       "499999         1072.652350    3    18       2        867    1  \n",
       "\n",
       "[500000 rows x 807 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df.dropna()\n",
    "gc.collect()\n",
    "dt=df.to_numpy(dtype=np.float32)\n",
    "#dt=df.to_numpy()\n",
    "dt=np.nan_to_num(dt,nan=0)\n",
    "#dt=dt.astype(np.float32)\n",
    "dt=np.nan_to_num(dt, neginf=0) \n",
    "dt=np.nan_to_num(dt, posinf=0) \n",
    "    #dt=tf.convert_to_tensor(dt, dtype=tf.float32)\n",
    "#dt = df.iloc[0:int(len(df/1.5))].to_numpy()\n",
    "#dt = np.concatenate((dt,df.iloc[int(len(df/2)):].to_numpy()),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goodcsv='/UltimeTradingBot/Data/csv/W20F4minP35.csv'\n",
    "\n",
    "# dt=pd.read_csv(goodcsv).sample(frac=1,random_state=2).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000000, 567)\n"
     ]
    }
   ],
   "source": [
    "# del dffull\n",
    "# df=df.iloc[int(len(df/1.5)):]\n",
    "# gc.collect()\n",
    "print(dt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt[:,-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.5800000e-02,  2.1834061e-03,  2.1834061e-03, ...,\n",
       "         2.3000000e+01, -6.3200000e+02,  0.0000000e+00],\n",
       "       [ 1.6510000e+01,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "         2.0000000e+00, -2.3100000e+02,  0.0000000e+00],\n",
       "       [ 2.4970000e+00, -8.0096116e-04,  8.0096116e-04, ...,\n",
       "         3.8000000e+01, -8.5500000e+02,  1.0000000e+00],\n",
       "       ...,\n",
       "       [ 2.7227300e+03, -2.0898143e-03, -3.3055057e-05, ...,\n",
       "         6.0000000e+00,  8.6700000e+02,  0.0000000e+00],\n",
       "       [ 5.4007499e-03, -4.8604361e-03, -1.3424061e-03, ...,\n",
       "         1.3000000e+01, -5.1000000e+01,  0.0000000e+00],\n",
       "       [ 1.2400000e+00, -8.0645159e-03, -8.0645159e-03, ...,\n",
       "         9.0000000e+00, -7.1600000e+02,  1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan_to_num(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3270000, 607)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#dt=np.genfromtxt('np_shuffled_cryptodata_w15.csv', delimiter=',')\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m index_20pct\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(index_20pct)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#dt=np.genfromtxt('np_shuffled_cryptodata_w15.csv', delimiter=',')\n",
    "index_20pct= int(0.2*df.shape[0])\n",
    "print(index_20pct)\n",
    "# XVALIDATION= df.iloc[:index_20pct, :-1]\n",
    "# YVALIDATION= df.iloc[:index_20pct,-1]\n",
    "# XTRAIN= df.iloc[index_20pct:, 0:-1]\n",
    "# YTRAIN= df.iloc[index_20pct:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PANDAS DIRECT NORMALIZATION #####\n",
    "if True:\n",
    "    #if FIRST_NORM_FLAG:\n",
    "    if True:\n",
    "        print(\"normalizing ...\")\n",
    "        mean = df.iloc[index_20pct:, 0:-1].mean(axis=0)\n",
    "        gc.collect()\n",
    "        std = df.iloc[index_20pct:, 0:-1].std(axis=0)\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "        # df.iloc[:, 0:-1] -= mean \n",
    "        # df.iloc[:, 0:-1] /= std\n",
    "\n",
    "        # XVALIDATION -=mean\n",
    "        # XVALIDATION /= std\n",
    "        FIRST_NORM_FLAG=False\n",
    "        ######################### SAVIN NORM ################\n",
    "        try:\n",
    "            Normalization={\"mean\":mean.tolist(),\"std\":std.tolist()}\n",
    "            with open(Normalization_File, 'w+') as fp:\n",
    "                        json.dump(Normalization, fp,  indent=4)\n",
    "                        print(Normalization_File)\n",
    "        except:\n",
    "            print(\"error Normalization in juppiter\")\n",
    "    else:print(\"already normalized\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Normalization_File) as json_file:\n",
    "                print(Normalization_File)\n",
    "                Normalization = json.load(json_file)\n",
    "                mean=np.array(Normalization[\"mean\"])\n",
    "                std=np.array(Normalization[\"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gc.collect()\n",
    "df.iloc[:1000000, 0:-1] -= Normalization[\"mean\"]\n",
    "gc.collect()\n",
    "\n",
    "df.iloc[:1000000, 0:-1] /= Normalization[\"std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather(f\"../Data/fea/w{WINDOW_SIZE}_buy{BUY_PCT}_noprice_normalized.fea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800000\n"
     ]
    }
   ],
   "source": [
    "index_20pct= int(0.2*len(dt[:,0]))\n",
    "print(index_20pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XVALIDATION= dt[:index_20pct, :-1]\n",
    "# YVALIDATION= dt[:index_20pct,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XTRAIN= dt[index_20pct:, 0:-1]\n",
    "# YTRAIN= dt[index_20pct:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "910"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.3638100e+01, -1.2575027e-03,  1.7242354e-03, ...,\n",
       "         4.5000000e+01, -2.3000000e+02,  1.0000000e+00],\n",
       "       [ 2.3380000e+02, -3.8494440e-03, -8.5543201e-04, ...,\n",
       "         5.9000000e+01,  2.9200000e+02,  1.0000000e+00],\n",
       "       [ 1.2633750e+00, -1.1279312e-03,  4.5513010e-04, ...,\n",
       "         2.4000000e+01,  6.0700000e+02,  1.0000000e+00],\n",
       "       ...,\n",
       "       [ 2.1244749e-01, -6.4133490e-03,  2.4829663e-03, ...,\n",
       "         5.0000000e+00,  1.8000000e+02,  1.0000000e+00],\n",
       "       [ 1.8200001e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "         5.7000000e+01, -2.2300000e+02,  0.0000000e+00],\n",
       "       [ 3.9640951e-01, -6.3923799e-04,  3.2648058e-03, ...,\n",
       "         5.8000000e+01,  1.8000000e+02,  0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenderalization (mean normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if True:\n",
    "#     #if FIRST_NORM_FLAG:\n",
    "#     if True:\n",
    "#         print(\"normalizing ...\")\n",
    "#         mean = XTRAIN.mean(axis=0)\n",
    "#         std = XTRAIN.std(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "#         XTRAIN -= mean \n",
    "#         XTRAIN /= std\n",
    "\n",
    "#         XVALIDATION -=mean\n",
    "#         XVALIDATION /= std\n",
    "#         FIRST_NORM_FLAG=False\n",
    "#         ######################### SAVIN NORM ################\n",
    "#         try:\n",
    "#             Normalization={\"mean\":mean.tolist(),\"std\":std.tolist()}\n",
    "#             with open(Normalization_File, 'w+') as fp:\n",
    "#                         json.dump(Normalization, fp,  indent=4)\n",
    "#                         print(Normalization_File)\n",
    "#         except:\n",
    "#             print(\"error Normalization in juppiter\")\n",
    "#     else:print(\"already normalized\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing ...\n",
      "/UltimeTradingBot/Data/tp70_w14_max7min_Norm_v1.json\n"
     ]
    }
   ],
   "source": [
    "# #dt=df.to_numpy()\n",
    "# dt=np.nan_to_num(dt,nan=0)\n",
    "# #dt=dt.astype(np.float32)\n",
    "# dt=np.nan_to_num(dt, neginf=0) \n",
    "# dt=np.nan_to_num(dt, posinf=0) \n",
    "if True:\n",
    "    #if FIRST_NORM_FLAG:\n",
    "    if True:\n",
    "        print(\"normalizing ...\")\n",
    "        mean = dt[index_20pct:, 0:-1].mean(axis=0)\n",
    "        std = dt[index_20pct:, 0:-1].std(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "        dt[index_20pct:, 0:-1] -= mean \n",
    "        dt[index_20pct:, 0:-1] /= std\n",
    "\n",
    "        dt[:index_20pct, :-1] -=mean\n",
    "        dt[:index_20pct, :-1] /= std\n",
    "        FIRST_NORM_FLAG=False\n",
    "        ######################### SAVIN NORM ################\n",
    "        try:\n",
    "            Normalization={\"mean\":mean.tolist(),\"std\":std.tolist()}\n",
    "            with open(Normalization_File, 'w+') as fp:\n",
    "                        json.dump(Normalization, fp,  indent=4)\n",
    "                        print(Normalization_File)\n",
    "        except:\n",
    "            print(\"error Normalization in juppiter\")\n",
    "    else:print(\"already normalized\")\n",
    "\n",
    "#dt=df.to_numpy()\n",
    "dt=np.nan_to_num(dt,nan=0)\n",
    "#dt=dt.astype(np.float32)\n",
    "dt=np.nan_to_num(dt, neginf=0) \n",
    "dt=np.nan_to_num(dt, posinf=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[:,:-1] -= mean \n",
    "dt[:,:-1] /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmean\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Normalization_File, 'w+') as fp:\n",
    "        json.dump(Normalization, fp,  indent=4)\n",
    "        print(Normalization_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/UltimeTradingBot/Data/tp120_w10_max5min_Norm_v1.json\n",
      "normalizing ...\n"
     ]
    }
   ],
   "source": [
    "################## V2 Testing ######################\n",
    "\n",
    "TESTING_MOD=True\n",
    "# Normalization\n",
    "if TESTING_MOD:\n",
    "    with open(Normalization_File) as json_file:\n",
    "                print(Normalization_File)\n",
    "                Normalization = json.load(json_file)\n",
    "                mean=np.array(Normalization[\"mean\"])\n",
    "                std=np.array(Normalization[\"std\"])\n",
    "# mean=np.array(Normalization[\"mean\"])\n",
    "\n",
    "if  TESTING_MOD:\n",
    "    if FIRST_NORM_FLAG:\n",
    "        print(\"normalizing ...\")\n",
    "        dt[:,0:-1] -= Normalization[\"mean\"] \n",
    "        dt[:,0:-1] /= Normalization[\"std\"] \n",
    "\n",
    "    \n",
    "        FIRST_NORM_FLAG=False\n",
    "        FIRST_NORM_FLAG=False\n",
    "    else:print(\"already normalized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/UltimeTradingBot/Data/tp70_w14_max7min_Norm_v1.json\n"
     ]
    }
   ],
   "source": [
    "print(Normalization_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XTRAIN.shape)\n",
    "print(YTRAIN.shape)\n",
    "print(XVALIDATION.shape)\n",
    "print(YVALIDATION.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def One_pair_AI_Gen(pair=\"ETH/USDT\"):\n",
    "    ResJS={}\n",
    "    price_volatility_15m=(100*(df_list15m[pair][\"high\"]-df_list15m[pair][\"low\"])/df_list15m[pair][\"high\"]).mean()\n",
    "    print(price_volatility_15m)\n",
    "    df=mini_expand3(pair=pair,i=0,j=len(df_list1m[pair]),window=WINDOW_SIZE,metadata=MetaData,BUY_PCT=max(price_volatility_15m*0.6,BUY_PCT),SELL_PCT=SELL_PCT)\n",
    "    print(\"df original shape \"+str(df.shape))\n",
    "    print(f\"df original shape buy mean : {df.buy.mean()*100}\")\n",
    "    df=df.reset_index()\n",
    "    try:df.pop(\"num_index\")\n",
    "    except: pass\n",
    "    try:df.pop(\"index\")\n",
    "    except: pass\n",
    "    try:df.pop(\"date\")\n",
    "    except: pass\n",
    "    df=data_shufler(df)            \n",
    "    #df=data_chooser(df,weight=50,row_numbers=df.buy.sum()*2)\n",
    "    df=data_chooser50(df,row_numbers=500000)\n",
    "    gc.collect()\n",
    "    df=data_cleanup(df)\n",
    "    df=df.dropna()\n",
    "    print(\"df choosen data shape\"+str(df.shape))\n",
    "    print(f\"pair: {(df.shape[0]/2)==df.buy.sum()}\")\n",
    "    dt=df.to_numpy(dtype=np.float32)\n",
    "    #dt=df.to_numpy()\n",
    "    dt=np.nan_to_num(dt,nan=0)\n",
    "    #dt=dt.astype(np.float32)\n",
    "    dt=np.nan_to_num(dt, neginf=0) \n",
    "    dt=np.nan_to_num(dt, posinf=0) \n",
    "\n",
    "    ## normalisation\n",
    "    index_20pct= int(0.2*len(dt[:,0]))\n",
    "    print(index_20pct)\n",
    "    if True:\n",
    "        if True:\n",
    "        #if True:\n",
    "            print(\"normalizing ...\")\n",
    "            mean = dt[index_20pct:, 0:-1].mean(axis=0)\n",
    "            std = dt[index_20pct:, 0:-1].std(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "            dt[index_20pct:, 0:-1] -= mean \n",
    "            dt[index_20pct:, 0:-1] /= std\n",
    "\n",
    "            dt[:index_20pct, :-1] -=mean\n",
    "            dt[:index_20pct, :-1] /= std\n",
    "            FIRST_NORM_FLAG=False\n",
    "            ######################### SAVIN NORM ################\n",
    "            try:\n",
    "                Normalization={\"mean\":mean.tolist(),\"std\":std.tolist()}\n",
    "                with open(f'{DATA_DIR}/{pair.replace(\"/\", \"-\")}-tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Norm_v{VERSION}.json', 'w+') as fp:\n",
    "                            json.dump(Normalization, fp,  indent=4)\n",
    "                            print(fp.name)\n",
    "            except Exception as e:\n",
    "                print(\"error Normalization in juppiter\")\n",
    "                print(e)\n",
    "        else:print(\"already normalized\")\n",
    "        \n",
    "    dt=np.nan_to_num(dt,nan=0)\n",
    "    dt=np.nan_to_num(dt, neginf=0) \n",
    "    dt=np.nan_to_num(dt, posinf=0) \n",
    "    dt=dt.astype(np.float32)\n",
    "    ## Model\n",
    "    IN_DIM=dt.shape[1]-1\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(250),input_dim=IN_DIM,activation='relu')) #( 100=>66.23)\n",
    "    # resultus withe 250 d0.3 50 d 20 d 8 = 65.6% vs  65.49 no droppout vs 65.78 d0.5 vs 65.68 d0.4 # 65.48 # one dropout of   0.5 = 66.11   #tanh 66.33 accuracy #softmax 66.12 #softplus 66.5 # sigmoid 66.21 / \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(int(20),activation='relu')) # best softplus 66.26(69) vs relu 66.65(70)  / -20 => 66.25 /250 ->65.78\n",
    "    #model2.add(Dropout(0.1)) #5=> 66.00  66.21 vs no dopout 66.28\n",
    "    #model2.add(Dense(int(20),activation='relu')) # disabled 6.24\n",
    "    model.add(Dense(int(50),activation='relu')) # -4 -> -> 66.24\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    print(model.summary())\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    callbacks_a = ModelCheckpoint(filepath =f'{DATA_DIR}/{pair.replace(\"/\", \"-\")}-tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model_v{VERSION}.hdf5',monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "    callbacks_b = EarlyStopping(monitor ='val_accuracy',mode='auto',patience=15,verbose=1)\n",
    "    history = model.fit(dt[index_20pct:, 0:-1],\n",
    "                    dt[index_20pct:,-1],\n",
    "                    validation_data=(dt[:index_20pct, :-1],dt[:index_20pct,-1]),\n",
    "                    epochs=6000,\n",
    "                    batch_size=256*10,\n",
    "                    callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "    print('##########################################################################')\n",
    "    print(MODEL_FILE.replace(\"/UltimeTradingBot/Data/\", \"/UltimeTradingBot/Data/\"+pair.replace(\"/\", \"-\")+\"-\"))\n",
    "    print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "    ResJS[pair]='{0:.4g}'.format(max(history.history['val_accuracy'])*100)\n",
    "    return( model , ResJS)\n",
    "    #94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True:\n",
    "#     IN_DIM=len(mean)\n",
    "# #     model = Sequential()\n",
    "# #     model.add(Dense(int(IN_DIM/2),input_dim=IN_DIM,activation='relu'))\n",
    "# #     model.add(Dropout(0.5))\n",
    "# #     model.add(Dense(int(IN_DIM/4),activation='relu'))\n",
    "# # #    model.add(Dropout(0.7))\n",
    "# #     model.add(Dense(8,activation='relu'))\n",
    "# # #    model.add(Dropout(0.7))\n",
    "# #     model.add(Dense(1,activation='sigmoid'))\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(IN_DIM,input_dim=IN_DIM,activation='relu'))\n",
    "#     model.add(Dense(100,activation='tanh'))\n",
    "#     model.add(Dense(100,activation='relu'))\n",
    "#     model.add(Dense(40,activation='relu'))\n",
    "#     model.add(Dense(40,activation='relu'))\n",
    "#     model.add(Dense(40,activation='relu'))\n",
    "# #    model.add(Dense(10,activation='relu'))\n",
    "# #    model.add(Dropout(0.5))\n",
    "# #    model.add(Dense(20,activation='relu'))\n",
    "# #    model.add(Dropout(0.7))\n",
    "#     model.add(Dense(4,activation='relu'))\n",
    "# #    model.add(Dropout(0.7))\n",
    "#     model.add(Dense(1,activation='sigmoid'))\n",
    "#     print(model.summary())\n",
    "#     model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#     callbacks_a = ModelCheckpoint(filepath=Model_FileName,monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "#     callbacks_b = EarlyStopping(monitor ='accuracy',mode='auto',patience=50,verbose=1)\n",
    "#     history = model.fit(XTRAIN,\n",
    "#                     YTRAIN,\n",
    "#                     validation_data=(XVALIDATION,YVALIDATION),\n",
    "#                     epochs=6000,\n",
    "#                     batch_size=128*50,\n",
    "#                     callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "#     print('##########################################################################')\n",
    "#     print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "#     #94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model2=load_model(Model_FileName+f\"1.dropout0.5.onelayer.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(XTRAIN,YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=dt[:,-1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED=model2.predict(dt[:,:-1]).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_PRED=np.array(((PRED[:,0]==1) & (Y==1)),dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_PRED.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[:,-1]=REAL_PRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[:,-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 05:28:59.815304: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-25 05:28:59.817371: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-25 05:28:59.818213: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: abj-K93SV\n",
      "2022-11-25 05:28:59.818266: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: abj-K93SV\n",
      "2022-11-25 05:28:59.819911: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-11-25 05:28:59.822216: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 390.154.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 250)               141750    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 250)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                5020      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 147,871\n",
      "Trainable params: 147,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 05:29:37.934875: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7244800000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6000\n",
      "1250/1250 [==============================] - 82s 63ms/step - loss: 0.3829 - accuracy: 0.8263 - val_loss: 0.3511 - val_accuracy: 0.8435\n",
      "Epoch 2/6000\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 0.3469 - accuracy: 0.8462 - val_loss: 0.3314 - val_accuracy: 0.8547\n",
      "Epoch 3/6000\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 0.3301 - accuracy: 0.8557 - val_loss: 0.3186 - val_accuracy: 0.8617\n",
      "Epoch 4/6000\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 0.3178 - accuracy: 0.8625 - val_loss: 0.3017 - val_accuracy: 0.8719\n",
      "Epoch 5/6000\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 0.3080 - accuracy: 0.8681 - val_loss: 0.2909 - val_accuracy: 0.8774\n",
      "Epoch 6/6000\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 0.3001 - accuracy: 0.8722 - val_loss: 0.2817 - val_accuracy: 0.8818\n",
      "Epoch 7/6000\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 0.2933 - accuracy: 0.8759 - val_loss: 0.2756 - val_accuracy: 0.8850\n",
      "Epoch 8/6000\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 0.2880 - accuracy: 0.8787 - val_loss: 0.2721 - val_accuracy: 0.8869\n",
      "Epoch 9/6000\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 0.2830 - accuracy: 0.8813 - val_loss: 0.2670 - val_accuracy: 0.8898\n",
      "Epoch 10/6000\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 0.2785 - accuracy: 0.8838 - val_loss: 0.2631 - val_accuracy: 0.8928\n",
      "Epoch 11/6000\n",
      "1250/1250 [==============================] - 69s 56ms/step - loss: 0.2746 - accuracy: 0.8858 - val_loss: 0.2578 - val_accuracy: 0.8944\n",
      "Epoch 12/6000\n",
      "1250/1250 [==============================] - 69s 56ms/step - loss: 0.2714 - accuracy: 0.8875 - val_loss: 0.2589 - val_accuracy: 0.8953\n",
      "Epoch 13/6000\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 0.2688 - accuracy: 0.8890 - val_loss: 0.2536 - val_accuracy: 0.8974\n",
      "Epoch 14/6000\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 0.2658 - accuracy: 0.8905 - val_loss: 0.2494 - val_accuracy: 0.8991\n",
      "Epoch 15/6000\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 0.2632 - accuracy: 0.8918 - val_loss: 0.2464 - val_accuracy: 0.9010\n",
      "Epoch 16/6000\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 0.2607 - accuracy: 0.8931 - val_loss: 0.2445 - val_accuracy: 0.9014\n",
      "Epoch 17/6000\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.2585 - accuracy: 0.8943 - val_loss: 0.2416 - val_accuracy: 0.9035\n",
      "Epoch 18/6000\n",
      "1250/1250 [==============================] - 69s 56ms/step - loss: 0.2569 - accuracy: 0.8951 - val_loss: 0.2408 - val_accuracy: 0.9040\n",
      "Epoch 19/6000\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 0.2547 - accuracy: 0.8964 - val_loss: 0.2367 - val_accuracy: 0.9057\n",
      "Epoch 20/6000\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 0.2527 - accuracy: 0.8973 - val_loss: 0.2385 - val_accuracy: 0.9045\n",
      "Epoch 21/6000\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 0.2513 - accuracy: 0.8980 - val_loss: 0.2356 - val_accuracy: 0.9068\n",
      "Epoch 22/6000\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 0.2495 - accuracy: 0.8990 - val_loss: 0.2326 - val_accuracy: 0.9080\n",
      "Epoch 23/6000\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 0.2479 - accuracy: 0.8999 - val_loss: 0.2316 - val_accuracy: 0.9082\n",
      "Epoch 24/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2468 - accuracy: 0.9004 - val_loss: 0.2297 - val_accuracy: 0.9091\n",
      "Epoch 25/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2452 - accuracy: 0.9012 - val_loss: 0.2300 - val_accuracy: 0.9091\n",
      "Epoch 26/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2440 - accuracy: 0.9018 - val_loss: 0.2269 - val_accuracy: 0.9108\n",
      "Epoch 27/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.2428 - accuracy: 0.9026 - val_loss: 0.2263 - val_accuracy: 0.9111\n",
      "Epoch 28/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.2412 - accuracy: 0.9032 - val_loss: 0.2237 - val_accuracy: 0.9121\n",
      "Epoch 29/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.2402 - accuracy: 0.9039 - val_loss: 0.2234 - val_accuracy: 0.9132\n",
      "Epoch 30/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.2391 - accuracy: 0.9044 - val_loss: 0.2241 - val_accuracy: 0.9125\n",
      "Epoch 31/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.2381 - accuracy: 0.9050 - val_loss: 0.2230 - val_accuracy: 0.9137\n",
      "Epoch 32/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2370 - accuracy: 0.9054 - val_loss: 0.2217 - val_accuracy: 0.9139\n",
      "Epoch 33/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.2360 - accuracy: 0.9056 - val_loss: 0.2181 - val_accuracy: 0.9154\n",
      "Epoch 34/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.2349 - accuracy: 0.9065 - val_loss: 0.2175 - val_accuracy: 0.9153\n",
      "Epoch 35/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.2343 - accuracy: 0.9068 - val_loss: 0.2175 - val_accuracy: 0.9158\n",
      "Epoch 36/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.2329 - accuracy: 0.9076 - val_loss: 0.2170 - val_accuracy: 0.9158\n",
      "Epoch 37/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.2326 - accuracy: 0.9076 - val_loss: 0.2153 - val_accuracy: 0.9166\n",
      "Epoch 38/6000\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 0.2315 - accuracy: 0.9084 - val_loss: 0.2135 - val_accuracy: 0.9175\n",
      "Epoch 39/6000\n",
      "1250/1250 [==============================] - 68s 54ms/step - loss: 0.2307 - accuracy: 0.9087 - val_loss: 0.2142 - val_accuracy: 0.9177\n",
      "Epoch 40/6000\n",
      "1250/1250 [==============================] - 74s 59ms/step - loss: 0.2300 - accuracy: 0.9089 - val_loss: 0.2137 - val_accuracy: 0.9176\n",
      "Epoch 41/6000\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 0.2289 - accuracy: 0.9096 - val_loss: 0.2150 - val_accuracy: 0.9162\n",
      "Epoch 42/6000\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 0.2283 - accuracy: 0.9098 - val_loss: 0.2138 - val_accuracy: 0.9173\n",
      "Epoch 43/6000\n",
      "1250/1250 [==============================] - 68s 54ms/step - loss: 0.2278 - accuracy: 0.9100 - val_loss: 0.2119 - val_accuracy: 0.9186\n",
      "Epoch 44/6000\n",
      "1250/1250 [==============================] - 68s 54ms/step - loss: 0.2268 - accuracy: 0.9105 - val_loss: 0.2107 - val_accuracy: 0.9187\n",
      "Epoch 45/6000\n",
      "1250/1250 [==============================] - 68s 55ms/step - loss: 0.2263 - accuracy: 0.9108 - val_loss: 0.2105 - val_accuracy: 0.9191\n",
      "Epoch 46/6000\n",
      "1250/1250 [==============================] - 68s 55ms/step - loss: 0.2254 - accuracy: 0.9112 - val_loss: 0.2098 - val_accuracy: 0.9197\n",
      "Epoch 47/6000\n",
      "1250/1250 [==============================] - 68s 55ms/step - loss: 0.2248 - accuracy: 0.9116 - val_loss: 0.2103 - val_accuracy: 0.9193\n",
      "Epoch 48/6000\n",
      "1250/1250 [==============================] - 72s 58ms/step - loss: 0.2238 - accuracy: 0.9119 - val_loss: 0.2081 - val_accuracy: 0.9201\n",
      "Epoch 49/6000\n",
      "1250/1250 [==============================] - 68s 55ms/step - loss: 0.2236 - accuracy: 0.9122 - val_loss: 0.2076 - val_accuracy: 0.9207\n",
      "Epoch 50/6000\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 0.2228 - accuracy: 0.9126 - val_loss: 0.2063 - val_accuracy: 0.9211\n",
      "Epoch 51/6000\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 0.2224 - accuracy: 0.9128 - val_loss: 0.2062 - val_accuracy: 0.9207\n",
      "Epoch 52/6000\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 0.2220 - accuracy: 0.9130 - val_loss: 0.2037 - val_accuracy: 0.9225\n",
      "Epoch 53/6000\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.2213 - accuracy: 0.9133 - val_loss: 0.2049 - val_accuracy: 0.9217\n",
      "Epoch 54/6000\n",
      "1250/1250 [==============================] - 79s 63ms/step - loss: 0.2208 - accuracy: 0.9134 - val_loss: 0.2038 - val_accuracy: 0.9223\n",
      "Epoch 55/6000\n",
      "1250/1250 [==============================] - 71s 57ms/step - loss: 0.2202 - accuracy: 0.9138 - val_loss: 0.2025 - val_accuracy: 0.9229\n",
      "Epoch 56/6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 68s 55ms/step - loss: 0.2193 - accuracy: 0.9142 - val_loss: 0.2025 - val_accuracy: 0.9233\n",
      "Epoch 57/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.2193 - accuracy: 0.9144 - val_loss: 0.2020 - val_accuracy: 0.9232\n",
      "Epoch 58/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.2186 - accuracy: 0.9146 - val_loss: 0.2026 - val_accuracy: 0.9231\n",
      "Epoch 59/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.2182 - accuracy: 0.9148 - val_loss: 0.2000 - val_accuracy: 0.9240\n",
      "Epoch 60/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.2174 - accuracy: 0.9153 - val_loss: 0.2008 - val_accuracy: 0.9239\n",
      "Epoch 61/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.2168 - accuracy: 0.9154 - val_loss: 0.2029 - val_accuracy: 0.9227\n",
      "Epoch 62/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2164 - accuracy: 0.9157 - val_loss: 0.1991 - val_accuracy: 0.9247\n",
      "Epoch 63/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2159 - accuracy: 0.9159 - val_loss: 0.2020 - val_accuracy: 0.9232\n",
      "Epoch 64/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2156 - accuracy: 0.9161 - val_loss: 0.2009 - val_accuracy: 0.9237\n",
      "Epoch 65/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2149 - accuracy: 0.9165 - val_loss: 0.1985 - val_accuracy: 0.9248\n",
      "Epoch 66/6000\n",
      "1250/1250 [==============================] - 68s 55ms/step - loss: 0.2144 - accuracy: 0.9168 - val_loss: 0.1987 - val_accuracy: 0.9248\n",
      "Epoch 67/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2142 - accuracy: 0.9168 - val_loss: 0.1993 - val_accuracy: 0.9244\n",
      "Epoch 68/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2138 - accuracy: 0.9170 - val_loss: 0.1990 - val_accuracy: 0.9249\n",
      "Epoch 69/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2132 - accuracy: 0.9172 - val_loss: 0.1961 - val_accuracy: 0.9263\n",
      "Epoch 70/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2129 - accuracy: 0.9174 - val_loss: 0.1974 - val_accuracy: 0.9253\n",
      "Epoch 71/6000\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 0.2125 - accuracy: 0.9176 - val_loss: 0.1964 - val_accuracy: 0.9259\n",
      "Epoch 72/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2126 - accuracy: 0.9176 - val_loss: 0.1961 - val_accuracy: 0.9262\n",
      "Epoch 73/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2116 - accuracy: 0.9180 - val_loss: 0.1975 - val_accuracy: 0.9249\n",
      "Epoch 74/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2114 - accuracy: 0.9182 - val_loss: 0.1952 - val_accuracy: 0.9266\n",
      "Epoch 75/6000\n",
      "1250/1250 [==============================] - 68s 54ms/step - loss: 0.2110 - accuracy: 0.9184 - val_loss: 0.1955 - val_accuracy: 0.9264\n",
      "Epoch 76/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2106 - accuracy: 0.9185 - val_loss: 0.1952 - val_accuracy: 0.9262\n",
      "Epoch 77/6000\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 0.2103 - accuracy: 0.9188 - val_loss: 0.1957 - val_accuracy: 0.9265\n",
      "Epoch 78/6000\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 0.2098 - accuracy: 0.9188 - val_loss: 0.1951 - val_accuracy: 0.9268\n",
      "Epoch 79/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2096 - accuracy: 0.9190 - val_loss: 0.1944 - val_accuracy: 0.9274\n",
      "Epoch 80/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2092 - accuracy: 0.9193 - val_loss: 0.1930 - val_accuracy: 0.9278\n",
      "Epoch 81/6000\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 0.2087 - accuracy: 0.9196 - val_loss: 0.1922 - val_accuracy: 0.9282\n",
      "Epoch 82/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2084 - accuracy: 0.9196 - val_loss: 0.1935 - val_accuracy: 0.9272\n",
      "Epoch 83/6000\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 0.2080 - accuracy: 0.9197 - val_loss: 0.1916 - val_accuracy: 0.9285\n",
      "Epoch 84/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2076 - accuracy: 0.9199 - val_loss: 0.1921 - val_accuracy: 0.9280\n",
      "Epoch 85/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2077 - accuracy: 0.9200 - val_loss: 0.1919 - val_accuracy: 0.9281\n",
      "Epoch 86/6000\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 0.2071 - accuracy: 0.9202 - val_loss: 0.1916 - val_accuracy: 0.9286\n",
      "Epoch 87/6000\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 0.2070 - accuracy: 0.9203 - val_loss: 0.1918 - val_accuracy: 0.9281\n",
      "Epoch 88/6000\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 0.2067 - accuracy: 0.9204 - val_loss: 0.1905 - val_accuracy: 0.9292\n",
      "Epoch 89/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2064 - accuracy: 0.9207 - val_loss: 0.1893 - val_accuracy: 0.9297\n",
      "Epoch 90/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2061 - accuracy: 0.9208 - val_loss: 0.1913 - val_accuracy: 0.9286\n",
      "Epoch 91/6000\n",
      "1250/1250 [==============================] - 64s 52ms/step - loss: 0.2056 - accuracy: 0.9209 - val_loss: 0.1884 - val_accuracy: 0.9297\n",
      "Epoch 92/6000\n",
      "1250/1250 [==============================] - 64s 52ms/step - loss: 0.2053 - accuracy: 0.9211 - val_loss: 0.1882 - val_accuracy: 0.9297\n",
      "Epoch 93/6000\n",
      "1250/1250 [==============================] - 64s 52ms/step - loss: 0.2048 - accuracy: 0.9212 - val_loss: 0.1896 - val_accuracy: 0.9292\n",
      "Epoch 94/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2045 - accuracy: 0.9216 - val_loss: 0.1881 - val_accuracy: 0.9301\n",
      "Epoch 95/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2041 - accuracy: 0.9218 - val_loss: 0.1882 - val_accuracy: 0.9298\n",
      "Epoch 96/6000\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 0.2041 - accuracy: 0.9216 - val_loss: 0.1892 - val_accuracy: 0.9295\n",
      "Epoch 97/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2037 - accuracy: 0.9219 - val_loss: 0.1889 - val_accuracy: 0.9295\n",
      "Epoch 98/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2038 - accuracy: 0.9220 - val_loss: 0.1879 - val_accuracy: 0.9302\n",
      "Epoch 99/6000\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 0.2032 - accuracy: 0.9222 - val_loss: 0.1875 - val_accuracy: 0.9303\n",
      "Epoch 100/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2031 - accuracy: 0.9223 - val_loss: 0.1878 - val_accuracy: 0.9299\n",
      "Epoch 101/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2029 - accuracy: 0.9223 - val_loss: 0.1863 - val_accuracy: 0.9312\n",
      "Epoch 102/6000\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 0.2024 - accuracy: 0.9226 - val_loss: 0.1884 - val_accuracy: 0.9293\n",
      "Epoch 103/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.2024 - accuracy: 0.9225 - val_loss: 0.1873 - val_accuracy: 0.9303\n",
      "Epoch 104/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2020 - accuracy: 0.9228 - val_loss: 0.1884 - val_accuracy: 0.9299\n",
      "Epoch 105/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2019 - accuracy: 0.9226 - val_loss: 0.1858 - val_accuracy: 0.9313\n",
      "Epoch 106/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2016 - accuracy: 0.9228 - val_loss: 0.1869 - val_accuracy: 0.9306\n",
      "Epoch 107/6000\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 0.2011 - accuracy: 0.9232 - val_loss: 0.1858 - val_accuracy: 0.9314\n",
      "Epoch 108/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2009 - accuracy: 0.9232 - val_loss: 0.1841 - val_accuracy: 0.9318\n",
      "Epoch 109/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2008 - accuracy: 0.9233 - val_loss: 0.1845 - val_accuracy: 0.9319\n",
      "Epoch 110/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.2004 - accuracy: 0.9235 - val_loss: 0.1867 - val_accuracy: 0.9304\n",
      "Epoch 111/6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.2002 - accuracy: 0.9236 - val_loss: 0.1847 - val_accuracy: 0.9319\n",
      "Epoch 112/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.2002 - accuracy: 0.9236 - val_loss: 0.1850 - val_accuracy: 0.9316\n",
      "Epoch 113/6000\n",
      "1250/1250 [==============================] - 62s 50ms/step - loss: 0.1999 - accuracy: 0.9236 - val_loss: 0.1842 - val_accuracy: 0.9323\n",
      "Epoch 114/6000\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 0.1997 - accuracy: 0.9237 - val_loss: 0.1844 - val_accuracy: 0.9318\n",
      "Epoch 115/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1994 - accuracy: 0.9240 - val_loss: 0.1829 - val_accuracy: 0.9325\n",
      "Epoch 116/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.1989 - accuracy: 0.9242 - val_loss: 0.1842 - val_accuracy: 0.9317\n",
      "Epoch 117/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.1991 - accuracy: 0.9241 - val_loss: 0.1830 - val_accuracy: 0.9327\n",
      "Epoch 118/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1989 - accuracy: 0.9243 - val_loss: 0.1841 - val_accuracy: 0.9323\n",
      "Epoch 119/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1986 - accuracy: 0.9245 - val_loss: 0.1822 - val_accuracy: 0.9334\n",
      "Epoch 120/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1985 - accuracy: 0.9244 - val_loss: 0.1829 - val_accuracy: 0.9325\n",
      "Epoch 121/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1982 - accuracy: 0.9245 - val_loss: 0.1818 - val_accuracy: 0.9334\n",
      "Epoch 122/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1978 - accuracy: 0.9248 - val_loss: 0.1822 - val_accuracy: 0.9330\n",
      "Epoch 123/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1977 - accuracy: 0.9249 - val_loss: 0.1825 - val_accuracy: 0.9333\n",
      "Epoch 124/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1971 - accuracy: 0.9250 - val_loss: 0.1823 - val_accuracy: 0.9328\n",
      "Epoch 125/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1972 - accuracy: 0.9250 - val_loss: 0.1827 - val_accuracy: 0.9326\n",
      "Epoch 126/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1972 - accuracy: 0.9250 - val_loss: 0.1809 - val_accuracy: 0.9335\n",
      "Epoch 127/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1970 - accuracy: 0.9250 - val_loss: 0.1816 - val_accuracy: 0.9330\n",
      "Epoch 128/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1969 - accuracy: 0.9251 - val_loss: 0.1811 - val_accuracy: 0.9337\n",
      "Epoch 129/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1965 - accuracy: 0.9252 - val_loss: 0.1803 - val_accuracy: 0.9337\n",
      "Epoch 130/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1964 - accuracy: 0.9254 - val_loss: 0.1824 - val_accuracy: 0.9327\n",
      "Epoch 131/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1962 - accuracy: 0.9256 - val_loss: 0.1804 - val_accuracy: 0.9339\n",
      "Epoch 132/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1956 - accuracy: 0.9257 - val_loss: 0.1816 - val_accuracy: 0.9331\n",
      "Epoch 133/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1958 - accuracy: 0.9257 - val_loss: 0.1814 - val_accuracy: 0.9331\n",
      "Epoch 134/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1953 - accuracy: 0.9258 - val_loss: 0.1816 - val_accuracy: 0.9332\n",
      "Epoch 135/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1954 - accuracy: 0.9259 - val_loss: 0.1809 - val_accuracy: 0.9335\n",
      "Epoch 136/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1953 - accuracy: 0.9259 - val_loss: 0.1792 - val_accuracy: 0.9344\n",
      "Epoch 137/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1948 - accuracy: 0.9262 - val_loss: 0.1801 - val_accuracy: 0.9339\n",
      "Epoch 138/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1949 - accuracy: 0.9261 - val_loss: 0.1811 - val_accuracy: 0.9333\n",
      "Epoch 139/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1945 - accuracy: 0.9263 - val_loss: 0.1813 - val_accuracy: 0.9333\n",
      "Epoch 140/6000\n",
      "1250/1250 [==============================] - 64s 52ms/step - loss: 0.1947 - accuracy: 0.9262 - val_loss: 0.1799 - val_accuracy: 0.9341\n",
      "Epoch 141/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1943 - accuracy: 0.9265 - val_loss: 0.1805 - val_accuracy: 0.9338\n",
      "Epoch 142/6000\n",
      "1250/1250 [==============================] - 64s 52ms/step - loss: 0.1939 - accuracy: 0.9265 - val_loss: 0.1805 - val_accuracy: 0.9335\n",
      "Epoch 143/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1941 - accuracy: 0.9265 - val_loss: 0.1784 - val_accuracy: 0.9347\n",
      "Epoch 144/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1939 - accuracy: 0.9265 - val_loss: 0.1791 - val_accuracy: 0.9342\n",
      "Epoch 145/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1934 - accuracy: 0.9269 - val_loss: 0.1799 - val_accuracy: 0.9339\n",
      "Epoch 146/6000\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 0.1935 - accuracy: 0.9268 - val_loss: 0.1807 - val_accuracy: 0.9335\n",
      "Epoch 147/6000\n",
      "1250/1250 [==============================] - 67s 53ms/step - loss: 0.1933 - accuracy: 0.9268 - val_loss: 0.1798 - val_accuracy: 0.9340\n",
      "Epoch 148/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1932 - accuracy: 0.9269 - val_loss: 0.1800 - val_accuracy: 0.9341\n",
      "Epoch 149/6000\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 0.1928 - accuracy: 0.9272 - val_loss: 0.1774 - val_accuracy: 0.9352\n",
      "Epoch 150/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1928 - accuracy: 0.9272 - val_loss: 0.1788 - val_accuracy: 0.9343\n",
      "Epoch 151/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1928 - accuracy: 0.9271 - val_loss: 0.1789 - val_accuracy: 0.9345\n",
      "Epoch 152/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1925 - accuracy: 0.9272 - val_loss: 0.1767 - val_accuracy: 0.9358\n",
      "Epoch 153/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1924 - accuracy: 0.9273 - val_loss: 0.1769 - val_accuracy: 0.9355\n",
      "Epoch 154/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1922 - accuracy: 0.9274 - val_loss: 0.1770 - val_accuracy: 0.9355\n",
      "Epoch 155/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1920 - accuracy: 0.9276 - val_loss: 0.1766 - val_accuracy: 0.9358\n",
      "Epoch 156/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1919 - accuracy: 0.9277 - val_loss: 0.1766 - val_accuracy: 0.9357\n",
      "Epoch 157/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1917 - accuracy: 0.9277 - val_loss: 0.1754 - val_accuracy: 0.9362\n",
      "Epoch 158/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1913 - accuracy: 0.9278 - val_loss: 0.1781 - val_accuracy: 0.9349\n",
      "Epoch 159/6000\n",
      "1250/1250 [==============================] - 67s 53ms/step - loss: 0.1915 - accuracy: 0.9277 - val_loss: 0.1763 - val_accuracy: 0.9357\n",
      "Epoch 160/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1911 - accuracy: 0.9279 - val_loss: 0.1776 - val_accuracy: 0.9348\n",
      "Epoch 161/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1910 - accuracy: 0.9280 - val_loss: 0.1747 - val_accuracy: 0.9365\n",
      "Epoch 162/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1908 - accuracy: 0.9280 - val_loss: 0.1766 - val_accuracy: 0.9356\n",
      "Epoch 163/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1907 - accuracy: 0.9281 - val_loss: 0.1755 - val_accuracy: 0.9362\n",
      "Epoch 164/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1906 - accuracy: 0.9282 - val_loss: 0.1763 - val_accuracy: 0.9358\n",
      "Epoch 165/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1906 - accuracy: 0.9282 - val_loss: 0.1745 - val_accuracy: 0.9369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/6000\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 0.1905 - accuracy: 0.9281 - val_loss: 0.1744 - val_accuracy: 0.9369\n",
      "Epoch 167/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.1902 - accuracy: 0.9284 - val_loss: 0.1747 - val_accuracy: 0.9365\n",
      "Epoch 168/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.1901 - accuracy: 0.9282 - val_loss: 0.1765 - val_accuracy: 0.9354\n",
      "Epoch 169/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1899 - accuracy: 0.9284 - val_loss: 0.1760 - val_accuracy: 0.9357\n",
      "Epoch 170/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1896 - accuracy: 0.9287 - val_loss: 0.1760 - val_accuracy: 0.9358\n",
      "Epoch 171/6000\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 0.1897 - accuracy: 0.9286 - val_loss: 0.1758 - val_accuracy: 0.9358\n",
      "Epoch 172/6000\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 0.1896 - accuracy: 0.9287 - val_loss: 0.1755 - val_accuracy: 0.9362\n",
      "Epoch 173/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.1891 - accuracy: 0.9288 - val_loss: 0.1750 - val_accuracy: 0.9364\n",
      "Epoch 174/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1893 - accuracy: 0.9288 - val_loss: 0.1747 - val_accuracy: 0.9365\n",
      "Epoch 175/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1893 - accuracy: 0.9287 - val_loss: 0.1744 - val_accuracy: 0.9368\n",
      "Epoch 176/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1892 - accuracy: 0.9288 - val_loss: 0.1734 - val_accuracy: 0.9374\n",
      "Epoch 177/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1889 - accuracy: 0.9289 - val_loss: 0.1740 - val_accuracy: 0.9365\n",
      "Epoch 178/6000\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 0.1887 - accuracy: 0.9291 - val_loss: 0.1747 - val_accuracy: 0.9365\n",
      "Epoch 179/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1887 - accuracy: 0.9290 - val_loss: 0.1742 - val_accuracy: 0.9366\n",
      "Epoch 180/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1885 - accuracy: 0.9292 - val_loss: 0.1737 - val_accuracy: 0.9368\n",
      "Epoch 181/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1881 - accuracy: 0.9292 - val_loss: 0.1741 - val_accuracy: 0.9368\n",
      "Epoch 182/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1883 - accuracy: 0.9292 - val_loss: 0.1751 - val_accuracy: 0.9364\n",
      "Epoch 183/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1878 - accuracy: 0.9295 - val_loss: 0.1744 - val_accuracy: 0.9366\n",
      "Epoch 184/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1883 - accuracy: 0.9292 - val_loss: 0.1746 - val_accuracy: 0.9363\n",
      "Epoch 185/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1876 - accuracy: 0.9295 - val_loss: 0.1722 - val_accuracy: 0.9380\n",
      "Epoch 186/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1877 - accuracy: 0.9296 - val_loss: 0.1736 - val_accuracy: 0.9373\n",
      "Epoch 187/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1873 - accuracy: 0.9297 - val_loss: 0.1735 - val_accuracy: 0.9369\n",
      "Epoch 188/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1873 - accuracy: 0.9296 - val_loss: 0.1734 - val_accuracy: 0.9370\n",
      "Epoch 189/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1874 - accuracy: 0.9296 - val_loss: 0.1728 - val_accuracy: 0.9374\n",
      "Epoch 190/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1871 - accuracy: 0.9298 - val_loss: 0.1742 - val_accuracy: 0.9367\n",
      "Epoch 191/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1872 - accuracy: 0.9296 - val_loss: 0.1725 - val_accuracy: 0.9375\n",
      "Epoch 192/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1870 - accuracy: 0.9298 - val_loss: 0.1712 - val_accuracy: 0.9381\n",
      "Epoch 193/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1868 - accuracy: 0.9300 - val_loss: 0.1737 - val_accuracy: 0.9367\n",
      "Epoch 194/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1869 - accuracy: 0.9299 - val_loss: 0.1719 - val_accuracy: 0.9377\n",
      "Epoch 195/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1864 - accuracy: 0.9300 - val_loss: 0.1731 - val_accuracy: 0.9369\n",
      "Epoch 196/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1866 - accuracy: 0.9300 - val_loss: 0.1724 - val_accuracy: 0.9375\n",
      "Epoch 197/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1860 - accuracy: 0.9303 - val_loss: 0.1723 - val_accuracy: 0.9377\n",
      "Epoch 198/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1865 - accuracy: 0.9300 - val_loss: 0.1726 - val_accuracy: 0.9375\n",
      "Epoch 199/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1858 - accuracy: 0.9303 - val_loss: 0.1724 - val_accuracy: 0.9375\n",
      "Epoch 200/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1861 - accuracy: 0.9303 - val_loss: 0.1718 - val_accuracy: 0.9377\n",
      "Epoch 201/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1858 - accuracy: 0.9304 - val_loss: 0.1721 - val_accuracy: 0.9376\n",
      "Epoch 202/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1860 - accuracy: 0.9302 - val_loss: 0.1720 - val_accuracy: 0.9378\n",
      "Epoch 203/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1856 - accuracy: 0.9305 - val_loss: 0.1703 - val_accuracy: 0.9385\n",
      "Epoch 204/6000\n",
      "1250/1250 [==============================] - 68s 55ms/step - loss: 0.1856 - accuracy: 0.9304 - val_loss: 0.1743 - val_accuracy: 0.9366\n",
      "Epoch 205/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1855 - accuracy: 0.9304 - val_loss: 0.1713 - val_accuracy: 0.9382\n",
      "Epoch 206/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1854 - accuracy: 0.9305 - val_loss: 0.1726 - val_accuracy: 0.9372\n",
      "Epoch 207/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1851 - accuracy: 0.9308 - val_loss: 0.1691 - val_accuracy: 0.9391\n",
      "Epoch 208/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1851 - accuracy: 0.9309 - val_loss: 0.1721 - val_accuracy: 0.9376\n",
      "Epoch 209/6000\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 0.1850 - accuracy: 0.9307 - val_loss: 0.1714 - val_accuracy: 0.9385\n",
      "Epoch 210/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1849 - accuracy: 0.9308 - val_loss: 0.1724 - val_accuracy: 0.9373\n",
      "Epoch 211/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1850 - accuracy: 0.9308 - val_loss: 0.1708 - val_accuracy: 0.9384\n",
      "Epoch 212/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1845 - accuracy: 0.9310 - val_loss: 0.1701 - val_accuracy: 0.9387\n",
      "Epoch 213/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1847 - accuracy: 0.9309 - val_loss: 0.1691 - val_accuracy: 0.9393\n",
      "Epoch 214/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1845 - accuracy: 0.9311 - val_loss: 0.1701 - val_accuracy: 0.9387\n",
      "Epoch 215/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1841 - accuracy: 0.9312 - val_loss: 0.1699 - val_accuracy: 0.9394\n",
      "Epoch 216/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.1841 - accuracy: 0.9312 - val_loss: 0.1705 - val_accuracy: 0.9386\n",
      "Epoch 217/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1844 - accuracy: 0.9310 - val_loss: 0.1704 - val_accuracy: 0.9384\n",
      "Epoch 218/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1839 - accuracy: 0.9312 - val_loss: 0.1698 - val_accuracy: 0.9387\n",
      "Epoch 219/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1839 - accuracy: 0.9312 - val_loss: 0.1700 - val_accuracy: 0.9388\n",
      "Epoch 220/6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.1840 - accuracy: 0.9311 - val_loss: 0.1699 - val_accuracy: 0.9388\n",
      "Epoch 221/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.1836 - accuracy: 0.9315 - val_loss: 0.1696 - val_accuracy: 0.9390\n",
      "Epoch 222/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1835 - accuracy: 0.9315 - val_loss: 0.1696 - val_accuracy: 0.9388\n",
      "Epoch 223/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1833 - accuracy: 0.9316 - val_loss: 0.1687 - val_accuracy: 0.9394\n",
      "Epoch 224/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1833 - accuracy: 0.9314 - val_loss: 0.1691 - val_accuracy: 0.9392\n",
      "Epoch 225/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1833 - accuracy: 0.9315 - val_loss: 0.1702 - val_accuracy: 0.9384\n",
      "Epoch 226/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1832 - accuracy: 0.9316 - val_loss: 0.1701 - val_accuracy: 0.9385\n",
      "Epoch 227/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1832 - accuracy: 0.9316 - val_loss: 0.1693 - val_accuracy: 0.9392\n",
      "Epoch 228/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1830 - accuracy: 0.9317 - val_loss: 0.1694 - val_accuracy: 0.9391\n",
      "Epoch 229/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1829 - accuracy: 0.9317 - val_loss: 0.1686 - val_accuracy: 0.9396\n",
      "Epoch 230/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1828 - accuracy: 0.9318 - val_loss: 0.1704 - val_accuracy: 0.9383\n",
      "Epoch 231/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1826 - accuracy: 0.9319 - val_loss: 0.1701 - val_accuracy: 0.9386\n",
      "Epoch 232/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1827 - accuracy: 0.9318 - val_loss: 0.1683 - val_accuracy: 0.9395\n",
      "Epoch 233/6000\n",
      "1250/1250 [==============================] - 66s 52ms/step - loss: 0.1826 - accuracy: 0.9319 - val_loss: 0.1693 - val_accuracy: 0.9390\n",
      "Epoch 234/6000\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 0.1825 - accuracy: 0.9319 - val_loss: 0.1682 - val_accuracy: 0.9397\n",
      "Epoch 235/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1821 - accuracy: 0.9322 - val_loss: 0.1680 - val_accuracy: 0.9397\n",
      "Epoch 236/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1825 - accuracy: 0.9319 - val_loss: 0.1688 - val_accuracy: 0.9394\n",
      "Epoch 237/6000\n",
      "1250/1250 [==============================] - 64s 52ms/step - loss: 0.1822 - accuracy: 0.9320 - val_loss: 0.1697 - val_accuracy: 0.9387\n",
      "Epoch 238/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1824 - accuracy: 0.9319 - val_loss: 0.1697 - val_accuracy: 0.9388\n",
      "Epoch 239/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1819 - accuracy: 0.9322 - val_loss: 0.1686 - val_accuracy: 0.9396\n",
      "Epoch 240/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1819 - accuracy: 0.9321 - val_loss: 0.1685 - val_accuracy: 0.9394\n",
      "Epoch 241/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1816 - accuracy: 0.9323 - val_loss: 0.1678 - val_accuracy: 0.9396\n",
      "Epoch 242/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1817 - accuracy: 0.9324 - val_loss: 0.1682 - val_accuracy: 0.9394\n",
      "Epoch 243/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1817 - accuracy: 0.9323 - val_loss: 0.1699 - val_accuracy: 0.9386\n",
      "Epoch 244/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1819 - accuracy: 0.9322 - val_loss: 0.1709 - val_accuracy: 0.9381\n",
      "Epoch 245/6000\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 0.1813 - accuracy: 0.9324 - val_loss: 0.1689 - val_accuracy: 0.9392\n",
      "Epoch 246/6000\n",
      "1250/1250 [==============================] - 64s 52ms/step - loss: 0.1815 - accuracy: 0.9324 - val_loss: 0.1678 - val_accuracy: 0.9400\n",
      "Epoch 247/6000\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 0.1811 - accuracy: 0.9325 - val_loss: 0.1671 - val_accuracy: 0.9399\n",
      "Epoch 248/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1811 - accuracy: 0.9325 - val_loss: 0.1703 - val_accuracy: 0.9384\n",
      "Epoch 249/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1810 - accuracy: 0.9326 - val_loss: 0.1676 - val_accuracy: 0.9400\n",
      "Epoch 250/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.1812 - accuracy: 0.9324 - val_loss: 0.1680 - val_accuracy: 0.9398\n",
      "Epoch 251/6000\n",
      "1250/1250 [==============================] - 64s 52ms/step - loss: 0.1808 - accuracy: 0.9327 - val_loss: 0.1663 - val_accuracy: 0.9407\n",
      "Epoch 252/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1808 - accuracy: 0.9327 - val_loss: 0.1673 - val_accuracy: 0.9400\n",
      "Epoch 253/6000\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 0.1807 - accuracy: 0.9327 - val_loss: 0.1690 - val_accuracy: 0.9390\n",
      "Epoch 254/6000\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 0.1806 - accuracy: 0.9328 - val_loss: 0.1700 - val_accuracy: 0.9385\n",
      "Epoch 255/6000\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 0.1808 - accuracy: 0.9328 - val_loss: 0.1663 - val_accuracy: 0.9407\n",
      "Epoch 256/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1806 - accuracy: 0.9328 - val_loss: 0.1677 - val_accuracy: 0.9401\n",
      "Epoch 257/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1805 - accuracy: 0.9329 - val_loss: 0.1658 - val_accuracy: 0.9408\n",
      "Epoch 258/6000\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 0.1804 - accuracy: 0.9331 - val_loss: 0.1671 - val_accuracy: 0.9403\n",
      "Epoch 259/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1804 - accuracy: 0.9330 - val_loss: 0.1664 - val_accuracy: 0.9405\n",
      "Epoch 260/6000\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 0.1803 - accuracy: 0.9329 - val_loss: 0.1670 - val_accuracy: 0.9400\n",
      "Epoch 261/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1799 - accuracy: 0.9330 - val_loss: 0.1659 - val_accuracy: 0.9407\n",
      "Epoch 262/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1798 - accuracy: 0.9331 - val_loss: 0.1666 - val_accuracy: 0.9403\n",
      "Epoch 263/6000\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 0.1800 - accuracy: 0.9331 - val_loss: 0.1668 - val_accuracy: 0.9401\n",
      "Epoch 264/6000\n",
      "1250/1250 [==============================] - 67s 53ms/step - loss: 0.1799 - accuracy: 0.9330 - val_loss: 0.1658 - val_accuracy: 0.9408\n",
      "Epoch 265/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1792 - accuracy: 0.9335 - val_loss: 0.1664 - val_accuracy: 0.9403\n",
      "Epoch 266/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1796 - accuracy: 0.9333 - val_loss: 0.1667 - val_accuracy: 0.9403\n",
      "Epoch 267/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1796 - accuracy: 0.9333 - val_loss: 0.1677 - val_accuracy: 0.9401\n",
      "Epoch 268/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1796 - accuracy: 0.9334 - val_loss: 0.1668 - val_accuracy: 0.9401\n",
      "Epoch 269/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1792 - accuracy: 0.9334 - val_loss: 0.1679 - val_accuracy: 0.9395\n",
      "Epoch 270/6000\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 0.1793 - accuracy: 0.9334 - val_loss: 0.1669 - val_accuracy: 0.9403\n",
      "Epoch 271/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1795 - accuracy: 0.9334 - val_loss: 0.1660 - val_accuracy: 0.9405\n",
      "Epoch 272/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1792 - accuracy: 0.9334 - val_loss: 0.1675 - val_accuracy: 0.9393\n",
      "Epoch 273/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1792 - accuracy: 0.9334 - val_loss: 0.1656 - val_accuracy: 0.9405\n",
      "Epoch 274/6000\n",
      "1250/1250 [==============================] - 64s 52ms/step - loss: 0.1787 - accuracy: 0.9336 - val_loss: 0.1664 - val_accuracy: 0.9403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.1789 - accuracy: 0.9336 - val_loss: 0.1664 - val_accuracy: 0.9405\n",
      "Epoch 276/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.1788 - accuracy: 0.9336 - val_loss: 0.1655 - val_accuracy: 0.9409\n",
      "Epoch 277/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1787 - accuracy: 0.9337 - val_loss: 0.1660 - val_accuracy: 0.9405\n",
      "Epoch 278/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1786 - accuracy: 0.9337 - val_loss: 0.1641 - val_accuracy: 0.9417\n",
      "Epoch 279/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.1790 - accuracy: 0.9335 - val_loss: 0.1662 - val_accuracy: 0.9405\n",
      "Epoch 280/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.1783 - accuracy: 0.9339 - val_loss: 0.1679 - val_accuracy: 0.9394\n",
      "Epoch 281/6000\n",
      "1250/1250 [==============================] - 67s 53ms/step - loss: 0.1783 - accuracy: 0.9340 - val_loss: 0.1658 - val_accuracy: 0.9407\n",
      "Epoch 282/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1783 - accuracy: 0.9339 - val_loss: 0.1671 - val_accuracy: 0.9400\n",
      "Epoch 283/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1781 - accuracy: 0.9339 - val_loss: 0.1665 - val_accuracy: 0.9400\n",
      "Epoch 284/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1781 - accuracy: 0.9339 - val_loss: 0.1642 - val_accuracy: 0.9416\n",
      "Epoch 285/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.1782 - accuracy: 0.9339 - val_loss: 0.1646 - val_accuracy: 0.9413\n",
      "Epoch 286/6000\n",
      "1250/1250 [==============================] - 63s 50ms/step - loss: 0.1780 - accuracy: 0.9340 - val_loss: 0.1660 - val_accuracy: 0.9405\n",
      "Epoch 287/6000\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.1781 - accuracy: 0.9340 - val_loss: 0.1656 - val_accuracy: 0.9407\n",
      "Epoch 288/6000\n",
      "1250/1250 [==============================] - 69s 56ms/step - loss: 0.1779 - accuracy: 0.9340 - val_loss: 0.1640 - val_accuracy: 0.9415\n",
      "Epoch 289/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1778 - accuracy: 0.9341 - val_loss: 0.1653 - val_accuracy: 0.9407\n",
      "Epoch 290/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1778 - accuracy: 0.9339 - val_loss: 0.1658 - val_accuracy: 0.9405\n",
      "Epoch 291/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1776 - accuracy: 0.9341 - val_loss: 0.1647 - val_accuracy: 0.9411\n",
      "Epoch 292/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1777 - accuracy: 0.9340 - val_loss: 0.1650 - val_accuracy: 0.9409\n",
      "Epoch 293/6000\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 0.1775 - accuracy: 0.9341 - val_loss: 0.1635 - val_accuracy: 0.9416\n",
      "Epoch 293: early stopping\n",
      "##########################################################################\n",
      "/UltimeTradingBot/Data/TRX-USDT-tp70_w14_max7min_Model_v1.hdf5\n",
      "------val_accuracy-----> 94.17 | 93.41 <----------accuracy----------\n"
     ]
    }
   ],
   "source": [
    "IN_DIM=dt.shape[1]-1\n",
    "model = Sequential()\n",
    "model.add(Dense(int(250),input_dim=IN_DIM,activation='relu')) #( 100=>66.23)\n",
    "# resultus withe 250 d0.3 50 d 20 d 8 = 65.6% vs  65.49 no droppout vs 65.78 d0.5 vs 65.68 d0.4 # 65.48 # one dropout of   0.5 = 66.11   #tanh 66.33 accuracy #softmax 66.12 #softplus 66.5 # sigmoid 66.21 / \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(int(20),activation='relu')) # best softplus 66.26(69) vs relu 66.65(70)  / -20 => 66.25 /250 ->65.78\n",
    "#model2.add(Dropout(0.1)) #5=> 66.00  66.21 vs no dopout 66.28\n",
    "#model2.add(Dense(int(20),activation='relu')) # disabled 6.24\n",
    "model.add(Dense(int(50),activation='relu')) # -4 -> -> 66.24\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "print(model.summary())\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "callbacks_a = ModelCheckpoint(filepath =Model_FileName,monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "callbacks_b = EarlyStopping(monitor ='val_accuracy',mode='auto',patience=15,verbose=1)\n",
    "history = model.fit(dt[index_20pct:, 0:-1],\n",
    "                dt[index_20pct:,-1],\n",
    "                validation_data=(dt[:index_20pct, :-1],dt[:index_20pct,-1]),\n",
    "                epochs=6000,\n",
    "                batch_size=256*10,\n",
    "                callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "print('##########################################################################')\n",
    "print(MODEL_FILE.replace(\"/UltimeTradingBot/Data/\", \"/UltimeTradingBot/Data/\"+pair.replace(\"/\", \"-\")+\"-\"))\n",
    "print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "#ResJS[pair]='{0:.4g}'.format(max(history.history['val_accuracy'])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(2):\n",
    "#if True:    \n",
    "    tv=ii\n",
    "    try : \n",
    "      PRED=model2.predict(dt[:,:-1]).round()\n",
    "      REAL_PRED=np.array(((PRED[:,0]==1) & (Y==1)),dtype=float)\n",
    "      dt[:,-1]=REAL_PRED\n",
    "      print(f\"--------------------Real prediction mean: {REAL_PRED.mean()} ---------------------------\")\n",
    "      del model2\n",
    "      del history\n",
    "    except: print(\"first time or error\")\n",
    "    gc.collect()\n",
    "    if True:\n",
    "        IN_DIM=dt.shape[1]-1\n",
    "        model2 = Sequential()\n",
    "        model2.add(Dense(int(100),input_dim=IN_DIM,activation='relu')) #( 100=>66.23)\n",
    "        # resultus withe 250 d0.3 50 d 20 d 8 = 65.6% vs  65.49 no droppout vs 65.78 d0.5 vs 65.68 d0.4 # 65.48 # one dropout of   0.5 = 66.11   #tanh 66.33 accuracy #softmax 66.12 #softplus 66.5 # sigmoid 66.21 / \n",
    "        model2.add(Dropout(0.5))\n",
    "        model2.add(Dense(int(20),activation='relu')) # best softplus 66.26(69) vs relu 66.65(70)  / -20 => 66.25 /250 ->65.78\n",
    "        #model2.add(Dropout(0.1)) #5=> 66.00  66.21 vs no dopout 66.28\n",
    "        #model2.add(Dense(int(20),activation='relu')) # disabled 6.24\n",
    "        model2.add(Dense(int(5),activation='relu')) # -4 -> -> 66.24\n",
    "        model2.add(Dense(1,activation='sigmoid'))\n",
    "        print(model2.summary())\n",
    "        model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        callbacks_a = ModelCheckpoint(filepath =MODEL_FILE+f\"{tv}.multi_train.h5\",monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "        callbacks_b = EarlyStopping(monitor ='val_accuracy',mode='auto',patience=15,verbose=1)\n",
    "        history = model2.fit(dt[index_20pct:, 0:-1],\n",
    "                        dt[index_20pct:,-1],\n",
    "                        validation_data=(dt[:index_20pct, :-1],Y[:index_20pct]),\n",
    "                        epochs=6000,\n",
    "                        batch_size=100000,\n",
    "                        callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "        print('##########################################################################')\n",
    "        print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "        #94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 16:50:24.967357: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7926480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102188/102188 [==============================] - 239s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction2=(model.predict( dt[:, 0:-1])).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "False_prediction=dt[:index_20pct,-1][(prediction2[:index_20pct].transpose()[0]!=Y[:index_20pct])]\n",
    "True_prediction=dt[:index_20pct,-1][(prediction2[:index_20pct].transpose()[0]==Y[:index_20pct])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction mean :54.65825796127319 %#### the colose to 50 the better\n",
      "False prediction class 0 :7.528899082568807 %#### it mean that x of the 0 class are wrong the buyed witch lead the losses\n",
      "False prediction class 1 :2.6438837920489298 %#### we don't buy x % of the correct chanses\n",
      "True prediction class 0 :42.52645259938838 %#### it mean that 40 % of class 0 are predicted correctly\n",
      "True prediction class 1 :47.300764525993884 %#### the only buying correct of all\n",
      "successful buy pct of unsuccessfull: 86.2685659785937  %\n"
     ]
    }
   ],
   "source": [
    "fp0=False_prediction[False_prediction==0].shape[0]*100/index_20pct #### it mean that 11.73 of the 0 class are wrong the buyed witch lead the losses\n",
    "print( f\"Prediction mean :{prediction2.mean()*100} %\"+'#### the colose to 50 the better')\n",
    "print( f\"False prediction class 0 :{fp0} %\"+'#### it mean that x of the 0 class are wrong the buyed witch lead the losses')\n",
    "fp1=False_prediction[False_prediction==1].shape[0]*100/index_20pct   #### we don't buy x % of the correct chanses\n",
    "print( f\"False prediction class 1 :{fp1} %\"+'#### we don\\'t buy x % of the correct chanses')\n",
    "trp0=True_prediction[True_prediction==0].shape[0]*100/index_20pct   #### it mean that 40 % of class 0 are predicted correctly\n",
    "trp1=True_prediction[True_prediction==1].shape[0]*100/index_20pct     #### the only buying correct of all\n",
    "print( f\"True prediction class 0 :{trp0} %\"+'#### it mean that 40 % of class 0 are predicted correctly')\n",
    "print( f\"True prediction class 1 :{trp1} %\"+'#### the only buying correct of all')\n",
    "print(f\"successful buy pct of unsuccessfull: {100*trp1/(trp1+fp0)}  %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(dt[:index_20pct,:-1], Y[:index_20pct]) #3-> 66.76 / 4 -> 65.75\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"../buy_model_w10_tp1.2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #minimodel\n",
    "# if True:\n",
    "#     IN_DIM=len(mean)\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(int(IN_DIM/2),input_dim=IN_DIM,activation='tanh'))\n",
    "#     model.add(Dense(int(IN_DIM/3),activation='tanh'))\n",
    "#     model.add(Dense(int(IN_DIM/1),activation='relu'))\n",
    "#     model.add(Dense(1,activation='sigmoid'))\n",
    "#     print(model.summary())\n",
    "#     model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#     callbacks_a = ModelCheckpoint(filepath=Model_FileName,monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "#     callbacks_b = EarlyStopping(monitor ='accuracy',mode='auto',patience=50,verbose=1)\n",
    "#     history = model.fit(XTRAIN,\n",
    "#                     YTRAIN,\n",
    "#                     validation_data=(XVALIDATION,YVALIDATION),\n",
    "#                     epochs=6000,\n",
    "#                     batch_size=128*500,\n",
    "#                     callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "#     print('##########################################################################')\n",
    "#     print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(Model_FileName+\"minx.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #minimodel\n",
    "# if True:\n",
    "#     IN_DIM=len(mean)\n",
    "#     model3 = Sequential()\n",
    "#     model3.add(Dense(int(25),input_dim=IN_DIM,activation='tanh'))\n",
    "#     model3.add(Dense(int(10),activation='relu'))\n",
    "#     model3.add(Dense(int(10),activation='relu'))\n",
    "#     model3.add(Dense(1,activation='sigmoid'))\n",
    "#     print(model3.summary())\n",
    "#     model3.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#     callbacks_a = ModelCheckpoint(filepath=Model_FileName+\"fast.h5\",monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "#     callbacks_b = EarlyStopping(monitor ='accuracy',mode='auto',patience=50,verbose=1)\n",
    "#     history = model3.fit(XTRAIN,\n",
    "#                     YTRAIN,\n",
    "#                     validation_data=(XVALIDATION,YVALIDATION),\n",
    "#                     epochs=6000,\n",
    "#                     batch_size=128*500,\n",
    "#                     callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "#     print('##########################################################################')\n",
    "#     print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #minimodel\n",
    "# if True:\n",
    "#     IN_DIM=len(mean)\n",
    "#     model3 = Sequential()\n",
    "#     model3.add(Dense(int(IN_DIM),input_dim=IN_DIM,activation='tanh'))\n",
    "#     model3.add(Dense(int(40),activation='relu'))\n",
    "#     model3.add(Dense(int(40),activation='relu'))\n",
    "#     model3.add(Dense(int(10),activation='relu'))\n",
    "#     model3.add(Dense(1,activation='sigmoid'))\n",
    "#     print(model3.summary())\n",
    "#     model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#     callbacks_a = ModelCheckpoint(filepath=Model_FileName,monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "#     callbacks_b = EarlyStopping(monitor ='accuracy',mode='auto',patience=50,verbose=1)\n",
    "#     history = model.fit(XTRAIN,\n",
    "#                     YTRAIN,\n",
    "#                     validation_data=(XVALIDATION,YVALIDATION),\n",
    "#                     epochs=6000,\n",
    "#                     batch_size=128*500,\n",
    "#                     callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "#     print('##########################################################################')\n",
    "#     print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True:\n",
    "#     IN_DIM=len(mean)\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(int(IN_DIM/1),input_dim=IN_DIM,activation='relu'))\n",
    "#     model.add(Dense(int(IN_DIM/1),activation='softplus'))\n",
    "#     model.add(Dense(int(IN_DIM/3),activation='relu'))\n",
    "#     model.add(Dense(int(IN_DIM/3),activation='relu'))\n",
    "#     model.add(Dense(int(IN_DIM/6),activation='relu'))\n",
    "#     model.add(Dense(1,activation='sigmoid'))\n",
    "#     print(model.summary())\n",
    "#     model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#     callbacks_a = ModelCheckpoint(filepath =MODEL_FILE,monitor ='val_loss',save_best_only = True, save_weights = True)\n",
    "#     callbacks_b = EarlyStopping(monitor ='val_loss',mode='auto',patience=30,verbose=1)\n",
    "#     history = model.fit(XTRAIN,\n",
    "#                     YTRAIN,\n",
    "#                     validation_data=(XVALIDATION,YVALIDATION),\n",
    "#                     epochs=6000,\n",
    "#                     batch_size=128*500,\n",
    "#                     callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "#     print('##########################################################################')\n",
    "#     print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "#     #94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Mega fast import\n",
    "# import numba as nb\n",
    "# import numpy as np\n",
    "# import os\n",
    "# os.environ[ 'NUMBA_CACHE_DIR' ] = '/UltimeTradingBot/Data/csv/tmp/'\n",
    "\n",
    "# @nb.njit('float64[:,:](uint8[::1],)', cache=True)\n",
    "# def decode_csv_buffer(rawData):\n",
    "#     COMMA = np.uint8(ord(','))\n",
    "#     CR = np.uint8(ord('\\r'))\n",
    "#     LF = np.uint8(ord('\\n'))\n",
    "#     ZERO = np.uint8(ord('0'))\n",
    "\n",
    "#     # Find the size of the matrix (`n`)\n",
    "\n",
    "#     n = 0\n",
    "#     lineSize = 0\n",
    "\n",
    "#     for i in range(rawData.size):\n",
    "#         c = rawData[i]\n",
    "#         if c == CR or c == LF:\n",
    "#             break\n",
    "#         n += rawData[i] == COMMA\n",
    "#         lineSize += 1\n",
    "    \n",
    "#     n += 1\n",
    "\n",
    "#     # Empty matrix\n",
    "#     if lineSize == 0:\n",
    "#         return np.empty((0, 0), dtype=np.float64)\n",
    "\n",
    "#     # Initialization\n",
    "\n",
    "#     res = np.empty(n * n, dtype=np.float64)\n",
    "\n",
    "#     # Fill the matrix\n",
    "\n",
    "#     curInt = 0\n",
    "#     curPos = 0\n",
    "#     lastCharIsDigit = True\n",
    "\n",
    "#     for i in range(len(rawData)):\n",
    "#         c = rawData[i]\n",
    "#         if c == CR or c == LF or c == COMMA:\n",
    "#             if lastCharIsDigit:\n",
    "#                 # Write the last int in the flatten matrix\n",
    "#                 res[curPos] = curInt\n",
    "#                 curPos += 1\n",
    "#                 curInt = 0\n",
    "#             lastCharIsDigit = False\n",
    "#         else:\n",
    "#             curInt = curInt * 10 + (c - ZERO)\n",
    "#             lastCharIsDigit = True\n",
    "\n",
    "#     return res.reshape(n, n)\n",
    "# def load_numba(filename):\n",
    "#     # Load fully the file in a raw memory buffer\n",
    "#     rawData = np.fromfile(filename, dtype=np.uint8)\n",
    "\n",
    "#     # Decode the buffer using the Numba JIT\n",
    "#     # This method only work for your specific needs and \n",
    "#     # can simply crash if the file content is invalid.\n",
    "#     return decode_csv_buffer(rawData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename='/UltimeTradingBot/Data/csv/W20F4minP35.csv'\n",
    "\n",
    "# dt=load_numba(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not TESTING_MOD:\n",
    "#     IN_DIM=len(mean)\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(int(IN_DIM/2),input_dim=IN_DIM,activation='softplus'))\n",
    "#     model.add(Dense(int(IN_DIM/2),activation='relu'))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(Dense(int(IN_DIM/5),activation='softplus'))\n",
    "#     model.add(Dense(int(IN_DIM/4),activation='softmax'))\n",
    "#     model.add(Dense(int(IN_DIM/1),activation='softplus'))\n",
    "#     model.add(Dense(1,activation='sigmoid'))\n",
    "#     print(model.summary())\n",
    "#     #model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "#     # model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#     # callbacks_a = ModelCheckpoint(filepath=Model_FileName+'.sftp.hdf5',monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "#     # callbacks_b = EarlyStopping(monitor ='val_accuracy',mode='auto',patience=10,verbose=1)\n",
    "#     model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#     callbacks_a = ModelCheckpoint(filepath=Model_FileName+'.sftp.hdf5',monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "#     callbacks_b = EarlyStopping(monitor ='val_accuracy',mode='auto',patience=10,verbose=1)\n",
    "#     history = model.fit(XTRAIN,\n",
    "#                     YTRAIN,\n",
    "#                     validation_data=(XVALIDATION,YVALIDATION),\n",
    "#                     epochs=6000,\n",
    "#                     batch_size=128*500,\n",
    "#                     callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "#     print('##########################################################################')\n",
    "#     print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "#     #94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('##########################################################################')\n",
    "print(f'Input shape: {XVALIDATION.shape}')\n",
    "print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt=df.to_numpy()\n",
    "#if TESTING_MOD:\n",
    "normalize(dt[:,0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(Model_FileName)\n",
    "\n",
    "print(Model_FileName+' Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth.iloc[:,:-8].reset_index().reset_index().drop(columns=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dteth=eth.iloc[:,:-8].reset_index().reset_index().drop(columns=\"date\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peth=model.predict(dteth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import tensorflow as tf\n",
    "dt=np.nan_to_num(dt)\n",
    "\n",
    "dt=tf.convert_to_tensor(dt, dtype=tf.float32)\n",
    "#dt==dt.astype(np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "XVALIDATION[YVALIDATION==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX0=XVALIDATION[YVALIDATION==0]\n",
    "YY0=YVALIDATION[YVALIDATION==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_SEP=int(XX0.shape[0]/4)\n",
    "XX0Train=XX0[INDEX_SEP:]\n",
    "YY0Train=YY0[INDEX_SEP:]\n",
    "\n",
    "XX0Val=XX0[:INDEX_SEP]\n",
    "YY0Val=YY0[:INDEX_SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX1=XVALIDATION[YVALIDATION==1]\n",
    "YY1=YVALIDATION[YVALIDATION==1]\n",
    "\n",
    "INDEX_SEP=int(XX1.shape[0]/4)\n",
    "XX1Train=XX1[INDEX_SEP:]\n",
    "YY1Train=YY1[INDEX_SEP:]\n",
    "\n",
    "XX1Val=XX1[:INDEX_SEP]\n",
    "YY1Val=YY1[:INDEX_SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy0 = model.evaluate(XX0, YY0)\n",
    "accuracy1 = model.evaluate(XX1, YY1)\n",
    "accuracy = model.evaluate(XVALIDATION, YVALIDATION)\n",
    "\n",
    "print(f\"class 0: {format(accuracy0[1]*100,'0.2f')} %\")\n",
    "print(f\"class 1: {format(accuracy1[1]*100,'0.2f')} %\")\n",
    "print(f\"FULL class : {format(accuracy[1]*100,'0.2f')} %\")\n",
    "\n",
    "#accuracy = model.evaluate(dt[:,0:-1], dt[:,-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.evaluate(XTRAIN, YTRAIN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"class 0: {format(accuracy0[1]*100,'0.2f')} %\")\n",
    "print(f\"class 1: {format(accuracy1[1]*100,'0.2f')} %\")\n",
    "print(f\"FULL class : {format(accuracy[1]*100,'0.2f')} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(Model_FileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_FileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XXXX=np.concatenate((XTRAIN,XX0Train))\n",
    "YYYY=np.concatenate((YTRAIN,YY0Train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XXXX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True:\n",
    "#     IN_DIM=len(mean)\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(int(IN_DIM/1),input_dim=IN_DIM,activation='relu'))\n",
    "#     model.add(Dense(int(IN_DIM/1),activation='softplus'))\n",
    "#     model.add(Dense(int(IN_DIM/3),activation='relu'))\n",
    "#     model.add(Dense(int(IN_DIM/3),activation='relu'))\n",
    "#     model.add(Dense(int(IN_DIM/6),activation='relu'))\n",
    "#     model.add(Dense(1,activation='sigmoid'))\n",
    "#     print(model.summary())\n",
    "#     model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#     callbacks_a = ModelCheckpoint(filepath =MODEL_FILE+\".z.h5\",monitor ='val_loss',save_best_only = True, save_weights = True)\n",
    "#     callbacks_b = EarlyStopping(monitor ='val_loss',mode='auto',patience=5,verbose=1)\n",
    "#     history = model.fit(XXXX,\n",
    "#                     YYYY,\n",
    "#                     validation_data=(XX0Val,YY0Val),\n",
    "#                     epochs=6000,\n",
    "#                     batch_size=128*500,\n",
    "#                     callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "#     print('##########################################################################')\n",
    "#     print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "#     #94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True:\n",
    "#     IN_DIM=len(mean)\n",
    "#     model2 = Sequential()\n",
    "#     model2.add(Dense(int(IN_DIM/1),input_dim=IN_DIM,activation='tanh'))\n",
    "#     model2.add(Dropout(0.3))\n",
    "#     model2.add(Dense(int(IN_DIM/1),activation='relu'))\n",
    "#     model2.add(Dropout(0.3))\n",
    "#     model2.add(Dense(int(IN_DIM/3),activation='relu'))\n",
    "#     model2.add(Dropout(0.3))\n",
    "#     model2.add(Dense(int(IN_DIM/3),activation='relu'))\n",
    "#     model2.add(Dropout(0.3))\n",
    "#     model2.add(Dense(int(IN_DIM/12),activation='relu'))\n",
    "#     model2.add(Dense(1,activation='sigmoid'))\n",
    "#     print(model2.summary())\n",
    "#     model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#     callbacks_a = ModelCheckpoint(filepath =MODEL_FILE+\".z2.h5\",monitor ='val_loss',save_best_only = True, save_weights = True)\n",
    "#     callbacks_b = EarlyStopping(monitor ='val_loss',mode='auto',patience=5,verbose=1)\n",
    "#     history = model2.fit(XXXX,\n",
    "#                     YYYY,\n",
    "#                     validation_data=(XX0Val,YY0Val),\n",
    "#                     epochs=6000,\n",
    "#                     batch_size=55555,\n",
    "#                     callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "#     print('##########################################################################')\n",
    "#     print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "#     #94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True:\n",
    "#     IN_DIM=len(mean)\n",
    "#     model2 = Sequential()\n",
    "#     model2.add(Dense(int(IN_DIM),input_dim=IN_DIM,activation='tanh'))\n",
    "#     model2.add(Dropout(0.3))\n",
    "#     model2.add(Dense(int(100),activation='relu'))\n",
    "#     model2.add(Dropout(0.3))\n",
    "#     model2.add(Dense(int(50),activation='relu'))\n",
    "#     model2.add(Dropout(0.3))\n",
    "#     model2.add(Dense(int(20),activation='relu'))\n",
    "#     model2.add(Dropout(0.3))\n",
    "#     model2.add(Dense(int(10),activation='relu'))\n",
    "#     model2.add(Dense(1,activation='sigmoid'))\n",
    "#     print(model2.summary())\n",
    "#     model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#     callbacks_a = ModelCheckpoint(filepath =MODEL_FILE+\".z4.h5\",monitor ='val_loss',save_best_only = True, save_weights = True)\n",
    "#     callbacks_b = EarlyStopping(monitor ='val_loss',mode='auto',patience=5,verbose=1)\n",
    "#     history = model2.fit(XXXX,\n",
    "#                     YYYY,\n",
    "#                     validation_data=(XX0Val,YY0Val),\n",
    "#                     epochs=6000,\n",
    "#                     batch_size=55555,\n",
    "#                     callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "#     print('##########################################################################')\n",
    "#     print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "#     #94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retest\n",
    "accuracy0 = model2.evaluate(XX0, YY0)\n",
    "accuracy1 = model2.evaluate(XX1, YY1)\n",
    "accuracy = model2.evaluate(XVALIDATION, YVALIDATION)\n",
    "\n",
    "print(f\"class 0: {accuracy0[1]*100}%\")\n",
    "print(f\"class 1: {accuracy1[1]*100}%\")\n",
    "print(f\"FULL Model : {accuracy[1]*100}%\")\n",
    "\n",
    "#accuracy = model.evaluate(dt[:,0:-1], dt[:,-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # make probability predictions with the model\n",
    "# predictions = model.predict(dt[0:,0:-1])\n",
    "# # round predictions \n",
    "# rounded = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(rounded)/len(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YVALIDATION[1002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Buy_Dessision(input):\n",
    "    predictions = model.predict(XVALIDATION)\n",
    "    rounded = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Costumaize buy condition here\n",
    "def buy_only(df,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=3):\n",
    "    try:\n",
    "        \n",
    "        ## test param\n",
    "        #BUY_PCT=1\n",
    "        #window=15\n",
    "        print (f\"---buy_only--- Buy pct: {BUY_PCT}%\")\n",
    "        mino=BUY_PCT*0.01\n",
    "        maxo=-SELL_PCT*0.01\n",
    "        codep1='df[\"b\"]=((('\n",
    "        for i in range(1,window):\n",
    "            codep1=codep1+'df[\"high\"].shift(periods='+str(-i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino )| (('\n",
    "        codep2='df[\"high\"].shift(periods='+str(-window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] >=mino)).replace({False: 0, True: 1})'\n",
    "        code=codep1+codep2\n",
    "        prerr(code)\n",
    "        exec(code)\n",
    "\n",
    "        \n",
    "        codep1='df[\"sell\"]=((( '\n",
    "        for i in range(1,window):\n",
    "            codep1=codep1+'df[\"low\"].shift(periods='+str(-i)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] <=maxo ) | (('\n",
    "        codep2='df[\"low\"].shift(periods='+str(-window)+', freq=None, axis=0, fill_value=None)-df[\"high\"])/df[\"high\"] <=maxo )).replace({False: 0, True: 1})'\n",
    "        code=codep1+codep2\n",
    "        prerr(code)\n",
    "        exec(code)\n",
    "\n",
    "        df[\"buy\"]=((df['b']==1 ) & (df['sell']==0)).replace({False: 0, True: 1})\n",
    "        \n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error buy only\")\n",
    "        print(e)\n",
    "    p=df.pop(\"b\")\n",
    "    p=df.pop(\"sell\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_expand3(pair=\"LTC/USDT\",i=0,j=10000,window=2,metadata=MetaData,high_weight=3,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT):\n",
    "    Pair_Full=full_expand(df_list1m[pair].iloc[i:j],df_list5m[pair],df_list15m[pair],df_list1h[pair],df_list1d[pair],window)\n",
    "    BTC_Full=full_expand(\n",
    "        df_list1m[\"BTC/USDT\"].loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" d\")).round(freq='1 min'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        df_list5m[\"BTC/USDT\"],#.loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" d\")).round(freq='5 min'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        df_list15m[\"BTC/USDT\"],#.loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" day\")).round(freq='15 min'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        df_list1h[\"BTC/USDT\"],#.loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" day\")).round(freq='1 H'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        df_list1d[\"BTC/USDT\"],#.loc[(Pair_Full.iloc[0].name-pd.Timedelta(str(window) +\" day\")).round(freq='1 d'):Pair_Full.iloc[len(Pair_Full)-1].name],\n",
    "        window)   \n",
    "    BTC_Full=BTC_Full.add_prefix(\"BTC_\")\n",
    "    # Merged=pd.merge(Pair_Full, BTC_Full, left_index=True, how='left',\n",
    "    #         right_index=True, suffixes=('', ''))\n",
    "    Merged=pd.merge(Pair_Full, BTC_Full, left_index=True, how='inner',\n",
    "            right_index=True, suffixes=('', ''))\n",
    "    day_expand(Merged)\n",
    "    Meta_expand(Merged,metadata,pair)\n",
    "    #buy_sell(Merged,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=MAX_FORCAST_SIZE)\n",
    "    buy_only(Merged,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=MAX_FORCAST_SIZE)\n",
    "    Merged[\"high\"]=(Merged[\"open\"]+high_weight*Merged[\"high\"]+Merged[\"low\"]+Merged[\"close\"])/(3+high_weight)\n",
    "    Merged.rename(columns={\"high\":\"price\"},inplace = True)\n",
    "    Merged[\"BTC_high\"]=(Merged[\"BTC_open\"]+high_weight*Merged[\"BTC_high\"]+Merged[\"BTC_low\"]+Merged[\"BTC_close\"])/(3+high_weight)\n",
    "    Merged.rename(columns={\"BTC_high\":\"BTC_price\"},inplace = True)\n",
    "    Merged=Merged.drop(columns=[\"BTC_open\",\"BTC_low\",\"BTC_close\",\"open\",\"low\",\"close\"])\n",
    "    # Merged=justlast_remover(Merged)\n",
    "    for key in Merged.keys():\n",
    "        if key.find(\"BTC\")!=-1 and (key.find(\"open\")!=-1 or\n",
    "        key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "            Merged[key]=-100*(Merged[\"BTC_price\"]-Merged[key])/Merged[\"BTC_price\"]\n",
    "        if key.find(\"BTC\")==-1 and (key.find(\"open\")!=-1 or\n",
    "        key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "            Merged[key]=-100*(Merged[\"price\"]-Merged[key])/Merged[\"price\"]\n",
    "    Merged=Merged.dropna()\n",
    "    return Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Garbage Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in Binance_USDT_HALAL:\n",
    "    price_volatility_5m=(100*(df_list5m[pair][\"high\"]-df_list5m[pair][\"low\"])/df_list5m[pair][\"high\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6588983589901976\n"
     ]
    }
   ],
   "source": [
    "pair=\"SOL/USDT\"\n",
    "price_volatility_5m=(100*(df_list5m[pair][\"high\"]-df_list5m[pair][\"low\"])/df_list5m[pair][\"high\"]).mean()\n",
    "print(price_volatility_5m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---buy_only--- Buy pct: 0.8%\n"
     ]
    }
   ],
   "source": [
    "df=mini_expand3(pair=pair,i=0,j=len(df_list1m[pair]),window=WINDOW_SIZE,metadata=MetaData,BUY_PCT=max(price_volatility_5m*0.6,0.8),SELL_PCT=SELL_PCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2020-08-21 00:00:00    11851.216667\n",
       "2020-08-21 00:01:00    11852.235000\n",
       "2020-08-21 00:02:00    11866.776667\n",
       "2020-08-21 00:03:00    11874.653333\n",
       "2020-08-21 00:04:00    11871.078333\n",
       "                           ...     \n",
       "2022-05-18 13:56:00    29416.931667\n",
       "2022-05-18 13:57:00    29379.176667\n",
       "2022-05-18 13:58:00    29355.188333\n",
       "2022-05-18 13:59:00    29370.298333\n",
       "2022-05-18 14:00:00    29365.115000\n",
       "Name: BTC_price, Length: 913897, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pop(\"price\")\n",
    "df.pop(\"BTC_price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.254192759140253\n"
     ]
    }
   ],
   "source": [
    "print(df.buy.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high-1</th>\n",
       "      <th>low-1</th>\n",
       "      <th>close-1</th>\n",
       "      <th>volume-1</th>\n",
       "      <th>high-2</th>\n",
       "      <th>low-2</th>\n",
       "      <th>close-2</th>\n",
       "      <th>volume-2</th>\n",
       "      <th>high-3</th>\n",
       "      <th>low-3</th>\n",
       "      <th>...</th>\n",
       "      <th>BTC_volume-9_5min</th>\n",
       "      <th>BTC_high-10_5min</th>\n",
       "      <th>BTC_low-10_5min</th>\n",
       "      <th>BTC_close-10_5min</th>\n",
       "      <th>BTC_volume-10_5min</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>lunch_day</th>\n",
       "      <th>buy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-08-21 00:00:00</th>\n",
       "      <td>-0.045238</td>\n",
       "      <td>-0.045238</td>\n",
       "      <td>-0.045238</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.045238</td>\n",
       "      <td>-0.045238</td>\n",
       "      <td>-0.045238</td>\n",
       "      <td>365.46</td>\n",
       "      <td>-0.042118</td>\n",
       "      <td>-0.042118</td>\n",
       "      <td>...</td>\n",
       "      <td>64.780713</td>\n",
       "      <td>-0.049756</td>\n",
       "      <td>-0.115319</td>\n",
       "      <td>-0.074563</td>\n",
       "      <td>126.811156</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-21 00:01:00</th>\n",
       "      <td>0.129063</td>\n",
       "      <td>0.038511</td>\n",
       "      <td>0.038511</td>\n",
       "      <td>474.40</td>\n",
       "      <td>0.038511</td>\n",
       "      <td>0.038511</td>\n",
       "      <td>0.038511</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.038511</td>\n",
       "      <td>0.038511</td>\n",
       "      <td>...</td>\n",
       "      <td>64.780713</td>\n",
       "      <td>-0.058343</td>\n",
       "      <td>-0.123901</td>\n",
       "      <td>-0.083149</td>\n",
       "      <td>126.811156</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-21 00:02:00</th>\n",
       "      <td>-0.038481</td>\n",
       "      <td>-0.153925</td>\n",
       "      <td>-0.153925</td>\n",
       "      <td>1272.74</td>\n",
       "      <td>0.052002</td>\n",
       "      <td>-0.038481</td>\n",
       "      <td>-0.038481</td>\n",
       "      <td>474.40</td>\n",
       "      <td>-0.038481</td>\n",
       "      <td>-0.038481</td>\n",
       "      <td>...</td>\n",
       "      <td>64.780713</td>\n",
       "      <td>-0.180813</td>\n",
       "      <td>-0.246290</td>\n",
       "      <td>-0.205588</td>\n",
       "      <td>126.811156</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-21 00:03:00</th>\n",
       "      <td>0.020789</td>\n",
       "      <td>-0.213087</td>\n",
       "      <td>0.020789</td>\n",
       "      <td>513.37</td>\n",
       "      <td>-0.094590</td>\n",
       "      <td>-0.209968</td>\n",
       "      <td>-0.209968</td>\n",
       "      <td>1272.74</td>\n",
       "      <td>-0.004158</td>\n",
       "      <td>-0.094590</td>\n",
       "      <td>...</td>\n",
       "      <td>64.780713</td>\n",
       "      <td>-0.247025</td>\n",
       "      <td>-0.312458</td>\n",
       "      <td>-0.271783</td>\n",
       "      <td>126.811156</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-21 00:04:00</th>\n",
       "      <td>0.149743</td>\n",
       "      <td>-0.131025</td>\n",
       "      <td>-0.131025</td>\n",
       "      <td>170.09</td>\n",
       "      <td>0.062393</td>\n",
       "      <td>-0.171580</td>\n",
       "      <td>0.062393</td>\n",
       "      <td>513.37</td>\n",
       "      <td>-0.053034</td>\n",
       "      <td>-0.168460</td>\n",
       "      <td>...</td>\n",
       "      <td>64.780713</td>\n",
       "      <td>-0.216984</td>\n",
       "      <td>-0.282437</td>\n",
       "      <td>-0.241750</td>\n",
       "      <td>126.811156</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-18 13:56:00</th>\n",
       "      <td>0.312651</td>\n",
       "      <td>0.041902</td>\n",
       "      <td>0.157937</td>\n",
       "      <td>4598.55</td>\n",
       "      <td>0.448026</td>\n",
       "      <td>0.080580</td>\n",
       "      <td>0.080580</td>\n",
       "      <td>3694.60</td>\n",
       "      <td>0.390008</td>\n",
       "      <td>-0.170830</td>\n",
       "      <td>...</td>\n",
       "      <td>306.828060</td>\n",
       "      <td>0.548250</td>\n",
       "      <td>0.131007</td>\n",
       "      <td>0.341430</td>\n",
       "      <td>853.220830</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>56</td>\n",
       "      <td>-223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-18 13:57:00</th>\n",
       "      <td>0.339114</td>\n",
       "      <td>-0.125957</td>\n",
       "      <td>-0.029067</td>\n",
       "      <td>8846.37</td>\n",
       "      <td>0.513516</td>\n",
       "      <td>0.242225</td>\n",
       "      <td>0.358492</td>\n",
       "      <td>4598.55</td>\n",
       "      <td>0.649162</td>\n",
       "      <td>0.280981</td>\n",
       "      <td>...</td>\n",
       "      <td>306.828060</td>\n",
       "      <td>0.677464</td>\n",
       "      <td>0.259685</td>\n",
       "      <td>0.470379</td>\n",
       "      <td>853.220830</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>57</td>\n",
       "      <td>-223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-18 13:58:00</th>\n",
       "      <td>0.255424</td>\n",
       "      <td>-0.132562</td>\n",
       "      <td>-0.054965</td>\n",
       "      <td>3061.43</td>\n",
       "      <td>0.449416</td>\n",
       "      <td>-0.016166</td>\n",
       "      <td>0.080830</td>\n",
       "      <td>8846.37</td>\n",
       "      <td>0.624010</td>\n",
       "      <td>0.352420</td>\n",
       "      <td>...</td>\n",
       "      <td>306.828060</td>\n",
       "      <td>0.759735</td>\n",
       "      <td>0.341615</td>\n",
       "      <td>0.552480</td>\n",
       "      <td>853.220830</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>58</td>\n",
       "      <td>-223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-18 13:59:00</th>\n",
       "      <td>-0.025833</td>\n",
       "      <td>-0.471454</td>\n",
       "      <td>-0.025833</td>\n",
       "      <td>7928.91</td>\n",
       "      <td>0.129166</td>\n",
       "      <td>-0.258331</td>\n",
       "      <td>-0.180832</td>\n",
       "      <td>3061.43</td>\n",
       "      <td>0.322914</td>\n",
       "      <td>-0.142082</td>\n",
       "      <td>...</td>\n",
       "      <td>306.828060</td>\n",
       "      <td>0.707898</td>\n",
       "      <td>0.289993</td>\n",
       "      <td>0.500750</td>\n",
       "      <td>853.220830</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>59</td>\n",
       "      <td>-223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-18 14:00:00</th>\n",
       "      <td>0.038707</td>\n",
       "      <td>-0.406425</td>\n",
       "      <td>-0.232243</td>\n",
       "      <td>9224.45</td>\n",
       "      <td>-0.135475</td>\n",
       "      <td>-0.580608</td>\n",
       "      <td>-0.135475</td>\n",
       "      <td>7928.91</td>\n",
       "      <td>0.019354</td>\n",
       "      <td>-0.367718</td>\n",
       "      <td>...</td>\n",
       "      <td>248.808760</td>\n",
       "      <td>0.929351</td>\n",
       "      <td>0.511679</td>\n",
       "      <td>0.877793</td>\n",
       "      <td>306.828060</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>-223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>913897 rows × 405 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       high-1     low-1   close-1  volume-1    high-2  \\\n",
       "date                                                                    \n",
       "2020-08-21 00:00:00 -0.045238 -0.045238 -0.045238      0.00 -0.045238   \n",
       "2020-08-21 00:01:00  0.129063  0.038511  0.038511    474.40  0.038511   \n",
       "2020-08-21 00:02:00 -0.038481 -0.153925 -0.153925   1272.74  0.052002   \n",
       "2020-08-21 00:03:00  0.020789 -0.213087  0.020789    513.37 -0.094590   \n",
       "2020-08-21 00:04:00  0.149743 -0.131025 -0.131025    170.09  0.062393   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2022-05-18 13:56:00  0.312651  0.041902  0.157937   4598.55  0.448026   \n",
       "2022-05-18 13:57:00  0.339114 -0.125957 -0.029067   8846.37  0.513516   \n",
       "2022-05-18 13:58:00  0.255424 -0.132562 -0.054965   3061.43  0.449416   \n",
       "2022-05-18 13:59:00 -0.025833 -0.471454 -0.025833   7928.91  0.129166   \n",
       "2022-05-18 14:00:00  0.038707 -0.406425 -0.232243   9224.45 -0.135475   \n",
       "\n",
       "                        low-2   close-2  volume-2    high-3     low-3  ...  \\\n",
       "date                                                                   ...   \n",
       "2020-08-21 00:00:00 -0.045238 -0.045238    365.46 -0.042118 -0.042118  ...   \n",
       "2020-08-21 00:01:00  0.038511  0.038511      0.00  0.038511  0.038511  ...   \n",
       "2020-08-21 00:02:00 -0.038481 -0.038481    474.40 -0.038481 -0.038481  ...   \n",
       "2020-08-21 00:03:00 -0.209968 -0.209968   1272.74 -0.004158 -0.094590  ...   \n",
       "2020-08-21 00:04:00 -0.171580  0.062393    513.37 -0.053034 -0.168460  ...   \n",
       "...                       ...       ...       ...       ...       ...  ...   \n",
       "2022-05-18 13:56:00  0.080580  0.080580   3694.60  0.390008 -0.170830  ...   \n",
       "2022-05-18 13:57:00  0.242225  0.358492   4598.55  0.649162  0.280981  ...   \n",
       "2022-05-18 13:58:00 -0.016166  0.080830   8846.37  0.624010  0.352420  ...   \n",
       "2022-05-18 13:59:00 -0.258331 -0.180832   3061.43  0.322914 -0.142082  ...   \n",
       "2022-05-18 14:00:00 -0.580608 -0.135475   7928.91  0.019354 -0.367718  ...   \n",
       "\n",
       "                     BTC_volume-9_5min  BTC_high-10_5min  BTC_low-10_5min  \\\n",
       "date                                                                        \n",
       "2020-08-21 00:00:00          64.780713         -0.049756        -0.115319   \n",
       "2020-08-21 00:01:00          64.780713         -0.058343        -0.123901   \n",
       "2020-08-21 00:02:00          64.780713         -0.180813        -0.246290   \n",
       "2020-08-21 00:03:00          64.780713         -0.247025        -0.312458   \n",
       "2020-08-21 00:04:00          64.780713         -0.216984        -0.282437   \n",
       "...                                ...               ...              ...   \n",
       "2022-05-18 13:56:00         306.828060          0.548250         0.131007   \n",
       "2022-05-18 13:57:00         306.828060          0.677464         0.259685   \n",
       "2022-05-18 13:58:00         306.828060          0.759735         0.341615   \n",
       "2022-05-18 13:59:00         306.828060          0.707898         0.289993   \n",
       "2022-05-18 14:00:00         248.808760          0.929351         0.511679   \n",
       "\n",
       "                     BTC_close-10_5min  BTC_volume-10_5min  day  hour  minute  \\\n",
       "date                                                                            \n",
       "2020-08-21 00:00:00          -0.074563          126.811156    5     0       0   \n",
       "2020-08-21 00:01:00          -0.083149          126.811156    5     0       1   \n",
       "2020-08-21 00:02:00          -0.205588          126.811156    5     0       2   \n",
       "2020-08-21 00:03:00          -0.271783          126.811156    5     0       3   \n",
       "2020-08-21 00:04:00          -0.241750          126.811156    5     0       4   \n",
       "...                                ...                 ...  ...   ...     ...   \n",
       "2022-05-18 13:56:00           0.341430          853.220830    3    13      56   \n",
       "2022-05-18 13:57:00           0.470379          853.220830    3    13      57   \n",
       "2022-05-18 13:58:00           0.552480          853.220830    3    13      58   \n",
       "2022-05-18 13:59:00           0.500750          853.220830    3    13      59   \n",
       "2022-05-18 14:00:00           0.877793          306.828060    3    14       0   \n",
       "\n",
       "                     lunch_day  buy  \n",
       "date                                 \n",
       "2020-08-21 00:00:00       -223    0  \n",
       "2020-08-21 00:01:00       -223    0  \n",
       "2020-08-21 00:02:00       -223    0  \n",
       "2020-08-21 00:03:00       -223    0  \n",
       "2020-08-21 00:04:00       -223    0  \n",
       "...                        ...  ...  \n",
       "2022-05-18 13:56:00       -223    0  \n",
       "2022-05-18 13:57:00       -223    0  \n",
       "2022-05-18 13:58:00       -223    0  \n",
       "2022-05-18 13:59:00       -223    0  \n",
       "2022-05-18 14:00:00       -223    0  \n",
       "\n",
       "[913897 rows x 405 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.reset_index()\n",
    "try:df.pop(\"num_index\")\n",
    "except: pass\n",
    "try:df.pop(\"index\")\n",
    "except: pass\n",
    "try:df.pop(\"date\")\n",
    "except: pass\n",
    "df=data_shufler(df)            \n",
    "df=data_chooser(df,weight=50,row_numbers=df.buy.sum()*2)\n",
    "gc.collect()\n",
    "df=data_cleanup(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.shape[0]/2)==df.buy.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=df.to_numpy(dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3307487935802198"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4120\n"
     ]
    }
   ],
   "source": [
    "index_20pct= int(0.1*len(dt[:,0]))\n",
    "print(index_20pct)\n",
    "XVALIDATION= dt[:index_20pct, :-1]\n",
    "YVALIDATION= dt[:index_20pct,-1]\n",
    "XTRAIN= dt[index_20pct:, 0:-1]\n",
    "YTRAIN= dt[index_20pct:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3307487935802198"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XVALIDATION[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing ...\n",
      "/UltimeTradingBot/Data/tp120_w10_max5min_Norm_v1.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if True:\n",
    "    if FIRST_NORM_FLAG:\n",
    "    #if True:\n",
    "        print(\"normalizing ...\")\n",
    "        mean = XTRAIN.mean(axis=0)\n",
    "        std = XTRAIN.std(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "        XTRAIN -= mean \n",
    "        XTRAIN /= std\n",
    "\n",
    "        XVALIDATION -=mean\n",
    "        XVALIDATION /= std\n",
    "        FIRST_NORM_FLAG=False\n",
    "        ######################### SAVIN NORM ################\n",
    "        try:\n",
    "            Normalization={\"mean\":mean.tolist(),\"std\":std.tolist()}\n",
    "            with open(Normalization_File.replace(\"/UltimeTradingBot/Data/\", \"/UltimeTradingBot/Data/\"+pair.replace(\"/\", \"-\")+\"-\"), 'w+') as fp:\n",
    "                        json.dump(Normalization, fp,  indent=4)\n",
    "                        print(Normalization_File)\n",
    "        except Exception as e:\n",
    "            print(\"error Normalization in juppiter\")\n",
    "            print(e)\n",
    "    else:print(\"already normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=dt[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 404)               163620    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 404)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                8100      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 172,821\n",
      "Trainable params: 172,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 22:46:14.452346: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-11 22:46:14.452417: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-11 22:46:14.452466: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: abj-K93SV\n",
      "2022-11-11 22:46:14.452485: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: abj-K93SV\n",
      "2022-11-11 22:46:14.452803: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-11-11 22:46:14.452911: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 390.154.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/6000\n",
      "38/38 [==============================] - 2s 24ms/step - loss: nan - accuracy: 0.5009 - val_loss: nan - val_accuracy: 0.4922\n",
      "Epoch 2/6000\n",
      "38/38 [==============================] - 1s 18ms/step - loss: nan - accuracy: 0.5009 - val_loss: nan - val_accuracy: 0.4922\n",
      "Epoch 3/6000\n",
      "38/38 [==============================] - 1s 18ms/step - loss: nan - accuracy: 0.5009 - val_loss: nan - val_accuracy: 0.4922\n",
      "Epoch 4/6000\n",
      "38/38 [==============================] - 1s 18ms/step - loss: nan - accuracy: 0.5009 - val_loss: nan - val_accuracy: 0.4922\n",
      "Epoch 5/6000\n",
      "38/38 [==============================] - 1s 18ms/step - loss: nan - accuracy: 0.5009 - val_loss: nan - val_accuracy: 0.4922\n",
      "Epoch 6/6000\n",
      "38/38 [==============================] - 1s 18ms/step - loss: nan - accuracy: 0.5009 - val_loss: nan - val_accuracy: 0.4922\n",
      "Epoch 7/6000\n",
      "38/38 [==============================] - 1s 18ms/step - loss: nan - accuracy: 0.5009 - val_loss: nan - val_accuracy: 0.4922\n",
      "Epoch 8/6000\n",
      "38/38 [==============================] - 1s 18ms/step - loss: nan - accuracy: 0.5009 - val_loss: nan - val_accuracy: 0.4922\n",
      "Epoch 9/6000\n",
      "38/38 [==============================] - 1s 18ms/step - loss: nan - accuracy: 0.5009 - val_loss: nan - val_accuracy: 0.4922\n",
      "Epoch 10/6000\n",
      "38/38 [==============================] - 1s 18ms/step - loss: nan - accuracy: 0.5009 - val_loss: nan - val_accuracy: 0.4922\n",
      "Epoch 11/6000\n",
      "38/38 [==============================] - 1s 21ms/step - loss: nan - accuracy: 0.5009 - val_loss: nan - val_accuracy: 0.4922\n",
      "Epoch 12/6000\n",
      "38/38 [==============================] - 1s 20ms/step - loss: nan - accuracy: 0.5009 - val_loss: nan - val_accuracy: 0.4922\n",
      "Epoch 13/6000\n",
      "38/38 [==============================] - 1s 20ms/step - loss: nan - accuracy: 0.5009 - val_loss: nan - val_accuracy: 0.4922\n",
      "Epoch 14/6000\n",
      "38/38 [==============================] - 1s 23ms/step - loss: nan - accuracy: 0.5009 - val_loss: nan - val_accuracy: 0.4922\n",
      "Epoch 15/6000\n",
      "38/38 [==============================] - 1s 20ms/step - loss: nan - accuracy: 0.5009 - val_loss: nan - val_accuracy: 0.4922\n",
      "Epoch 16/6000\n",
      "38/38 [==============================] - 1s 21ms/step - loss: nan - accuracy: 0.5009 - val_loss: nan - val_accuracy: 0.4922\n",
      "Epoch 16: early stopping\n",
      "##########################################################################\n",
      "------val_accuracy-----> 49.22 | 50.09 <----------accuracy----------\n"
     ]
    }
   ],
   "source": [
    "IN_DIM=dt.shape[1]-1\n",
    "model = Sequential()\n",
    "model.add(Dense(int(IN_DIM),input_dim=IN_DIM,activation='relu')) #( 100=>66.23)\n",
    "# resultus withe 250 d0.3 50 d 20 d 8 = 65.6% vs  65.49 no droppout vs 65.78 d0.5 vs 65.68 d0.4 # 65.48 # one dropout of   0.5 = 66.11   #tanh 66.33 accuracy #softmax 66.12 #softplus 66.5 # sigmoid 66.21 / \n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(int(20),activation='relu')) # best softplus 66.26(69) vs relu 66.65(70)  / -20 => 66.25 /250 ->65.78\n",
    "#model2.add(Dropout(0.1)) #5=> 66.00  66.21 vs no dopout 66.28\n",
    "#model2.add(Dense(int(20),activation='relu')) # disabled 6.24\n",
    "model.add(Dense(int(50),activation='relu')) # -4 -> -> 66.24\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "print(model.summary())\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "callbacks_a = ModelCheckpoint(filepath =MODEL_FILE+f\"test.multi_train.h5\",monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "callbacks_b = EarlyStopping(monitor ='val_accuracy',mode='auto',patience=15,verbose=1)\n",
    "history = model.fit(dt[index_20pct:, 0:-1],\n",
    "                dt[index_20pct:,-1],\n",
    "                validation_data=(dt[:index_20pct, :-1],Y[:index_20pct]),\n",
    "                epochs=6000,\n",
    "                batch_size=1000,\n",
    "                callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "print('##########################################################################')\n",
    "print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "#94%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

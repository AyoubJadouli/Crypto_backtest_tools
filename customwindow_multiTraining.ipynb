{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single AI crypto concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINDOW:15 - BUY_PCT:1 MAX_FORCAST_SIZE:15 - BUY_MODE:IS_MIN \n"
     ]
    }
   ],
   "source": [
    "from xdata_config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Imports and fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 17:53:18.019012: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-03 17:53:18.019146: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-03 17:53:18.244264: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-03 17:53:22.841096: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-03 17:53:22.841448: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-03 17:53:22.841499: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 3883.89 MB\n"
     ]
    }
   ],
   "source": [
    "from functions_module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.constraints import MaxNorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "from keras.models import load_model\n",
    "from keras.layers import BatchNormalization, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buy_optimal_5m(df,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=MAX_FORCAST_SIZE):\n",
    "    #df = df.fillna(0)\n",
    "    mino = BUY_PCT / 100.0\n",
    "    maxo = SELL_PCT / 100.0\n",
    "    window=max(7,int(window/5))\n",
    "    max_forecast_size=window#MAX_FORCAST_SIZE\n",
    "    try:\n",
    "        after_dip_val=AFTER_MARK\n",
    "    except:\n",
    "        after_dip_val=3\n",
    "    print(f\"after mark = : {after_dip_val}\")\n",
    "    try:\n",
    "        print(f\"optimalbuy buy maximum forcast size={max_forecast_size} at {BUY_PCT}% of the current price \")\n",
    "    except:\n",
    "        max_forecast_size = 3\n",
    "        print(\"optimalbuy buy default window=3\")\n",
    "        \n",
    "    rolling_max_close_diff = ((df['close-1_5min'].rolling(window=window).max().shift(-window+1) / df['close']) - 1).fillna(0)\n",
    "    df['buy']=(rolling_max_close_diff >= mino).astype(int)\n",
    "    \n",
    "    # Compute rolling minimum values\n",
    "    window_list=[window]#[3, 5, 7, 10, 15, 20]\n",
    "    \n",
    "    for window_size in window_list:\n",
    "        col_name = f'ismin{window_size}'\n",
    "        rolling_min = (df['close'].shift(after_dip_val) <= df.shift(-window_size-1)['close-1_5min'].rolling(2*window_size).min())\n",
    "        df = df.assign(**{col_name: rolling_min.astype(int)})\n",
    "\n",
    "    df['ismin'] = df[[f'ismin{window_size}' for window_size in window_list ]].any(axis=1).astype(int)        \n",
    "\n",
    "    # # Compute buy and sell signals\n",
    "    rolling_low_close_diff =  ((df['low-1_5min'].rolling(window=int(window/2)).min().shift(-int(window/2)+1)/ df['close'] ) -1).fillna(0)\n",
    "    df['sell'] = (rolling_low_close_diff <= -maxo).astype(int)\n",
    "\n",
    "    \n",
    "    # Compute final buy signal\n",
    "    df['buy'] = ((df['buy'] == 1) & (df['sell'] == 0) & (df['ismin'] == 1)).astype(int)\n",
    "    # Remove unnecessary columns\n",
    "    df = df.drop(columns=['sell', 'ismin'] + [f'ismin{window_size}' for window_size in window_list], errors='ignore')\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def full_expand_costum(df1m,df5m,df15m,df1h,df1d,w1m=10,w5m=30,w15m=30,w1h=3,w1d=7):\n",
    "    d1min=df1m.copy()\n",
    "    d1min=expand_previous(d1min,window=w1m).drop(columns=[\"volume\"])\n",
    "    d1min=rapid1d_expand(d1min,df1d,w1d)\n",
    "    d1min=rapid1h_expand(d1min,df1h,w1h)\n",
    "    d1min=rapid15m_expand(d1min,df15m,w15m)\n",
    "    d1min=rapid5m_expand(d1min,df5m,w5m)\n",
    "    return d1min\n",
    "\n",
    "def maxi_expand(pair=\"GMT/USDT\", i=0, j=10000, window=2, metadata=MetaData,\n",
    "                 high_weight=1, BUY_PCT=BUY_PCT, SELL_PCT=SELL_PCT,\n",
    "                 buy_function=buy_alwase,w1m=6,w5m=30,w15m=30,w1h=3,w1d=7,btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=30,btc_w1d=30):\n",
    "    start_index=i\n",
    "    end_index=j\n",
    "    window_size=window\n",
    "    buy_fn=buy_function\n",
    "    \"\"\"\n",
    "    This function takes in several parameters to calculate technical indicators and returns a merged dataframe.\n",
    "    \n",
    "    :param pair: str, default \"GMT/USDT\"\n",
    "        The trading pair to analyze.\n",
    "        \n",
    "    :param start_index: int, default 0\n",
    "        The start index for selecting data.\n",
    "        \n",
    "    :param end_index: int, default 10000\n",
    "        The end index for selecting data.\n",
    "    \n",
    "    :param window_size: int, default 2\n",
    "        The window size to use for analyzing the data.\n",
    "    \n",
    "    :param metadata: MetaData\n",
    "        The metadata to use for analyzing the data.\n",
    "    \n",
    "    :param high_weight: int, default 1\n",
    "        The weight to use for calculating the high.\n",
    "    \n",
    "    :param BUY_PCT: float, default BUY_PCT\n",
    "        The buy pct to use for analyzing the data.\n",
    "    \n",
    "    :param SELL_PCT: float, default SELL_PCT\n",
    "        The sell pct to use for analyzing the data.\n",
    "    \n",
    "    :param buy_fn: function, default buy_min_up\n",
    "        The buy function to use for analyzing the data.\n",
    "    \n",
    "    :return: pd.DataFrame\n",
    "        A merged dataframe containing the calculated technical indicators.\n",
    "    \"\"\"\n",
    "    print(f\"maxi custum expend : {pair} with those parameters: w1m={w1m},w5m={w5m},w15m={w15m},w1h={w1h},w1d={w1d} btc_w1m={btc_w1m},btc_w5m={btc_w5m},btc_w15m={btc_w15m},btc_w1h={btc_w1h},btc_w1d={btc_w1d}\")\n",
    "    # Select data\n",
    "    pair_df = df_list1m[pair].iloc[start_index:end_index]\n",
    "    btc_df = df_list1m[\"BTC/USDT\"].loc[(pair_df.index[0] - pd.DateOffset(days=window_size+1)).round(freq='1 min'):pair_df.index[-1]+pd.Timedelta(f\"{window_size} day\")]\n",
    "    # Calculate technical indicators\n",
    "    pair_full = full_expand_costum(pair_df, df_list5m[pair], df_list15m[pair], df_list1h[pair], df_list1d[pair],w1m=w1m,w5m=w5m,w15m=w15m,w1h=w1h,w1d=w1d)\n",
    "    btc_full = full_expand_costum(btc_df, df_list5m[\"BTC/USDT\"], df_list15m[\"BTC/USDT\"], df_list1h[\"BTC/USDT\"], df_list1d[\"BTC/USDT\"], w1m=btc_w1m,w5m=btc_w5m,w15m=btc_w15m,w1h=btc_w1h,w1d=btc_w1d)   \n",
    "    btc_full = btc_full.add_prefix(\"BTC_\")\n",
    "    merged = pd.merge(pair_full, btc_full, left_index=True, right_index=True)\n",
    "    day_expand(merged)\n",
    "    Meta_expand(merged, metadata, pair)\n",
    "    print(merged.columns)\n",
    "    merged = buy_fn(merged, BUY_PCT=BUY_PCT, SELL_PCT=SELL_PCT, window=MAX_FORCAST_SIZE)\n",
    "    merged[\"high\"] = (merged[\"open\"] + high_weight * merged[\"high\"] + merged[\"low\"] + merged[\"close\"]) / (3 + high_weight)\n",
    "    merged[\"BTC_high\"] = (merged[\"BTC_open\"] + high_weight * merged[\"BTC_high\"] + merged[\"BTC_low\"] + merged[\"BTC_close\"]) / (3 + high_weight)\n",
    "    merged.rename(columns={\"high\":\"price\"},inplace=True)\n",
    "    merged.rename(columns={\"BTC_high\":\"BTC_price\"},inplace=True)\n",
    "    merged = merged.drop(columns=[\"BTC_open\",\"BTC_low\",\"BTC_close\",\"open\",\"low\",\"close\"])\n",
    "    open_high_low_close_cols = merged.columns.str.contains(\"open|high|low|close\")\n",
    "    # merged.loc[:, open_high_low_close_cols & merged.columns.str.contains(\"BTC\")] = (\n",
    "    #     (merged[\"BTC_price\"] - merged.loc[:, open_high_low_close_cols & merged.columns.str.contains(\"BTC\")]) / merged[\"BTC_price\"]\n",
    "    # )\n",
    "    # merged.loc[:, open_high_low_close_cols & ~merged.columns.str.contains(\"BTC\")] = (\n",
    "    #     (merged[\"price\"] - merged.loc[:, open_high_low_close_cols & ~merged.columns.str.contains(\"BTC\")]) / merged[\"price\"]\n",
    "    # )\n",
    "    for key in merged.keys():\n",
    "        if key.find(\"BTC\")!=-1 and (key.find(\"open\")!=-1 or\n",
    "    key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "            merged[key]=(merged[\"BTC_price\"]-merged[key])/merged[\"BTC_price\"]\n",
    "        if key.find(\"BTC\")==-1 and (key.find(\"open\")!=-1 or\n",
    "    key.find(\"high\")!=-1 or key.find(\"low\")!=-1 or key.find(\"close\")!=-1):\n",
    "            merged[key]=(merged[\"price\"]-merged[key])/merged[\"price\"]\n",
    "\n",
    "    merged=merged.dropna()\n",
    "    print(f'######################  max expend {pair} - shape {merged.shape}  buy mean : {hp(merged.buy.mean())} ############################')\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buy_optimal(df,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=3):\n",
    "    #df = df.fillna(0)\n",
    "    mino = BUY_PCT / 100.0\n",
    "    maxo = SELL_PCT / 100.0\n",
    "    window=15\n",
    "    max_forecast_size=15#MAX_FORCAST_SIZE\n",
    "    try:\n",
    "        after_dip_val=1\n",
    "    except:\n",
    "        after_dip_val=1\n",
    "    print(f\"after mark = : {after_dip_val}\")\n",
    "    try:\n",
    "        print(f\"optimalbuy buy maximum forcast size={max_forecast_size} at {BUY_PCT}% of the current price \")\n",
    "    except:\n",
    "        max_forecast_size = 3\n",
    "        print(\"optimalbuy buy default window=3\")\n",
    "        \n",
    "    rolling_max_close_diff = ((df['close'].rolling(window=window).max().shift(-window+1) / df['close']) - 1).fillna(0)\n",
    "    df['buy']=(rolling_max_close_diff >= mino).astype(int)\n",
    "    \n",
    "    # Compute rolling minimum values\n",
    "    \n",
    "    window_list=[5,window]#[3, 5, 7, 10, 15, 20]\n",
    "    \n",
    "    for window_size in window_list:\n",
    "        col_name = f'ismin{window_size}'\n",
    "        rolling_min = (df['close'].shift(after_dip_val) <= df.shift(-window_size-1)['close'].rolling(2*window_size).min())\n",
    "        df = df.assign(**{col_name: rolling_min.astype(int)})\n",
    "\n",
    "    df['ismin'] = df[[f'ismin{window_size}' for window_size in window_list ]].any(axis=1).astype(int)        \n",
    "\n",
    "    # # Compute buy and sell signals\n",
    "    rolling_low_close_diff =  ((df['low'].rolling(window=int(window/2)).min().shift(-int(window/2)+1)/ df['close'] ) -1).fillna(0)\n",
    "    df['sell'] = (rolling_low_close_diff <= -maxo).astype(int)\n",
    "\n",
    "    \n",
    "    # Compute final buy signal\n",
    "    df['buy'] = ((df['buy'] == 1) & (df['sell'] == 0) & (df['ismin'] == 1)).astype(int)\n",
    "    # Remove unnecessary columns\n",
    "    df = df.drop(columns=['sell', 'ismin'] + [f'ismin{window_size}' for window_size in window_list], errors='ignore')\n",
    "    return df\n",
    "def plot_data(Model_FileName, pair_to_test, winratio, OnePair_DF, i_start, window_size, PREDICTION_TO_TEST,dot_color=\"g\"):\n",
    "    i_end=i_start+window_size\n",
    "    mname = Model_FileName.replace(\"/UltimeTradingBot/Data\",\"\")\n",
    "    coin = pair_to_test.replace('/', '-')\n",
    "    mtitle = f\"{coin} WinRatio:{hp(winratio)}% - {mname}\".replace(\"/\", \"-\")\n",
    "    \n",
    "    # Set the background color of the plot to white\n",
    "    plt.rcParams['axes.facecolor'] = 'black'\n",
    " \n",
    "    # Plot all the prices\n",
    "    plt.plot(OnePair_DF.index[i_start:i_end], OnePair_DF.price[i_start:i_end], label='Price',c=\"w\")\n",
    "\n",
    "    # Overlay the 'buy' dots on the plot\n",
    "    plt.scatter(OnePair_DF[i_start:i_end][PREDICTION_TO_TEST[i_start:i_end]==1].index, OnePair_DF[i_start:i_end][PREDICTION_TO_TEST[i_start:i_end]==1].price, color=dot_color, marker='o', label='Buy')\n",
    "\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title(mtitle)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_local_min(df, BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,window=5):\n",
    "    \"\"\"\n",
    "    Add a binary column to the OHLCV DataFrame to indicate if the close price in the row is a local minimum.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the OHLCV data.\n",
    "    window (int): The window size for computing local minimum.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The input DataFrame with an additional column indicating local minimum.\n",
    "    \"\"\"\n",
    "    # Compute rolling minimum close\n",
    "    rolling_min_close = df['close'].rolling(window=window, center=True, min_periods=1).min()\n",
    "\n",
    "    # Check if close price is a local minimum\n",
    "    local_min = (df['close'] == rolling_min_close).astype(int)\n",
    "\n",
    "    # Add the local minimum column to the DataFrame\n",
    "    df['buy'] = local_min\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def is_near_min_v1(df, BUY_PCT=BUY_PCT, SELL_PCT=SELL_PCT, window=5, num_values=3):\n",
    "    \"\"\"\n",
    "    Add a binary column to the OHLCV DataFrame to indicate if the close price in the row is a local minimum\n",
    "    or near the local minimum.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the OHLCV data.\n",
    "    window (int): The window size for computing local minimum.\n",
    "    num_values (int): The number of values near the local minimum to include.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The input DataFrame with an additional column indicating local minimum and its neighbors.\n",
    "    \"\"\"\n",
    "    # Compute rolling minimum close\n",
    "    rolling_min_close = df['close'].rolling(window=window, center=True, min_periods=1).min()\n",
    "\n",
    "    # Check if close price is a local minimum or near the local minimum\n",
    "    close_diff = np.abs(df['close'] - rolling_min_close)\n",
    "    threshold = close_diff.nsmallest(num_values+1).iloc[-1]\n",
    "    local_min = (close_diff <= threshold).astype(int)\n",
    "\n",
    "    # Add the local minimum column to the DataFrame\n",
    "    df['buy'] = local_min\n",
    "\n",
    "    return df\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def is_near_min(df, BUY_PCT=BUY_PCT, SELL_PCT=SELL_PCT, window=5, num_values=3):\n",
    "    \"\"\"\n",
    "    Add a binary column to the OHLCV DataFrame to indicate if the close price in the row is a local minimum\n",
    "    or within the specified range before or after the local minimum.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the OHLCV data.\n",
    "    window (int): The window size for computing local minimum.\n",
    "    num_values (int): The number of values before and after the local minimum to include.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The input DataFrame with an additional column indicating local minimum and its neighbors.\n",
    "    \"\"\"\n",
    "    # Compute rolling minimum close\n",
    "    rolling_min_close = df['close'].rolling(window=window, center=True, min_periods=1).min()\n",
    "\n",
    "    # Check if close price is a local minimum\n",
    "    local_min = (df['close'] == rolling_min_close).astype(int)\n",
    "\n",
    "    # Add the local minimum column to the DataFrame\n",
    "    df['buy'] = local_min\n",
    "\n",
    "    # Include values before and after the local minimum\n",
    "    for i in range(1, num_values+1):\n",
    "        df['buy'] = df['buy'] | df['buy'].shift(-i) | df['buy'].shift(i)\n",
    "\n",
    "    # Fill any NaN values introduced by shifting with 0\n",
    "    df['buy'].fillna(0, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def is_max_win(df, BUY_PCT=BUY_PCT, SELL_PCT=SELL_PCT, window=5):\n",
    "    \"\"\"\n",
    "    Add a binary column to the OHLCV DataFrame to indicate if the close price in the row is a winning trade.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the OHLCV data.\n",
    "    BUY_PCT (float): Minimum percentage change required for a trade to be profitable.\n",
    "    window (int): The window size for computing maximum price change.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The input DataFrame with an additional column indicating winning trades.\n",
    "    \"\"\"\n",
    "    # Compute rolling minimum close\n",
    "    rolling_min_close = df['close'].rolling(window=7, center=True, min_periods=1).min()\n",
    "\n",
    "    # Check if close price is a local minimum\n",
    "    local_min = (df['close'] == rolling_min_close)\n",
    "\n",
    "    # Compute maximum price change over next `window` rows\n",
    "    # max_price = df['close'].rolling(window=window, min_periods=1).max()\n",
    "    # max_price_shifted = max_price.shift(-window)\n",
    "    # max_price_change = ((max_price_shifted - max_price)/max_price).fillna(0)\n",
    "    max_price = df['close'].shift(periods=-window+1).rolling(window=window, min_periods=1).max()#.pct_change(window=window-1)\n",
    "\n",
    "    # Check if the maximum price change is greater than the BUY_PCT threshold\n",
    "    win = (max_price >= (BUY_PCT/100+1)*df['close'])\n",
    "\n",
    "    # Combine local minimum and winning trade conditions\n",
    "    df['buy'] = (local_min & win).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "def is_close_win(df, BUY_PCT=BUY_PCT, SELL_PCT=SELL_PCT, window=5):\n",
    "    \"\"\"\n",
    "    Add a binary column to the OHLCV DataFrame to indicate if the close price in the row is a winning trade.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the OHLCV data.\n",
    "    BUY_PCT (float): Minimum percentage change required for a trade to be profitable.\n",
    "    window (int): The window size for computing maximum price change.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The input DataFrame with an additional column indicating winning trades.\n",
    "    \"\"\"\n",
    "\n",
    "    max_price = df['close'].shift(periods=-window+1).rolling(window=window, min_periods=1).max()#.pct_change(window=window-1)\n",
    "\n",
    "    # Check if the maximum price change is greater than the BUY_PCT threshold\n",
    "    win = (max_price >= (BUY_PCT/100+1)*df['close'])\n",
    "\n",
    "    # Combine local minimum and winning trade conditions\n",
    "    df['buy'] = (win).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "def is_high_win(df, BUY_PCT=BUY_PCT, SELL_PCT=SELL_PCT, window=5):\n",
    "    \"\"\"\n",
    "    Add a binary column to the OHLCV DataFrame to indicate if the close price in the row is a winning trade.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the OHLCV data.\n",
    "    BUY_PCT (float): Minimum percentage change required for a trade to be profitable.\n",
    "    window (int): The window size for computing maximum price change.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The input DataFrame with an additional column indicating winning trades.\n",
    "    \"\"\"\n",
    "    max_price = df['high'].shift(periods=-window+1).rolling(window=window, min_periods=1).max()#.pct_change(window=window-1)\n",
    "\n",
    "    # Check if the maximum price change is greater than the BUY_PCT threshold\n",
    "    win = (max_price >= (BUY_PCT/100+1)*df['close'])\n",
    "\n",
    "    # Combine local minimum and winning trade conditions\n",
    "    df['buy'] = (win).astype(int)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini_expand : SNM/BUSD\n",
      "Precent Mean: 9.191%\n",
      "######################  mini_expand5 SNM/BUSD - shape (163689, 87)  buy mean : 9.191 ############################\n",
      "Precent Mean: 0.000%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Test\n",
    "pair=\"SNM/BUSD\"\n",
    "#df=maxi_expand(pair=pair,i=0,j=len(df_list1m[pair]),window=WINDOW_SIZE,metadata=MetaData,BUY_PCT=0.6,SELL_PCT=0.3,buy_function=buy_only)\n",
    "df=mini_expand5(pair=pair,i=0,j=len(df_list1m[pair]),window=2,metadata=MetaData,BUY_PCT=1.7,SELL_PCT=0.3,buy_function=is_local_min)\n",
    "#df = full_expand_costum(df_list1m[pair], df_list5m[pair], df_list15m[pair], df_list1h[pair], df_list1d[pair],w1m=6,w5m=30,w15m=30,w1h=3,w1d=7)\n",
    "plot_data(\"test big opt\", pair, 0, df, 1000, 60,df.buy,dot_color=\"g\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxi custum expend : SNM/BUSD with those parameters: w1m=6,w5m=30,w15m=30,w1h=3,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=30,btc_w1d=30\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=616)\n",
      "Precent Mean: 9.336%\n",
      "######################  max expend SNM/BUSD - shape (156489, 611)  buy mean : 9.336 ############################\n"
     ]
    }
   ],
   "source": [
    "df=maxi_expand(pair=pair,i=0,j=len(df_list1m[pair]),window=2,metadata=MetaData,BUY_PCT=1.7,SELL_PCT=0.3,buy_function=is_local_min)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special list if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Binance_USDT_HALAL.index(\"ROSE/USDT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import date\n",
    "# TICKERS = \"../Binance-Fast-Trade-Bot/volatile_volume_\" + str(date.today()) + \".txt\"\n",
    "# VOLATILE_COINS=[line.strip() for line in open(TICKERS)]\n",
    "# PAIR_WITH=\"USDT\"\n",
    "# VOLATILE_USDT_PAIRS=[coin+\"/USDT\" for coin in VOLATILE_COINS]\n",
    "# VOLATILE_BUSD_PAIRS=[coin+\"/BUSD\" for coin in VOLATILE_COINS]\n",
    "# VOLATILE_USDT_PAIRS\n",
    "\n",
    "# coins_to_download=''\n",
    "# for coin in VOLATILE_COINS:\n",
    "#     coins_to_download=coins_to_download+\" \"+coin\n",
    "# f\"node database/ddargs.js {coins_to_download} {PAIR_WITH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coins_to_download=''\n",
    "# for coin in VOLATILE_COINS:\n",
    "#     coins_to_download=coins_to_download+\" \"+coin\n",
    "# os.system(f\"node database/ddargs.js {coins_to_download} {PAIR_WITH}\")#node database/ddargs.js ORN BUSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair_list = find_intersection(VOLATILE_USDT_PAIRS,Binance_USDT_HALAL)\n",
    "# #tf = '1m'\n",
    "# oldest_pair = \"BTC/USDT\"\n",
    "# if oldest_pair not in pair_list: pair_list.append(oldest_pair)\n",
    "# df_list1m = {}\n",
    "# df_list1d = {}\n",
    "# df_list1h = {}\n",
    "# df_list5m = {}\n",
    "# df_list15m = {}\n",
    "\n",
    "\n",
    "# for pair in pair_list:\n",
    "#     df = get_historical_from_db(ccxt.binance(), pair, '1m', path=\"./database/\")\n",
    "#     df_list1m[pair] = df.loc[:]\n",
    "\n",
    "# for pair in pair_list:\n",
    "#     df = get_historical_from_db(ccxt.binance(), pair, '1d', path=\"./database/\")\n",
    "#     df_list1d[pair] = df.loc[:]\n",
    "\n",
    "# for pair in pair_list:\n",
    "#     df = get_historical_from_db(ccxt.binance(), pair, '1h', path=\"./database/\")\n",
    "#     df_list1h[pair] = df.loc[:]\n",
    "\n",
    "# for pair in pair_list:\n",
    "#     df = get_historical_from_db(ccxt.binance(), pair, '5m', path=\"./database/\")\n",
    "#     df_list5m[pair] = df.loc[:]\n",
    "\n",
    "# for pair in pair_list:\n",
    "#     df = get_historical_from_db(\n",
    "#         ccxt.binance(), pair, '15m', path=\"./database/\")\n",
    "#     df_list15m[pair] = df.loc[:]\n",
    "# del(df)\n",
    "# df_list = df_list1m\n",
    "# prerr(\"Data load 100% use df_list1d[\\\"BTC/USDT\\\"] for exemple to access\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chking import\n",
    "MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BUY_MODE==\"BUY_ONLY\":\n",
    "    buy_function=buy_up_only\n",
    "elif BUY_MODE==\"BUY_UP\":\n",
    "    buy_function=buy_up\n",
    "elif  BUY_MODE==\"BUY_DIP\":\n",
    "    buy_function=buy_min_up\n",
    "elif  BUY_MODE==\"AFTER_DEPTH\":\n",
    "    buy_function=buy_after_depth\n",
    "elif  BUY_MODE==\"BUY_UP_CLOSE\":\n",
    "    buy_function=buy_up_close\n",
    "elif  BUY_MODE==\"AFTER_DEPTH_CLOSE\":\n",
    "    buy_function=buy_after_depth_close\n",
    "elif  BUY_MODE==\"BUY_TEST\":\n",
    "    buy_function=buy_test\n",
    "elif BUY_MODE==\"BUY_MIN_CLOSE\":\n",
    "    buy_function=buy_min_close\n",
    "elif  BUY_MODE==\"SELL_TEST\":\n",
    "    buy_function=sell_test\n",
    "elif  BUY_MODE==\"BUY_FIX\":\n",
    "    buy_function=buy_fix\n",
    "elif  BUY_MODE==\"BUY_OPTIMAL\":\n",
    "    buy_function=buy_optimal\n",
    "elif  BUY_MODE==\"IS_MIN\":\n",
    "    buy_function=is_local_min\n",
    "\n",
    "\n",
    "try:\n",
    "    os.mkdir(DATA_DIR, mode = 0o777)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "print(f\"Results dir: {DATA_DIR}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on: SNM/BUSD -->maxi custum expend : SNM/BUSD with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 9.336%\n",
      "######################  max expend SNM/BUSD - shape (156489, 399)  buy mean : 9.336 ############################\n",
      "df original shape (156489, 399)\n",
      "df original shape buy mean : 9.336119471656154\n",
      "SNM/BUSD is processed -- 0/112\n",
      "working on: LUNA/USDT -->maxi custum expend : LUNA/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 4.889%\n",
      "######################  max expend LUNA/USDT - shape (942285, 399)  buy mean : 4.889 ############################\n",
      "df original shape (942285, 399)\n",
      "df original shape buy mean : 4.8894973389155085\n",
      "LUNA/USDT is processed -- 1/112\n",
      "working on: GMT/USDT -->maxi custum expend : GMT/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 5.024%\n",
      "######################  max expend GMT/USDT - shape (358605, 399)  buy mean : 5.024 ############################\n",
      "df original shape (358605, 399)\n",
      "df original shape buy mean : 5.0236332454929515\n",
      "GMT/USDT is processed -- 2/112\n",
      "working on: UST/USDT -->maxi custum expend : UST/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 30.365%\n",
      "######################  max expend UST/USDT - shape (180050, 399)  buy mean : 30.365 ############################\n",
      "df original shape (180050, 399)\n",
      "df original shape buy mean : 30.365454040544293\n",
      "UST/USDT is processed -- 3/112\n",
      "working on: SOL/USDT -->maxi custum expend : SOL/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 5.150%\n",
      "######################  max expend SOL/USDT - shape (968522, 399)  buy mean : 5.15 ############################\n",
      "df original shape (968522, 399)\n",
      "df original shape buy mean : 5.150012080262504\n",
      "SOL/USDT is processed -- 4/112\n",
      "working on: APE/USDT -->maxi custum expend : APE/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 5.076%\n",
      "######################  max expend APE/USDT - shape (347087, 399)  buy mean : 5.076 ############################\n",
      "df original shape (347087, 399)\n",
      "df original shape buy mean : 5.0762488943694235\n",
      "APE/USDT is processed -- 5/112\n",
      "working on: XRP/USDT -->maxi custum expend : XRP/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 5.487%\n",
      "######################  max expend XRP/USDT - shape (968516, 399)  buy mean : 5.487 ############################\n",
      "df original shape (968516, 399)\n",
      "df original shape buy mean : 5.48715767214997\n",
      "XRP/USDT is processed -- 6/112\n",
      "working on: IDEX/USDT -->maxi custum expend : IDEX/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 8.019%\n",
      "######################  max expend IDEX/USDT - shape (455090, 399)  buy mean : 8.019 ############################\n",
      "df original shape (455090, 399)\n",
      "df original shape buy mean : 8.018633676855128\n",
      "IDEX/USDT is processed -- 7/112\n",
      "working on: AVAX/USDT -->maxi custum expend : AVAX/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 5.720%\n",
      "######################  max expend AVAX/USDT - shape (968523, 399)  buy mean : 5.72 ############################\n",
      "df original shape (968523, 399)\n",
      "df original shape buy mean : 5.720463014301157\n",
      "AVAX/USDT is processed -- 8/112\n",
      "working on: DOT/USDT -->maxi custum expend : DOT/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 8.491%\n",
      "######################  max expend DOT/USDT - shape (968524, 399)  buy mean : 8.491 ############################\n",
      "df original shape (968524, 399)\n",
      "df original shape buy mean : 8.490858254415997\n",
      "DOT/USDT is processed -- 9/112\n",
      "working on: ADA/USDT -->maxi custum expend : ADA/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 6.771%\n",
      "######################  max expend ADA/USDT - shape (968514, 399)  buy mean : 6.771 ############################\n",
      "df original shape (968514, 399)\n",
      "df original shape buy mean : 6.770784934445966\n",
      "ADA/USDT is processed -- 10/112\n",
      "working on: JASMY/USDT -->maxi custum expend : JASMY/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 11.089%\n",
      "######################  max expend JASMY/USDT - shape (455092, 399)  buy mean : 11.089 ############################\n",
      "df original shape (455092, 399)\n",
      "df original shape buy mean : 11.088746890738575\n",
      "JASMY/USDT is processed -- 11/112\n",
      "working on: TRX/USDT -->maxi custum expend : TRX/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 6.254%\n",
      "######################  max expend TRX/USDT - shape (455093, 399)  buy mean : 6.254 ############################\n",
      "df original shape (455093, 399)\n",
      "df original shape buy mean : 6.254106303546747\n",
      "TRX/USDT is processed -- 12/112\n",
      "working on: NEAR/USDT -->maxi custum expend : NEAR/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 5.116%\n",
      "######################  max expend NEAR/USDT - shape (968528, 399)  buy mean : 5.116 ############################\n",
      "df original shape (968528, 399)\n",
      "df original shape buy mean : 5.116011101382717\n",
      "NEAR/USDT is processed -- 13/112\n",
      "working on: AXS/USDT -->maxi custum expend : AXS/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 8.114%\n",
      "######################  max expend AXS/USDT - shape (455094, 399)  buy mean : 8.114 ############################\n",
      "df original shape (455094, 399)\n",
      "df original shape buy mean : 8.114367581203004\n",
      "AXS/USDT is processed -- 14/112\n",
      "working on: GAL/USDT -->maxi custum expend : GAL/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 6.979%\n",
      "######################  max expend GAL/USDT - shape (276534, 399)  buy mean : 6.979 ############################\n",
      "df original shape (276534, 399)\n",
      "df original shape buy mean : 6.978888671917377\n",
      "GAL/USDT is processed -- 15/112\n",
      "working on: GALA/USDT -->maxi custum expend : GALA/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 5.293%\n",
      "######################  max expend GALA/USDT - shape (455096, 399)  buy mean : 5.293 ############################\n",
      "df original shape (455096, 399)\n",
      "df original shape buy mean : 5.293388647669942\n",
      "GALA/USDT is processed -- 16/112\n",
      "working on: SHIB/USDT -->maxi custum expend : SHIB/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 9.681%\n",
      "######################  max expend SHIB/USDT - shape (455097, 399)  buy mean : 9.681 ############################\n",
      "df original shape (455097, 399)\n",
      "df original shape buy mean : 9.681232792130029\n",
      "SHIB/USDT is processed -- 17/112\n",
      "working on: ZIL/USDT -->maxi custum expend : ZIL/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 6.120%\n",
      "######################  max expend ZIL/USDT - shape (455098, 399)  buy mean : 6.12 ############################\n",
      "df original shape (455098, 399)\n",
      "df original shape buy mean : 6.120000527358942\n",
      "ZIL/USDT is processed -- 18/112\n",
      "working on: ENS/USDT -->maxi custum expend : ENS/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 7.923%\n",
      "######################  max expend ENS/USDT - shape (455098, 399)  buy mean : 7.923 ############################\n",
      "df original shape (455098, 399)\n",
      "df original shape buy mean : 7.923128644819358\n",
      "ENS/USDT is processed -- 19/112\n",
      "working on: DOGE/USDT -->maxi custum expend : DOGE/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 6.684%\n",
      "######################  max expend DOGE/USDT - shape (968520, 399)  buy mean : 6.684 ############################\n",
      "df original shape (968520, 399)\n",
      "df original shape buy mean : 6.6840127204394335\n",
      "DOGE/USDT is processed -- 20/112\n",
      "working on: LTC/USDT -->maxi custum expend : LTC/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 7.361%\n",
      "######################  max expend LTC/USDT - shape (968519, 399)  buy mean : 7.361 ############################\n",
      "df original shape (968519, 399)\n",
      "df original shape buy mean : 7.361135919894189\n",
      "LTC/USDT is processed -- 21/112\n",
      "working on: MANA/USDT -->maxi custum expend : MANA/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 5.134%\n",
      "######################  max expend MANA/USDT - shape (449670, 399)  buy mean : 5.134 ############################\n",
      "df original shape (449670, 399)\n",
      "df original shape buy mean : 5.133987146129384\n",
      "MANA/USDT is processed -- 22/112\n",
      "working on: DAR/USDT -->maxi custum expend : DAR/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 5.101%\n",
      "######################  max expend DAR/USDT - shape (455101, 399)  buy mean : 5.101 ############################\n",
      "df original shape (455101, 399)\n",
      "df original shape buy mean : 5.100845746328837\n",
      "DAR/USDT is processed -- 23/112\n",
      "working on: WAVES/USDT -->maxi custum expend : WAVES/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 7.944%\n",
      "######################  max expend WAVES/USDT - shape (455102, 399)  buy mean : 7.944 ############################\n",
      "df original shape (455102, 399)\n",
      "df original shape buy mean : 7.9437137169249965\n",
      "WAVES/USDT is processed -- 24/112\n",
      "working on: LAZIO/USDT -->maxi custum expend : LAZIO/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 7.465%\n",
      "######################  max expend LAZIO/USDT - shape (455102, 399)  buy mean : 7.465 ############################\n",
      "df original shape (455102, 399)\n",
      "df original shape buy mean : 7.464700221049347\n",
      "LAZIO/USDT is processed -- 25/112\n",
      "working on: ALICE/USDT -->maxi custum expend : ALICE/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 10.685%\n",
      "######################  max expend ALICE/USDT - shape (455103, 399)  buy mean : 10.685 ############################\n",
      "df original shape (455103, 399)\n",
      "df original shape buy mean : 10.684614252158303\n",
      "ALICE/USDT is processed -- 26/112\n",
      "working on: ROSE/USDT -->maxi custum expend : ROSE/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 5.146%\n",
      "######################  max expend ROSE/USDT - shape (455103, 399)  buy mean : 5.146 ############################\n",
      "df original shape (455103, 399)\n",
      "df original shape buy mean : 5.146087808693856\n",
      "ROSE/USDT is processed -- 27/112\n",
      "working on: ZEC/USDT -->maxi custum expend : ZEC/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 15.614%\n",
      "######################  max expend ZEC/USDT - shape (455104, 399)  buy mean : 15.614 ############################\n",
      "df original shape (455104, 399)\n",
      "df original shape buy mean : 15.614452960202504\n",
      "ZEC/USDT is processed -- 28/112\n",
      "working on: ALGO/USDT -->maxi custum expend : ALGO/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 5.871%\n",
      "######################  max expend ALGO/USDT - shape (455105, 399)  buy mean : 5.871 ############################\n",
      "df original shape (455105, 399)\n",
      "df original shape buy mean : 5.871392316058931\n",
      "ALGO/USDT is processed -- 29/112\n",
      "working on: GRT/USDT -->maxi custum expend : GRT/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 9.136%\n",
      "######################  max expend GRT/USDT - shape (455105, 399)  buy mean : 9.136 ############################\n",
      "df original shape (455105, 399)\n",
      "df original shape buy mean : 9.136353149273244\n",
      "GRT/USDT is processed -- 30/112\n",
      "working on: PSG/USDT -->maxi custum expend : PSG/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 17.946%\n",
      "######################  max expend PSG/USDT - shape (455106, 399)  buy mean : 17.946 ############################\n",
      "df original shape (455106, 399)\n",
      "df original shape buy mean : 17.946368538318545\n",
      "PSG/USDT is processed -- 31/112\n",
      "working on: SLP/USDT -->maxi custum expend : SLP/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 29.877%\n",
      "######################  max expend SLP/USDT - shape (455106, 399)  buy mean : 29.877 ############################\n",
      "df original shape (455106, 399)\n",
      "df original shape buy mean : 29.87699568891643\n",
      "SLP/USDT is processed -- 32/112\n",
      "working on: EOS/USDT -->maxi custum expend : EOS/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 10.172%\n",
      "######################  max expend EOS/USDT - shape (455107, 399)  buy mean : 10.172 ############################\n",
      "df original shape (455107, 399)\n",
      "df original shape buy mean : 10.171673914046586\n",
      "EOS/USDT is processed -- 33/112\n",
      "working on: PORTO/USDT -->maxi custum expend : PORTO/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 7.701%\n",
      "######################  max expend PORTO/USDT - shape (449670, 399)  buy mean : 7.701 ############################\n",
      "df original shape (449670, 399)\n",
      "df original shape buy mean : 7.700980719194075\n",
      "PORTO/USDT is processed -- 34/112\n",
      "working on: ICP/USDT -->maxi custum expend : ICP/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 12.471%\n",
      "######################  max expend ICP/USDT - shape (455108, 399)  buy mean : 12.471 ############################\n",
      "df original shape (455108, 399)\n",
      "df original shape buy mean : 12.470666303382934\n",
      "ICP/USDT is processed -- 35/112\n",
      "working on: EGLD/USDT -->maxi custum expend : EGLD/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 5.028%\n",
      "######################  max expend EGLD/USDT - shape (968529, 399)  buy mean : 5.028 ############################\n",
      "df original shape (968529, 399)\n",
      "df original shape buy mean : 5.028450361321137\n",
      "EGLD/USDT is processed -- 36/112\n",
      "working on: XMR/USDT -->maxi custum expend : XMR/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 9.409%\n",
      "######################  max expend XMR/USDT - shape (455109, 399)  buy mean : 9.409 ############################\n",
      "df original shape (455109, 399)\n",
      "df original shape buy mean : 9.409174505448146\n",
      "XMR/USDT is processed -- 37/112\n",
      "working on: KDA/USDT -->maxi custum expend : KDA/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 9.800%\n",
      "######################  max expend KDA/USDT - shape (355750, 399)  buy mean : 9.8 ############################\n",
      "df original shape (355750, 399)\n",
      "df original shape buy mean : 9.80042164441321\n",
      "KDA/USDT is processed -- 38/112\n",
      "working on: ETC/USDT -->maxi custum expend : ETC/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 6.919%\n",
      "######################  max expend ETC/USDT - shape (455111, 399)  buy mean : 6.919 ############################\n",
      "df original shape (455111, 399)\n",
      "df original shape buy mean : 6.918971415764506\n",
      "ETC/USDT is processed -- 39/112\n",
      "working on: MBOX/USDT -->maxi custum expend : MBOX/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 15.910%\n",
      "######################  max expend MBOX/USDT - shape (455111, 399)  buy mean : 15.91 ############################\n",
      "df original shape (455111, 399)\n",
      "df original shape buy mean : 15.910404275001044\n",
      "MBOX/USDT is processed -- 40/112\n",
      "working on: OGN/USDT -->maxi custum expend : OGN/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 8.097%\n",
      "######################  max expend OGN/USDT - shape (455112, 399)  buy mean : 8.097 ############################\n",
      "df original shape (455112, 399)\n",
      "df original shape buy mean : 8.097347466118231\n",
      "OGN/USDT is processed -- 41/112\n",
      "working on: AR/USDT -->maxi custum expend : AR/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 8.729%\n",
      "######################  max expend AR/USDT - shape (455112, 399)  buy mean : 8.729 ############################\n",
      "df original shape (455112, 399)\n",
      "df original shape buy mean : 8.729499551758687\n",
      "AR/USDT is processed -- 42/112\n",
      "working on: GLMR/USDT -->maxi custum expend : GLMR/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 5.876%\n",
      "######################  max expend GLMR/USDT - shape (440713, 399)  buy mean : 5.876 ############################\n",
      "df original shape (440713, 399)\n",
      "df original shape buy mean : 5.876159768375337\n",
      "GLMR/USDT is processed -- 43/112\n",
      "working on: LOKA/USDT -->maxi custum expend : LOKA/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 7.509%\n",
      "######################  max expend LOKA/USDT - shape (427754, 399)  buy mean : 7.509 ############################\n",
      "df original shape (427754, 399)\n",
      "df original shape buy mean : 7.508521252869641\n",
      "LOKA/USDT is processed -- 44/112\n",
      "working on: XLM/USDT -->maxi custum expend : XLM/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 10.806%\n",
      "######################  max expend XLM/USDT - shape (455114, 399)  buy mean : 10.806 ############################\n",
      "df original shape (455114, 399)\n",
      "df original shape buy mean : 10.806083750444943\n",
      "XLM/USDT is processed -- 45/112\n",
      "working on: MTL/USDT -->maxi custum expend : MTL/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 13.500%\n",
      "######################  max expend MTL/USDT - shape (455115, 399)  buy mean : 13.5 ############################\n",
      "df original shape (455115, 399)\n",
      "df original shape buy mean : 13.50032409391033\n",
      "MTL/USDT is processed -- 46/112\n",
      "working on: SNX/USDT -->maxi custum expend : SNX/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 6.117%\n",
      "######################  max expend SNX/USDT - shape (455116, 399)  buy mean : 6.117 ############################\n",
      "df original shape (455116, 399)\n",
      "df original shape buy mean : 6.116902064528603\n",
      "SNX/USDT is processed -- 47/112\n",
      "working on: PYR/USDT -->maxi custum expend : PYR/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 16.771%\n",
      "######################  max expend PYR/USDT - shape (455116, 399)  buy mean : 16.771 ############################\n",
      "df original shape (455116, 399)\n",
      "df original shape buy mean : 16.770669455699206\n",
      "PYR/USDT is processed -- 48/112\n",
      "working on: DASH/USDT -->maxi custum expend : DASH/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 13.462%\n",
      "######################  max expend DASH/USDT - shape (455117, 399)  buy mean : 13.462 ############################\n",
      "df original shape (455117, 399)\n",
      "df original shape buy mean : 13.46159339246831\n",
      "DASH/USDT is processed -- 49/112\n",
      "working on: CITY/USDT -->maxi custum expend : CITY/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 23.056%\n",
      "######################  max expend CITY/USDT - shape (433170, 399)  buy mean : 23.056 ############################\n",
      "df original shape (433170, 399)\n",
      "df original shape buy mean : 23.05561326961701\n",
      "CITY/USDT is processed -- 50/112\n",
      "working on: ASTR/USDT -->maxi custum expend : ASTR/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 21.297%\n",
      "######################  max expend ASTR/USDT - shape (371598, 399)  buy mean : 21.297 ############################\n",
      "df original shape (371598, 399)\n",
      "df original shape buy mean : 21.297477381471374\n",
      "ASTR/USDT is processed -- 51/112\n",
      "working on: IOTA/USDT -->maxi custum expend : IOTA/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 6.721%\n",
      "######################  max expend IOTA/USDT - shape (455119, 399)  buy mean : 6.721 ############################\n",
      "df original shape (455119, 399)\n",
      "df original shape buy mean : 6.721319039635787\n",
      "IOTA/USDT is processed -- 52/112\n",
      "working on: ACM/USDT -->maxi custum expend : ACM/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 15.124%\n",
      "######################  max expend ACM/USDT - shape (445170, 399)  buy mean : 15.124 ############################\n",
      "df original shape (445170, 399)\n",
      "df original shape buy mean : 15.12388525731743\n",
      "ACM/USDT is processed -- 53/112\n",
      "working on: BAR/USDT -->maxi custum expend : BAR/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 27.128%\n",
      "######################  max expend BAR/USDT - shape (455120, 399)  buy mean : 27.128 ############################\n",
      "df original shape (455120, 399)\n",
      "df original shape buy mean : 27.127790472842328\n",
      "BAR/USDT is processed -- 54/112\n",
      "working on: JUV/USDT -->maxi custum expend : JUV/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 29.007%\n",
      "######################  max expend JUV/USDT - shape (455121, 399)  buy mean : 29.007 ############################\n",
      "df original shape (455121, 399)\n",
      "df original shape buy mean : 29.007011322263747\n",
      "JUV/USDT is processed -- 55/112\n",
      "working on: SYS/USDT -->maxi custum expend : SYS/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 10.760%\n",
      "######################  max expend SYS/USDT - shape (455121, 399)  buy mean : 10.76 ############################\n",
      "df original shape (455121, 399)\n",
      "df original shape buy mean : 10.759775971664679\n",
      "SYS/USDT is processed -- 56/112\n",
      "working on: RVN/USDT -->maxi custum expend : RVN/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 6.130%\n",
      "######################  max expend RVN/USDT - shape (455122, 399)  buy mean : 6.13 ############################\n",
      "df original shape (455122, 399)\n",
      "df original shape buy mean : 6.129784980730442\n",
      "RVN/USDT is processed -- 57/112\n",
      "working on: MBL/USDT -->maxi custum expend : MBL/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 12.024%\n",
      "######################  max expend MBL/USDT - shape (455123, 399)  buy mean : 12.024 ############################\n",
      "df original shape (455123, 399)\n",
      "df original shape buy mean : 12.024002302674223\n",
      "MBL/USDT is processed -- 58/112\n",
      "working on: REN/USDT -->maxi custum expend : REN/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 9.312%\n",
      "######################  max expend REN/USDT - shape (455123, 399)  buy mean : 9.312 ############################\n",
      "df original shape (455123, 399)\n",
      "df original shape buy mean : 9.311768466985848\n",
      "REN/USDT is processed -- 59/112\n",
      "working on: JST/USDT -->maxi custum expend : JST/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 7.985%\n",
      "######################  max expend JST/USDT - shape (455124, 399)  buy mean : 7.985 ############################\n",
      "df original shape (455124, 399)\n",
      "df original shape buy mean : 7.984856874170555\n",
      "JST/USDT is processed -- 60/112\n",
      "working on: OMG/USDT -->maxi custum expend : OMG/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 8.406%\n",
      "######################  max expend OMG/USDT - shape (455124, 399)  buy mean : 8.406 ############################\n",
      "df original shape (455124, 399)\n",
      "df original shape buy mean : 8.406060765857216\n",
      "OMG/USDT is processed -- 61/112\n",
      "working on: ATM/USDT -->maxi custum expend : ATM/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 30.566%\n",
      "######################  max expend ATM/USDT - shape (455125, 399)  buy mean : 30.566 ############################\n",
      "df original shape (455125, 399)\n",
      "df original shape buy mean : 30.566327931886843\n",
      "ATM/USDT is processed -- 62/112\n",
      "working on: XEC/USDT -->maxi custum expend : XEC/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 6.547%\n",
      "######################  max expend XEC/USDT - shape (455126, 399)  buy mean : 6.547 ############################\n",
      "df original shape (455126, 399)\n",
      "df original shape buy mean : 6.5474176381925\n",
      "XEC/USDT is processed -- 63/112\n",
      "working on: STORJ/USDT -->maxi custum expend : STORJ/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 7.108%\n",
      "######################  max expend STORJ/USDT - shape (455126, 399)  buy mean : 7.108 ############################\n",
      "df original shape (455126, 399)\n",
      "df original shape buy mean : 7.107702042950743\n",
      "STORJ/USDT is processed -- 64/112\n",
      "working on: ZRX/USDT -->maxi custum expend : ZRX/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 8.303%\n",
      "######################  max expend ZRX/USDT - shape (455127, 399)  buy mean : 8.303 ############################\n",
      "df original shape (455127, 399)\n",
      "df original shape buy mean : 8.302737477671068\n",
      "ZRX/USDT is processed -- 65/112\n",
      "working on: SRM/USDT -->maxi custum expend : SRM/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 13.355%\n",
      "######################  max expend SRM/USDT - shape (455127, 399)  buy mean : 13.355 ############################\n",
      "df original shape (455127, 399)\n",
      "df original shape buy mean : 13.354733953380046\n",
      "SRM/USDT is processed -- 66/112\n",
      "working on: ICX/USDT -->maxi custum expend : ICX/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 20.316%\n",
      "######################  max expend ICX/USDT - shape (455128, 399)  buy mean : 20.316 ############################\n",
      "df original shape (455128, 399)\n",
      "df original shape buy mean : 20.316042959343307\n",
      "ICX/USDT is processed -- 67/112\n",
      "working on: API3/USDT -->maxi custum expend : API3/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 9.327%\n",
      "######################  max expend API3/USDT - shape (426329, 399)  buy mean : 9.327 ############################\n",
      "df original shape (426329, 399)\n",
      "df original shape buy mean : 9.327303561334087\n",
      "API3/USDT is processed -- 68/112\n",
      "working on: ONT/USDT -->maxi custum expend : ONT/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 8.014%\n",
      "######################  max expend ONT/USDT - shape (455129, 399)  buy mean : 8.014 ############################\n",
      "df original shape (455129, 399)\n",
      "df original shape buy mean : 8.014431073387984\n",
      "ONT/USDT is processed -- 69/112\n",
      "working on: SKL/USDT -->maxi custum expend : SKL/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 11.392%\n",
      "######################  max expend SKL/USDT - shape (455130, 399)  buy mean : 11.392 ############################\n",
      "df original shape (455130, 399)\n",
      "df original shape buy mean : 11.392349438621933\n",
      "SKL/USDT is processed -- 70/112\n",
      "working on: MULTI/USDT -->maxi custum expend : MULTI/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 37.874%\n",
      "######################  max expend MULTI/USDT - shape (318330, 399)  buy mean : 37.874 ############################\n",
      "df original shape (318330, 399)\n",
      "df original shape buy mean : 37.873904438789936\n",
      "MULTI/USDT is processed -- 71/112\n",
      "working on: QTUM/USDT -->maxi custum expend : QTUM/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 7.797%\n",
      "######################  max expend QTUM/USDT - shape (455131, 399)  buy mean : 7.797 ############################\n",
      "df original shape (455131, 399)\n",
      "df original shape buy mean : 7.79709578121464\n",
      "QTUM/USDT is processed -- 72/112\n",
      "working on: COCOS/USDT -->maxi custum expend : COCOS/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 10.506%\n",
      "######################  max expend COCOS/USDT - shape (455132, 399)  buy mean : 10.506 ############################\n",
      "df original shape (455132, 399)\n",
      "df original shape buy mean : 10.505523672253323\n",
      "COCOS/USDT is processed -- 73/112\n",
      "working on: VOXEL/USDT -->maxi custum expend : VOXEL/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 8.747%\n",
      "######################  max expend VOXEL/USDT - shape (444420, 399)  buy mean : 8.747 ############################\n",
      "df original shape (444420, 399)\n",
      "df original shape buy mean : 8.74690607983439\n",
      "VOXEL/USDT is processed -- 74/112\n",
      "working on: HIVE/USDT -->maxi custum expend : HIVE/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 10.384%\n",
      "######################  max expend HIVE/USDT - shape (455133, 399)  buy mean : 10.384 ############################\n",
      "df original shape (455133, 399)\n",
      "df original shape buy mean : 10.383777928649428\n",
      "HIVE/USDT is processed -- 75/112\n",
      "working on: KP3R/USDT -->maxi custum expend : KP3R/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 7.308%\n",
      "######################  max expend KP3R/USDT - shape (455134, 399)  buy mean : 7.308 ############################\n",
      "df original shape (455134, 399)\n",
      "df original shape buy mean : 7.3077379409141034\n",
      "KP3R/USDT is processed -- 76/112\n",
      "working on: ATA/USDT -->maxi custum expend : ATA/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 8.691%\n",
      "######################  max expend ATA/USDT - shape (455134, 399)  buy mean : 8.691 ############################\n",
      "df original shape (455134, 399)\n",
      "df original shape buy mean : 8.691066806698688\n",
      "ATA/USDT is processed -- 77/112\n",
      "working on: STMX/USDT -->maxi custum expend : STMX/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 13.877%\n",
      "######################  max expend STMX/USDT - shape (455135, 399)  buy mean : 13.877 ############################\n",
      "df original shape (455135, 399)\n",
      "df original shape buy mean : 13.877420984982477\n",
      "STMX/USDT is processed -- 78/112\n",
      "working on: ADX/USDT -->maxi custum expend : ADX/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 15.522%\n",
      "######################  max expend ADX/USDT - shape (455136, 399)  buy mean : 15.522 ############################\n",
      "df original shape (455136, 399)\n",
      "df original shape buy mean : 15.521953877522323\n",
      "ADX/USDT is processed -- 79/112\n",
      "working on: HIGH/USDT -->maxi custum expend : HIGH/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 22.700%\n",
      "######################  max expend HIGH/USDT - shape (455136, 399)  buy mean : 22.7 ############################\n",
      "df original shape (455136, 399)\n",
      "df original shape buy mean : 22.699808408915136\n",
      "HIGH/USDT is processed -- 80/112\n",
      "working on: NULS/USDT -->maxi custum expend : NULS/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 13.888%\n",
      "######################  max expend NULS/USDT - shape (455137, 399)  buy mean : 13.888 ############################\n",
      "df original shape (455137, 399)\n",
      "df original shape buy mean : 13.888125992832927\n",
      "NULS/USDT is processed -- 81/112\n",
      "working on: MLN/USDT -->maxi custum expend : MLN/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 39.189%\n",
      "######################  max expend MLN/USDT - shape (455137, 399)  buy mean : 39.189 ############################\n",
      "df original shape (455137, 399)\n",
      "df original shape buy mean : 39.18885961809301\n",
      "MLN/USDT is processed -- 82/112\n",
      "working on: YGG/USDT -->maxi custum expend : YGG/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 8.416%\n",
      "######################  max expend YGG/USDT - shape (455138, 399)  buy mean : 8.416 ############################\n",
      "df original shape (455138, 399)\n",
      "df original shape buy mean : 8.416348448162974\n",
      "YGG/USDT is processed -- 83/112\n",
      "working on: SC/USDT -->maxi custum expend : SC/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 25.096%\n",
      "######################  max expend SC/USDT - shape (455139, 399)  buy mean : 25.096 ############################\n",
      "df original shape (455139, 399)\n",
      "df original shape buy mean : 25.095630126181234\n",
      "SC/USDT is processed -- 84/112\n",
      "working on: CKB/USDT -->maxi custum expend : CKB/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 24.767%\n",
      "######################  max expend CKB/USDT - shape (455139, 399)  buy mean : 24.767 ############################\n",
      "df original shape (455139, 399)\n",
      "df original shape buy mean : 24.766939330622073\n",
      "CKB/USDT is processed -- 85/112\n",
      "working on: TOMO/USDT -->maxi custum expend : TOMO/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 15.522%\n",
      "######################  max expend TOMO/USDT - shape (455140, 399)  buy mean : 15.522 ############################\n",
      "df original shape (455140, 399)\n",
      "df original shape buy mean : 15.52181746275871\n",
      "TOMO/USDT is processed -- 86/112\n",
      "working on: STX/USDT -->maxi custum expend : STX/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 27.798%\n",
      "######################  max expend STX/USDT - shape (455140, 399)  buy mean : 27.798 ############################\n",
      "df original shape (455140, 399)\n",
      "df original shape buy mean : 27.79760073823439\n",
      "STX/USDT is processed -- 87/112\n",
      "working on: FLUX/USDT -->maxi custum expend : FLUX/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 15.974%\n",
      "######################  max expend FLUX/USDT - shape (455141, 399)  buy mean : 15.974 ############################\n",
      "df original shape (455141, 399)\n",
      "df original shape buy mean : 15.974170641625344\n",
      "FLUX/USDT is processed -- 88/112\n",
      "working on: DNT/USDT -->maxi custum expend : DNT/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 30.200%\n",
      "######################  max expend DNT/USDT - shape (416700, 399)  buy mean : 30.2 ############################\n",
      "df original shape (416700, 399)\n",
      "df original shape buy mean : 30.20014398848092\n",
      "DNT/USDT is processed -- 89/112\n",
      "working on: ORN/USDT -->maxi custum expend : ORN/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 17.142%\n",
      "######################  max expend ORN/USDT - shape (455142, 399)  buy mean : 17.142 ############################\n",
      "df original shape (455142, 399)\n",
      "df original shape buy mean : 17.14168325489627\n",
      "ORN/USDT is processed -- 90/112\n",
      "working on: PLA/USDT -->maxi custum expend : PLA/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 33.127%\n",
      "######################  max expend PLA/USDT - shape (455143, 399)  buy mean : 33.127 ############################\n",
      "df original shape (455143, 399)\n",
      "df original shape buy mean : 33.12673159864043\n",
      "PLA/USDT is processed -- 91/112\n",
      "working on: BADGER/USDT -->maxi custum expend : BADGER/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 27.735%\n",
      "######################  max expend BADGER/USDT - shape (455143, 399)  buy mean : 27.735 ############################\n",
      "df original shape (455143, 399)\n",
      "df original shape buy mean : 27.734799832140666\n",
      "BADGER/USDT is processed -- 92/112\n",
      "working on: DF/USDT -->maxi custum expend : DF/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 32.674%\n",
      "######################  max expend DF/USDT - shape (455144, 399)  buy mean : 32.674 ############################\n",
      "df original shape (455144, 399)\n",
      "df original shape buy mean : 32.67405480463326\n",
      "DF/USDT is processed -- 93/112\n",
      "working on: MOB/USDT -->maxi custum expend : MOB/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 27.605%\n",
      "######################  max expend MOB/USDT - shape (285225, 399)  buy mean : 27.605 ############################\n",
      "df original shape (285225, 399)\n",
      "df original shape buy mean : 27.604873345604346\n",
      "MOB/USDT is processed -- 94/112\n",
      "working on: LPT/USDT -->maxi custum expend : LPT/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 11.129%\n",
      "######################  max expend LPT/USDT - shape (455145, 399)  buy mean : 11.129 ############################\n",
      "df original shape (455145, 399)\n",
      "df original shape buy mean : 11.128980874226894\n",
      "LPT/USDT is processed -- 95/112\n",
      "working on: SCRT/USDT -->maxi custum expend : SCRT/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 16.273%\n",
      "######################  max expend SCRT/USDT - shape (426346, 399)  buy mean : 16.273 ############################\n",
      "df original shape (426346, 399)\n",
      "df original shape buy mean : 16.2731678026767\n",
      "SCRT/USDT is processed -- 96/112\n",
      "working on: RAD/USDT -->maxi custum expend : RAD/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 14.223%\n",
      "######################  max expend RAD/USDT - shape (621579, 399)  buy mean : 14.223 ############################\n",
      "df original shape (621579, 399)\n",
      "df original shape buy mean : 14.222649092070355\n",
      "RAD/USDT is processed -- 97/112\n",
      "working on: NMR/USDT -->maxi custum expend : NMR/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 23.421%\n",
      "######################  max expend NMR/USDT - shape (455147, 399)  buy mean : 23.421 ############################\n",
      "df original shape (455147, 399)\n",
      "df original shape buy mean : 23.420784933219377\n",
      "NMR/USDT is processed -- 98/112\n",
      "working on: ELF/USDT -->maxi custum expend : ELF/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 19.839%\n",
      "######################  max expend ELF/USDT - shape (455148, 399)  buy mean : 19.839 ############################\n",
      "df original shape (455148, 399)\n",
      "df original shape buy mean : 19.839480784272368\n",
      "ELF/USDT is processed -- 99/112\n",
      "working on: TORN/USDT -->maxi custum expend : TORN/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 12.882%\n",
      "######################  max expend TORN/USDT - shape (444420, 399)  buy mean : 12.882 ############################\n",
      "df original shape (444420, 399)\n",
      "df original shape buy mean : 12.882183520093605\n",
      "TORN/USDT is processed -- 100/112\n",
      "working on: T/USDT -->maxi custum expend : T/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 39.747%\n",
      "######################  max expend T/USDT - shape (375949, 399)  buy mean : 39.747 ############################\n",
      "df original shape (375949, 399)\n",
      "df original shape buy mean : 39.746880560927146\n",
      "T/USDT is processed -- 101/112\n",
      "working on: QUICK/USDT -->maxi custum expend : QUICK/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 23.208%\n",
      "######################  max expend QUICK/USDT - shape (455150, 399)  buy mean : 23.208 ############################\n",
      "df original shape (455150, 399)\n",
      "df original shape buy mean : 23.20817312973745\n",
      "QUICK/USDT is processed -- 102/112\n",
      "working on: LSK/USDT -->maxi custum expend : LSK/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 25.500%\n",
      "######################  max expend LSK/USDT - shape (455150, 399)  buy mean : 25.5 ############################\n",
      "df original shape (455150, 399)\n",
      "df original shape buy mean : 25.49994507305284\n",
      "LSK/USDT is processed -- 103/112\n",
      "working on: FIDA/USDT -->maxi custum expend : FIDA/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 14.400%\n",
      "######################  max expend FIDA/USDT - shape (455151, 399)  buy mean : 14.4 ############################\n",
      "df original shape (455151, 399)\n",
      "df original shape buy mean : 14.399616830458465\n",
      "FIDA/USDT is processed -- 104/112\n",
      "working on: XNO/USDT -->maxi custum expend : XNO/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 23.189%\n",
      "######################  max expend XNO/USDT - shape (416272, 399)  buy mean : 23.189 ############################\n",
      "df original shape (416272, 399)\n",
      "df original shape buy mean : 23.188684321789598\n",
      "XNO/USDT is processed -- 105/112\n",
      "working on: BTG/USDT -->maxi custum expend : BTG/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 21.837%\n",
      "######################  max expend BTG/USDT - shape (416700, 399)  buy mean : 21.837 ############################\n",
      "df original shape (416700, 399)\n",
      "df original shape buy mean : 21.83705303575714\n",
      "BTG/USDT is processed -- 106/112\n",
      "working on: GHST/USDT -->maxi custum expend : GHST/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 39.994%\n",
      "######################  max expend GHST/USDT - shape (455153, 399)  buy mean : 39.994 ############################\n",
      "df original shape (455153, 399)\n",
      "df original shape buy mean : 39.99424369387876\n",
      "GHST/USDT is processed -- 107/112\n",
      "working on: EPS/USDT -->maxi custum expend : EPS/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n",
      "Precent Mean: 8.349%\n",
      "######################  max expend EPS/USDT - shape (174480, 399)  buy mean : 8.349 ############################\n",
      "df original shape (174480, 399)\n",
      "df original shape buy mean : 8.349381017881706\n",
      "EPS/USDT is processed -- 108/112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdf=pd.DataFrame()\n",
    "count=0\n",
    "row_numbers=15000\n",
    "for pair in pair_list[:]:\n",
    "    if pair != \"BTC/USDT\" and pair != \"EUR/USDT\" and pair != \"ETH/USDT\" :\n",
    "        print(\"working on: \"+pair ,end=\" -->\")\n",
    "        try:\n",
    "            \n",
    "            df=maxi_expand(pair=pair,i=0,j=len(df_list1m[pair]),window=WINDOW_SIZE,metadata=MetaData,BUY_PCT=BUY_PCT,SELL_PCT=SELL_PCT,buy_function=is_local_min,\n",
    "                           w1m=6,w5m=10,w15m=25,w1h=8,w1d=7,\n",
    "                           btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15)\n",
    "            print(\"df original shape \"+str(df.shape))\n",
    "            print(f\"df original shape buy mean : {df.buy.mean()*100}\")\n",
    "            df=df.reset_index()\n",
    "            try:df.pop(\"num_index\")\n",
    "            except: pass\n",
    "            try:df.pop(\"index\")\n",
    "            except: pass\n",
    "            try:df.pop(\"date\")\n",
    "            except: pass\n",
    "            df=data_shufler(df)            \n",
    "            #df=data_chooser(df,weight=50,row_numbers=df.buy.sum()*2)\n",
    "            df=data_chooser50(df,row_numbers=row_numbers)\n",
    "            gc.collect()\n",
    "            df=data_cleanup(df)\n",
    "            df=df.dropna()\n",
    "            print(pair+f\" is processed -- {count}/{len(pair_list)}\")\n",
    "            # print(df.iloc[0:1])\n",
    "        except Exception as e:\n",
    "            print(f\"error while processing {pair} {count}/{len(pair_list)}\")\n",
    "            print(e)\n",
    "        xdf=pd.concat([xdf,df],axis=0)\n",
    "        count+=1\n",
    "        del(df)\n",
    "        gc.collect()\n",
    "df=xdf\n",
    "del xdf\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>high-1</th>\n",
       "      <th>low-1</th>\n",
       "      <th>close-1</th>\n",
       "      <th>volume-1</th>\n",
       "      <th>high-2</th>\n",
       "      <th>low-2</th>\n",
       "      <th>close-2</th>\n",
       "      <th>volume-2</th>\n",
       "      <th>high-3</th>\n",
       "      <th>...</th>\n",
       "      <th>BTC_volume-3_5min</th>\n",
       "      <th>BTC_high-4_5min</th>\n",
       "      <th>BTC_low-4_5min</th>\n",
       "      <th>BTC_close-4_5min</th>\n",
       "      <th>BTC_volume-4_5min</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>lunch_day</th>\n",
       "      <th>buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.927500</td>\n",
       "      <td>-0.003288</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>370.380</td>\n",
       "      <td>-0.006382</td>\n",
       "      <td>-0.001740</td>\n",
       "      <td>-0.001740</td>\n",
       "      <td>363.030</td>\n",
       "      <td>-0.006382</td>\n",
       "      <td>...</td>\n",
       "      <td>224.521180</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>173.654890</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "      <td>-231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.975500</td>\n",
       "      <td>-0.001176</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>-0.001176</td>\n",
       "      <td>1459.400</td>\n",
       "      <td>-0.000840</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>-0.000840</td>\n",
       "      <td>476.000</td>\n",
       "      <td>-0.001512</td>\n",
       "      <td>...</td>\n",
       "      <td>90.089310</td>\n",
       "      <td>-0.002719</td>\n",
       "      <td>-0.001880</td>\n",
       "      <td>-0.002719</td>\n",
       "      <td>40.845320</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>-596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.178575</td>\n",
       "      <td>-0.004620</td>\n",
       "      <td>-0.000700</td>\n",
       "      <td>-0.000700</td>\n",
       "      <td>18093.000</td>\n",
       "      <td>-0.012460</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>-0.000700</td>\n",
       "      <td>180757.000</td>\n",
       "      <td>-0.019180</td>\n",
       "      <td>...</td>\n",
       "      <td>153.420600</td>\n",
       "      <td>-0.011647</td>\n",
       "      <td>-0.009802</td>\n",
       "      <td>-0.009963</td>\n",
       "      <td>148.105520</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>-632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.246450</td>\n",
       "      <td>-0.001420</td>\n",
       "      <td>-0.000609</td>\n",
       "      <td>-0.000609</td>\n",
       "      <td>306.000</td>\n",
       "      <td>-0.001420</td>\n",
       "      <td>-0.001420</td>\n",
       "      <td>-0.001420</td>\n",
       "      <td>161.000</td>\n",
       "      <td>-0.001014</td>\n",
       "      <td>...</td>\n",
       "      <td>317.341530</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>-0.002756</td>\n",
       "      <td>480.416350</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82.580000</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>513.700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>507.510</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>...</td>\n",
       "      <td>63.827530</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>72.917020</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>-233</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634995</th>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18519.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3937.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>352.068320</td>\n",
       "      <td>-0.004730</td>\n",
       "      <td>-0.001774</td>\n",
       "      <td>-0.002197</td>\n",
       "      <td>515.408130</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>-391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634996</th>\n",
       "      <td>0.628500</td>\n",
       "      <td>-0.001114</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>-0.001114</td>\n",
       "      <td>4905.600</td>\n",
       "      <td>-0.001591</td>\n",
       "      <td>-0.000796</td>\n",
       "      <td>-0.000796</td>\n",
       "      <td>693.800</td>\n",
       "      <td>-0.002705</td>\n",
       "      <td>...</td>\n",
       "      <td>130.832730</td>\n",
       "      <td>-0.002010</td>\n",
       "      <td>-0.000992</td>\n",
       "      <td>-0.001032</td>\n",
       "      <td>109.139040</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>-741</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634997</th>\n",
       "      <td>0.216700</td>\n",
       "      <td>-0.000923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>602442.000</td>\n",
       "      <td>-0.001846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>727757.000</td>\n",
       "      <td>-0.001846</td>\n",
       "      <td>...</td>\n",
       "      <td>141.525320</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.005045</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>205.412840</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634998</th>\n",
       "      <td>194.325000</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>181.680</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>118.896</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>...</td>\n",
       "      <td>66.039570</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>91.872360</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>55</td>\n",
       "      <td>749</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634999</th>\n",
       "      <td>65.207500</td>\n",
       "      <td>-0.000882</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>95.753</td>\n",
       "      <td>-0.000851</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>-0.000851</td>\n",
       "      <td>70.564</td>\n",
       "      <td>-0.000820</td>\n",
       "      <td>...</td>\n",
       "      <td>159.336437</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>184.275611</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>-246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1635000 rows × 399 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              price    high-1     low-1   close-1    volume-1    high-2  \\\n",
       "0         12.927500 -0.003288  0.007542  0.007542     370.380 -0.006382   \n",
       "1          2.975500 -0.001176  0.000840 -0.001176    1459.400 -0.000840   \n",
       "2          0.178575 -0.004620 -0.000700 -0.000700   18093.000 -0.012460   \n",
       "3          0.246450 -0.001420 -0.000609 -0.000609     306.000 -0.001420   \n",
       "4         82.580000 -0.000242  0.000242 -0.000121     513.700  0.000000   \n",
       "...             ...       ...       ...       ...         ...       ...   \n",
       "1634995    0.004800  0.000000  0.000000  0.000000   18519.000  0.000000   \n",
       "1634996    0.628500 -0.001114  0.000159 -0.001114    4905.600 -0.001591   \n",
       "1634997    0.216700 -0.000923  0.000000 -0.000461  602442.000 -0.001846   \n",
       "1634998  194.325000 -0.000386  0.000643  0.000129     181.680  0.000129   \n",
       "1634999   65.207500 -0.000882  0.000130  0.000130      95.753 -0.000851   \n",
       "\n",
       "            low-2   close-2    volume-2    high-3  ...  BTC_volume-3_5min  \\\n",
       "0       -0.001740 -0.001740     363.030 -0.006382  ...         224.521180   \n",
       "1        0.001176 -0.000840     476.000 -0.001512  ...          90.089310   \n",
       "2        0.004900 -0.000700  180757.000 -0.019180  ...         153.420600   \n",
       "3       -0.001420 -0.001420     161.000 -0.001014  ...         317.341530   \n",
       "4        0.001211  0.000242     507.510  0.000605  ...          63.827530   \n",
       "...           ...       ...         ...       ...  ...                ...   \n",
       "1634995  0.000000  0.000000    3937.000  0.000000  ...         352.068320   \n",
       "1634996 -0.000796 -0.000796     693.800 -0.002705  ...         130.832730   \n",
       "1634997  0.000000 -0.000461  727757.000 -0.001846  ...         141.525320   \n",
       "1634998  0.000643  0.000643     118.896  0.000129  ...          66.039570   \n",
       "1634999  0.000130 -0.000851      70.564 -0.000820  ...         159.336437   \n",
       "\n",
       "         BTC_high-4_5min  BTC_low-4_5min  BTC_close-4_5min  BTC_volume-4_5min  \\\n",
       "0               0.000415        0.002628          0.001140         173.654890   \n",
       "1              -0.002719       -0.001880         -0.002719          40.845320   \n",
       "2              -0.011647       -0.009802         -0.009963         148.105520   \n",
       "3              -0.005020       -0.000190         -0.002756         480.416350   \n",
       "4               0.000585        0.001255          0.001138          72.917020   \n",
       "...                  ...             ...               ...                ...   \n",
       "1634995        -0.004730       -0.001774         -0.002197         515.408130   \n",
       "1634996        -0.002010       -0.000992         -0.001032         109.139040   \n",
       "1634997         0.000443        0.005045          0.002790         205.412840   \n",
       "1634998         0.003419        0.005450          0.003962          91.872360   \n",
       "1634999         0.001499        0.003953          0.002994         184.275611   \n",
       "\n",
       "         day  hour  minute  lunch_day  buy  \n",
       "0          3    17      50       -231    0  \n",
       "1          6     6      16       -596    0  \n",
       "2          4     8      24       -632    0  \n",
       "3          6    14      42        572    1  \n",
       "4          5    21      35       -233    0  \n",
       "...      ...   ...     ...        ...  ...  \n",
       "1634995    6     3      22       -391    1  \n",
       "1634996    4     6      11       -741    1  \n",
       "1634997    3    21       8        180    1  \n",
       "1634998    1    21      55        749    0  \n",
       "1634999    7     3      36       -246    0  \n",
       "\n",
       "[1635000 rows x 399 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.reset_index().drop(columns=\"num_index\")\n",
    "gc.collect()\n",
    "for i in range(1):\n",
    "    df = df.reindex(np.random.permutation(df.index)).reset_index().drop(columns=\"index\")\n",
    "    gc.collect()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>high-1</th>\n",
       "      <th>low-1</th>\n",
       "      <th>close-1</th>\n",
       "      <th>volume-1</th>\n",
       "      <th>high-2</th>\n",
       "      <th>low-2</th>\n",
       "      <th>close-2</th>\n",
       "      <th>volume-2</th>\n",
       "      <th>high-3</th>\n",
       "      <th>...</th>\n",
       "      <th>BTC_volume-3_5min</th>\n",
       "      <th>BTC_high-4_5min</th>\n",
       "      <th>BTC_low-4_5min</th>\n",
       "      <th>BTC_close-4_5min</th>\n",
       "      <th>BTC_volume-4_5min</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>lunch_day</th>\n",
       "      <th>buy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8016</th>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>...</td>\n",
       "      <td>715.29984</td>\n",
       "      <td>-0.001843</td>\n",
       "      <td>-0.001065</td>\n",
       "      <td>-0.001613</td>\n",
       "      <td>356.60344</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>-968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9063</th>\n",
       "      <td>0.243500</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.011910</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>2907.0</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.016016</td>\n",
       "      <td>...</td>\n",
       "      <td>354.09154</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>476.68357</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>-968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.345725</td>\n",
       "      <td>-0.004266</td>\n",
       "      <td>0.002676</td>\n",
       "      <td>-0.001374</td>\n",
       "      <td>34181.0</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.006725</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>45507.0</td>\n",
       "      <td>-0.001952</td>\n",
       "      <td>...</td>\n",
       "      <td>1262.12175</td>\n",
       "      <td>-0.002446</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>1607.60755</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>-968</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4318</th>\n",
       "      <td>0.718450</td>\n",
       "      <td>-0.005916</td>\n",
       "      <td>-0.002714</td>\n",
       "      <td>-0.004663</td>\n",
       "      <td>32259.0</td>\n",
       "      <td>-0.010370</td>\n",
       "      <td>0.005916</td>\n",
       "      <td>-0.002853</td>\n",
       "      <td>38568.0</td>\n",
       "      <td>-0.013293</td>\n",
       "      <td>...</td>\n",
       "      <td>1100.47780</td>\n",
       "      <td>-0.002212</td>\n",
       "      <td>-0.000431</td>\n",
       "      <td>-0.000733</td>\n",
       "      <td>1128.53811</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-968</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9747</th>\n",
       "      <td>0.570425</td>\n",
       "      <td>-0.002060</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>-0.002060</td>\n",
       "      <td>2162.0</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003287</td>\n",
       "      <td>...</td>\n",
       "      <td>465.29594</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>385.90179</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>-968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13941</th>\n",
       "      <td>0.230000</td>\n",
       "      <td>-0.000870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1198.0</td>\n",
       "      <td>-0.000870</td>\n",
       "      <td>-0.000870</td>\n",
       "      <td>-0.000870</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>-0.000870</td>\n",
       "      <td>...</td>\n",
       "      <td>134.74287</td>\n",
       "      <td>-0.003238</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>-0.001292</td>\n",
       "      <td>151.28124</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>-457</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>0.202800</td>\n",
       "      <td>-0.000493</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>9876.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>3928.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>81.69297</td>\n",
       "      <td>-0.001258</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>150.07153</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>-457</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.161900</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11113.0</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>293.0</td>\n",
       "      <td>-0.001853</td>\n",
       "      <td>...</td>\n",
       "      <td>49.51890</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>61.59302</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>48</td>\n",
       "      <td>-457</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13218</th>\n",
       "      <td>0.177350</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>8528.0</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>8244.0</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>...</td>\n",
       "      <td>135.18476</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>-0.003849</td>\n",
       "      <td>-0.004719</td>\n",
       "      <td>297.55159</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>-457</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12945</th>\n",
       "      <td>0.174000</td>\n",
       "      <td>-0.002299</td>\n",
       "      <td>-0.000575</td>\n",
       "      <td>-0.002299</td>\n",
       "      <td>11477.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>52.08557</td>\n",
       "      <td>-0.000894</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>-0.000893</td>\n",
       "      <td>126.88343</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>-457</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1635000 rows × 399 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              price    high-1     low-1   close-1  volume-1    high-2  \\\n",
       "num_index                                                               \n",
       "8016       0.206000  0.003398  0.003398  0.003398       0.0  0.003398   \n",
       "9063       0.243500  0.009856  0.011910  0.010267    2907.0  0.013963   \n",
       "199        0.345725 -0.004266  0.002676 -0.001374   34181.0  0.001229   \n",
       "4318       0.718450 -0.005916 -0.002714 -0.004663   32259.0 -0.010370   \n",
       "9747       0.570425 -0.002060 -0.000131 -0.002060    2162.0 -0.000131   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "13941      0.230000 -0.000870  0.000000  0.000000    1198.0 -0.000870   \n",
       "8997       0.202800 -0.000493  0.001972  0.001972    9876.0  0.000000   \n",
       "16         0.161900 -0.001235  0.000000  0.000000   11113.0 -0.001235   \n",
       "13218      0.177350  0.001410  0.002537  0.001410    8528.0  0.002537   \n",
       "12945      0.174000 -0.002299 -0.000575 -0.002299   11477.0  0.000000   \n",
       "\n",
       "              low-2   close-2  volume-2    high-3  ...  BTC_volume-3_5min  \\\n",
       "num_index                                          ...                      \n",
       "8016       0.003398  0.003398    1041.0  0.000971  ...          715.29984   \n",
       "9063       0.013963  0.013963     204.0  0.016016  ...          354.09154   \n",
       "199        0.006725  0.001229   45507.0 -0.001952  ...         1262.12175   \n",
       "4318       0.005916 -0.002853   38568.0 -0.013293  ...         1100.47780   \n",
       "9747      -0.000131 -0.000131       0.0 -0.003287  ...          465.29594   \n",
       "...             ...       ...       ...       ...  ...                ...   \n",
       "13941     -0.000870 -0.000870    1434.0 -0.000870  ...          134.74287   \n",
       "8997       0.000986  0.000986    3928.0  0.000000  ...           81.69297   \n",
       "16        -0.001235 -0.001235     293.0 -0.001853  ...           49.51890   \n",
       "13218      0.002537  0.002537    8244.0  0.003101  ...          135.18476   \n",
       "12945      0.000000  0.000000       0.0  0.000000  ...           52.08557   \n",
       "\n",
       "           BTC_high-4_5min  BTC_low-4_5min  BTC_close-4_5min  \\\n",
       "num_index                                                      \n",
       "8016             -0.001843       -0.001065         -0.001613   \n",
       "9063              0.000734        0.001578          0.001043   \n",
       "199              -0.002446        0.000900          0.000364   \n",
       "4318             -0.002212       -0.000431         -0.000733   \n",
       "9747              0.000433        0.001011          0.000811   \n",
       "...                    ...             ...               ...   \n",
       "13941            -0.003238        0.000516         -0.001292   \n",
       "8997             -0.001258        0.001172          0.000195   \n",
       "16                0.000140        0.001517          0.001000   \n",
       "13218            -0.007546       -0.003849         -0.004719   \n",
       "12945            -0.000894        0.000912         -0.000893   \n",
       "\n",
       "           BTC_volume-4_5min  day  hour  minute  lunch_day  buy  \n",
       "num_index                                                        \n",
       "8016               356.60344    5     5      48       -968    0  \n",
       "9063               476.68357    4     9      21       -968    0  \n",
       "199               1607.60755    2     9      43       -968    1  \n",
       "4318              1128.53811    4     1       7       -968    1  \n",
       "9747               385.90179    4     3      35       -968    0  \n",
       "...                      ...  ...   ...     ...        ...  ...  \n",
       "13941              151.28124    4    19      23       -457    0  \n",
       "8997               150.07153    1     2      48       -457    0  \n",
       "16                  61.59302    6    14      48       -457    1  \n",
       "13218              297.55159    2     1      20       -457    0  \n",
       "12945              126.88343    4    23      13       -457    0  \n",
       "\n",
       "[1635000 rows x 399 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather(f\"../BigFiles/fea/w{WINDOW_SIZE}_buy{BUY_PCT}_forcasr{MAX_FORCAST_SIZE}min_{BUY_MODE}.fea\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df choosen data shape(1635000, 399)\n",
      "pair: True\n",
      "327000\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print(\"df choosen data shape\"+str(df.shape))\n",
    "print(f\"pair: {(df.shape[0]/2)==df.buy.sum()}\")\n",
    "dt=df.to_numpy(dtype=np.float32)\n",
    "#dt=df.to_numpy()\n",
    "dt=np.nan_to_num(dt,nan=0)\n",
    "#dt=dt.astype(np.float32)\n",
    "dt=np.nan_to_num(dt, neginf=0) \n",
    "dt=np.nan_to_num(dt, posinf=0) \n",
    "\n",
    "index_20pct= int(0.2*len(dt[:,0]))\n",
    "print(index_20pct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # feather loading\n",
    "# df=pd.read_feather(f\"../Data/fea/w{WINDOW_SIZE}_buy{BUY_PCT}_forcasr{MAX_FORCAST_SIZE}min_{BUY_MODE}.fea\")\n",
    "# dt=df.to_numpy(dtype=np.float32)\n",
    "# dt=fixdt(dt)\n",
    "# index_20pct= int(0.2*len(dt[:,0]))\n",
    "# gc.collect()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Normalized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 398)              1592      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 250)               99750     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 250)              1000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                5020      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 22:43:17.001645: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-04-03 22:43:17.002068: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-03 22:43:17.002111: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: abj-K93SV\n",
      "2023-04-03 22:43:17.002128: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: abj-K93SV\n",
      "2023-04-03 22:43:17.002219: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2023-04-03 22:43:17.002817: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 390.154.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 107,167\n",
      "Non-trainable params: 1,296\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 22:43:22.408796: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2082336000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6000\n",
      "511/511 [==============================] - 23s 43ms/step - loss: 0.4789 - accuracy: 0.7633 - val_loss: 0.5571 - val_accuracy: 0.7197\n",
      "Epoch 2/6000\n",
      "511/511 [==============================] - 22s 42ms/step - loss: 0.4353 - accuracy: 0.7969 - val_loss: 0.4267 - val_accuracy: 0.8039\n",
      "Epoch 3/6000\n",
      "511/511 [==============================] - 27s 53ms/step - loss: 0.4234 - accuracy: 0.8052 - val_loss: 0.4218 - val_accuracy: 0.8063\n",
      "Epoch 4/6000\n",
      "511/511 [==============================] - 27s 54ms/step - loss: 0.4151 - accuracy: 0.8104 - val_loss: 0.4133 - val_accuracy: 0.8124\n",
      "Epoch 5/6000\n",
      "511/511 [==============================] - 27s 53ms/step - loss: 0.4081 - accuracy: 0.8145 - val_loss: 0.4079 - val_accuracy: 0.8149\n",
      "Epoch 6/6000\n",
      "511/511 [==============================] - 27s 53ms/step - loss: 0.4035 - accuracy: 0.8169 - val_loss: 0.4037 - val_accuracy: 0.8162\n",
      "Epoch 7/6000\n",
      "511/511 [==============================] - 28s 54ms/step - loss: 0.4003 - accuracy: 0.8181 - val_loss: 0.4027 - val_accuracy: 0.8171\n",
      "Epoch 8/6000\n",
      "511/511 [==============================] - 28s 55ms/step - loss: 0.3978 - accuracy: 0.8193 - val_loss: 0.3979 - val_accuracy: 0.8193\n",
      "Epoch 9/6000\n",
      "511/511 [==============================] - 28s 56ms/step - loss: 0.3949 - accuracy: 0.8205 - val_loss: 0.3981 - val_accuracy: 0.8197\n",
      "Epoch 10/6000\n",
      "511/511 [==============================] - 30s 58ms/step - loss: 0.3928 - accuracy: 0.8214 - val_loss: 0.3947 - val_accuracy: 0.8211\n",
      "Epoch 11/6000\n",
      "511/511 [==============================] - 29s 56ms/step - loss: 0.3898 - accuracy: 0.8232 - val_loss: 0.3951 - val_accuracy: 0.8228\n",
      "Epoch 12/6000\n",
      "511/511 [==============================] - 30s 58ms/step - loss: 0.3875 - accuracy: 0.8244 - val_loss: 0.3907 - val_accuracy: 0.8239\n",
      "Epoch 13/6000\n",
      "511/511 [==============================] - 30s 59ms/step - loss: 0.3857 - accuracy: 0.8254 - val_loss: 0.3873 - val_accuracy: 0.8250\n",
      "Epoch 14/6000\n",
      "511/511 [==============================] - 30s 59ms/step - loss: 0.3832 - accuracy: 0.8268 - val_loss: 0.3864 - val_accuracy: 0.8254\n",
      "Epoch 15/6000\n",
      "511/511 [==============================] - 30s 59ms/step - loss: 0.3812 - accuracy: 0.8280 - val_loss: 0.3885 - val_accuracy: 0.8249\n",
      "Epoch 16/6000\n",
      "511/511 [==============================] - 30s 59ms/step - loss: 0.3795 - accuracy: 0.8287 - val_loss: 0.3840 - val_accuracy: 0.8271\n",
      "Epoch 17/6000\n",
      "511/511 [==============================] - 30s 59ms/step - loss: 0.3774 - accuracy: 0.8298 - val_loss: 0.3856 - val_accuracy: 0.8275\n",
      "Epoch 18/6000\n",
      "511/511 [==============================] - 30s 59ms/step - loss: 0.3758 - accuracy: 0.8307 - val_loss: 0.3811 - val_accuracy: 0.8295\n",
      "Epoch 19/6000\n",
      "511/511 [==============================] - 31s 60ms/step - loss: 0.3734 - accuracy: 0.8322 - val_loss: 0.3802 - val_accuracy: 0.8297\n",
      "Epoch 20/6000\n",
      "511/511 [==============================] - 31s 60ms/step - loss: 0.3721 - accuracy: 0.8328 - val_loss: 0.3779 - val_accuracy: 0.8302\n",
      "Epoch 21/6000\n",
      "511/511 [==============================] - 30s 59ms/step - loss: 0.3706 - accuracy: 0.8337 - val_loss: 0.3792 - val_accuracy: 0.8297\n",
      "Epoch 22/6000\n",
      "511/511 [==============================] - 33s 64ms/step - loss: 0.3696 - accuracy: 0.8343 - val_loss: 0.3793 - val_accuracy: 0.8299\n",
      "Epoch 23/6000\n",
      "511/511 [==============================] - 42s 82ms/step - loss: 0.3684 - accuracy: 0.8347 - val_loss: 0.3787 - val_accuracy: 0.8303\n",
      "Epoch 24/6000\n",
      "511/511 [==============================] - 42s 82ms/step - loss: 0.3674 - accuracy: 0.8354 - val_loss: 0.3780 - val_accuracy: 0.8308\n",
      "Epoch 25/6000\n",
      "511/511 [==============================] - 40s 79ms/step - loss: 0.3665 - accuracy: 0.8359 - val_loss: 0.3744 - val_accuracy: 0.8332\n",
      "Epoch 26/6000\n",
      "511/511 [==============================] - 34s 66ms/step - loss: 0.3655 - accuracy: 0.8364 - val_loss: 0.3794 - val_accuracy: 0.8315\n",
      "Epoch 27/6000\n",
      "511/511 [==============================] - 39s 75ms/step - loss: 0.3648 - accuracy: 0.8368 - val_loss: 0.3813 - val_accuracy: 0.8322\n",
      "Epoch 28/6000\n",
      "511/511 [==============================] - 41s 81ms/step - loss: 0.3645 - accuracy: 0.8369 - val_loss: 0.3752 - val_accuracy: 0.8334\n",
      "Epoch 29/6000\n",
      "511/511 [==============================] - 39s 76ms/step - loss: 0.3636 - accuracy: 0.8375 - val_loss: 0.3739 - val_accuracy: 0.8338\n",
      "Epoch 30/6000\n",
      "511/511 [==============================] - 42s 82ms/step - loss: 0.3631 - accuracy: 0.8376 - val_loss: 0.3719 - val_accuracy: 0.8340\n",
      "Epoch 31/6000\n",
      "511/511 [==============================] - 40s 78ms/step - loss: 0.3621 - accuracy: 0.8381 - val_loss: 0.3738 - val_accuracy: 0.8323\n",
      "Epoch 32/6000\n",
      "511/511 [==============================] - 41s 79ms/step - loss: 0.3617 - accuracy: 0.8382 - val_loss: 0.3740 - val_accuracy: 0.8343\n",
      "Epoch 33/6000\n",
      "511/511 [==============================] - 42s 81ms/step - loss: 0.3609 - accuracy: 0.8388 - val_loss: 0.3718 - val_accuracy: 0.8345\n",
      "Epoch 34/6000\n",
      "511/511 [==============================] - 40s 79ms/step - loss: 0.3607 - accuracy: 0.8388 - val_loss: 0.3748 - val_accuracy: 0.8329\n",
      "Epoch 35/6000\n",
      "511/511 [==============================] - 41s 79ms/step - loss: 0.3601 - accuracy: 0.8392 - val_loss: 0.3722 - val_accuracy: 0.8342\n",
      "Epoch 36/6000\n",
      "511/511 [==============================] - 41s 81ms/step - loss: 0.3599 - accuracy: 0.8392 - val_loss: 0.3747 - val_accuracy: 0.8323\n",
      "Epoch 37/6000\n",
      "511/511 [==============================] - 40s 79ms/step - loss: 0.3593 - accuracy: 0.8396 - val_loss: 0.3747 - val_accuracy: 0.8334\n",
      "Epoch 38/6000\n",
      "511/511 [==============================] - 41s 80ms/step - loss: 0.3588 - accuracy: 0.8397 - val_loss: 0.3736 - val_accuracy: 0.8342\n",
      "Epoch 39/6000\n",
      "511/511 [==============================] - 41s 80ms/step - loss: 0.3582 - accuracy: 0.8400 - val_loss: 0.3749 - val_accuracy: 0.8334\n",
      "Epoch 40/6000\n",
      "511/511 [==============================] - 43s 84ms/step - loss: 0.3579 - accuracy: 0.8401 - val_loss: 0.3729 - val_accuracy: 0.8339\n",
      "Epoch 41/6000\n",
      "511/511 [==============================] - 40s 78ms/step - loss: 0.3576 - accuracy: 0.8403 - val_loss: 0.3779 - val_accuracy: 0.8327\n",
      "Epoch 42/6000\n",
      "511/511 [==============================] - 40s 79ms/step - loss: 0.3570 - accuracy: 0.8403 - val_loss: 0.3715 - val_accuracy: 0.8350\n",
      "Epoch 43/6000\n",
      "511/511 [==============================] - 40s 79ms/step - loss: 0.3565 - accuracy: 0.8409 - val_loss: 0.3722 - val_accuracy: 0.8345\n",
      "Epoch 44/6000\n",
      "511/511 [==============================] - 42s 82ms/step - loss: 0.3563 - accuracy: 0.8410 - val_loss: 0.3756 - val_accuracy: 0.8330\n",
      "Epoch 45/6000\n",
      "511/511 [==============================] - 42s 82ms/step - loss: 0.3557 - accuracy: 0.8412 - val_loss: 0.3749 - val_accuracy: 0.8339\n",
      "Epoch 46/6000\n",
      "511/511 [==============================] - 41s 81ms/step - loss: 0.3551 - accuracy: 0.8415 - val_loss: 0.3794 - val_accuracy: 0.8336\n",
      "Epoch 47/6000\n",
      "511/511 [==============================] - 42s 82ms/step - loss: 0.3551 - accuracy: 0.8416 - val_loss: 0.3764 - val_accuracy: 0.8348\n",
      "Epoch 48/6000\n",
      "511/511 [==============================] - 40s 79ms/step - loss: 0.3545 - accuracy: 0.8419 - val_loss: 0.3739 - val_accuracy: 0.8340\n",
      "Epoch 49/6000\n",
      "511/511 [==============================] - 42s 81ms/step - loss: 0.3546 - accuracy: 0.8419 - val_loss: 0.3739 - val_accuracy: 0.8330\n",
      "Epoch 50/6000\n",
      "511/511 [==============================] - 42s 82ms/step - loss: 0.3538 - accuracy: 0.8421 - val_loss: 0.3762 - val_accuracy: 0.8328\n",
      "Epoch 51/6000\n",
      "511/511 [==============================] - 40s 78ms/step - loss: 0.3540 - accuracy: 0.8419 - val_loss: 0.3739 - val_accuracy: 0.8338\n",
      "Epoch 52/6000\n",
      "511/511 [==============================] - 42s 82ms/step - loss: 0.3535 - accuracy: 0.8423 - val_loss: 0.3736 - val_accuracy: 0.8340\n",
      "Epoch 53/6000\n",
      "511/511 [==============================] - 41s 81ms/step - loss: 0.3531 - accuracy: 0.8425 - val_loss: 0.3729 - val_accuracy: 0.8343\n",
      "Epoch 54/6000\n",
      "511/511 [==============================] - 40s 79ms/step - loss: 0.3529 - accuracy: 0.8426 - val_loss: 0.3784 - val_accuracy: 0.8342\n",
      "Epoch 55/6000\n",
      "511/511 [==============================] - 42s 82ms/step - loss: 0.3522 - accuracy: 0.8428 - val_loss: 0.3782 - val_accuracy: 0.8344\n",
      "Epoch 56/6000\n",
      "511/511 [==============================] - 41s 80ms/step - loss: 0.3523 - accuracy: 0.8429 - val_loss: 0.3757 - val_accuracy: 0.8330\n",
      "Epoch 57/6000\n",
      "511/511 [==============================] - 41s 81ms/step - loss: 0.3517 - accuracy: 0.8432 - val_loss: 0.3736 - val_accuracy: 0.8340\n",
      "Epoch 57: early stopping\n",
      "##########################################################################\n",
      "------val_accuracy-----> 83.5 | 84.32 <----------accuracy----------\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Norm_v1.json\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "save to: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_vInit.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Normalzed Model\n",
    "IN_DIM=dt.shape[1]-1\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(IN_DIM,)))\n",
    "model.add(Dense(int(250),activation='relu')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(20),activation='relu')) \n",
    "model.add(Dense(int(50),activation='relu')) \n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "print(model.summary())\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "callbacks_a = ModelCheckpoint(filepath =Model_FileName,monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "callbacks_b = EarlyStopping(monitor ='val_accuracy',mode='auto',patience=15,verbose=1)\n",
    "print(\"saving file in: \"+Model_FileName)\n",
    "history = model.fit(dt[index_20pct:, 0:-1],\n",
    "                dt[index_20pct:,-1],\n",
    "                validation_data=(dt[:index_20pct, :-1],dt[:index_20pct,-1]),\n",
    "                epochs=6000,\n",
    "                batch_size=256*10,\n",
    "                callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "print('##########################################################################')\n",
    "print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "print(Normalization_File)\n",
    "print(Model_FileName)\n",
    "model_init_file=Model_FileName.replace(f\"_v{VERSION}\", \"_vInit\")\n",
    "print(f\"save to: {model_init_file}\")\n",
    "model.save(model_init_file)\n",
    "model_init=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_init_file=Model_FileName.replace(f\"_v{VERSION}\", \"_vInit\")\n",
    "# print(f\"save to: {model_init_file}\")\n",
    "# model.save(model_init_file)\n",
    "# model_init=model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Model Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_2 (Batc  (None, 398)              1592      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 300)               119700    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 300)              1200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 300)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 200)              800       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 80)               320       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 80)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 80)               320       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 80)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 80)               320       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 80)               320       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 80)               320       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 20)                1620      \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 20)               80        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 228,813\n",
      "Trainable params: 226,177\n",
      "Non-trainable params: 2,636\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 23:25:07.548465: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2082336000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 66s 120ms/step - loss: 0.4846 - accuracy: 0.7604 - val_loss: 0.5021 - val_accuracy: 0.7645\n",
      "Epoch 2/500\n",
      "511/511 [==============================] - 69s 135ms/step - loss: 0.4355 - accuracy: 0.7983 - val_loss: 0.4264 - val_accuracy: 0.8044\n",
      "Epoch 3/500\n",
      "511/511 [==============================] - 73s 143ms/step - loss: 0.4223 - accuracy: 0.8065 - val_loss: 0.4105 - val_accuracy: 0.8148\n",
      "Epoch 4/500\n",
      "511/511 [==============================] - 74s 145ms/step - loss: 0.4109 - accuracy: 0.8131 - val_loss: 0.4038 - val_accuracy: 0.8171\n",
      "Epoch 5/500\n",
      "511/511 [==============================] - 82s 161ms/step - loss: 0.4050 - accuracy: 0.8161 - val_loss: 0.4009 - val_accuracy: 0.8171\n",
      "Epoch 6/500\n",
      "511/511 [==============================] - 101s 198ms/step - loss: 0.3994 - accuracy: 0.8193 - val_loss: 0.3954 - val_accuracy: 0.8199\n",
      "Epoch 7/500\n",
      "511/511 [==============================] - 89s 174ms/step - loss: 0.3943 - accuracy: 0.8221 - val_loss: 0.3900 - val_accuracy: 0.8253\n",
      "Epoch 8/500\n",
      "511/511 [==============================] - 97s 190ms/step - loss: 0.3902 - accuracy: 0.8243 - val_loss: 0.3858 - val_accuracy: 0.8268\n",
      "Epoch 9/500\n",
      "511/511 [==============================] - 114s 223ms/step - loss: 0.3860 - accuracy: 0.8266 - val_loss: 0.3807 - val_accuracy: 0.8301\n",
      "Epoch 10/500\n",
      "511/511 [==============================] - 116s 228ms/step - loss: 0.3829 - accuracy: 0.8284 - val_loss: 0.3796 - val_accuracy: 0.8301\n",
      "Epoch 11/500\n",
      "511/511 [==============================] - 101s 197ms/step - loss: 0.3808 - accuracy: 0.8299 - val_loss: 0.3754 - val_accuracy: 0.8324\n",
      "Epoch 12/500\n",
      "511/511 [==============================] - 102s 199ms/step - loss: 0.3785 - accuracy: 0.8312 - val_loss: 0.3755 - val_accuracy: 0.8328\n",
      "Epoch 13/500\n",
      "511/511 [==============================] - 103s 202ms/step - loss: 0.3766 - accuracy: 0.8324 - val_loss: 0.3748 - val_accuracy: 0.8330\n",
      "Epoch 14/500\n",
      "511/511 [==============================] - 101s 198ms/step - loss: 0.3753 - accuracy: 0.8331 - val_loss: 0.3725 - val_accuracy: 0.8346\n",
      "Epoch 15/500\n",
      "511/511 [==============================] - 103s 201ms/step - loss: 0.3741 - accuracy: 0.8338 - val_loss: 0.3738 - val_accuracy: 0.8334\n",
      "Epoch 16/500\n",
      "511/511 [==============================] - 112s 219ms/step - loss: 0.3735 - accuracy: 0.8344 - val_loss: 0.3703 - val_accuracy: 0.8354\n",
      "Epoch 17/500\n",
      "511/511 [==============================] - 118s 231ms/step - loss: 0.3726 - accuracy: 0.8346 - val_loss: 0.3735 - val_accuracy: 0.8346\n",
      "Epoch 18/500\n",
      "511/511 [==============================] - 130s 254ms/step - loss: 0.3721 - accuracy: 0.8350 - val_loss: 0.3718 - val_accuracy: 0.8350\n",
      "Epoch 19/500\n",
      "511/511 [==============================] - 115s 224ms/step - loss: 0.3716 - accuracy: 0.8353 - val_loss: 0.3701 - val_accuracy: 0.8357\n",
      "Epoch 20/500\n",
      "511/511 [==============================] - 120s 236ms/step - loss: 0.3711 - accuracy: 0.8357 - val_loss: 0.3672 - val_accuracy: 0.8377\n",
      "Epoch 21/500\n",
      "511/511 [==============================] - 126s 246ms/step - loss: 0.3705 - accuracy: 0.8357 - val_loss: 0.3708 - val_accuracy: 0.8357\n",
      "Epoch 22/500\n",
      "511/511 [==============================] - 113s 222ms/step - loss: 0.3702 - accuracy: 0.8359 - val_loss: 0.3701 - val_accuracy: 0.8354\n",
      "Epoch 23/500\n",
      "511/511 [==============================] - 119s 233ms/step - loss: 0.3698 - accuracy: 0.8362 - val_loss: 0.3699 - val_accuracy: 0.8357\n",
      "Epoch 24/500\n",
      "511/511 [==============================] - 115s 224ms/step - loss: 0.3695 - accuracy: 0.8363 - val_loss: 0.3680 - val_accuracy: 0.8368\n",
      "Epoch 25/500\n",
      "511/511 [==============================] - 123s 241ms/step - loss: 0.3690 - accuracy: 0.8366 - val_loss: 0.3681 - val_accuracy: 0.8371\n",
      "Epoch 26/500\n",
      "511/511 [==============================] - 106s 208ms/step - loss: 0.3687 - accuracy: 0.8368 - val_loss: 0.3688 - val_accuracy: 0.8366\n",
      "Epoch 26: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_VeryDeep.h5\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# Define the class weights\n",
    "class_weights = {0: 1., 1: 1.}\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "SizeTunner = 1\n",
    "IN_DIM = dt.shape[1] - 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(IN_DIM,)))\n",
    "model.add(Dense(int(300 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(200 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(80 * SizeTunner), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(20 * SizeTunner), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=Model_FileName, monitor='val_accuracy', save_best_only=True, save_weights=True),\n",
    "    EarlyStopping(monitor='val_accuracy', mode='auto', patience=6, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"saving file in: \" + Model_FileName)\n",
    "history = model.fit(dt[index_20pct:, :-1],\n",
    "                    dt[index_20pct:, -1],\n",
    "                    validation_data=(dt[:index_20pct, :-1], dt[:index_20pct, -1]),\n",
    "                    epochs=500,\n",
    "                    batch_size=256*10,\n",
    "                    callbacks=callbacks,\n",
    "                    class_weight=class_weights)\n",
    "\n",
    "verydeep_model_file=f'{DATA_DIR}/tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+\"_VeryDeep.h5\"\n",
    "model.save(verydeep_model_file)\n",
    "print(verydeep_model_file)\n",
    "very_deep_model=load_model(f'{DATA_DIR}/tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+\"_VeryDeep.h5\")\n",
    "#868/868 [==============================] - 30s 35ms/step - loss: 0.6078 - accuracy: 0.6664 - val_loss: 0.6107 - val_accuracy: 0.6639 >0.6646\n",
    "#Results after 380 min\n",
    "# Epoch 133/500\n",
    "# 347/347 [==============================] - 138s 398ms/step - loss: 0.5867 - accuracy: 0.6842 - val_loss: 0.5839 - val_accuracy: 0.6863\n",
    "# Epoch 134/500\n",
    "# 347/347 [==============================] - 137s 395ms/step - loss: 0.5865 - accuracy: 0.6843 - val_loss: 0.5845 - val_accuracy: 0.6861\n",
    "# Epoch 134: early stopping\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Binary Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "# from keras.optimizers import Nadam\n",
    "# from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# from keras.utils import to_categorical\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "# from tensorflow.keras.layers.experimental.preprocessing import BinaryQuantization\n",
    "\n",
    "# # Define the class weights\n",
    "# class_weights = {0: 1., 1: 1.}\n",
    "\n",
    "# gc.collect()\n",
    "\n",
    "# SizeTunner = 1\n",
    "# IN_DIM = dt.shape[1] - 1\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(BinaryQuantization(input_shape=(IN_DIM,)))\n",
    "\n",
    "# model.add(Dense(int(300 * SizeTunner)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(BinaryQuantization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(int(200 * SizeTunner)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(BinaryQuantization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(int(80 * SizeTunner)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(BinaryQuantization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(int(80 * SizeTunner)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(BinaryQuantization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(int(80 * SizeTunner)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(BinaryQuantization())\n",
    "# model.add(Dense(int(80 * SizeTunner)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(BinaryQuantization())\n",
    "# model.add(Dense(int(80 * SizeTunner)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(BinaryQuantization())\n",
    "# model.add(Dense(int(20 * SizeTunner)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(BinaryQuantization())\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "# optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
    "# model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# callbacks = [\n",
    "#     ModelCheckpoint(filepath=Model_FileName, monitor='val_accuracy', save_best_only=True, save_weights=True),\n",
    "#     EarlyStopping(monitor='val_accuracy', mode='auto', patience=6, verbose=1)\n",
    "# ]\n",
    "\n",
    "# print(\"saving file in: \" + Model_FileName)\n",
    "# history = model.fit(dt[index_20pct:, :-1],\n",
    "#                     dt[index_20pct:, -1],\n",
    "#                     validation_data=(dt[:index_20pct, :-1], dt[:index_20pct, -1]),\n",
    "#                     epochs=500,\n",
    "#                     batch_size=256*10,\n",
    "#                     callbacks=callbacks,\n",
    "#                     class_weight=class_weights)\n",
    "# # Save the model\n",
    "# binary_model_file=f'{DATA_DIR}/tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+\"_BINARY.h5\"\n",
    "# model.save(binary_model_file)\n",
    "# binary_model_file=tf.keras.models.load_model(binary_model_file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini_range_start=0\n",
    "# mini_range_stop=200000\n",
    "# model.evaluate(dt[mini_range_start:mini_range_stop,:-1],dt[mini_range_start:mini_range_stop,-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-  Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stats plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 00:33:01.693924: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2602920000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51094/51094 [==============================] - 185s 4ms/step\n",
      "Precent Mean: 61.661%\n",
      "Precent Mean: 0.000%\n",
      "ModelAccuracy: 83.720%\n",
      "True Win Predictions Mean of all: 47.691%\n",
      "XXX Loss Buy Mean of all: 13.970%\n",
      "Missed good deal off all: 2.309%\n",
      "Good Zero prediction Mean: 36.030%\n",
      "good fiability\n",
      "========= Win Ratio:77.34386403074878 ====================\n"
     ]
    }
   ],
   "source": [
    "USED_MODEL=very_deep_model\n",
    "#model_init=model\n",
    "#USED_MODEL=model_init#load_model(\"/UltimeTradingBot/Data/BUY_UP_CLOSE/tp60_w6_max3min_Model_GoodVeryDeep.h5\")\n",
    "Prediction_Note=USED_MODEL.predict( dt[:, 0:-1])\n",
    "prediction2=Prediction_Note.round()\n",
    "hp(prediction2[:,0].mean())\n",
    "PesemisticPrediction=(Prediction_Note[:,0]-0.49).round()\n",
    "hp(PesemisticPrediction.mean())\n",
    "Y=dt[:,-1].copy()\n",
    "Pred01=prediction2[:,-1]\n",
    "Original_Traget_Data=Y\n",
    "Predicted_Data=Pred01\n",
    "\n",
    "TruePred=((Original_Traget_Data==Predicted_Data)).copy()\n",
    "ModelAccuracy=hp(TruePred.mean(),\"ModelAccuracy\")\n",
    "\n",
    "TrueWinPred=((Predicted_Data==1) & (Original_Traget_Data==1) ).copy()\n",
    "TrueWinPred_Mean=hp(TrueWinPred.mean(),\"True Win Predictions Mean of all\")\n",
    "\n",
    "LossPred=((Predicted_Data==1) & (Original_Traget_Data==0) ).copy()\n",
    "LossPred_Mean=hp(LossPred.mean(),\"XXX Loss Buy Mean of all\")\n",
    "\n",
    "MissedDealPred=((Predicted_Data==0) & (Original_Traget_Data==1) ).copy()\n",
    "MissedDeal_Mean=hp(MissedDealPred.mean(),\"Missed good deal off all\")\n",
    "\n",
    "GoodZeroPred=((Predicted_Data==0) & (Original_Traget_Data==0) ).copy()\n",
    "GoodZero_Mean=hp(GoodZeroPred.mean(),\"Good Zero prediction Mean\")\n",
    "\n",
    "fiability=TrueWinPred_Mean + LossPred_Mean + MissedDeal_Mean + GoodZero_Mean\n",
    "if( fiability == 100):print(\"good fiability\")\n",
    "else: print(f\"check the fiability {fiability}\")\n",
    "\n",
    "winratio=TrueWinPred_Mean/(LossPred_Mean+TrueWinPred_Mean)\n",
    "print(f\"========= Win Ratio:{winratio*100} ====================\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN v1\n",
    "import gc\n",
    "from keras.layers import Conv1D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define the class weights\n",
    "class_weights = {0: 1., 1: 1.}\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "SizeTunner = 1\n",
    "IN_DIM = dt.shape[1] - 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(int(300 * SizeTunner), kernel_size=3, activation='elu', padding='same', input_shape=(IN_DIM, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(int(200 * SizeTunner), kernel_size=3, activation='elu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(int(80 * SizeTunner), kernel_size=3, activation='elu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(int(80 * SizeTunner), kernel_size=3, activation='elu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(80 * SizeTunner), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(20 * SizeTunner), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=Model_FileName, monitor='val_accuracy', save_best_only=True, save_weights=True),\n",
    "    EarlyStopping(monitor='val_accuracy', mode='auto', patience=6, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"saving file in: \" + Model_FileName)\n",
    "\n",
    "# Reshape the input data to have a single channel\n",
    "X_train = dt[index_20pct:, :-1].reshape(-1, IN_DIM, 1)\n",
    "y_train = dt[index_20pct:, -1]\n",
    "X_val = dt[:index_20pct, :-1].reshape(-1, IN_DIM, 1)\n",
    "y_val = dt[:index_20pct, -1]\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=500,\n",
    "                    batch_size=256*10,\n",
    "                    callbacks=callbacks,\n",
    "                    class_weight=class_weights)\n",
    "\n",
    "cnn1_model_file = f'{DATA_DIR}/tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+\"_cnn1.h5\"\n",
    "model.save(cnn1_model_file)\n",
    "print(cnn1_model_file)\n",
    "cnn1_model = load_model(f'{DATA_DIR}/tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+\"_cnn1.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_103 (Ba  (None, 398, 1)           4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 398, 75)           300       \n",
      "                                                                 \n",
      " batch_normalization_104 (Ba  (None, 398, 75)          300       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 199, 75)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 199, 75)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 14925)             0         \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 20)                298520    \n",
      "                                                                 \n",
      " batch_normalization_105 (Ba  (None, 20)               80        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 20)                420       \n",
      "                                                                 \n",
      " batch_normalization_106 (Ba  (None, 20)               80        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 20)                420       \n",
      "                                                                 \n",
      " batch_normalization_107 (Ba  (None, 20)               80        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 5)                 105       \n",
      "                                                                 \n",
      " batch_normalization_108 (Ba  (None, 5)                20        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 300,335\n",
      "Trainable params: 300,053\n",
      "Non-trainable params: 282\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/100\n",
      "121/126 [===========================>..] - ETA: 1:24 - loss: 0.6965 - accuracy: 0.5006"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb Cell 40\u001b[0m in \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m X_val \u001b[39m=\u001b[39m dt[:\u001b[39m25000\u001b[39m, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, IN_DIM, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m y_val \u001b[39m=\u001b[39m dt[:\u001b[39m25000\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m(X_val, y_val),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m                     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m                     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m cnn2_model_file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mDATA_DIR\u001b[39m}\u001b[39;00m\u001b[39m/tp\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mint\u001b[39m(BUY_PCT\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m_w\u001b[39m\u001b[39m{\u001b[39;00mWINDOW_SIZE\u001b[39m}\u001b[39;00m\u001b[39m_max\u001b[39m\u001b[39m{\u001b[39;00mMAX_FORCAST_SIZE\u001b[39m}\u001b[39;00m\u001b[39mmin_Model\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_cnn2.h5\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m model\u001b[39m.\u001b[39msave(cnn2_model_file)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## CNN v2:\n",
    "import gc\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "SizeTunner = 0.5\n",
    "IN_DIM = dt.shape[1] - 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(IN_DIM, 1)))\n",
    "model.add(Conv1D(int(150 * SizeTunner), kernel_size=3, activation='elu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Conv1D(int(100 * SizeTunner), kernel_size=3, activation='elu', padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Conv1D(int(40 * SizeTunner), kernel_size=3, activation='elu', padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(int(40 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(40 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(40 * SizeTunner), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(10 * SizeTunner), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "optimizer = RMSprop(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=Model_FileName, monitor='val_accuracy', save_best_only=True, save_weights=True),\n",
    "    EarlyStopping(monitor='val_accuracy', mode='auto', patience=6, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"saving file in: \" + Model_FileName)\n",
    "\n",
    "X_train = dt[25000:, :-1].reshape(-1, IN_DIM, 1)\n",
    "y_train = dt[25000:, -1]\n",
    "X_val = dt[:25000, :-1].reshape(-1, IN_DIM, 1)\n",
    "y_val = dt[:25000, -1]\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=100,\n",
    "                    batch_size=128*100,\n",
    "                    callbacks=callbacks,\n",
    "                    )\n",
    "\n",
    "cnn2_model_file = f'{DATA_DIR}/tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+\"_cnn2.h5\"\n",
    "model.save(cnn2_model_file)\n",
    "print(cnn2_model_file)\n",
    "cnn2_model = load_model(f'{DATA_DIR}/tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+\"_cnn2.h5\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MINI FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_11 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               51072     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63,929\n",
      "Trainable params: 62,685\n",
      "Non-trainable params: 1,244\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 00:36:58.541985: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2082336000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 30s 56ms/step - loss: 0.5680 - accuracy: 0.7123 - val_loss: 0.5350 - val_accuracy: 0.7220\n",
      "Epoch 2/100\n",
      "511/511 [==============================] - 28s 55ms/step - loss: 0.4768 - accuracy: 0.7733 - val_loss: 0.4528 - val_accuracy: 0.7854\n",
      "Epoch 3/100\n",
      "511/511 [==============================] - 28s 54ms/step - loss: 0.4625 - accuracy: 0.7839 - val_loss: 0.4416 - val_accuracy: 0.7948\n",
      "Epoch 4/100\n",
      "511/511 [==============================] - 30s 60ms/step - loss: 0.4520 - accuracy: 0.7916 - val_loss: 0.4349 - val_accuracy: 0.8004\n",
      "Epoch 5/100\n",
      "511/511 [==============================] - 28s 55ms/step - loss: 0.4442 - accuracy: 0.7970 - val_loss: 0.4259 - val_accuracy: 0.8051\n",
      "Epoch 6/100\n",
      "511/511 [==============================] - 30s 59ms/step - loss: 0.4378 - accuracy: 0.8010 - val_loss: 0.4210 - val_accuracy: 0.8079\n",
      "Epoch 7/100\n",
      "511/511 [==============================] - 30s 59ms/step - loss: 0.4327 - accuracy: 0.8043 - val_loss: 0.4175 - val_accuracy: 0.8127\n",
      "Epoch 8/100\n",
      "511/511 [==============================] - 31s 60ms/step - loss: 0.4282 - accuracy: 0.8071 - val_loss: 0.4129 - val_accuracy: 0.8123\n",
      "Epoch 9/100\n",
      "511/511 [==============================] - 35s 68ms/step - loss: 0.4247 - accuracy: 0.8090 - val_loss: 0.4100 - val_accuracy: 0.8166\n",
      "Epoch 10/100\n",
      "511/511 [==============================] - 32s 62ms/step - loss: 0.4217 - accuracy: 0.8108 - val_loss: 0.4049 - val_accuracy: 0.8189\n",
      "Epoch 11/100\n",
      "511/511 [==============================] - 33s 64ms/step - loss: 0.4188 - accuracy: 0.8128 - val_loss: 0.4023 - val_accuracy: 0.8202\n",
      "Epoch 12/100\n",
      "511/511 [==============================] - 32s 62ms/step - loss: 0.4165 - accuracy: 0.8141 - val_loss: 0.4009 - val_accuracy: 0.8216\n",
      "Epoch 13/100\n",
      "511/511 [==============================] - 31s 61ms/step - loss: 0.4142 - accuracy: 0.8154 - val_loss: 0.3984 - val_accuracy: 0.8211\n",
      "Epoch 14/100\n",
      "511/511 [==============================] - 32s 62ms/step - loss: 0.4126 - accuracy: 0.8164 - val_loss: 0.4024 - val_accuracy: 0.8202\n",
      "Epoch 15/100\n",
      "511/511 [==============================] - 31s 61ms/step - loss: 0.4105 - accuracy: 0.8172 - val_loss: 0.3951 - val_accuracy: 0.8230\n",
      "Epoch 16/100\n",
      "511/511 [==============================] - 31s 61ms/step - loss: 0.4087 - accuracy: 0.8184 - val_loss: 0.3946 - val_accuracy: 0.8255\n",
      "Epoch 17/100\n",
      "511/511 [==============================] - 32s 63ms/step - loss: 0.4069 - accuracy: 0.8189 - val_loss: 0.3941 - val_accuracy: 0.8239\n",
      "Epoch 18/100\n",
      "511/511 [==============================] - 31s 62ms/step - loss: 0.4059 - accuracy: 0.8198 - val_loss: 0.3917 - val_accuracy: 0.8259\n",
      "Epoch 19/100\n",
      "511/511 [==============================] - 32s 62ms/step - loss: 0.4044 - accuracy: 0.8207 - val_loss: 0.3910 - val_accuracy: 0.8257\n",
      "Epoch 20/100\n",
      "511/511 [==============================] - 32s 63ms/step - loss: 0.4031 - accuracy: 0.8212 - val_loss: 0.3897 - val_accuracy: 0.8264\n",
      "Epoch 21/100\n",
      "511/511 [==============================] - 32s 63ms/step - loss: 0.4016 - accuracy: 0.8221 - val_loss: 0.3872 - val_accuracy: 0.8280\n",
      "Epoch 22/100\n",
      "511/511 [==============================] - 32s 63ms/step - loss: 0.4006 - accuracy: 0.8224 - val_loss: 0.3903 - val_accuracy: 0.8281\n",
      "Epoch 23/100\n",
      "511/511 [==============================] - 32s 63ms/step - loss: 0.3996 - accuracy: 0.8229 - val_loss: 0.3861 - val_accuracy: 0.8286\n",
      "Epoch 24/100\n",
      "511/511 [==============================] - 34s 66ms/step - loss: 0.3993 - accuracy: 0.8234 - val_loss: 0.3870 - val_accuracy: 0.8286\n",
      "Epoch 25/100\n",
      "511/511 [==============================] - 32s 62ms/step - loss: 0.3983 - accuracy: 0.8237 - val_loss: 0.3831 - val_accuracy: 0.8297\n",
      "Epoch 26/100\n",
      "511/511 [==============================] - 33s 65ms/step - loss: 0.3979 - accuracy: 0.8237 - val_loss: 0.3834 - val_accuracy: 0.8303\n",
      "Epoch 27/100\n",
      "511/511 [==============================] - 33s 64ms/step - loss: 0.3973 - accuracy: 0.8239 - val_loss: 0.3826 - val_accuracy: 0.8303\n",
      "Epoch 28/100\n",
      "511/511 [==============================] - 33s 64ms/step - loss: 0.3971 - accuracy: 0.8241 - val_loss: 0.3833 - val_accuracy: 0.8302\n",
      "Epoch 29/100\n",
      "511/511 [==============================] - 34s 67ms/step - loss: 0.3963 - accuracy: 0.8248 - val_loss: 0.3826 - val_accuracy: 0.8315\n",
      "Epoch 30/100\n",
      "511/511 [==============================] - 31s 61ms/step - loss: 0.3961 - accuracy: 0.8247 - val_loss: 0.3844 - val_accuracy: 0.8306\n",
      "Epoch 31/100\n",
      "511/511 [==============================] - 34s 67ms/step - loss: 0.3955 - accuracy: 0.8250 - val_loss: 0.3814 - val_accuracy: 0.8315\n",
      "Epoch 32/100\n",
      "511/511 [==============================] - 33s 65ms/step - loss: 0.3956 - accuracy: 0.8252 - val_loss: 0.3829 - val_accuracy: 0.8318\n",
      "Epoch 33/100\n",
      "511/511 [==============================] - 32s 63ms/step - loss: 0.3949 - accuracy: 0.8253 - val_loss: 0.3825 - val_accuracy: 0.8316\n",
      "Epoch 34/100\n",
      "511/511 [==============================] - 33s 66ms/step - loss: 0.3948 - accuracy: 0.8254 - val_loss: 0.3813 - val_accuracy: 0.8311\n",
      "Epoch 35/100\n",
      "511/511 [==============================] - 33s 65ms/step - loss: 0.3944 - accuracy: 0.8254 - val_loss: 0.3791 - val_accuracy: 0.8323\n",
      "Epoch 36/100\n",
      "511/511 [==============================] - 33s 65ms/step - loss: 0.3941 - accuracy: 0.8257 - val_loss: 0.3788 - val_accuracy: 0.8317\n",
      "Epoch 37/100\n",
      "511/511 [==============================] - 33s 64ms/step - loss: 0.3940 - accuracy: 0.8258 - val_loss: 0.3833 - val_accuracy: 0.8310\n",
      "Epoch 38/100\n",
      "511/511 [==============================] - 35s 68ms/step - loss: 0.3936 - accuracy: 0.8259 - val_loss: 0.3815 - val_accuracy: 0.8313\n",
      "Epoch 39/100\n",
      "511/511 [==============================] - 31s 61ms/step - loss: 0.3935 - accuracy: 0.8260 - val_loss: 0.3839 - val_accuracy: 0.8318\n",
      "Epoch 40/100\n",
      "511/511 [==============================] - 34s 66ms/step - loss: 0.3936 - accuracy: 0.8258 - val_loss: 0.3779 - val_accuracy: 0.8322\n",
      "Epoch 41/100\n",
      "511/511 [==============================] - 36s 71ms/step - loss: 0.3934 - accuracy: 0.8258 - val_loss: 0.3797 - val_accuracy: 0.8317\n",
      "Epoch 42/100\n",
      "511/511 [==============================] - 34s 66ms/step - loss: 0.3929 - accuracy: 0.8261 - val_loss: 0.3912 - val_accuracy: 0.8308\n",
      "Epoch 43/100\n",
      "511/511 [==============================] - 35s 68ms/step - loss: 0.3929 - accuracy: 0.8261 - val_loss: 0.3795 - val_accuracy: 0.8319\n",
      "Epoch 44/100\n",
      "511/511 [==============================] - 37s 72ms/step - loss: 0.3926 - accuracy: 0.8264 - val_loss: 0.3818 - val_accuracy: 0.8308\n",
      "Epoch 45/100\n",
      "511/511 [==============================] - 39s 77ms/step - loss: 0.3920 - accuracy: 0.8268 - val_loss: 0.3783 - val_accuracy: 0.8324\n",
      "Epoch 46/100\n",
      "511/511 [==============================] - 38s 74ms/step - loss: 0.3924 - accuracy: 0.8264 - val_loss: 0.3796 - val_accuracy: 0.8331\n",
      "Epoch 47/100\n",
      "511/511 [==============================] - 34s 67ms/step - loss: 0.3923 - accuracy: 0.8265 - val_loss: 0.3785 - val_accuracy: 0.8325\n",
      "Epoch 48/100\n",
      "511/511 [==============================] - 34s 67ms/step - loss: 0.3920 - accuracy: 0.8267 - val_loss: 0.3834 - val_accuracy: 0.8310\n",
      "Epoch 49/100\n",
      "511/511 [==============================] - 33s 64ms/step - loss: 0.3924 - accuracy: 0.8265 - val_loss: 0.3795 - val_accuracy: 0.8320\n",
      "Epoch 50/100\n",
      "511/511 [==============================] - 34s 66ms/step - loss: 0.3920 - accuracy: 0.8266 - val_loss: 0.3790 - val_accuracy: 0.8333\n",
      "Epoch 51/100\n",
      "511/511 [==============================] - 33s 66ms/step - loss: 0.3918 - accuracy: 0.8267 - val_loss: 0.3800 - val_accuracy: 0.8312\n",
      "Epoch 51: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_ffnn.h5\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "IN_DIM = dt.shape[1] - 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(IN_DIM,)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=Model_FileName, monitor='val_accuracy', save_best_only=True, save_weights=True),\n",
    "    EarlyStopping(monitor='accuracy', mode='auto', patience=6, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"saving file in: \" + Model_FileName)\n",
    "\n",
    "X_train = dt[index_20pct:, :-1]\n",
    "y_train = dt[index_20pct:, -1]\n",
    "X_val = dt[:index_20pct, :-1]\n",
    "y_val = dt[:index_20pct, -1]\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=100,\n",
    "                    batch_size=256*10,\n",
    "                    callbacks=callbacks,\n",
    "                    class_weight=class_weights)\n",
    "\n",
    "ffnn_model_file = f'{DATA_DIR}/tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+\"_ffnn.h5\"\n",
    "model.save(ffnn_model_file)\n",
    "print(ffnn_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(dt[:,:-1],dt[:,-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests and Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBOOST:\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare the data\n",
    "X = dt[:, :-1]\n",
    "y = dt[:, -1]\n",
    "\n",
    "# Split the data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=1000, random_state=42)\n",
    "\n",
    "# Create the XGBoost classifier\n",
    "model = xgb.XGBClassifier(n_estimators=500,\n",
    "                          max_depth=5,\n",
    "                          learning_rate=0.1,\n",
    "                          subsample=0.8,\n",
    "                          colsample_bytree=0.8,\n",
    "                          gamma=0.1,\n",
    "                          random_state=42,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, early_stopping_rounds=10, eval_set=[(X_val, y_val)], verbose=True)\n",
    "\n",
    "# Predict the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Save the model\n",
    "xgb_model_file = f'{DATA_DIR}/tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+\"_xgb.pkl\"\n",
    "model.save_model(xgb_model_file)\n",
    "print(xgb_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LightGBM\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANTI Retrain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_dt=dt[TruePred]\n",
    "# good_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bad_dt=dt[ np.logical_not(TruePred)]\n",
    "bad_dt=dt[Predicted_Data==1 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anti prediction\n",
    "\n",
    "BadONE=bad_dt[bad_dt[:,-1]==0]\n",
    "TrueOne=bad_dt[bad_dt[:,-1]==1][:BadONE.shape[0]]\n",
    "AntiPrediction_DT=np.concatenate((BadONE,TrueOne),axis=0)\n",
    "np.random.shuffle(AntiPrediction_DT)\n",
    "\n",
    "retrain_dt=AntiPrediction_DT\n",
    "print(f\"Dataset Size is : {retrain_dt.shape[0]}\")\n",
    "class_1_weight=hp(retrain_dt[:,-1].mean())/100\n",
    "\n",
    "import gc\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# Define the class weights\n",
    "index_20pct=int(retrain_dt.shape[1]*0.2)\n",
    "\n",
    "class_weights = {0: 1-class_1_weight, 1: class_1_weight}\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "SizeTunner = 1\n",
    "IN_DIM = retrain_dt.shape[1] - 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(IN_DIM,)))\n",
    "model.add(Dense(int(200 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "model.add(Dense(int(80 * SizeTunner), activation='relu'))\n",
    "model.add(Dense(int(20 * SizeTunner), activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=Model_FileName, monitor='loss', save_best_only=True, save_weights=True),\n",
    "    EarlyStopping(monitor='loss', mode='auto', patience=20, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"saving file in: \" + Model_FileName)\n",
    "history = model.fit(retrain_dt[index_20pct:, :-1],\n",
    "                    retrain_dt[index_20pct:, -1],\n",
    "                    validation_data=(retrain_dt[:index_20pct, :-1], retrain_dt[:index_20pct, -1]),\n",
    "                    epochs=500,\n",
    "                    batch_size=256*5,\n",
    "                    callbacks=callbacks,\n",
    "                    class_weight=class_weights)\n",
    "\n",
    "#868/868 [==============================] - 30s 35ms/step - loss: 0.6078 - accuracy: 0.6664 - val_loss: 0.6107 - val_accuracy: 0.6639 >0.6646\n",
    "#Results after 380 min\n",
    "# Epoch 133/500\n",
    "# 347/347 [==============================] - 138s 398ms/step - loss: 0.5867 - accuracy: 0.6842 - val_loss: 0.5839 - val_accuracy: 0.6863\n",
    "# Epoch 134/500\n",
    "# 347/347 [==============================] - 137s 395ms/step - loss: 0.5865 - accuracy: 0.6843 - val_loss: 0.5845 - val_accuracy: 0.6861\n",
    "# Epoch 134: early stopping\n",
    "justgood_good_model=model\n",
    "justgood_good_model_wheretosave=f'{DATA_DIR}/tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Anti-Model_v2.h5'\n",
    "justgood_good_model.save(justgood_good_model_wheretosave)\n",
    "print(justgood_good_model_wheretosave)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# True PredONly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_15 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 80)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 01:04:55.050720: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2602794232 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 58s 42ms/step - loss: 0.2176 - accuracy: 0.7910 - val_loss: 0.4003 - val_accuracy: 0.8101\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1908 - accuracy: 0.8276 - val_loss: 0.3461 - val_accuracy: 0.8481\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 77s 60ms/step - loss: 0.1842 - accuracy: 0.8347 - val_loss: 0.3590 - val_accuracy: 0.8228\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 62s 48ms/step - loss: 0.1791 - accuracy: 0.8404 - val_loss: 0.3406 - val_accuracy: 0.8861\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 70s 55ms/step - loss: 0.1750 - accuracy: 0.8450 - val_loss: 0.3161 - val_accuracy: 0.8734\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1724 - accuracy: 0.8478 - val_loss: 0.3090 - val_accuracy: 0.8987\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1708 - accuracy: 0.8495 - val_loss: 0.3169 - val_accuracy: 0.8861\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1698 - accuracy: 0.8505 - val_loss: 0.3160 - val_accuracy: 0.8608\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1686 - accuracy: 0.8518 - val_loss: 0.3177 - val_accuracy: 0.8608\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 73s 58ms/step - loss: 0.1675 - accuracy: 0.8534 - val_loss: 0.3000 - val_accuracy: 0.8861\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 72s 57ms/step - loss: 0.1669 - accuracy: 0.8540 - val_loss: 0.3031 - val_accuracy: 0.8734\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 72s 57ms/step - loss: 0.1661 - accuracy: 0.8549 - val_loss: 0.2895 - val_accuracy: 0.8608\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 71s 56ms/step - loss: 0.1657 - accuracy: 0.8553 - val_loss: 0.2849 - val_accuracy: 0.8734\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1653 - accuracy: 0.8558 - val_loss: 0.3013 - val_accuracy: 0.8734\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 72s 57ms/step - loss: 0.1648 - accuracy: 0.8561 - val_loss: 0.2913 - val_accuracy: 0.8734\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1646 - accuracy: 0.8565 - val_loss: 0.2877 - val_accuracy: 0.8987\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1643 - accuracy: 0.8567 - val_loss: 0.3049 - val_accuracy: 0.8481\n",
      "Epoch 18/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1642 - accuracy: 0.8569 - val_loss: 0.3178 - val_accuracy: 0.8734\n",
      "Epoch 19/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1638 - accuracy: 0.8571 - val_loss: 0.3166 - val_accuracy: 0.8734\n",
      "Epoch 20/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1638 - accuracy: 0.8573 - val_loss: 0.3070 - val_accuracy: 0.8734\n",
      "Epoch 21/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1635 - accuracy: 0.8576 - val_loss: 0.3154 - val_accuracy: 0.8734\n",
      "Epoch 22/500\n",
      "1278/1278 [==============================] - 72s 57ms/step - loss: 0.1633 - accuracy: 0.8578 - val_loss: 0.2764 - val_accuracy: 0.8861\n",
      "Epoch 22: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re1.h5\n",
      "51094/51094 [==============================] - 147s 3ms/step\n",
      "ModelAccuracy: 83.755%\n",
      "True Win Predictions Mean of all: 46.294%\n",
      "XXX Loss Buy Mean of all: 12.539%\n",
      "Missed good deal off all: 3.706%\n",
      "Good Zero prediction Mean: 37.461%\n",
      "good fiability\n",
      "========= Win Ratio:78.68713137184913 ====================\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_19 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 66s 47ms/step - loss: 0.2143 - accuracy: 0.7923 - val_loss: 0.3567 - val_accuracy: 0.8228\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 55s 43ms/step - loss: 0.1847 - accuracy: 0.8334 - val_loss: 0.3114 - val_accuracy: 0.8734\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1774 - accuracy: 0.8416 - val_loss: 0.3681 - val_accuracy: 0.8228\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 77s 60ms/step - loss: 0.1714 - accuracy: 0.8484 - val_loss: 0.2605 - val_accuracy: 0.8861\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 63s 49ms/step - loss: 0.1668 - accuracy: 0.8542 - val_loss: 0.3096 - val_accuracy: 0.8481\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 70s 55ms/step - loss: 0.1648 - accuracy: 0.8563 - val_loss: 0.3179 - val_accuracy: 0.8228\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1630 - accuracy: 0.8583 - val_loss: 0.2807 - val_accuracy: 0.8861\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1621 - accuracy: 0.8595 - val_loss: 0.2749 - val_accuracy: 0.8861\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1608 - accuracy: 0.8612 - val_loss: 0.2635 - val_accuracy: 0.8987\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1594 - accuracy: 0.8628 - val_loss: 0.2538 - val_accuracy: 0.9114\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1587 - accuracy: 0.8639 - val_loss: 0.2576 - val_accuracy: 0.8861\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1581 - accuracy: 0.8644 - val_loss: 0.2768 - val_accuracy: 0.8861\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 77s 60ms/step - loss: 0.1578 - accuracy: 0.8648 - val_loss: 0.2533 - val_accuracy: 0.9114\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1574 - accuracy: 0.8653 - val_loss: 0.2718 - val_accuracy: 0.8734\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 0.1571 - accuracy: 0.8654 - val_loss: 0.2485 - val_accuracy: 0.9114\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1568 - accuracy: 0.8657 - val_loss: 0.2563 - val_accuracy: 0.8861\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 89s 70ms/step - loss: 0.1566 - accuracy: 0.8659 - val_loss: 0.2679 - val_accuracy: 0.8987\n",
      "Epoch 18/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1563 - accuracy: 0.8663 - val_loss: 0.2950 - val_accuracy: 0.8861\n",
      "Epoch 19/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1561 - accuracy: 0.8666 - val_loss: 0.2629 - val_accuracy: 0.8987\n",
      "Epoch 20/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1559 - accuracy: 0.8668 - val_loss: 0.2758 - val_accuracy: 0.8734\n",
      "Epoch 21/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1557 - accuracy: 0.8670 - val_loss: 0.2605 - val_accuracy: 0.8861\n",
      "Epoch 22/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1559 - accuracy: 0.8669 - val_loss: 0.2591 - val_accuracy: 0.8861\n",
      "Epoch 23/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1553 - accuracy: 0.8676 - val_loss: 0.2570 - val_accuracy: 0.9114\n",
      "Epoch 24/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1556 - accuracy: 0.8672 - val_loss: 0.2678 - val_accuracy: 0.8987\n",
      "Epoch 25/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1550 - accuracy: 0.8678 - val_loss: 0.2617 - val_accuracy: 0.8987\n",
      "Epoch 26/500\n",
      "1278/1278 [==============================] - 76s 60ms/step - loss: 0.1549 - accuracy: 0.8678 - val_loss: 0.2598 - val_accuracy: 0.8987\n",
      "Epoch 26: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re2.h5\n",
      "51094/51094 [==============================] - 150s 3ms/step\n",
      "ModelAccuracy: 83.721%\n",
      "True Win Predictions Mean of all: 45.595%\n",
      "XXX Loss Buy Mean of all: 11.874%\n",
      "Missed good deal off all: 4.405%\n",
      "Good Zero prediction Mean: 38.126%\n",
      "good fiability\n",
      "========= Win Ratio:79.3384259339818 ====================\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_23 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 72s 54ms/step - loss: 0.2120 - accuracy: 0.7936 - val_loss: 0.3284 - val_accuracy: 0.7975\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 71s 56ms/step - loss: 0.1816 - accuracy: 0.8359 - val_loss: 0.3338 - val_accuracy: 0.8354\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1735 - accuracy: 0.8454 - val_loss: 0.2888 - val_accuracy: 0.8861\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1680 - accuracy: 0.8518 - val_loss: 0.2954 - val_accuracy: 0.8608\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1639 - accuracy: 0.8571 - val_loss: 0.2691 - val_accuracy: 0.8734\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1612 - accuracy: 0.8602 - val_loss: 0.2780 - val_accuracy: 0.8734\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1594 - accuracy: 0.8624 - val_loss: 0.2796 - val_accuracy: 0.8861\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1578 - accuracy: 0.8644 - val_loss: 0.2511 - val_accuracy: 0.9114\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1562 - accuracy: 0.8664 - val_loss: 0.2446 - val_accuracy: 0.9114\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1553 - accuracy: 0.8675 - val_loss: 0.2496 - val_accuracy: 0.8987\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1547 - accuracy: 0.8680 - val_loss: 0.2470 - val_accuracy: 0.8987\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1544 - accuracy: 0.8685 - val_loss: 0.2394 - val_accuracy: 0.9114\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1539 - accuracy: 0.8692 - val_loss: 0.2461 - val_accuracy: 0.9114\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 86s 68ms/step - loss: 0.1536 - accuracy: 0.8694 - val_loss: 0.2916 - val_accuracy: 0.8734\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 82s 64ms/step - loss: 0.1534 - accuracy: 0.8696 - val_loss: 0.2842 - val_accuracy: 0.8734\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 0.1530 - accuracy: 0.8702 - val_loss: 0.2551 - val_accuracy: 0.8987\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1526 - accuracy: 0.8707 - val_loss: 0.2506 - val_accuracy: 0.8734\n",
      "Epoch 18/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1524 - accuracy: 0.8709 - val_loss: 0.2453 - val_accuracy: 0.9114\n",
      "Epoch 19/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1522 - accuracy: 0.8711 - val_loss: 0.2561 - val_accuracy: 0.8987\n",
      "Epoch 20/500\n",
      "1278/1278 [==============================] - 72s 57ms/step - loss: 0.1519 - accuracy: 0.8713 - val_loss: 0.2447 - val_accuracy: 0.9114\n",
      "Epoch 21/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1518 - accuracy: 0.8715 - val_loss: 0.2428 - val_accuracy: 0.9114\n",
      "Epoch 22/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1518 - accuracy: 0.8715 - val_loss: 0.2590 - val_accuracy: 0.8861\n",
      "Epoch 23/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1516 - accuracy: 0.8717 - val_loss: 0.2523 - val_accuracy: 0.9114\n",
      "Epoch 24/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1513 - accuracy: 0.8721 - val_loss: 0.2601 - val_accuracy: 0.8987\n",
      "Epoch 24: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re3.h5\n",
      "51094/51094 [==============================] - 151s 3ms/step\n",
      "ModelAccuracy: 82.699%\n",
      "True Win Predictions Mean of all: 43.061%\n",
      "XXX Loss Buy Mean of all: 10.361%\n",
      "Missed good deal off all: 6.939%\n",
      "Good Zero prediction Mean: 39.639%\n",
      "good fiability\n",
      "========= Win Ratio:80.60536857474449 ====================\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_27 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 74s 56ms/step - loss: 0.2049 - accuracy: 0.7973 - val_loss: 0.3301 - val_accuracy: 0.8354\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 71s 56ms/step - loss: 0.1734 - accuracy: 0.8423 - val_loss: 0.2965 - val_accuracy: 0.8608\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1639 - accuracy: 0.8536 - val_loss: 0.3202 - val_accuracy: 0.7975\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1581 - accuracy: 0.8613 - val_loss: 0.3158 - val_accuracy: 0.8228\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1546 - accuracy: 0.8656 - val_loss: 0.2800 - val_accuracy: 0.8608\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1517 - accuracy: 0.8695 - val_loss: 0.2737 - val_accuracy: 0.8481\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1495 - accuracy: 0.8724 - val_loss: 0.2676 - val_accuracy: 0.8608\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1484 - accuracy: 0.8737 - val_loss: 0.2700 - val_accuracy: 0.8608\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1471 - accuracy: 0.8753 - val_loss: 0.2740 - val_accuracy: 0.8608\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1459 - accuracy: 0.8769 - val_loss: 0.2579 - val_accuracy: 0.8987\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1451 - accuracy: 0.8783 - val_loss: 0.2497 - val_accuracy: 0.8861\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1443 - accuracy: 0.8792 - val_loss: 0.3533 - val_accuracy: 0.8354\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1438 - accuracy: 0.8796 - val_loss: 0.2458 - val_accuracy: 0.8861\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1434 - accuracy: 0.8802 - val_loss: 0.2683 - val_accuracy: 0.8734\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1429 - accuracy: 0.8807 - val_loss: 0.3086 - val_accuracy: 0.8608\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1426 - accuracy: 0.8811 - val_loss: 0.2754 - val_accuracy: 0.8608\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1424 - accuracy: 0.8812 - val_loss: 0.2785 - val_accuracy: 0.8481\n",
      "Epoch 18/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1419 - accuracy: 0.8817 - val_loss: 0.2654 - val_accuracy: 0.8481\n",
      "Epoch 19/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1417 - accuracy: 0.8821 - val_loss: 0.2840 - val_accuracy: 0.8481\n",
      "Epoch 20/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1416 - accuracy: 0.8823 - val_loss: 0.2502 - val_accuracy: 0.8734\n",
      "Epoch 21/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1412 - accuracy: 0.8826 - val_loss: 0.2680 - val_accuracy: 0.8608\n",
      "Epoch 22/500\n",
      "1278/1278 [==============================] - 76s 59ms/step - loss: 0.1412 - accuracy: 0.8828 - val_loss: 0.3028 - val_accuracy: 0.8481\n",
      "Epoch 23/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1410 - accuracy: 0.8828 - val_loss: 0.2446 - val_accuracy: 0.8987\n",
      "Epoch 24/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1408 - accuracy: 0.8831 - val_loss: 0.2345 - val_accuracy: 0.8987\n",
      "Epoch 25/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1408 - accuracy: 0.8832 - val_loss: 0.2425 - val_accuracy: 0.8987\n",
      "Epoch 26/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1404 - accuracy: 0.8836 - val_loss: 0.2558 - val_accuracy: 0.8734\n",
      "Epoch 26: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re4.h5\n",
      "51094/51094 [==============================] - 149s 3ms/step\n",
      "ModelAccuracy: 82.092%\n",
      "True Win Predictions Mean of all: 41.925%\n",
      "XXX Loss Buy Mean of all: 9.833%\n",
      "Missed good deal off all: 8.075%\n",
      "Good Zero prediction Mean: 40.167%\n",
      "good fiability\n",
      "========= Win Ratio:81.00197070984196 ====================\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_31 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 75s 56ms/step - loss: 0.2022 - accuracy: 0.7972 - val_loss: 0.3122 - val_accuracy: 0.8481\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1694 - accuracy: 0.8444 - val_loss: 0.3003 - val_accuracy: 0.8481\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1586 - accuracy: 0.8581 - val_loss: 0.2666 - val_accuracy: 0.8481\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 72s 57ms/step - loss: 0.1521 - accuracy: 0.8670 - val_loss: 0.2919 - val_accuracy: 0.8354\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1486 - accuracy: 0.8710 - val_loss: 0.2658 - val_accuracy: 0.8481\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1460 - accuracy: 0.8746 - val_loss: 0.2676 - val_accuracy: 0.8734\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1438 - accuracy: 0.8779 - val_loss: 0.2683 - val_accuracy: 0.8734\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1423 - accuracy: 0.8797 - val_loss: 0.2634 - val_accuracy: 0.8734\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1411 - accuracy: 0.8815 - val_loss: 0.2650 - val_accuracy: 0.8608\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 0.1397 - accuracy: 0.8832 - val_loss: 0.2700 - val_accuracy: 0.8734\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1393 - accuracy: 0.8838 - val_loss: 0.2367 - val_accuracy: 0.8861\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1383 - accuracy: 0.8852 - val_loss: 0.2536 - val_accuracy: 0.8608\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1380 - accuracy: 0.8857 - val_loss: 0.2532 - val_accuracy: 0.8734\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1376 - accuracy: 0.8861 - val_loss: 0.2292 - val_accuracy: 0.8734\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1371 - accuracy: 0.8866 - val_loss: 0.2488 - val_accuracy: 0.8608\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1369 - accuracy: 0.8868 - val_loss: 0.2629 - val_accuracy: 0.8608\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1366 - accuracy: 0.8873 - val_loss: 0.2552 - val_accuracy: 0.8734\n",
      "Epoch 18/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1362 - accuracy: 0.8877 - val_loss: 0.2581 - val_accuracy: 0.8608\n",
      "Epoch 19/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1362 - accuracy: 0.8878 - val_loss: 0.2537 - val_accuracy: 0.8861\n",
      "Epoch 20/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1358 - accuracy: 0.8882 - val_loss: 0.2475 - val_accuracy: 0.8734\n",
      "Epoch 21/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1356 - accuracy: 0.8884 - val_loss: 0.2522 - val_accuracy: 0.8734\n",
      "Epoch 22/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1353 - accuracy: 0.8887 - val_loss: 0.2715 - val_accuracy: 0.8608\n",
      "Epoch 23/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1351 - accuracy: 0.8890 - val_loss: 0.2433 - val_accuracy: 0.8734\n",
      "Epoch 24/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1350 - accuracy: 0.8891 - val_loss: 0.2347 - val_accuracy: 0.8734\n",
      "Epoch 25/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1348 - accuracy: 0.8894 - val_loss: 0.2464 - val_accuracy: 0.8608\n",
      "Epoch 26/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1348 - accuracy: 0.8893 - val_loss: 0.2366 - val_accuracy: 0.8734\n",
      "Epoch 27/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1347 - accuracy: 0.8895 - val_loss: 0.2394 - val_accuracy: 0.8861\n",
      "Epoch 27: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re5.h5\n",
      "51094/51094 [==============================] - 154s 3ms/step\n",
      "ModelAccuracy: 81.853%\n",
      "True Win Predictions Mean of all: 41.590%\n",
      "XXX Loss Buy Mean of all: 9.737%\n",
      "Missed good deal off all: 8.410%\n",
      "Good Zero prediction Mean: 40.263%\n",
      "good fiability\n",
      "========= Win Ratio:81.02947766282853 ====================\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_35 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 75s 56ms/step - loss: 0.2014 - accuracy: 0.7960 - val_loss: 0.2935 - val_accuracy: 0.8101\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1673 - accuracy: 0.8454 - val_loss: 0.2598 - val_accuracy: 0.8608\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1573 - accuracy: 0.8580 - val_loss: 0.2518 - val_accuracy: 0.8734\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 71s 56ms/step - loss: 0.1511 - accuracy: 0.8667 - val_loss: 0.2902 - val_accuracy: 0.8608\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1471 - accuracy: 0.8722 - val_loss: 0.2434 - val_accuracy: 0.8734\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1440 - accuracy: 0.8763 - val_loss: 0.2398 - val_accuracy: 0.8987\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 56s 44ms/step - loss: 0.1425 - accuracy: 0.8784 - val_loss: 0.2327 - val_accuracy: 0.9241\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 58s 45ms/step - loss: 0.1412 - accuracy: 0.8803 - val_loss: 0.2286 - val_accuracy: 0.8987\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 78s 61ms/step - loss: 0.1397 - accuracy: 0.8824 - val_loss: 0.2394 - val_accuracy: 0.8861\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1382 - accuracy: 0.8846 - val_loss: 0.2329 - val_accuracy: 0.8861\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 71s 55ms/step - loss: 0.1373 - accuracy: 0.8857 - val_loss: 0.2304 - val_accuracy: 0.9114\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1367 - accuracy: 0.8865 - val_loss: 0.2225 - val_accuracy: 0.9114\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1363 - accuracy: 0.8869 - val_loss: 0.2276 - val_accuracy: 0.8987\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1356 - accuracy: 0.8877 - val_loss: 0.2342 - val_accuracy: 0.8987\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1357 - accuracy: 0.8876 - val_loss: 0.2295 - val_accuracy: 0.8987\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1351 - accuracy: 0.8885 - val_loss: 0.2328 - val_accuracy: 0.8987\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1348 - accuracy: 0.8889 - val_loss: 0.2385 - val_accuracy: 0.8861\n",
      "Epoch 18/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1346 - accuracy: 0.8891 - val_loss: 0.2297 - val_accuracy: 0.8987\n",
      "Epoch 19/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1344 - accuracy: 0.8893 - val_loss: 0.2154 - val_accuracy: 0.8987\n",
      "Epoch 20/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1342 - accuracy: 0.8894 - val_loss: 0.2033 - val_accuracy: 0.9241\n",
      "Epoch 21/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1339 - accuracy: 0.8901 - val_loss: 0.2505 - val_accuracy: 0.8861\n",
      "Epoch 22/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1338 - accuracy: 0.8900 - val_loss: 0.2349 - val_accuracy: 0.8987\n",
      "Epoch 23/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1337 - accuracy: 0.8904 - val_loss: 0.2188 - val_accuracy: 0.8861\n",
      "Epoch 23: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re6.h5\n",
      "51094/51094 [==============================] - 149s 3ms/step\n",
      "ModelAccuracy: 80.504%\n",
      "True Win Predictions Mean of all: 39.364%\n",
      "XXX Loss Buy Mean of all: 8.860%\n",
      "Missed good deal off all: 10.636%\n",
      "Good Zero prediction Mean: 41.140%\n",
      "good fiability\n",
      "========= Win Ratio:81.62740544127406 ====================\n"
     ]
    }
   ],
   "source": [
    "#Change retaindt\n",
    "for rrr in range(1,7):\n",
    "    retrain_dt=dt\n",
    "    class_1_weight=TrueWinPred.mean()\n",
    "\n",
    "    import gc\n",
    "    from keras.layers import Dense\n",
    "    from keras.models import Sequential\n",
    "    from keras.optimizers import Nadam\n",
    "    from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "    # Define the class weights\n",
    "    index_20pct=int(retrain_dt.shape[1]*0.2)\n",
    "    class_weights = {0: 1-class_1_weight, 1: class_1_weight}\n",
    "    gc.collect()\n",
    "\n",
    "    SizeTunner = 1\n",
    "    IN_DIM = retrain_dt.shape[1] - 1\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(IN_DIM,)))\n",
    "    model.add(Dense(int(200 * SizeTunner), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    # model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    model.add(Dense(int(80 * SizeTunner), activation='relu'))\n",
    "    model.add(Dense(int(20 * SizeTunner), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(filepath=Model_FileName, monitor='val_accuracy', save_best_only=True, save_weights=True),\n",
    "        EarlyStopping(monitor='val_accuracy', mode='auto', patience=16, verbose=1)\n",
    "    ]\n",
    "\n",
    "    print(\"saving file in: \" + Model_FileName)\n",
    "    history = model.fit(retrain_dt[index_20pct:, :-1],\n",
    "                        TrueWinPred[index_20pct:],\n",
    "                        validation_data=(retrain_dt[:index_20pct, :-1], TrueWinPred[:index_20pct]),\n",
    "                        epochs=500,\n",
    "                        batch_size=256*5,\n",
    "                        callbacks=callbacks,\n",
    "                        class_weight=class_weights)\n",
    "\n",
    "    #868/868 [==============================] - 30s 35ms/step - loss: 0.6078 - accuracy: 0.6664 - val_loss: 0.6107 - val_accuracy: 0.6639 >0.6646\n",
    "    #Results after 380 min\n",
    "    # Epoch 133/500\n",
    "    # 347/347 [==============================] - 138s 398ms/step - loss: 0.5867 - accuracy: 0.6842 - val_loss: 0.5839 - val_accuracy: 0.6863\n",
    "    # Epoch 134/500\n",
    "    # 347/347 [==============================] - 137s 395ms/step - loss: 0.5865 - accuracy: 0.6843 - val_loss: 0.5845 - val_accuracy: 0.6861\n",
    "    # Epoch 134: early stopping\n",
    "\n",
    "    true_win_model=model\n",
    "    wheretosave=f'{DATA_DIR}/tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+f\"_true_win_model_Re{rrr}.h5\"\n",
    "    true_win_model.save(wheretosave)\n",
    "    print(wheretosave)\n",
    "    USED_MODEL=true_win_model\n",
    "    bad_Prediction_Note=USED_MODEL.predict( dt[:, 0:-1])\n",
    "    Pred02=bad_Prediction_Note.round()\n",
    "    Original_Traget_Data=Y\n",
    "    Predicted_Data=Pred02[:,0]\n",
    "\n",
    "    BadTruePred=(Original_Traget_Data==Predicted_Data).copy()\n",
    "    BadModelAccuracy=hp(BadTruePred.mean(),\"ModelAccuracy\")\n",
    "\n",
    "    BadTrueWinPred=((Predicted_Data==1) & (Original_Traget_Data==1) ).copy()\n",
    "    BadTrueWinPred_Mean=hp(BadTrueWinPred.mean(),\"True Win Predictions Mean of all\")\n",
    "\n",
    "    BadLossPred=((Predicted_Data==1) & (Original_Traget_Data==0) ).copy()\n",
    "    BadLossPred_Mean=hp(BadLossPred.mean(),\"XXX Loss Buy Mean of all\")\n",
    "\n",
    "    BadMissedDealPred=((Predicted_Data==0) & (Original_Traget_Data==1) ).copy()\n",
    "    BadMissedDeal_Mean=hp(BadMissedDealPred.mean(),\"Missed good deal off all\")\n",
    "\n",
    "    BadGoodZeroPred=((Predicted_Data==0) & (Original_Traget_Data==0) ).copy()\n",
    "    BadGoodZero_Mean=hp(BadGoodZeroPred.mean(),\"Good Zero prediction Mean\")\n",
    "\n",
    "    fiability=BadTrueWinPred_Mean + BadLossPred_Mean + BadMissedDeal_Mean + BadGoodZero_Mean\n",
    "    if( fiability == 100):print(\"good fiability\")\n",
    "    else: print(f\"check the fiability {fiability}\")\n",
    "    winratio=BadTrueWinPred_Mean/(BadLossPred_Mean+BadTrueWinPred_Mean)\n",
    "    print(f\"========= Win Ratio:{winratio*100} ====================\")\n",
    "    ## for retraining again\n",
    "    TrueWinPred=BadTrueWinPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_39 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 40s 29ms/step - loss: 0.1943 - accuracy: 0.7974 - val_loss: 0.2715 - val_accuracy: 0.8734\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 45s 36ms/step - loss: 0.1600 - accuracy: 0.8486 - val_loss: 0.2490 - val_accuracy: 0.8861\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 50s 39ms/step - loss: 0.1494 - accuracy: 0.8629 - val_loss: 0.2669 - val_accuracy: 0.8608\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 49s 38ms/step - loss: 0.1429 - accuracy: 0.8724 - val_loss: 0.2357 - val_accuracy: 0.8861\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 50s 39ms/step - loss: 0.1394 - accuracy: 0.8771 - val_loss: 0.2299 - val_accuracy: 0.8734\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 50s 39ms/step - loss: 0.1362 - accuracy: 0.8818 - val_loss: 0.2124 - val_accuracy: 0.8987\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 51s 40ms/step - loss: 0.1344 - accuracy: 0.8846 - val_loss: 0.2215 - val_accuracy: 0.8861\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 53s 41ms/step - loss: 0.1329 - accuracy: 0.8865 - val_loss: 0.2103 - val_accuracy: 0.9114\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 54s 42ms/step - loss: 0.1317 - accuracy: 0.8884 - val_loss: 0.2198 - val_accuracy: 0.9114\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 53s 42ms/step - loss: 0.1306 - accuracy: 0.8900 - val_loss: 0.2264 - val_accuracy: 0.8861\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 54s 42ms/step - loss: 0.1296 - accuracy: 0.8912 - val_loss: 0.2032 - val_accuracy: 0.9241\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 54s 42ms/step - loss: 0.1290 - accuracy: 0.8924 - val_loss: 0.1936 - val_accuracy: 0.9241\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 58s 45ms/step - loss: 0.1286 - accuracy: 0.8928 - val_loss: 0.1910 - val_accuracy: 0.9241\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 62s 48ms/step - loss: 0.1282 - accuracy: 0.8932 - val_loss: 0.2027 - val_accuracy: 0.9114\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 85s 67ms/step - loss: 0.1276 - accuracy: 0.8941 - val_loss: 0.4781 - val_accuracy: 0.8481\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 82s 64ms/step - loss: 0.1275 - accuracy: 0.8943 - val_loss: 0.1937 - val_accuracy: 0.9241\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 0.1272 - accuracy: 0.8948 - val_loss: 0.1965 - val_accuracy: 0.9114\n",
      "Epoch 18/500\n",
      "1278/1278 [==============================] - 81s 63ms/step - loss: 0.1270 - accuracy: 0.8951 - val_loss: 0.1826 - val_accuracy: 0.9114\n",
      "Epoch 19/500\n",
      "1278/1278 [==============================] - 82s 64ms/step - loss: 0.1268 - accuracy: 0.8951 - val_loss: 0.2128 - val_accuracy: 0.9114\n",
      "Epoch 20/500\n",
      "1278/1278 [==============================] - 83s 65ms/step - loss: 0.1264 - accuracy: 0.8956 - val_loss: 0.2198 - val_accuracy: 0.8861\n",
      "Epoch 21/500\n",
      "1278/1278 [==============================] - 83s 65ms/step - loss: 0.1262 - accuracy: 0.8960 - val_loss: 0.1875 - val_accuracy: 0.9114\n",
      "Epoch 22/500\n",
      "1278/1278 [==============================] - 83s 65ms/step - loss: 0.1260 - accuracy: 0.8964 - val_loss: 0.2073 - val_accuracy: 0.8987\n",
      "Epoch 23/500\n",
      "1278/1278 [==============================] - 84s 66ms/step - loss: 0.1259 - accuracy: 0.8964 - val_loss: 0.2064 - val_accuracy: 0.8987\n",
      "Epoch 24/500\n",
      "1278/1278 [==============================] - 76s 60ms/step - loss: 0.1256 - accuracy: 0.8966 - val_loss: 0.1940 - val_accuracy: 0.9114\n",
      "Epoch 25/500\n",
      "1278/1278 [==============================] - 71s 56ms/step - loss: 0.1255 - accuracy: 0.8968 - val_loss: 0.1879 - val_accuracy: 0.9114\n",
      "Epoch 26/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1254 - accuracy: 0.8969 - val_loss: 0.2105 - val_accuracy: 0.8987\n",
      "Epoch 27/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1253 - accuracy: 0.8971 - val_loss: 0.1994 - val_accuracy: 0.9114\n",
      "Epoch 27: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re7.h5\n",
      "51094/51094 [==============================] - 151s 3ms/step\n",
      "ModelAccuracy: 79.616%\n",
      "True Win Predictions Mean of all: 37.905%\n",
      "XXX Loss Buy Mean of all: 8.289%\n",
      "Missed good deal off all: 12.095%\n",
      "Good Zero prediction Mean: 41.711%\n",
      "good fiability\n",
      "========= Win Ratio:82.05611118327056 ====================\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_43 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_46 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 71s 53ms/step - loss: 0.1883 - accuracy: 0.7987 - val_loss: 0.2655 - val_accuracy: 0.8734\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 70s 55ms/step - loss: 0.1535 - accuracy: 0.8528 - val_loss: 0.2293 - val_accuracy: 0.8861\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 76s 59ms/step - loss: 0.1431 - accuracy: 0.8671 - val_loss: 0.2348 - val_accuracy: 0.9114\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1360 - accuracy: 0.8777 - val_loss: 0.2585 - val_accuracy: 0.8608\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1329 - accuracy: 0.8822 - val_loss: 0.2212 - val_accuracy: 0.8861\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 72s 57ms/step - loss: 0.1309 - accuracy: 0.8847 - val_loss: 0.2219 - val_accuracy: 0.9114\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 71s 56ms/step - loss: 0.1291 - accuracy: 0.8878 - val_loss: 0.2317 - val_accuracy: 0.8734\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1276 - accuracy: 0.8901 - val_loss: 0.2042 - val_accuracy: 0.8987\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 71s 55ms/step - loss: 0.1264 - accuracy: 0.8917 - val_loss: 0.2070 - val_accuracy: 0.8734\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1250 - accuracy: 0.8940 - val_loss: 0.2118 - val_accuracy: 0.8987\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1241 - accuracy: 0.8953 - val_loss: 0.2163 - val_accuracy: 0.8861\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 81s 63ms/step - loss: 0.1232 - accuracy: 0.8965 - val_loss: 0.2085 - val_accuracy: 0.8987\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 84s 65ms/step - loss: 0.1229 - accuracy: 0.8970 - val_loss: 0.2010 - val_accuracy: 0.8861\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1221 - accuracy: 0.8982 - val_loss: 0.2091 - val_accuracy: 0.9114\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1217 - accuracy: 0.8988 - val_loss: 0.2121 - val_accuracy: 0.8608\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 0.1213 - accuracy: 0.8993 - val_loss: 0.2039 - val_accuracy: 0.9114\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 0.1211 - accuracy: 0.8994 - val_loss: 0.2065 - val_accuracy: 0.8987\n",
      "Epoch 18/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1209 - accuracy: 0.8998 - val_loss: 0.2557 - val_accuracy: 0.8608\n",
      "Epoch 19/500\n",
      "1278/1278 [==============================] - 72s 57ms/step - loss: 0.1205 - accuracy: 0.9004 - val_loss: 0.1888 - val_accuracy: 0.9114\n",
      "Epoch 19: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re8.h5\n",
      "51094/51094 [==============================] - 151s 3ms/step\n",
      "ModelAccuracy: 78.814%\n",
      "True Win Predictions Mean of all: 36.641%\n",
      "XXX Loss Buy Mean of all: 7.827%\n",
      "Missed good deal off all: 13.359%\n",
      "Good Zero prediction Mean: 42.173%\n",
      "good fiability\n",
      "========= Win Ratio:82.39857875326078 ====================\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_47 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 74s 56ms/step - loss: 0.1832 - accuracy: 0.7997 - val_loss: 0.2591 - val_accuracy: 0.8734\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 72s 57ms/step - loss: 0.1478 - accuracy: 0.8556 - val_loss: 0.2225 - val_accuracy: 0.8987\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1363 - accuracy: 0.8724 - val_loss: 0.2382 - val_accuracy: 0.8734\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1300 - accuracy: 0.8827 - val_loss: 0.2187 - val_accuracy: 0.9114\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1265 - accuracy: 0.8876 - val_loss: 0.2220 - val_accuracy: 0.8861\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1245 - accuracy: 0.8906 - val_loss: 0.2178 - val_accuracy: 0.8861\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1228 - accuracy: 0.8933 - val_loss: 0.2088 - val_accuracy: 0.8861\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1213 - accuracy: 0.8956 - val_loss: 0.2121 - val_accuracy: 0.9114\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1203 - accuracy: 0.8972 - val_loss: 0.2111 - val_accuracy: 0.8987\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1195 - accuracy: 0.8985 - val_loss: 0.2196 - val_accuracy: 0.8861\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1185 - accuracy: 0.8997 - val_loss: 0.2046 - val_accuracy: 0.8987\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1177 - accuracy: 0.9010 - val_loss: 0.2218 - val_accuracy: 0.8987\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 84s 66ms/step - loss: 0.1173 - accuracy: 0.9015 - val_loss: 0.2239 - val_accuracy: 0.9114\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 0.1172 - accuracy: 0.9018 - val_loss: 0.1964 - val_accuracy: 0.8987\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1165 - accuracy: 0.9025 - val_loss: 0.1934 - val_accuracy: 0.9114\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1161 - accuracy: 0.9030 - val_loss: 0.2133 - val_accuracy: 0.9241\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1160 - accuracy: 0.9034 - val_loss: 0.1886 - val_accuracy: 0.9114\n",
      "Epoch 18/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1156 - accuracy: 0.9038 - val_loss: 0.1891 - val_accuracy: 0.9114\n",
      "Epoch 19/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1153 - accuracy: 0.9043 - val_loss: 0.1880 - val_accuracy: 0.9241\n",
      "Epoch 20/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1149 - accuracy: 0.9050 - val_loss: 0.1931 - val_accuracy: 0.9114\n",
      "Epoch 21/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1150 - accuracy: 0.9046 - val_loss: 0.1880 - val_accuracy: 0.9114\n",
      "Epoch 22/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1150 - accuracy: 0.9048 - val_loss: 0.1843 - val_accuracy: 0.9114\n",
      "Epoch 23/500\n",
      "1278/1278 [==============================] - 72s 57ms/step - loss: 0.1147 - accuracy: 0.9052 - val_loss: 0.1841 - val_accuracy: 0.8987\n",
      "Epoch 24/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1143 - accuracy: 0.9058 - val_loss: 0.1915 - val_accuracy: 0.9241\n",
      "Epoch 25/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1143 - accuracy: 0.9057 - val_loss: 0.1953 - val_accuracy: 0.9114\n",
      "Epoch 26/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1141 - accuracy: 0.9058 - val_loss: 0.1952 - val_accuracy: 0.9114\n",
      "Epoch 27/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1140 - accuracy: 0.9061 - val_loss: 0.1938 - val_accuracy: 0.8987\n",
      "Epoch 28/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1137 - accuracy: 0.9066 - val_loss: 0.1841 - val_accuracy: 0.9241\n",
      "Epoch 29/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1136 - accuracy: 0.9067 - val_loss: 0.1886 - val_accuracy: 0.9114\n",
      "Epoch 30/500\n",
      "1278/1278 [==============================] - 73s 58ms/step - loss: 0.1135 - accuracy: 0.9068 - val_loss: 0.1887 - val_accuracy: 0.9241\n",
      "Epoch 31/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1134 - accuracy: 0.9071 - val_loss: 0.1959 - val_accuracy: 0.9114\n",
      "Epoch 32/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1134 - accuracy: 0.9071 - val_loss: 0.1836 - val_accuracy: 0.9114\n",
      "Epoch 32: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re9.h5\n",
      "51094/51094 [==============================] - 151s 3ms/step\n",
      "ModelAccuracy: 77.093%\n",
      "True Win Predictions Mean of all: 34.015%\n",
      "XXX Loss Buy Mean of all: 6.922%\n",
      "Missed good deal off all: 15.985%\n",
      "Good Zero prediction Mean: 43.078%\n",
      "good fiability\n",
      "========= Win Ratio:83.09109118890002 ====================\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_51 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_52 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_53 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 74s 55ms/step - loss: 0.1695 - accuracy: 0.8056 - val_loss: 0.2495 - val_accuracy: 0.9114\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 71s 56ms/step - loss: 0.1366 - accuracy: 0.8602 - val_loss: 0.2071 - val_accuracy: 0.8987\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1265 - accuracy: 0.8760 - val_loss: 0.2306 - val_accuracy: 0.9114\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1205 - accuracy: 0.8864 - val_loss: 0.2116 - val_accuracy: 0.8987\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 71s 56ms/step - loss: 0.1176 - accuracy: 0.8910 - val_loss: 0.2367 - val_accuracy: 0.9114\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 0.1155 - accuracy: 0.8942 - val_loss: 0.1910 - val_accuracy: 0.9367\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1139 - accuracy: 0.8971 - val_loss: 0.2039 - val_accuracy: 0.9241\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1123 - accuracy: 0.8994 - val_loss: 0.1912 - val_accuracy: 0.9241\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1115 - accuracy: 0.9011 - val_loss: 0.1955 - val_accuracy: 0.9367\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 72s 57ms/step - loss: 0.1106 - accuracy: 0.9024 - val_loss: 0.1982 - val_accuracy: 0.9114\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1099 - accuracy: 0.9039 - val_loss: 0.1950 - val_accuracy: 0.9241\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1093 - accuracy: 0.9047 - val_loss: 0.1932 - val_accuracy: 0.8861\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1089 - accuracy: 0.9055 - val_loss: 0.2061 - val_accuracy: 0.9114\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 76s 59ms/step - loss: 0.1084 - accuracy: 0.9062 - val_loss: 0.1857 - val_accuracy: 0.8987\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 0.1081 - accuracy: 0.9065 - val_loss: 0.2005 - val_accuracy: 0.9241\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1079 - accuracy: 0.9069 - val_loss: 0.1890 - val_accuracy: 0.9114\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 0.1074 - accuracy: 0.9077 - val_loss: 0.1852 - val_accuracy: 0.9114\n",
      "Epoch 18/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1071 - accuracy: 0.9082 - val_loss: 0.2230 - val_accuracy: 0.8734\n",
      "Epoch 19/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.1068 - accuracy: 0.9086 - val_loss: 0.1852 - val_accuracy: 0.9367\n",
      "Epoch 20/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 0.1065 - accuracy: 0.9090 - val_loss: 0.1818 - val_accuracy: 0.9114\n",
      "Epoch 21/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1065 - accuracy: 0.9088 - val_loss: 0.1817 - val_accuracy: 0.9114\n",
      "Epoch 22/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1060 - accuracy: 0.9096 - val_loss: 0.1802 - val_accuracy: 0.9114\n",
      "Epoch 22: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re10.h5\n",
      "51094/51094 [==============================] - 151s 3ms/step\n",
      "ModelAccuracy: 75.311%\n",
      "True Win Predictions Mean of all: 31.522%\n",
      "XXX Loss Buy Mean of all: 6.210%\n",
      "Missed good deal off all: 18.478%\n",
      "Good Zero prediction Mean: 43.790%\n",
      "good fiability\n",
      "========= Win Ratio:83.5418212657691 ====================\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_55 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 75s 56ms/step - loss: 0.1566 - accuracy: 0.8082 - val_loss: 0.2670 - val_accuracy: 0.8987\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1248 - accuracy: 0.8654 - val_loss: 0.2188 - val_accuracy: 0.9114\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1149 - accuracy: 0.8826 - val_loss: 0.2160 - val_accuracy: 0.8987\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1090 - accuracy: 0.8930 - val_loss: 0.2370 - val_accuracy: 0.9241\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1061 - accuracy: 0.8982 - val_loss: 0.2708 - val_accuracy: 0.9114\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1041 - accuracy: 0.9015 - val_loss: 0.1790 - val_accuracy: 0.9367\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1026 - accuracy: 0.9043 - val_loss: 0.1464 - val_accuracy: 0.9620\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 76s 60ms/step - loss: 0.1014 - accuracy: 0.9066 - val_loss: 0.1709 - val_accuracy: 0.9241\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1006 - accuracy: 0.9081 - val_loss: 0.2738 - val_accuracy: 0.8861\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.0999 - accuracy: 0.9093 - val_loss: 0.1935 - val_accuracy: 0.9367\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.0994 - accuracy: 0.9105 - val_loss: 0.1600 - val_accuracy: 0.9494\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0988 - accuracy: 0.9114 - val_loss: 0.1438 - val_accuracy: 0.9241\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0983 - accuracy: 0.9123 - val_loss: 0.1557 - val_accuracy: 0.9494\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0977 - accuracy: 0.9128 - val_loss: 0.1478 - val_accuracy: 0.9494\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.0974 - accuracy: 0.9135 - val_loss: 0.1635 - val_accuracy: 0.9367\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.0970 - accuracy: 0.9143 - val_loss: 0.2257 - val_accuracy: 0.9367\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0968 - accuracy: 0.9144 - val_loss: 0.2123 - val_accuracy: 0.9367\n",
      "Epoch 18/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0964 - accuracy: 0.9153 - val_loss: 0.2481 - val_accuracy: 0.9114\n",
      "Epoch 19/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0964 - accuracy: 0.9152 - val_loss: 0.1722 - val_accuracy: 0.9367\n",
      "Epoch 20/500\n",
      "1278/1278 [==============================] - 76s 59ms/step - loss: 0.0963 - accuracy: 0.9154 - val_loss: 0.1349 - val_accuracy: 0.9620\n",
      "Epoch 21/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0958 - accuracy: 0.9162 - val_loss: 0.1939 - val_accuracy: 0.9367\n",
      "Epoch 22/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0956 - accuracy: 0.9165 - val_loss: 0.1768 - val_accuracy: 0.9241\n",
      "Epoch 23/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0956 - accuracy: 0.9166 - val_loss: 0.1521 - val_accuracy: 0.9494\n",
      "Epoch 23: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re11.h5\n",
      "51094/51094 [==============================] - 150s 3ms/step\n",
      "ModelAccuracy: 75.361%\n",
      "True Win Predictions Mean of all: 31.598%\n",
      "XXX Loss Buy Mean of all: 6.237%\n",
      "Missed good deal off all: 18.402%\n",
      "Good Zero prediction Mean: 43.763%\n",
      "good fiability\n",
      "========= Win Ratio:83.51526364477336 ====================\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_59 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_60 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_61 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_62 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 77s 58ms/step - loss: 0.1573 - accuracy: 0.8084 - val_loss: 0.2585 - val_accuracy: 0.8861\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 71s 56ms/step - loss: 0.1246 - accuracy: 0.8659 - val_loss: 0.1946 - val_accuracy: 0.9367\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 0.1143 - accuracy: 0.8835 - val_loss: 0.1802 - val_accuracy: 0.9494\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1083 - accuracy: 0.8947 - val_loss: 0.1821 - val_accuracy: 0.9241\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.1052 - accuracy: 0.9001 - val_loss: 0.1680 - val_accuracy: 0.9241\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1034 - accuracy: 0.9033 - val_loss: 0.1684 - val_accuracy: 0.9241\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1021 - accuracy: 0.9057 - val_loss: 0.1554 - val_accuracy: 0.9367\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 76s 59ms/step - loss: 0.1009 - accuracy: 0.9074 - val_loss: 0.1465 - val_accuracy: 0.9494\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.1000 - accuracy: 0.9093 - val_loss: 0.1432 - val_accuracy: 0.9494\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0995 - accuracy: 0.9102 - val_loss: 0.1571 - val_accuracy: 0.9494\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0988 - accuracy: 0.9112 - val_loss: 0.1585 - val_accuracy: 0.9494\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0984 - accuracy: 0.9120 - val_loss: 0.1556 - val_accuracy: 0.9241\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0979 - accuracy: 0.9128 - val_loss: 0.1926 - val_accuracy: 0.9241\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0975 - accuracy: 0.9136 - val_loss: 0.1429 - val_accuracy: 0.9494\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0971 - accuracy: 0.9142 - val_loss: 0.1649 - val_accuracy: 0.9241\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.0966 - accuracy: 0.9152 - val_loss: 0.1738 - val_accuracy: 0.9367\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.0966 - accuracy: 0.9153 - val_loss: 0.1494 - val_accuracy: 0.9367\n",
      "Epoch 18/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0961 - accuracy: 0.9160 - val_loss: 0.2455 - val_accuracy: 0.9241\n",
      "Epoch 19/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0959 - accuracy: 0.9163 - val_loss: 0.1654 - val_accuracy: 0.9241\n",
      "Epoch 19: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re12.h5\n",
      "51094/51094 [==============================] - 149s 3ms/step\n",
      "ModelAccuracy: 72.440%\n",
      "True Win Predictions Mean of all: 27.635%\n",
      "XXX Loss Buy Mean of all: 5.196%\n",
      "Missed good deal off all: 22.365%\n",
      "Good Zero prediction Mean: 44.804%\n",
      "good fiability\n",
      "========= Win Ratio:84.17349456306539 ====================\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_63 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_64 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_65 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_66 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 75s 56ms/step - loss: 0.1356 - accuracy: 0.8142 - val_loss: 0.1844 - val_accuracy: 0.9114\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.1083 - accuracy: 0.8674 - val_loss: 0.1678 - val_accuracy: 0.9620\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0991 - accuracy: 0.8869 - val_loss: 0.1306 - val_accuracy: 0.9620\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0933 - accuracy: 0.8988 - val_loss: 0.1609 - val_accuracy: 0.9367\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0904 - accuracy: 0.9045 - val_loss: 0.1133 - val_accuracy: 0.9494\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0886 - accuracy: 0.9078 - val_loss: 0.1102 - val_accuracy: 0.9747\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0877 - accuracy: 0.9095 - val_loss: 0.1252 - val_accuracy: 0.9620\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0867 - accuracy: 0.9116 - val_loss: 0.1143 - val_accuracy: 0.9747\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.0860 - accuracy: 0.9133 - val_loss: 0.1271 - val_accuracy: 0.9747\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0854 - accuracy: 0.9143 - val_loss: 0.1350 - val_accuracy: 0.9620\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0848 - accuracy: 0.9157 - val_loss: 0.1154 - val_accuracy: 0.9747\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0846 - accuracy: 0.9166 - val_loss: 0.1251 - val_accuracy: 0.9494\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0841 - accuracy: 0.9176 - val_loss: 0.1090 - val_accuracy: 0.9747\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0837 - accuracy: 0.9183 - val_loss: 0.1212 - val_accuracy: 0.9747\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0835 - accuracy: 0.9187 - val_loss: 0.1217 - val_accuracy: 0.9620\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 0.0832 - accuracy: 0.9196 - val_loss: 0.1149 - val_accuracy: 0.9620\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0829 - accuracy: 0.9201 - val_loss: 0.1256 - val_accuracy: 0.9747\n",
      "Epoch 18/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0827 - accuracy: 0.9202 - val_loss: 0.1170 - val_accuracy: 0.9494\n",
      "Epoch 19/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0826 - accuracy: 0.9208 - val_loss: 0.1156 - val_accuracy: 0.9620\n",
      "Epoch 20/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0824 - accuracy: 0.9210 - val_loss: 0.1199 - val_accuracy: 0.9620\n",
      "Epoch 21/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0820 - accuracy: 0.9214 - val_loss: 0.1158 - val_accuracy: 0.9494\n",
      "Epoch 22/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0820 - accuracy: 0.9216 - val_loss: 0.1098 - val_accuracy: 0.9620\n",
      "Epoch 22: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re13.h5\n",
      "51094/51094 [==============================] - 152s 3ms/step\n",
      "ModelAccuracy: 70.380%\n",
      "True Win Predictions Mean of all: 24.900%\n",
      "XXX Loss Buy Mean of all: 4.520%\n",
      "Missed good deal off all: 25.100%\n",
      "Good Zero prediction Mean: 45.480%\n",
      "good fiability\n",
      "========= Win Ratio:84.63630183548607 ====================\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_67 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_68 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_69 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_70 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 74s 55ms/step - loss: 0.1211 - accuracy: 0.8167 - val_loss: 0.2165 - val_accuracy: 0.8861\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0963 - accuracy: 0.8664 - val_loss: 0.1500 - val_accuracy: 0.9620\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 71s 56ms/step - loss: 0.0875 - accuracy: 0.8881 - val_loss: 0.1397 - val_accuracy: 0.9367\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0822 - accuracy: 0.9004 - val_loss: 0.1518 - val_accuracy: 0.9241\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0794 - accuracy: 0.9067 - val_loss: 0.1125 - val_accuracy: 0.9620\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.0781 - accuracy: 0.9096 - val_loss: 0.1100 - val_accuracy: 0.9620\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0770 - accuracy: 0.9122 - val_loss: 0.1174 - val_accuracy: 0.9747\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0761 - accuracy: 0.9144 - val_loss: 0.1405 - val_accuracy: 0.9747\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0756 - accuracy: 0.9156 - val_loss: 0.1165 - val_accuracy: 0.9620\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0749 - accuracy: 0.9167 - val_loss: 0.1204 - val_accuracy: 0.9494\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0745 - accuracy: 0.9177 - val_loss: 0.1287 - val_accuracy: 0.9494\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0741 - accuracy: 0.9190 - val_loss: 0.1124 - val_accuracy: 0.9620\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0738 - accuracy: 0.9201 - val_loss: 0.1056 - val_accuracy: 0.9747\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 71s 56ms/step - loss: 0.0735 - accuracy: 0.9206 - val_loss: 0.1005 - val_accuracy: 0.9620\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0732 - accuracy: 0.9209 - val_loss: 0.1224 - val_accuracy: 0.9620\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 72s 57ms/step - loss: 0.0730 - accuracy: 0.9219 - val_loss: 0.1162 - val_accuracy: 0.9620\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.0727 - accuracy: 0.9219 - val_loss: 0.1097 - val_accuracy: 0.9494\n",
      "Epoch 18/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0726 - accuracy: 0.9228 - val_loss: 0.1121 - val_accuracy: 0.9494\n",
      "Epoch 19/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0724 - accuracy: 0.9231 - val_loss: 0.1243 - val_accuracy: 0.9620\n",
      "Epoch 20/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.0722 - accuracy: 0.9236 - val_loss: 0.1253 - val_accuracy: 0.9494\n",
      "Epoch 21/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.0720 - accuracy: 0.9237 - val_loss: 0.1116 - val_accuracy: 0.9620\n",
      "Epoch 22/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.0719 - accuracy: 0.9242 - val_loss: 0.1074 - val_accuracy: 0.9620\n",
      "Epoch 23/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0718 - accuracy: 0.9241 - val_loss: 0.1718 - val_accuracy: 0.8987\n",
      "Epoch 23: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re14.h5\n",
      "51094/51094 [==============================] - 149s 3ms/step\n",
      "ModelAccuracy: 62.822%\n",
      "True Win Predictions Mean of all: 15.664%\n",
      "XXX Loss Buy Mean of all: 2.842%\n",
      "Missed good deal off all: 34.336%\n",
      "Good Zero prediction Mean: 47.158%\n",
      "good fiability\n",
      "========= Win Ratio:84.64281854533664 ====================\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_71 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_72 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_73 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_74 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 77s 58ms/step - loss: 0.0695 - accuracy: 0.8522 - val_loss: 0.0962 - val_accuracy: 0.9241\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 72s 57ms/step - loss: 0.0538 - accuracy: 0.8685 - val_loss: 0.0992 - val_accuracy: 0.9241\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.0494 - accuracy: 0.8744 - val_loss: 0.0843 - val_accuracy: 0.9367\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0471 - accuracy: 0.8778 - val_loss: 0.0809 - val_accuracy: 0.9241\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0456 - accuracy: 0.8795 - val_loss: 0.0893 - val_accuracy: 0.9367\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 76s 59ms/step - loss: 0.0446 - accuracy: 0.8812 - val_loss: 0.0829 - val_accuracy: 0.9367\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0439 - accuracy: 0.8834 - val_loss: 0.1054 - val_accuracy: 0.9241\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0434 - accuracy: 0.8852 - val_loss: 0.0964 - val_accuracy: 0.9620\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0430 - accuracy: 0.8851 - val_loss: 0.0859 - val_accuracy: 0.9620\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 76s 59ms/step - loss: 0.0427 - accuracy: 0.8860 - val_loss: 0.0773 - val_accuracy: 0.9367\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0425 - accuracy: 0.8862 - val_loss: 0.0848 - val_accuracy: 0.9241\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 77s 60ms/step - loss: 0.0422 - accuracy: 0.8881 - val_loss: 0.0759 - val_accuracy: 0.9367\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0421 - accuracy: 0.8875 - val_loss: 0.0753 - val_accuracy: 0.9494\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0419 - accuracy: 0.8872 - val_loss: 0.0814 - val_accuracy: 0.9367\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0418 - accuracy: 0.8881 - val_loss: 0.1015 - val_accuracy: 0.9494\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 0.0416 - accuracy: 0.8885 - val_loss: 0.0874 - val_accuracy: 0.9494\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 76s 60ms/step - loss: 0.0415 - accuracy: 0.8889 - val_loss: 0.1025 - val_accuracy: 0.9367\n",
      "Epoch 18/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0413 - accuracy: 0.8886 - val_loss: 0.0825 - val_accuracy: 0.9494\n",
      "Epoch 19/500\n",
      "1278/1278 [==============================] - 76s 60ms/step - loss: 0.0413 - accuracy: 0.8887 - val_loss: 0.1029 - val_accuracy: 0.9241\n",
      "Epoch 20/500\n",
      "1278/1278 [==============================] - 77s 60ms/step - loss: 0.0411 - accuracy: 0.8903 - val_loss: 0.1062 - val_accuracy: 0.9241\n",
      "Epoch 21/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 0.0411 - accuracy: 0.8887 - val_loss: 0.1188 - val_accuracy: 0.9241\n",
      "Epoch 22/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0410 - accuracy: 0.8886 - val_loss: 0.0850 - val_accuracy: 0.9367\n",
      "Epoch 23/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0409 - accuracy: 0.8900 - val_loss: 0.0833 - val_accuracy: 0.9367\n",
      "Epoch 24/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.0408 - accuracy: 0.8894 - val_loss: 0.1110 - val_accuracy: 0.9241\n",
      "Epoch 24: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re15.h5\n",
      "51094/51094 [==============================] - 150s 3ms/step\n",
      "ModelAccuracy: 54.077%\n",
      "True Win Predictions Mean of all: 4.641%\n",
      "XXX Loss Buy Mean of all: 0.564%\n",
      "Missed good deal off all: 45.359%\n",
      "Good Zero prediction Mean: 49.436%\n",
      "good fiability\n",
      "========= Win Ratio:89.164265129683 ====================\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_75 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_76 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_77 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_78 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 78s 58ms/step - loss: 0.0131 - accuracy: 0.9527 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0089 - accuracy: 0.9537 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0081 - accuracy: 0.9537 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 76s 59ms/step - loss: 0.0075 - accuracy: 0.9538 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 0.0072 - accuracy: 0.9539 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 76s 59ms/step - loss: 0.0069 - accuracy: 0.9539 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0068 - accuracy: 0.9540 - val_loss: 6.3095e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 0.0066 - accuracy: 0.9538 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0066 - accuracy: 0.9537 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.0065 - accuracy: 0.9538 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 0.0064 - accuracy: 0.9538 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.0063 - accuracy: 0.9539 - val_loss: 3.9192e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 0.0063 - accuracy: 0.9539 - val_loss: 8.4300e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.0062 - accuracy: 0.9538 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 0.0062 - accuracy: 0.9538 - val_loss: 9.4245e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 77s 60ms/step - loss: 0.0061 - accuracy: 0.9544 - val_loss: 8.4755e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 0.0061 - accuracy: 0.9541 - val_loss: 9.9116e-04 - val_accuracy: 1.0000\n",
      "Epoch 17: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re16.h5\n",
      "51094/51094 [==============================] - 149s 3ms/step\n",
      "ModelAccuracy: 50.032%\n",
      "True Win Predictions Mean of all: 0.033%\n",
      "XXX Loss Buy Mean of all: 0.001%\n",
      "Missed good deal off all: 49.967%\n",
      "Good Zero prediction Mean: 49.999%\n",
      "good fiability\n",
      "========= Win Ratio:97.05882352941177 ====================\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_79 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_80 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_81 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_82 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 77s 57ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 5.2720e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 2.6077e-06 - accuracy: 0.9997 - val_loss: 1.1937e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 2.1013e-06 - accuracy: 0.9997 - val_loss: 5.5189e-08 - val_accuracy: 1.0000\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 2.0036e-06 - accuracy: 0.9997 - val_loss: 3.7607e-08 - val_accuracy: 1.0000\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 1.9540e-06 - accuracy: 0.9997 - val_loss: 3.5469e-08 - val_accuracy: 1.0000\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 1.8904e-06 - accuracy: 0.9997 - val_loss: 3.5625e-08 - val_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 1.8623e-06 - accuracy: 0.9997 - val_loss: 4.5836e-08 - val_accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 1.7953e-06 - accuracy: 0.9997 - val_loss: 5.7753e-08 - val_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 76s 60ms/step - loss: 1.7282e-06 - accuracy: 0.9997 - val_loss: 8.0358e-08 - val_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 1.6601e-06 - accuracy: 0.9997 - val_loss: 4.1944e-08 - val_accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 1.6090e-06 - accuracy: 0.9997 - val_loss: 5.0910e-08 - val_accuracy: 1.0000\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 1.5696e-06 - accuracy: 0.9997 - val_loss: 5.4329e-08 - val_accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 76s 59ms/step - loss: 1.5341e-06 - accuracy: 0.9997 - val_loss: 8.7123e-08 - val_accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 1.5185e-06 - accuracy: 0.9997 - val_loss: 8.8832e-08 - val_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 1.4879e-06 - accuracy: 0.9997 - val_loss: 1.2960e-07 - val_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 77s 60ms/step - loss: 1.4543e-06 - accuracy: 0.9997 - val_loss: 1.4323e-08 - val_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 1.4556e-06 - accuracy: 0.9997 - val_loss: 2.3662e-07 - val_accuracy: 1.0000\n",
      "Epoch 17: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re17.h5\n",
      "51094/51094 [==============================] - 149s 3ms/step\n",
      "ModelAccuracy: 50.000%\n",
      "True Win Predictions Mean of all: 0.000%\n",
      "XXX Loss Buy Mean of all: 0.000%\n",
      "Missed good deal off all: 50.000%\n",
      "Good Zero prediction Mean: 50.000%\n",
      "good fiability\n",
      "========= Win Ratio:nan ====================\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_83 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_84 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_85 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_86 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 78s 58ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 8.2615e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 9.1848e-07 - accuracy: 1.0000 - val_loss: 1.5312e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 2.4369e-07 - accuracy: 1.0000 - val_loss: 4.4848e-08 - val_accuracy: 1.0000\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 9.3089e-08 - accuracy: 1.0000 - val_loss: 1.7277e-08 - val_accuracy: 1.0000\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 3.9877e-08 - accuracy: 1.0000 - val_loss: 6.9451e-09 - val_accuracy: 1.0000\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 77s 60ms/step - loss: 1.8960e-08 - accuracy: 1.0000 - val_loss: 2.9410e-09 - val_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 8.6351e-09 - accuracy: 1.0000 - val_loss: 1.2741e-09 - val_accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 4.3183e-09 - accuracy: 1.0000 - val_loss: 5.2273e-10 - val_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 76s 59ms/step - loss: 2.1865e-09 - accuracy: 1.0000 - val_loss: 2.6396e-10 - val_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 2.0118e-09 - accuracy: 1.0000 - val_loss: 1.4789e-10 - val_accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 8.4931e-10 - accuracy: 1.0000 - val_loss: 5.9289e-11 - val_accuracy: 1.0000\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 3.4941e-10 - accuracy: 1.0000 - val_loss: 3.0720e-11 - val_accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 2.1503e-10 - accuracy: 1.0000 - val_loss: 1.7840e-11 - val_accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 76s 59ms/step - loss: 1.1666e-10 - accuracy: 1.0000 - val_loss: 1.0538e-11 - val_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 8.9618e-11 - accuracy: 1.0000 - val_loss: 6.3321e-12 - val_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 5.7261e-11 - accuracy: 1.0000 - val_loss: 3.6939e-12 - val_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 76s 60ms/step - loss: 3.1459e-11 - accuracy: 1.0000 - val_loss: 2.6969e-12 - val_accuracy: 1.0000\n",
      "Epoch 17: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re18.h5\n",
      "51094/51094 [==============================] - 147s 3ms/step\n",
      "ModelAccuracy: 50.000%\n",
      "True Win Predictions Mean of all: 0.000%\n",
      "XXX Loss Buy Mean of all: 0.000%\n",
      "Missed good deal off all: 50.000%\n",
      "Good Zero prediction Mean: 50.000%\n",
      "good fiability\n",
      "========= Win Ratio:nan ====================\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_87 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_88 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_89 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_90 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 76s 57ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 7.8892e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 1.3770e-06 - accuracy: 1.0000 - val_loss: 1.6287e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 3.2878e-07 - accuracy: 1.0000 - val_loss: 5.2735e-08 - val_accuracy: 1.0000\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 76s 59ms/step - loss: 1.2794e-07 - accuracy: 1.0000 - val_loss: 2.0640e-08 - val_accuracy: 1.0000\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 5.8601e-08 - accuracy: 1.0000 - val_loss: 8.6417e-09 - val_accuracy: 1.0000\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 2.6573e-08 - accuracy: 1.0000 - val_loss: 3.7929e-09 - val_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 1.3402e-08 - accuracy: 1.0000 - val_loss: 1.7147e-09 - val_accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 6.5320e-09 - accuracy: 1.0000 - val_loss: 7.8804e-10 - val_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 3.2974e-09 - accuracy: 1.0000 - val_loss: 3.7426e-10 - val_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 1.6621e-09 - accuracy: 1.0000 - val_loss: 1.8214e-10 - val_accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 76s 60ms/step - loss: 5.1685e-09 - accuracy: 1.0000 - val_loss: 1.2518e-10 - val_accuracy: 1.0000\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 76s 59ms/step - loss: 5.3003e-10 - accuracy: 1.0000 - val_loss: 5.0798e-11 - val_accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 2.9724e-10 - accuracy: 1.0000 - val_loss: 2.6086e-11 - val_accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 2.3485e-10 - accuracy: 1.0000 - val_loss: 1.0695e-11 - val_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 75s 58ms/step - loss: 1.0330e-10 - accuracy: 1.0000 - val_loss: 6.3210e-12 - val_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 76s 59ms/step - loss: 6.2662e-11 - accuracy: 1.0000 - val_loss: 4.0647e-12 - val_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 8.6664e-11 - accuracy: 1.0000 - val_loss: 3.3448e-12 - val_accuracy: 1.0000\n",
      "Epoch 17: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re19.h5\n",
      "51094/51094 [==============================] - 151s 3ms/step\n",
      "ModelAccuracy: 50.000%\n",
      "True Win Predictions Mean of all: 0.000%\n",
      "XXX Loss Buy Mean of all: 0.000%\n",
      "Missed good deal off all: 50.000%\n",
      "Good Zero prediction Mean: 50.000%\n",
      "good fiability\n",
      "========= Win Ratio:nan ====================\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_91 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_92 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_93 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_94 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 75s 56ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 8.5467e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 73s 58ms/step - loss: 1.2024e-06 - accuracy: 1.0000 - val_loss: 1.6575e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 72s 56ms/step - loss: 3.3568e-07 - accuracy: 1.0000 - val_loss: 4.8022e-08 - val_accuracy: 1.0000\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 1.3172e-07 - accuracy: 1.0000 - val_loss: 1.7324e-08 - val_accuracy: 1.0000\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 5.9669e-08 - accuracy: 1.0000 - val_loss: 6.5437e-09 - val_accuracy: 1.0000\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 2.6743e-08 - accuracy: 1.0000 - val_loss: 3.2207e-09 - val_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 1.2804e-08 - accuracy: 1.0000 - val_loss: 1.4337e-09 - val_accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 6.1187e-09 - accuracy: 1.0000 - val_loss: 6.2771e-10 - val_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 3.0454e-09 - accuracy: 1.0000 - val_loss: 3.1923e-10 - val_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 77s 60ms/step - loss: 6.6530e-09 - accuracy: 1.0000 - val_loss: 3.2560e-10 - val_accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 1.5781e-09 - accuracy: 1.0000 - val_loss: 5.3937e-11 - val_accuracy: 1.0000\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 5.5174e-10 - accuracy: 1.0000 - val_loss: 2.2814e-11 - val_accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 2.3540e-10 - accuracy: 1.0000 - val_loss: 1.2974e-11 - val_accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 1.5736e-10 - accuracy: 1.0000 - val_loss: 7.1371e-12 - val_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 76s 60ms/step - loss: 8.6785e-11 - accuracy: 1.0000 - val_loss: 4.3500e-12 - val_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 6.4573e-11 - accuracy: 1.0000 - val_loss: 2.4467e-12 - val_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 3.9379e-11 - accuracy: 1.0000 - val_loss: 1.8691e-12 - val_accuracy: 1.0000\n",
      "Epoch 17: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re20.h5\n",
      "51094/51094 [==============================] - 148s 3ms/step\n",
      "ModelAccuracy: 50.000%\n",
      "True Win Predictions Mean of all: 0.000%\n",
      "XXX Loss Buy Mean of all: 0.000%\n",
      "Missed good deal off all: 50.000%\n",
      "Good Zero prediction Mean: 50.000%\n",
      "good fiability\n",
      "========= Win Ratio:nan ====================\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_95 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_96 (Bat  (None, 200)              800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_97 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_98 (Bat  (None, 80)               320       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_160 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 75s 56ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 3.5549e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 4.8772e-07 - accuracy: 1.0000 - val_loss: 6.9353e-08 - val_accuracy: 1.0000\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 1.4759e-07 - accuracy: 1.0000 - val_loss: 2.2270e-08 - val_accuracy: 1.0000\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 5.8570e-08 - accuracy: 1.0000 - val_loss: 9.1417e-09 - val_accuracy: 1.0000\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 3.0918e-08 - accuracy: 1.0000 - val_loss: 3.9076e-09 - val_accuracy: 1.0000\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 1.1940e-08 - accuracy: 1.0000 - val_loss: 1.6329e-09 - val_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 76s 59ms/step - loss: 9.1096e-09 - accuracy: 1.0000 - val_loss: 8.1080e-10 - val_accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 3.0081e-09 - accuracy: 1.0000 - val_loss: 2.9881e-10 - val_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 1.3717e-09 - accuracy: 1.0000 - val_loss: 1.4090e-10 - val_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 7.1787e-10 - accuracy: 1.0000 - val_loss: 6.8718e-11 - val_accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "1278/1278 [==============================] - 75s 59ms/step - loss: 4.0939e-10 - accuracy: 1.0000 - val_loss: 3.6290e-11 - val_accuracy: 1.0000\n",
      "Epoch 12/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 2.1954e-10 - accuracy: 1.0000 - val_loss: 2.0004e-11 - val_accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 1.3512e-10 - accuracy: 1.0000 - val_loss: 1.1364e-11 - val_accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 8.6656e-11 - accuracy: 1.0000 - val_loss: 6.6735e-12 - val_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 5.6871e-11 - accuracy: 1.0000 - val_loss: 4.3028e-12 - val_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "1278/1278 [==============================] - 76s 59ms/step - loss: 9.8319e-11 - accuracy: 1.0000 - val_loss: 2.3578e-12 - val_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 2.3596e-11 - accuracy: 1.0000 - val_loss: 1.6650e-12 - val_accuracy: 1.0000\n",
      "Epoch 17: early stopping\n",
      "/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_true_win_model_Re21.h5\n",
      "51094/51094 [==============================] - 149s 3ms/step\n",
      "ModelAccuracy: 50.000%\n",
      "True Win Predictions Mean of all: 0.000%\n",
      "XXX Loss Buy Mean of all: 0.000%\n",
      "Missed good deal off all: 50.000%\n",
      "Good Zero prediction Mean: 50.000%\n",
      "good fiability\n",
      "========= Win Ratio:nan ====================\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_99 (Bat  (None, 398)              1592      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 200)               79800     \n",
      "                                                                 \n",
      " batch_normalization_100 (Ba  (None, 200)              800       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 80)                16080     \n",
      "                                                                 \n",
      " batch_normalization_101 (Ba  (None, 80)               320       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " batch_normalization_102 (Ba  (None, 80)               320       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 20)                1620      \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,993\n",
      "Trainable params: 118,477\n",
      "Non-trainable params: 1,516\n",
      "_________________________________________________________________\n",
      "None\n",
      "saving file in: /UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_v1.h5\n",
      "Epoch 1/500\n",
      "1278/1278 [==============================] - 76s 56ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 6.3845e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 8.5177e-07 - accuracy: 1.0000 - val_loss: 1.3283e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 2.5431e-07 - accuracy: 1.0000 - val_loss: 4.0982e-08 - val_accuracy: 1.0000\n",
      "Epoch 4/500\n",
      "1278/1278 [==============================] - 74s 58ms/step - loss: 9.8721e-08 - accuracy: 1.0000 - val_loss: 1.6151e-08 - val_accuracy: 1.0000\n",
      "Epoch 5/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 4.2916e-08 - accuracy: 1.0000 - val_loss: 6.4587e-09 - val_accuracy: 1.0000\n",
      "Epoch 6/500\n",
      "1278/1278 [==============================] - 76s 60ms/step - loss: 1.9846e-08 - accuracy: 1.0000 - val_loss: 2.8126e-09 - val_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 9.8067e-09 - accuracy: 1.0000 - val_loss: 1.2887e-09 - val_accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "1278/1278 [==============================] - 77s 60ms/step - loss: 4.8863e-09 - accuracy: 1.0000 - val_loss: 5.7725e-10 - val_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "1278/1278 [==============================] - 73s 57ms/step - loss: 2.6350e-09 - accuracy: 1.0000 - val_loss: 2.7375e-10 - val_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      " 630/1278 [=============>................] - ETA: 38s - loss: 1.4736e-09 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb Cell 54\u001b[0m in \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m callbacks \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m     ModelCheckpoint(filepath\u001b[39m=\u001b[39mModel_FileName, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, save_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m     EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m ]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39msaving file in: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m Model_FileName)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(retrain_dt[index_20pct:, :\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m                     TrueWinPred[index_20pct:],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m(retrain_dt[:index_20pct, :\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], TrueWinPred[:index_20pct]),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m                     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m                     class_weight\u001b[39m=\u001b[39;49mclass_weights)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m#868/868 [==============================] - 30s 35ms/step - loss: 0.6078 - accuracy: 0.6664 - val_loss: 0.6107 - val_accuracy: 0.6639 >0.6646\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m#Results after 380 min\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39m# Epoch 133/500\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m# 347/347 [==============================] - 137s 395ms/step - loss: 0.5865 - accuracy: 0.6843 - val_loss: 0.5845 - val_accuracy: 0.6861\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39m# Epoch 134: early stopping\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpyhome/UltimeTradingBot/Crypto_backtest_tools/customwindow_multiTraining.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m true_win_model\u001b[39m=\u001b[39mmodel\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## AGRESSIVE\n",
    "#Change retaindt\n",
    "for rrr in range(7,30):\n",
    "    retrain_dt=dt\n",
    "    class_1_weight=TrueWinPred.mean()\n",
    "\n",
    "    import gc\n",
    "    from keras.layers import Dense\n",
    "    from keras.models import Sequential\n",
    "    from keras.optimizers import Nadam\n",
    "    from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "    # Define the class weights\n",
    "    index_20pct=int(retrain_dt.shape[1]*0.2)\n",
    "    class_weights = {0: 1-class_1_weight, 1: class_1_weight}\n",
    "    gc.collect()\n",
    "\n",
    "    SizeTunner = 1\n",
    "    IN_DIM = retrain_dt.shape[1] - 1\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(IN_DIM,)))\n",
    "    model.add(Dense(int(200 * SizeTunner), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    # model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(int(80 * SizeTunner), activation='elu'))\n",
    "    model.add(Dense(int(80 * SizeTunner), activation='relu'))\n",
    "    model.add(Dense(int(20 * SizeTunner), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(filepath=Model_FileName, monitor='val_accuracy', save_best_only=True, save_weights=True),\n",
    "        EarlyStopping(monitor='val_accuracy', mode='auto', patience=16, verbose=1)\n",
    "    ]\n",
    "\n",
    "    print(\"saving file in: \" + Model_FileName)\n",
    "    history = model.fit(retrain_dt[index_20pct:, :-1],\n",
    "                        TrueWinPred[index_20pct:],\n",
    "                        validation_data=(retrain_dt[:index_20pct, :-1], TrueWinPred[:index_20pct]),\n",
    "                        epochs=500,\n",
    "                        batch_size=256*5,\n",
    "                        callbacks=callbacks,\n",
    "                        class_weight=class_weights)\n",
    "\n",
    "    #868/868 [==============================] - 30s 35ms/step - loss: 0.6078 - accuracy: 0.6664 - val_loss: 0.6107 - val_accuracy: 0.6639 >0.6646\n",
    "    #Results after 380 min\n",
    "    # Epoch 133/500\n",
    "    # 347/347 [==============================] - 138s 398ms/step - loss: 0.5867 - accuracy: 0.6842 - val_loss: 0.5839 - val_accuracy: 0.6863\n",
    "    # Epoch 134/500\n",
    "    # 347/347 [==============================] - 137s 395ms/step - loss: 0.5865 - accuracy: 0.6843 - val_loss: 0.5845 - val_accuracy: 0.6861\n",
    "    # Epoch 134: early stopping\n",
    "\n",
    "    true_win_model=model\n",
    "    wheretosave=f'{DATA_DIR}/tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+f\"_true_win_model_Re{rrr}.h5\"\n",
    "    true_win_model.save(wheretosave)\n",
    "    print(wheretosave)\n",
    "    USED_MODEL=true_win_model\n",
    "    bad_Prediction_Note=USED_MODEL.predict( dt[:, 0:-1])\n",
    "    Pred02=bad_Prediction_Note.round()\n",
    "    Original_Traget_Data=Y\n",
    "    Predicted_Data=Pred02[:,0]\n",
    "\n",
    "    BadTruePred=(Original_Traget_Data==Predicted_Data).copy()\n",
    "    BadModelAccuracy=hp(BadTruePred.mean(),\"ModelAccuracy\")\n",
    "\n",
    "    BadTrueWinPred=((Predicted_Data==1) & (Original_Traget_Data==1) ).copy()\n",
    "    BadTrueWinPred_Mean=hp(BadTrueWinPred.mean(),\"True Win Predictions Mean of all\")\n",
    "\n",
    "    BadLossPred=((Predicted_Data==1) & (Original_Traget_Data==0) ).copy()\n",
    "    BadLossPred_Mean=hp(BadLossPred.mean(),\"XXX Loss Buy Mean of all\")\n",
    "\n",
    "    BadMissedDealPred=((Predicted_Data==0) & (Original_Traget_Data==1) ).copy()\n",
    "    BadMissedDeal_Mean=hp(BadMissedDealPred.mean(),\"Missed good deal off all\")\n",
    "\n",
    "    BadGoodZeroPred=((Predicted_Data==0) & (Original_Traget_Data==0) ).copy()\n",
    "    BadGoodZero_Mean=hp(BadGoodZeroPred.mean(),\"Good Zero prediction Mean\")\n",
    "\n",
    "    fiability=BadTrueWinPred_Mean + BadLossPred_Mean + BadMissedDeal_Mean + BadGoodZero_Mean\n",
    "    if( fiability == 100):print(\"good fiability\")\n",
    "    else: print(f\"check the fiability {fiability}\")\n",
    "    winratio=BadTrueWinPred_Mean/(BadLossPred_Mean+BadTrueWinPred_Mean)\n",
    "    print(f\"========= Win Ratio:{winratio*100} ====================\")\n",
    "    ## for retraining again\n",
    "    TrueWinPred=BadTrueWinPred\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Win-Loss Double Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deep neural network to predict a binary outcome (win or loss) and applying class weights to the loss function. To implement cost-sensitive learning or ensemble methods, you can make the following modifications:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from keras.layers import Dense, Dropout, BatchNormalization\n",
    "# from keras.models import Sequential\n",
    "# from keras.optimizers import Nadam\n",
    "# from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# # Custom cost-sensitive loss function\n",
    "# def cost_sensitive_loss(y_true, y_pred):\n",
    "#     cost_matrix = tf.constant([[0, 1], [10, 0]], dtype=tf.float32)\n",
    "    \n",
    "#     y_pred_probs = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "#     y_pred_1_probs = 1 - y_pred_probs\n",
    "    \n",
    "#     y_true_int = tf.cast(y_true, tf.int32)\n",
    "#     cost_weights = tf.gather(cost_matrix, y_true_int[:, 0])\n",
    "#     loss = -tf.reduce_mean(cost_weights * (y_true * tf.math.log(y_pred_probs) + (1 - y_true) * tf.math.log(y_pred_1_probs)))\n",
    "\n",
    "#     return loss\n",
    "\n",
    "\n",
    "# # Function to create the model\n",
    "# def create_model(input_dim):\n",
    "#     model = Sequential()\n",
    "#     model.add(BatchNormalization(input_shape=(input_dim,)))\n",
    "#     model.add(Dense(200, activation='elu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.2))\n",
    "\n",
    "#     model.add(Dense(80, activation='elu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.2))\n",
    "\n",
    "#     model.add(Dense(80, activation='elu'))\n",
    "#     model.add(BatchNormalization())\n",
    "\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# # Prepare the data\n",
    "# retrain_dt = dt\n",
    "# index_20pct = int(retrain_dt.shape[1] * 0.2)\n",
    "# X_train, X_val = retrain_dt[index_20pct:, :-1], retrain_dt[:index_20pct, :-1]\n",
    "# y_train, y_val = retrain_dt[index_20pct:,-1], retrain_dt[:index_20pct,-1]\n",
    "\n",
    "# # Define the optimizer and callbacks\n",
    "# optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
    "# callbacks = [\n",
    "#     ModelCheckpoint(filepath=Model_FileName, monitor='val_accuracy', save_best_only=True, save_weights=True),\n",
    "#     EarlyStopping(monitor='val_accuracy', mode='auto', patience=16, verbose=1)\n",
    "# ]\n",
    "\n",
    "# # Train the model for class 1 (win)\n",
    "# model_win = create_model(input_dim=IN_DIM)\n",
    "# model_win.compile(optimizer=optimizer, loss=cost_sensitive_loss, metrics=['accuracy'])\n",
    "# model_win.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=500, batch_size=256 * 5, callbacks=callbacks)\n",
    "\n",
    "# # Train the model for class 0 (loss)\n",
    "# model_loss = create_model(input_dim=IN_DIM)\n",
    "# model_loss.compile(optimizer=optimizer, loss=cost_sensitive_loss,metrics=['accuracy'])\n",
    "# model_loss.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=500, batch_size=256 * 5, callbacks=callbacks)\n",
    "\n",
    "# # Combine the predictions from both models\n",
    "# win_preds = model_win.predict(dt[:, 0:-1])\n",
    "# loss_preds = model_loss.predict(dt[:, 0:-1])\n",
    "\n",
    "# # Use a strategy such as averaging, voting, or another combination method\n",
    "# combined_preds = (win_preds + loss_preds) / 2\n",
    "# combined_preds_rounded = np.round(combined_preds)\n",
    "\n",
    "# # Calculate the accuracy and other metrics\n",
    "# y_true = Y\n",
    "# accuracy = np.mean(combined_preds_rounded == y_true)\n",
    "# print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# # Additional metrics\n",
    "# true_positive = np.mean((combined_preds_rounded == 1) & (y_true == 1))\n",
    "# false_positive = np.mean((combined_preds_rounded == 1) & (y_true == 0))\n",
    "# true_negative = np.mean((combined_preds_rounded == 0) & (y_true == 0))\n",
    "# false_negative = np.mean((combined_preds_rounded == 0) & (y_true == 1))\n",
    "\n",
    "# print(f\"True Positive Rate: {true_positive * 100:.2f}%\")\n",
    "# print(f\"False Positive Rate: {false_positive * 100:.2f}%\")\n",
    "# print(f\"True Negative Rate: {true_negative * 100:.2f}%\")\n",
    "# print(f\"False Negative Rate: {false_negative * 100:.2f}%\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Input, concatenate\n",
    "# from keras.models import Model\n",
    "\n",
    "# # 1. Freeze the weights of model_win and model_loss\n",
    "# for layer in model_win.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# for layer in model_loss.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# # 2. Add an additional layer to each model to obtain the intermediate features\n",
    "# model_win_intermediate = Dense(64, activation='relu')(model_win.output)\n",
    "# model_loss_intermediate = Dense(64, activation='relu')(model_loss.output)\n",
    "\n",
    "# # 3. Create a new model that takes the outputs of the intermediate layers from both models and combines them\n",
    "# combined_input = concatenate([model_win_intermediate, model_loss_intermediate])\n",
    "# combined_output = Dense(1, activation='sigmoid')(combined_input)\n",
    "\n",
    "# combined_model = Model(inputs=[model_win.input, model_loss.input], outputs=combined_output)\n",
    "\n",
    "# # 4. Train the new model to make predictions using the intermediate features from both models\n",
    "# optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
    "# combined_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# callbacks = [\n",
    "#     ModelCheckpoint(filepath=Model_FileName, monitor='val_accuracy', save_best_only=True, save_weights=True),\n",
    "#     EarlyStopping(monitor='val_accuracy', mode='auto', patience=16, verbose=1)\n",
    "# ]\n",
    "\n",
    "# # Train the combined model\n",
    "# combined_model.fit([X_train, X_train], y_train, validation_data=([X_val, X_val], y_val), epochs=500, batch_size=256 * 5, callbacks=callbacks)\n",
    "\n",
    "# # Make predictions using the combined model\n",
    "# combined_preds = combined_model.predict([dt[:, 0:-1], dt[:, 0:-1]])\n",
    "# combined_preds_rounded = np.round(combined_preds)\n",
    "\n",
    "# # Calculate the accuracy and other metrics\n",
    "# y_true = Y\n",
    "# accuracy = np.mean(combined_preds_rounded == y_true)\n",
    "# print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Input, concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "# Custom cost-sensitive loss function\n",
    "def cost_sensitive_loss(y_true, y_pred):\n",
    "    cost_matrix = tf.constant([[0, 1], [10, 0]], dtype=tf.float32)\n",
    "    y_pred_probs = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "    y_pred_1_probs = 1 - y_pred_probs\n",
    "    y_true_int = tf.cast(y_true, tf.int32)\n",
    "    cost_weights = tf.gather(cost_matrix, y_true_int[:, 0])\n",
    "    loss = -tf.reduce_mean(cost_weights * (y_true * tf.math.log(y_pred_probs) + (1 - y_true) * tf.math.log(y_pred_1_probs)))\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Function to create the model\n",
    "def create_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(input_dim,)))\n",
    "    model.add(Dense(200, activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(80, activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(80, activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, loss_function):\n",
    "    optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(filepath=Model_FileName, monitor='val_accuracy', save_best_only=True, save_weights=True),\n",
    "        EarlyStopping(monitor='val_accuracy', mode='auto', patience=16, verbose=1)\n",
    "    ]\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=500, batch_size=256 * 5, callbacks=callbacks)\n",
    "\n",
    "# Prepare the data\n",
    "retrain_dt = dt\n",
    "index_20pct = int(retrain_dt.shape[1] * 0.2)\n",
    "X_train, X_val = retrain_dt[index_20pct:, :-1], retrain_dt[:index_20pct, :-1]\n",
    "y_train, y_val = retrain_dt[index_20pct:,-1], retrain_dt[:index_20pct,-1]\n",
    "\n",
    "\n",
    "# Train the model for class 1 (win)\n",
    "model_win = create_model(input_dim=IN_DIM)\n",
    "model_win.compile(optimizer=optimizer, loss=cost_sensitive_loss, metrics=['accuracy'])\n",
    "model_win.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=500, batch_size=256 * 5, callbacks=callbacks)\n",
    "\n",
    "# Train the model for class 0 (loss)\n",
    "model_loss = create_model(input_dim=IN_DIM)\n",
    "model_loss.compile(optimizer=optimizer, loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "model_loss.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=500, batch_size=256 * 5, callbacks=callbacks)\n",
    "\n",
    "\n",
    "# Freeze the weights of model_win and model_loss\n",
    "for layer in model_win.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in model_loss.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add an additional layer to each model\n",
    "# Add an additional layer to each model to obtain the intermediate features\n",
    "model_win_intermediate = Dense(64, activation='relu')(model_win.output)\n",
    "model_loss_intermediate = Dense(64, activation='relu')(model_loss.output)\n",
    "\n",
    "# Create a new model that takes the outputs of the intermediate layers from both models and combines them\n",
    "combined_input = concatenate([model_win_intermediate, model_loss_intermediate])\n",
    "combined_output = Dense(1, activation='sigmoid')(combined_input)\n",
    "\n",
    "combined_model = Model(inputs=[model_win.input, model_loss.input], outputs=combined_output)\n",
    "\n",
    "# Train the new model to make predictions using the intermediate features from both models\n",
    "optimizer = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
    "combined_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=Model_FileName, monitor='val_accuracy', save_best_only=True, save_weights=True),\n",
    "    EarlyStopping(monitor='val_accuracy', mode='auto', patience=16, verbose=1)\n",
    "]\n",
    "\n",
    "# Train the combined model\n",
    "combined_model.fit([X_train, X_train], y_train, validation_data=([X_val, X_val], y_val), epochs=500, batch_size=256 * 5, callbacks=callbacks)\n",
    "\n",
    "# Make predictions using the combined model\n",
    "combined_preds = combined_model.predict([dt[:, 0:-1], dt[:, 0:-1]])\n",
    "combined_preds_rounded = np.round(combined_preds).reshape(-1)\n",
    "\n",
    "# Calculate the accuracy and other metrics\n",
    "y_true = Y\n",
    "accuracy = np.mean(combined_preds_rounded == y_true)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Additional metrics\n",
    "true_positive = np.mean((combined_preds_rounded == 1) & (y_true == 1))\n",
    "false_positive = np.mean((combined_preds_rounded == 1) & (y_true == 0))\n",
    "true_negative = np.mean((combined_preds_rounded == 0) & (y_true == 0))\n",
    "false_negative = np.mean((combined_preds_rounded == 0) & (y_true == 1))\n",
    "\n",
    "print(f\"True Positive Rate: {true_positive * 100:.2f}%\")\n",
    "print(f\"False Positive Rate: {false_positive * 100:.2f}%\")\n",
    "print(f\"True Negative Rate: {true_negative * 100:.2f}%\")\n",
    "print(f\"False Negative Rate: {false_negative * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Lambda\n",
    "\n",
    "# Create a new input layer for the single input\n",
    "single_input = Input(shape=(IN_DIM,))\n",
    "\n",
    "# Duplicate the input for the two original models\n",
    "input_duplication = Lambda(lambda x: tf.tile(tf.expand_dims(x, axis=1), [1, 2, 1]))(single_input)\n",
    "input_for_model_win = Lambda(lambda x: x[:, 0])(input_duplication)\n",
    "input_for_model_loss = Lambda(lambda x: x[:, 1])(input_duplication)\n",
    "\n",
    "# Feed the duplicated input into the original models\n",
    "model_win_output = model_win(input_for_model_win)\n",
    "model_loss_output = model_loss(input_for_model_loss)\n",
    "\n",
    "# Combine the outputs of the original models\n",
    "combined_input = concatenate([model_win_output, model_loss_output])\n",
    "combined_output = Dense(1, activation='sigmoid')(combined_input)\n",
    "\n",
    "# Create the new model\n",
    "single_input_combined_model = Model(inputs=single_input, outputs=combined_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_preds = single_input_combined_model.predict(dt[:, 0:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the combined model\n",
    "# combined_preds = combined_model.predict([dt[:, 0:-1], dt[:, 0:-1]])\n",
    "\n",
    "combined_preds_rounded = np.round(combined_preds).reshape(-1)\n",
    "\n",
    "# Calculate the accuracy and other metrics\n",
    "y_true = Y\n",
    "accuracy = np.mean(combined_preds_rounded == y_true)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Additional metrics\n",
    "true_positive = np.mean((combined_preds_rounded == 1) & (y_true == 1))\n",
    "false_positive = np.mean((combined_preds_rounded == 1) & (y_true == 0))\n",
    "true_negative = np.mean((combined_preds_rounded == 0) & (y_true == 0))\n",
    "false_negative = np.mean((combined_preds_rounded == 0) & (y_true == 1))\n",
    "\n",
    "print(f\"True Positive Rate: {true_positive * 100:.2f}%\")\n",
    "print(f\"False Positive Rate: {false_positive * 100:.2f}%\")\n",
    "print(f\"True Negative Rate: {true_negative * 100:.2f}%\")\n",
    "print(f\"False Negative Rate: {false_negative * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very_deep_good_model=model\n",
    "wheretosave=f'{DATA_DIR}/tp{int(BUY_PCT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model'+\"_CombinedLOssWin.h5\"\n",
    "combined_model.save(wheretosave)\n",
    "print(wheretosave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test On special coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxi custum expend : GMT/USDT with those parameters: w1m=6,w5m=10,w15m=25,w1h=8,w1d=7 btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15\n",
      "Index(['open', 'high', 'low', 'close', 'high-1', 'low-1', 'close-1',\n",
      "       'volume-1', 'high-2', 'low-2',\n",
      "       ...\n",
      "       'BTC_close-3_5min', 'BTC_volume-3_5min', 'BTC_high-4_5min',\n",
      "       'BTC_low-4_5min', 'BTC_close-4_5min', 'BTC_volume-4_5min', 'day',\n",
      "       'hour', 'minute', 'lunch_day'],\n",
      "      dtype='object', length=404)\n"
     ]
    }
   ],
   "source": [
    "## Generate Data\n",
    "BAD_PERIOD_START=\"2022-08-30\"\n",
    "BAD_PERIOD_END=\"2022-11-22\"\n",
    "pair_to_test=\"GMT/USDT\"\n",
    "MAX_FORCAST_SIZE=120\n",
    "Model_FileName = \"/UltimeTradingBot/Data/IS_MIN/tp100_w15_max15min_Model_vInit.h5\"\n",
    "USED_MODEL=load_model(Model_FileName)\n",
    "\n",
    "BUY_PCT_TEST=0.45\n",
    "loc_start=0\n",
    "loc_end=1000000\n",
    "\n",
    "\n",
    "i_start=71000\n",
    "i_end=i_start+200\n",
    "\n",
    "# loc_start=df_list1m[pair_to_test].index.get_loc(pd.to_datetime(BAD_PERIOD_START))\n",
    "# loc_end=df_list1m[pair_to_test].index.get_loc(pd.to_datetime(BAD_PERIOD_END))\n",
    "\n",
    "pair=pair_to_test\n",
    "OnePair_DF=maxi_expand(pair=pair,i=loc_start,j=loc_end,window=WINDOW_SIZE,metadata=MetaData,BUY_PCT=BUY_PCT_TEST,SELL_PCT=SELL_PCT,buy_function=is_close_win,\n",
    "                           w1m=6,w5m=10,w15m=25,w1h=8,w1d=7,\n",
    "                           btc_w1m=6,btc_w5m=4,btc_w15m=5,btc_w1h=12,btc_w1d=15)\n",
    "\n",
    "OnePair_DT=OnePair_DF.to_numpy()\n",
    "gc.collect()\n",
    "OnePair_DT=fixdt(OnePair_DT)\n",
    "print(OnePair_DT[0,0] == OnePair_DF.iloc[0,0])\n",
    "print(OnePair_DT[5,5] == OnePair_DF.iloc[5,5])\n",
    "hp(OnePair_DF.buy.mean(),\"Buy mean pct\")\n",
    "\n",
    "\n",
    "plot_data(\"Original\", pair_to_test, winratio, OnePair_DF, i_start, 300, OnePair_DF.buy,dot_color=\"r\")\n",
    "\n",
    "OnePair_PredNote=USED_MODEL.predict( OnePair_DT[:, 0:-1])\n",
    "OnePair_Pred=OnePair_PredNote.round()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "Original_Traget_Data=OnePair_DT[:,-1]\n",
    "Predicted_Data=OnePair_Pred[:,0]\n",
    "gc.collect()\n",
    "TruePred=(Original_Traget_Data==Predicted_Data).copy()\n",
    "ModelAccuracy=hp(TruePred.mean(),\"ModelAccuracy\")\n",
    "gc.collect()\n",
    "TrueWinPred=((Predicted_Data==1) & (Original_Traget_Data==1) ).copy()\n",
    "TrueWinPred_Mean=hp(TrueWinPred.mean(),\"True Win Predictions Mean of all\")\n",
    "gc.collect()\n",
    "LossPred=((Predicted_Data==1) & (Original_Traget_Data==0) ).copy()\n",
    "LossPred_Mean=hp(LossPred.mean(),\"XXX Loss Buy Mean of all\")\n",
    "gc.collect()\n",
    "\n",
    "MissedDealPred=((Predicted_Data==0) & (Original_Traget_Data==1) ).copy()\n",
    "MissedDeal_Mean=hp(MissedDealPred.mean(),\"Missed good deal off all\")\n",
    "gc.collect()\n",
    "\n",
    "GoodZeroPred=((Predicted_Data==0) & (Original_Traget_Data==0) ).copy()\n",
    "GoodZero_Mean=hp(GoodZeroPred.mean(),\"Good Zero prediction Mean\")\n",
    "gc.collect()\n",
    "\n",
    "fiability=TrueWinPred_Mean + LossPred_Mean + MissedDeal_Mean + GoodZero_Mean\n",
    "if( fiability == 100):print(\"good fiability\")\n",
    "else: print(f\"check the fiability {fiability}\")\n",
    "winratio=TrueWinPred_Mean/(LossPred_Mean+TrueWinPred_Mean)\n",
    "\n",
    "print(f\"========= Win Ratio:{winratio*100} %====================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PREDICTION_TO_TEST=Predicted_Data\n",
    "\n",
    "\n",
    "\n",
    "plot_data(Model_FileName, pair_to_test, winratio, OnePair_DF, i_start, 300, PREDICTION_TO_TEST,dot_color=\"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX=OnePair_DT[:100000,:-1]\n",
    "YY=OnePair_DT[:100000,-1]\n",
    "precision=0.0\n",
    "# Good_Prediction_Note=very_deep_good_model.predict( XX)\n",
    "# Bad_Prediction_Note=very_deep_bad_model.predict( XX)\n",
    "# Initial_Pred_Note=model_init.predict( XX)\n",
    "Predicted_Data=OnePair_Pred[:300000,0]\n",
    "goodp=(Good_Prediction_Note-precision).round()\n",
    "# badp=(Bad_Prediction_Note).round()\n",
    "# initp=Initial_Pred_Note.round()\n",
    "\n",
    "# Original_Traget_Data=YY\n",
    "\n",
    "#Predicted_Data=((goodp==badp|initp==goodp))[:,0]\n",
    "Predicted_Data=(goodp)[:,0]\n",
    "\n",
    "GoodTruePred=(Original_Traget_Data==Predicted_Data).copy()\n",
    "GoodModelAccuracy=hp(GoodTruePred.mean(),\"ModelAccuracy\")\n",
    "\n",
    "GoodTrueWinPred=((Predicted_Data==1) & (Original_Traget_Data==1) ).copy()\n",
    "GoodTrueWinPred_Mean=hp(GoodTrueWinPred.mean(),\"True Win Predictions Mean of all\")\n",
    "\n",
    "GoodLossPred=((Predicted_Data==1) & (Original_Traget_Data==0) ).copy()\n",
    "GoodLossPred_Mean=hp(GoodLossPred.mean(),\"XXX Loss Buy Mean of all\")\n",
    "\n",
    "GoodMissedDealPred=((Predicted_Data==0) & (Original_Traget_Data==1) ).copy()\n",
    "GoodMissedDeal_Mean=hp(GoodMissedDealPred.mean(),\"Missed good deal off all\")\n",
    "\n",
    "GoodGoodZeroPred=((Predicted_Data==0) & (Original_Traget_Data==0) ).copy()\n",
    "GoodGoodZero_Mean=hp(GoodGoodZeroPred.mean(),\"Good Zero prediction Mean\")\n",
    "\n",
    "winratio=GoodTrueWinPred_Mean/(GoodTrueWinPred_Mean+GoodLossPred_Mean)\n",
    "fiability=GoodTrueWinPred_Mean + GoodLossPred_Mean + GoodMissedDeal_Mean + GoodGoodZero_Mean\n",
    "if( fiability == 100):print(\"good fiability\")\n",
    "else: print(f\"check the fiability {fiability}\")\n",
    "print(f\"========= Win Ratio:{winratio*100} ====================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction(XX,YY,USEDMODEL)\n",
    "XX=OnePair_DT[:100000,:-1]\n",
    "YY=OnePair_DT[:100000,-1]\n",
    "\n",
    "# Good_Prediction_Note=very_deep_good_model.predict( XX)\n",
    "# Bad_Prediction_Note=very_deep_bad_model.predict( XX)\n",
    "# Initial_Pred_Note=model_init.predict( XX)\n",
    "goodp=(Good_Prediction_Note-precision).round()\n",
    "# badp=(Bad_Prediction_Note).round()\n",
    "# initp=Initial_Pred_Note.round()\n",
    "\n",
    "# Original_Traget_Data=YY\n",
    "\n",
    "#Predicted_Data=((goodp==badp|initp==goodp))[:,0]\n",
    "Predicted_Data=(goodp)[:,0]\n",
    "\n",
    "GoodTruePred=(Original_Traget_Data==Predicted_Data).copy()\n",
    "GoodModelAccuracy=hp(GoodTruePred.mean(),\"ModelAccuracy\")\n",
    "\n",
    "GoodTrueWinPred=((Predicted_Data==1) & (Original_Traget_Data==1) ).copy()\n",
    "GoodTrueWinPred_Mean=hp(GoodTrueWinPred.mean(),\"True Win Predictions Mean of all\")\n",
    "\n",
    "GoodLossPred=((Predicted_Data==1) & (Original_Traget_Data==0) ).copy()\n",
    "GoodLossPred_Mean=hp(GoodLossPred.mean(),\"XXX Loss Buy Mean of all\")\n",
    "\n",
    "GoodMissedDealPred=((Predicted_Data==0) & (Original_Traget_Data==1) ).copy()\n",
    "GoodMissedDeal_Mean=hp(GoodMissedDealPred.mean(),\"Missed good deal off all\")\n",
    "\n",
    "GoodGoodZeroPred=((Predicted_Data==0) & (Original_Traget_Data==0) ).copy()\n",
    "GoodGoodZero_Mean=hp(GoodGoodZeroPred.mean(),\"Good Zero prediction Mean\")\n",
    "\n",
    "winratio=GoodTrueWinPred_Mean/(GoodTrueWinPred_Mean+GoodLossPred_Mean)\n",
    "fiability=GoodTrueWinPred_Mean + GoodLossPred_Mean + GoodMissedDeal_Mean + GoodGoodZero_Mean\n",
    "if( fiability == 100):print(\"good fiability\")\n",
    "else: print(f\"check the fiability {fiability}\")\n",
    "print(f\"========= Win Ratio:{winratio*100} ====================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

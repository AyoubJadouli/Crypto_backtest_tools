{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/UltimeTradingBot/Crypto_backtest_tools\n"
     ]
    }
   ],
   "source": [
    "# Final Model Prediction\n",
    "import sys\n",
    "sys.path.append('/UltimeTradingBot/Crypto_backtest_tools')\n",
    "%cd /UltimeTradingBot/Crypto_backtest_tools\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import urllib\n",
    "#import ccxt\n",
    "import  ccxt  \n",
    "import random\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import asyncio\n",
    "import tensorflow as tf\n",
    "## Garbage collection\n",
    "import gc\n",
    "gc.collect()    \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "PRERR=False\n",
    "def prerr(err):\n",
    "    if PRERR:\n",
    "        print(\"\\033[0;31m Error in \"+str(sys._getframe().f_code.co_name) +\" \\033[0;33m\"+str(err))\n",
    "## Gloabale variables\n",
    "Normalization=None\n",
    "Model_FileName='../Data/X004_15min_model87.hdf5'\n",
    "Normalization_File='../Data/Moramalization_val_004w15.json'\n",
    "Binance_USDT_HALAL = [\n",
    "    \"BTC/USDT\",\n",
    "    \"LUNA/USDT\",\n",
    "    \"ETH/USDT\",\n",
    "    \"GMT/USDT\",\n",
    "    \"UST/USDT\",\n",
    "    \"SOL/USDT\",\n",
    "    \"APE/USDT\",\n",
    "    \"XRP/USDT\",\n",
    "    \"IDEX/USDT\",\n",
    "    \"AVAX/USDT\",\n",
    "    \"DOT/USDT\",\n",
    "    \"ADA/USDT\",\n",
    "    \"JASMY/USDT\",\n",
    "    \"TRX/USDT\",\n",
    "    \"NEAR/USDT\",\n",
    "    \"AXS/USDT\",\n",
    "    \"GAL/USDT\",\n",
    "    \"GALA/USDT\",\n",
    "    \"SHIB/USDT\",\n",
    "    \"ZIL/USDT\",\n",
    "    \"ENS/USDT\",\n",
    "    \"DOGE/USDT\",\n",
    "    \"LTC/USDT\",\n",
    "    \"EUR/USDT\",\n",
    "    \"MANA/USDT\",\n",
    "    \"DAR/USDT\",\n",
    "    \"WAVES/USDT\",\n",
    "    \"LAZIO/USDT\",\n",
    "    \"ALICE/USDT\",\n",
    "    \"ROSE/USDT\",\n",
    "    \"ZEC/USDT\",\n",
    "    \"ALGO/USDT\",\n",
    "    \"GRT/USDT\",\n",
    "    \"PSG/USDT\",\n",
    "    \"SLP/USDT\",\n",
    "    \"EOS/USDT\",\n",
    "    \"PORTO/USDT\",\n",
    "    \"ICP/USDT\",\n",
    "    \"EGLD/USDT\",\n",
    "    \"XMR/USDT\",\n",
    "    \"KDA/USDT\",\n",
    "    \"ETC/USDT\",\n",
    "    \"MBOX/USDT\",\n",
    "    \"OGN/USDT\",\n",
    "    \"AR/USDT\",\n",
    "    \"GLMR/USDT\",\n",
    "    \"LOKA/USDT\",\n",
    "    \"XLM/USDT\",\n",
    "    \"MTL/USDT\",\n",
    "    \"SNX/USDT\",\n",
    "    \"PYR/USDT\",\n",
    "    \"DASH/USDT\",\n",
    "    \"CITY/USDT\",\n",
    "    \"ASTR/USDT\",\n",
    "    \"IOTA/USDT\",\n",
    "    \"ACM/USDT\",\n",
    "    \"BAR/USDT\",\n",
    "    \"JUV/USDT\",\n",
    "    \"SYS/USDT\",\n",
    "    \"RVN/USDT\",\n",
    "    \"MBL/USDT\",\n",
    "    \"REN/USDT\",\n",
    "    \"JST/USDT\",\n",
    "    \"OMG/USDT\",\n",
    "    \"ATM/USDT\",\n",
    "    \"XEC/USDT\",\n",
    "    \"STORJ/USDT\",\n",
    "    \"ZRX/USDT\",\n",
    "    \"SRM/USDT\",\n",
    "    \"ICX/USDT\",\n",
    "    \"API3/USDT\",\n",
    "    \"ONT/USDT\",\n",
    "    \"SKL/USDT\",\n",
    "    \"MULTI/USDT\",\n",
    "    \"QTUM/USDT\",\n",
    "    \"COCOS/USDT\",\n",
    "    \"VOXEL/USDT\",\n",
    "    \"HIVE/USDT\",\n",
    "    \"KP3R/USDT\",\n",
    "    \"ATA/USDT\",\n",
    "    \"STMX/USDT\",\n",
    "    \"ADX/USDT\",\n",
    "    \"HIGH/USDT\",\n",
    "    \"NULS/USDT\",\n",
    "    \"MLN/USDT\",\n",
    "    \"YGG/USDT\",\n",
    "    \"SC/USDT\",\n",
    "    \"CKB/USDT\",\n",
    "    \"TOMO/USDT\",\n",
    "    \"STX/USDT\",\n",
    "    \"FLUX/USDT\",\n",
    "    \"DNT/USDT\",\n",
    "    \"ORN/USDT\",\n",
    "    \"PLA/USDT\",\n",
    "    \"BADGER/USDT\",\n",
    "    \"DF/USDT\",\n",
    "    \"MOB/USDT\",\n",
    "    \"LPT/USDT\",\n",
    "    \"SCRT/USDT\",\n",
    "    \"RAD/USDT\",\n",
    "    \"NMR/USDT\",\n",
    "    \"ELF/USDT\",\n",
    "    \"TORN/USDT\",\n",
    "    \"T/USDT\",\n",
    "    \"QUICK/USDT\",\n",
    "    \"LSK/USDT\",\n",
    "    \"FIDA/USDT\",\n",
    "    \"XNO/USDT\",\n",
    "    \"BTG/USDT\",\n",
    "    \"GHST/USDT\",\n",
    "    \"EPS/USDT\"\n",
    "]\n",
    "\n",
    "pair_list = Binance_USDT_HALAL\n",
    "\n",
    "## Local Functions first\n",
    "# Get list of all IDs on binance\n",
    "def give_first_kline_open_stamp(interval, symbol, start_ts=1499990400000):\n",
    "        '''\n",
    "        Returns the first kline from an interval and start timestamp and symbol\n",
    "        :param interval:  1w, 1d, 1m etc - the bar length to query\n",
    "        :param symbol:    BTCUSDT or LTCBTC etc\n",
    "        :param start_ts:  Timestamp in miliseconds to start the query from\n",
    "        :return:          The first open candle timestamp\n",
    "        '''\n",
    "\n",
    "        url_stub = \"http://api.binance.com/api/v1/klines?interval=\"\n",
    "\n",
    "        #/api/v1/klines?interval=1m&startTime=1536349500000&symbol=ETCBNB\n",
    "        addInterval   = url_stub     + str(interval) + \"&\"\n",
    "        addStarttime  = addInterval   + \"startTime=\"  + str(start_ts) + \"&\"\n",
    "        addSymbol     = addStarttime + \"symbol=\"     + str(symbol)\n",
    "        url_to_get = addSymbol\n",
    "\n",
    "        kline_data = urllib.request.urlopen(url_to_get).read().decode(\"utf-8\")\n",
    "        kline_data = json.loads(kline_data)\n",
    "\n",
    "        return kline_data[0][0]\n",
    "\n",
    "def get_crypto_metadata(pair_list):\n",
    "    Binance_USDT_HALAL=pair_list\n",
    "    ids = []\n",
    "    #ids = all_ids()\n",
    "    for halalpair in Binance_USDT_HALAL:\n",
    "    #    print( halalpair.replace('/',''))\n",
    "        ids.append(halalpair.replace('/',''))\n",
    "    #print(ids)\n",
    "    MetaData=pd.DataFrame(ids)\n",
    "    MetaData[\"Pair\"]=Binance_USDT_HALAL\n",
    "    counters=0\n",
    "    for this_id in ids:\n",
    "        '''\n",
    "        Find launch Week of symbol, start at Binance launch date 2017-07-14 (1499990400000)\n",
    "        Find launch Day of symbol in week\n",
    "        Find launch minute of symbol in day\n",
    "        '''\n",
    "\n",
    "        symbol_launch_week_stamp   = give_first_kline_open_stamp('1w', this_id, 1499990400000 )\n",
    "        symbol_launch_day_stamp    = give_first_kline_open_stamp('1d', this_id, symbol_launch_week_stamp)\n",
    "        symbol_launch_minute_stamp = give_first_kline_open_stamp('1m', this_id, symbol_launch_day_stamp)\n",
    "        MetaData.loc[counters,\"launch_week_stamp\"]=str(symbol_launch_week_stamp)\n",
    "        MetaData.loc[counters,\"launch_day_stamp\"]=str(symbol_launch_day_stamp)\n",
    "        MetaData.loc[counters,\"launch_minute\"]=pd.to_datetime(symbol_launch_minute_stamp, unit='ms')\n",
    "\n",
    "        counters += 1\n",
    "\n",
    "        #print(\"Week stamp\", symbol_launch_week_stamp)\n",
    "        #print(\"Day  stamp\", symbol_launch_day_stamp)\n",
    "        #print(\"Min  stamp\", symbol_launch_minute_stamp)\n",
    "        print(counters,end=\" \")\n",
    "        #print(this_id, \"launched\", symbol_launch_minute_stamp )\n",
    "    return MetaData\n",
    "    #print(\"\")\n",
    "    \n",
    "def instant_pair_data(pair=\"GMT/BUSD\",exchange=ccxt.binance(),window=15):\n",
    "    ex=exchange\n",
    "    ticker = ex.fetch_ticker(pair)\n",
    "    pair_current_price=ticker['info']['askPrice']\n",
    "    #print(pair_current_price)\n",
    "\n",
    "    ohlcv1m = ex.fetch_ohlcv(pair, '1m', limit=15)\n",
    "    ohlcv5m = ex.fetch_ohlcv(pair, '5m', limit=15)\n",
    "    ohlcv15m = ex.fetch_ohlcv(pair, '15m', limit=15)\n",
    "    ohlcv1h = ex.fetch_ohlcv(pair, '1h', limit=15)\n",
    "    ohlcv1d = ex.fetch_ohlcv(pair, '1d', limit=15)\n",
    "\n",
    "    pair_data=pd.DataFrame()\n",
    "    pair_data.loc[0,\"price\"]=float(pair_current_price)\n",
    "    #minute\n",
    "    for window_i in range(1,window+1):\n",
    "        pair_data.loc[0,\"high-\"+str(window_i)]=ohlcv1m[-window_i][1]\n",
    "        pair_data.loc[0,\"low-\"+str(window_i)]=ohlcv1m[-window_i][2]\n",
    "        pair_data.loc[0,\"open-\"+str(window_i)]=ohlcv1m[-window_i][0]\n",
    "        pair_data.loc[0,\"close-\"+str(window_i)]=ohlcv1m[-window_i][3]\n",
    "        if(window_i!=1):pair_data.loc[0,\"volume-\"+str(window_i)]=ohlcv1m[-window_i][4]\n",
    "\n",
    "    for window_i in range(1,window+1):\n",
    "        pair_data.loc[0,\"high-\"+str(window_i)+\"_day\"]=ohlcv1d[-window_i][1]\n",
    "        pair_data.loc[0,\"low-\"+str(window_i)+\"_day\"]=ohlcv1d[-window_i][2]\n",
    "        pair_data.loc[0,\"open-\"+str(window_i)+\"_day\"]=ohlcv1d[-window_i][0]\n",
    "        pair_data.loc[0,\"close-\"+str(window_i)+\"_day\"]=ohlcv1d[-window_i][3]\n",
    "        if(window_i!=1):pair_data.loc[0,\"volume-\"+str(window_i)+\"_day\"]=ohlcv1d[-window_i][4]  \n",
    "\n",
    "    for window_i in range(1,window+1):\n",
    "        pair_data.loc[0,\"high-\"+str(window_i)+\"_hour\"]=ohlcv1h[-window_i][1]\n",
    "        pair_data.loc[0,\"low-\"+str(window_i)+\"_hour\"]=ohlcv1h[-window_i][2]\n",
    "        pair_data.loc[0,\"open-\"+str(window_i)+\"_hour\"]=ohlcv1h[-window_i][0]\n",
    "        pair_data.loc[0,\"close-\"+str(window_i)+\"_hour\"]=ohlcv1h[-window_i][3]\n",
    "        if(window_i!=1):pair_data.loc[0,\"volume-\"+str(window_i)+\"_hour\"]=ohlcv1h[-window_i][4]  \n",
    "\n",
    "    for window_i in range(1,window+1):\n",
    "        pair_data.loc[0,\"high-\"+str(window_i)+\"_15min\"]=ohlcv15m[-window_i][1]\n",
    "        pair_data.loc[0,\"low-\"+str(window_i)+\"_15min\"]=ohlcv15m[-window_i][2]\n",
    "        pair_data.loc[0,\"open-\"+str(window_i)+\"_15min\"]=ohlcv15m[-window_i][0]\n",
    "        pair_data.loc[0,\"close-\"+str(window_i)+\"_15min\"]=ohlcv15m[-window_i][3]\n",
    "        if(window_i!=1):pair_data.loc[0,\"volume-\"+str(window_i)+\"_15min\"]=ohlcv5m[-window_i][4]  \n",
    "\n",
    "    for window_i in range(1,window+1):\n",
    "        pair_data.loc[0,\"high-\"+str(window_i)+\"_5min\"]=ohlcv5m[-window_i][1]\n",
    "        pair_data.loc[0,\"low-\"+str(window_i)+\"_5min\"]=ohlcv5m[-window_i][2]\n",
    "        pair_data.loc[0,\"open-\"+str(window_i)+\"_5min\"]=ohlcv5m[-window_i][0]\n",
    "        pair_data.loc[0,\"close-\"+str(window_i)+\"_5min\"]=ohlcv5m[-window_i][3]\n",
    "        if(window_i!=1):pair_data.loc[0,\"volume-\"+str(window_i)+\"_5min\"]=ohlcv5m[-window_i][4]   \n",
    "    return  pair_data\n",
    "\n",
    "def normalize(dataset,file='w15_NoVol_Normalization.json'):\n",
    "    global Normalization\n",
    "    try:\n",
    "        N=Normalization\n",
    "    except:\n",
    "        Normalization=None\n",
    "    if(Normalization==None):\n",
    "        #print('Loading normalization from file')\n",
    "        with open(file) as json_file:\n",
    "            Normalization = json.load(json_file)\n",
    "    else:\n",
    "        #print('normalization is loaded')\n",
    "        pass\n",
    "\n",
    "    mean=np.array(Normalization[\"mean\"])\n",
    "    std=np.array(Normalization[\"std\"])\n",
    "    dataset -= mean \n",
    "    dataset /= std\n",
    "    return(dataset)\n",
    "\n",
    "def Buy_Dessision(input):\n",
    "    A=np.array(input)\n",
    "    A = A.reshape(1,A.shape[0])\n",
    "    predictions = model.predict(normalize(A))\n",
    "    rounded = [round(x[0]) for x in predictions]\n",
    "    return(rounded[0])\n",
    "\n",
    "def Buy_Dessision_Normalized(input):\n",
    "    A=np.array(input)\n",
    "    A = A.reshape(1,A.shape[0])\n",
    "    predictions = model.predict(A)\n",
    "    rounded = [round(x[0]) for x in predictions]\n",
    "    return(rounded[0])\n",
    "\n",
    "def Buy_Dessision_Multi_In_Out(input):\n",
    "    A=np.array(input)\n",
    "    predictions = model.predict(normalize(A))\n",
    "    rounded = [round(x[0]) for x in predictions]\n",
    "    return(rounded)\n",
    "\n",
    "def Buy_Dessision_Multi_In_Out_Normalized(input):\n",
    "    A=np.array(input)\n",
    "    predictions = model.predict(A)\n",
    "    rounded = [round(x[0]) for x in predictions]\n",
    "    return(rounded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 13:07:33.734200: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-25 13:07:33.734237: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-25 13:07:33.734264: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ibm56go): /proc/driver/nvidia/version does not exist\n",
      "2022-09-25 13:07:33.734524: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Getting Vars\n",
    "\n",
    "try:\n",
    "    MetaData=pd.read_csv(\"../Data/MetaData.csv\")\n",
    "except:\n",
    "    MetaData=get_crypto_metadata(Binance_USDT_HALAL)\n",
    "\n",
    "## loding the model\n",
    "model = load_model(Model_FileName)\n",
    "Exchange=ccxt.binance()\n",
    "ex=Exchange\n",
    "pair='GMT/BUSD'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv(\"../Data/004Precent-w15_crypto_shufled_NoVol.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"buy\"]==1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

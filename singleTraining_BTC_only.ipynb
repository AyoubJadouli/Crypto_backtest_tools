{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single AI crypto concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xdata_config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Imports and fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/pandas/core/arrays/masked.py:59: UserWarning: Pandas requires version '1.3.2' or newer of 'bottleneck' (version '1.2.1' currently installed).\n",
      "  from pandas.core import (\n",
      "2022-12-07 06:40:44.003623: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-07 06:40:44.003673: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-07 06:40:44.069319: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-07 06:40:45.391231: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-07 06:40:45.391398: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-07 06:40:45.391421: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from functions_module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BTC/BUSD']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "TICKERS = \"../Binance-Fast-Trade-Bot/volatile_volume_\" + str(date.today()) + \".txt\"\n",
    "VOLATILE_COINS=[line.strip() for line in open(TICKERS)]\n",
    "PAIR_WITH=\"BUSD\"\n",
    "VOLATILE_USDT_PAIRS=[coin+\"/USDT\" for coin in VOLATILE_COINS]\n",
    "VOLATILE_BUSD_PAIRS=[coin+\"/BUSD\" for coin in VOLATILE_COINS]\n",
    "VOLATILE_BUSD_PAIRS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins_to_download=''\n",
    "for coin in VOLATILE_COINS:\n",
    "    coins_to_download=coins_to_download+\" \"+coin\n",
    "os.system(f\"node database/ddargs.js {coins_to_download} {PAIR_WITH}\")#node database/ddargs.js ORN BUSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_list = VOLATILE_BUSD_PAIRS\n",
    "#tf = '1m'\n",
    "oldest_pair = \"BTC/USDT\"\n",
    "if oldest_pair not in pair_list: pair_list.append(oldest_pair)\n",
    "df_list1m = {}\n",
    "df_list1d = {}\n",
    "df_list1h = {}\n",
    "df_list5m = {}\n",
    "df_list15m = {}\n",
    "\n",
    "\n",
    "for pair in pair_list:\n",
    "    df = get_historical_from_db(ccxt.binance(), pair, '1m', path=\"./database/\")\n",
    "    df_list1m[pair] = df.loc[:]\n",
    "\n",
    "for pair in pair_list:\n",
    "    df = get_historical_from_db(ccxt.binance(), pair, '1d', path=\"./database/\")\n",
    "    df_list1d[pair] = df.loc[:]\n",
    "\n",
    "for pair in pair_list:\n",
    "    df = get_historical_from_db(ccxt.binance(), pair, '1h', path=\"./database/\")\n",
    "    df_list1h[pair] = df.loc[:]\n",
    "\n",
    "for pair in pair_list:\n",
    "    df = get_historical_from_db(ccxt.binance(), pair, '5m', path=\"./database/\")\n",
    "    df_list5m[pair] = df.loc[:]\n",
    "\n",
    "for pair in pair_list:\n",
    "    df = get_historical_from_db(\n",
    "        ccxt.binance(), pair, '15m', path=\"./database/\")\n",
    "    df_list15m[pair] = df.loc[:]\n",
    "del(df)\n",
    "df_list = df_list1m\n",
    "prerr(\"Data load 100% use df_list1d[\\\"BTC/USDT\\\"] for exemple to access\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.constraints import MaxNorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chking import\n",
    "MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results dir: /UltimeTradingBot/Data/AFTER_DEPTH\n"
     ]
    }
   ],
   "source": [
    "if BUY_MODE==\"BUY_ONLY\":\n",
    "    buy_function=buy_only_up\n",
    "elif BUY_MODE==\"BUY_UP\":\n",
    "    buy_function=buy_up\n",
    "elif  BUY_MODE==\"BUY_DIP\":\n",
    "    buy_function=buy_min_up\n",
    "elif  BUY_MODE==\"AFTER_DEPTH\":\n",
    "    buy_function=buy_after_depth\n",
    "    \n",
    "\n",
    "\n",
    "os.mkdir(DATA_DIR, mode = 0o777)\n",
    "print(f\"Results dir: {DATA_DIR}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def One_pair_AI_Gen(pair=\"ETH/USDT\",row_numbers=500000):\n",
    "    ResJS={}\n",
    "    mfile=f'{DATA_DIR}/{pair.replace(\"/\", \"-\")}-tp{int(BUY_PERCENT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Model_v{VERSION}.hdf5'\n",
    "    nfile=f'{DATA_DIR}/{pair.replace(\"/\", \"-\")}-tp{int(BUY_PERCENT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Norm_v{VERSION}.json'\n",
    "    price_volatility_15m=round((100*(df_list15m[pair][\"high\"]-df_list15m[pair][\"low\"])/df_list15m[pair][\"high\"]).mean()*0.75,2)\n",
    "    print(f\"price_volatility_15m:{price_volatility_15m}%\")\n",
    "    df=mini_expand3(pair=pair,i=0,j=len(df_list1m[pair]),window=WINDOW_SIZE,metadata=MetaData,buy_pourcent=max(price_volatility_15m,BUY_PERCENT),sell_pourcent=SELL_PERCENT)\n",
    "    print(\"df original shape \"+str(df.shape))\n",
    "    print(f\"df original shape buy mean : {df.buy.mean()*100}\")\n",
    "    df=df.reset_index()\n",
    "    try:df.pop(\"num_index\")\n",
    "    except: pass\n",
    "    try:df.pop(\"index\")\n",
    "    except: pass\n",
    "    try:df.pop(\"date\")\n",
    "    except: pass\n",
    "    df=data_shufler(df)            \n",
    "    #df=data_chooser(df,weight=50,row_numbers=df.buy.sum()*2)\n",
    "    df=data_chooser50(df,row_numbers=row_numbers)\n",
    "    gc.collect()\n",
    "    df=data_cleanup(df)\n",
    "    df=df.dropna()\n",
    "    print(\"df choosen data shape\"+str(df.shape))\n",
    "    print(f\"pair: {(df.shape[0]/2)==df.buy.sum()}\")\n",
    "    dt=df.to_numpy(dtype=np.float32)\n",
    "    #dt=df.to_numpy()\n",
    "    dt=np.nan_to_num(dt,nan=0)\n",
    "    #dt=dt.astype(np.float32)\n",
    "    dt=np.nan_to_num(dt, neginf=0) \n",
    "    dt=np.nan_to_num(dt, posinf=0) \n",
    "\n",
    "    ## normalisation\n",
    "    index_20percent= int(0.2*len(dt[:,0]))\n",
    "    print(index_20percent)\n",
    "    if True:\n",
    "        if True:\n",
    "        #if True:\n",
    "            print(\"normalizing ...\")\n",
    "            mean = dt[index_20percent:, 0:-1].mean(axis=0)\n",
    "            std = dt[index_20percent:, 0:-1].std(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "            dt[index_20percent:, 0:-1] -= mean \n",
    "            dt[index_20percent:, 0:-1] /= std\n",
    "\n",
    "            dt[:index_20percent, :-1] -=mean\n",
    "            dt[:index_20percent, :-1] /= std\n",
    "            FIRST_NORM_FLAG=False\n",
    "            ######################### SAVIN NORM ################\n",
    "            try:\n",
    "                Normalization={\"mean\":mean.tolist(),\"std\":std.tolist()}\n",
    "                with open(nfile, 'w+') as fp:\n",
    "                            json.dump(Normalization, fp,  indent=4)\n",
    "                            print(fp.name)\n",
    "            except Exception as e:\n",
    "                print(\"error Normalization in juppiter\")\n",
    "                print(e)\n",
    "        else:print(\"already normalized\")\n",
    "        \n",
    "    dt=np.nan_to_num(dt,nan=0)\n",
    "    dt=np.nan_to_num(dt, neginf=0) \n",
    "    dt=np.nan_to_num(dt, posinf=0) \n",
    "    dt=dt.astype(np.float32)\n",
    "    ## Model\n",
    "    IN_DIM=dt.shape[1]-1\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(250),input_dim=IN_DIM,activation='relu')) #( 100=>66.23)\n",
    "    # resultus withe 250 d0.3 50 d 20 d 8 = 65.6% vs  65.49 no droppout vs 65.78 d0.5 vs 65.68 d0.4 # 65.48 # one dropout of   0.5 = 66.11   #tanh 66.33 accuracy #softmax 66.12 #softplus 66.5 # sigmoid 66.21 / \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(int(20),activation='relu')) # best softplus 66.26(69) vs relu 66.65(70)  / -20 => 66.25 /250 ->65.78\n",
    "    #model2.add(Dropout(0.1)) #5=> 66.00  66.21 vs no dopout 66.28\n",
    "    #model2.add(Dense(int(20),activation='relu')) # disabled 6.24\n",
    "    model.add(Dense(int(50),activation='relu')) # -4 -> -> 66.24\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    print(model.summary())\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    callbacks_a = ModelCheckpoint(filepath =mfile,monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "    callbacks_b = EarlyStopping(monitor ='val_accuracy',mode='auto',patience=15,verbose=1)\n",
    "    print(\"saving file in: \"+mfile)\n",
    "    history = model.fit(dt[index_20percent:, 0:-1],\n",
    "                    dt[index_20percent:,-1],\n",
    "                    validation_data=(dt[:index_20percent, :-1],dt[:index_20percent,-1]),\n",
    "                    epochs=6000,\n",
    "                    batch_size=256*10,\n",
    "                    callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "    print('##########################################################################')\n",
    "    print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "    print(nfile)\n",
    "    print(mfile)\n",
    "    ResJS[pair]='{0:.4g}'.format(max(history.history['val_accuracy'])*100)\n",
    "    return( model , ResJS)\n",
    "    #94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalDataTest(pair=\"ETH/USDT\"):\n",
    "    price_volatility_15m=round((100*(df_list15m[pair][\"high\"]-df_list15m[pair][\"low\"])/df_list15m[pair][\"high\"]).mean()*0.75,2)\n",
    "    print(f\"price_volatility_15m:{price_volatility_15m}%\")\n",
    "    df=mini_expand3(pair=pair,i=0,j=len(df_list1m[pair]),window=WINDOW_SIZE,metadata=MetaData,buy_pourcent=max(price_volatility_15m,BUY_PERCENT),sell_pourcent=SELL_PERCENT)\n",
    "    print(\"df original shape \"+str(df.shape))\n",
    "    print(f\"df original shape buy mean : {df.buy.mean()*100}\")\n",
    "    df=df.reset_index()\n",
    "    try:df.pop(\"num_index\")\n",
    "    except: pass\n",
    "    try:df.pop(\"index\")\n",
    "    except: pass\n",
    "    try:df.pop(\"date\")\n",
    "    except: pass\n",
    "    # df=data_shufler(df)            \n",
    "    # #df=data_chooser(df,weight=50,row_numbers=df.buy.sum()*2)\n",
    "    # df=data_chooser50(df,row_numbers=500000)\n",
    "    # gc.collect()\n",
    "    df=data_cleanup(df)\n",
    "    df=df.dropna()\n",
    "    print(\"df choosen data shape\"+str(df.shape))\n",
    "    print(f\"pair: {(df.shape[0]/2)==df.buy.sum()}\")\n",
    "    dt=df.to_numpy(dtype=np.float32)\n",
    "    #dt=df.to_numpy()\n",
    "    dt=np.nan_to_num(dt,nan=0)\n",
    "    #dt=dt.astype(np.float32)\n",
    "    dt=np.nan_to_num(dt, neginf=0) \n",
    "    dt=np.nan_to_num(dt, posinf=0) \n",
    "\n",
    "    ## normalisation\n",
    "    #index_20percent= int(0.2*len(dt[:,0]))\n",
    "    #print(index_20percent)\n",
    "    Y=dt[:,-1].copy()\n",
    "    dt[:,:-1]=normalize(dt[:,:-1],f'{DATA_DIR}/{pair.replace(\"/\", \"-\")}-tp{int(BUY_PERCENT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Norm_v{VERSION}.json')\n",
    "    dt=np.nan_to_num(dt,nan=0)\n",
    "    dt=np.nan_to_num(dt, neginf=0) \n",
    "    dt=np.nan_to_num(dt, posinf=0) \n",
    "    dt=dt.astype(np.float32)\n",
    "    ## Model\n",
    "    return dt\n",
    "    #94%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Garbage Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m,h=One_pair_AI_Gen(pair=\"ETH/USDT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair=\"ETH/USDT\"\n",
    "# model = load_model(MODEL_FILE.replace(\"/UltimeTradingBot/Data/\", \"/UltimeTradingBot/Data/\"+pair.replace(\"/\", \"-\")+\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on pair: BTG/BUSD\n",
      "'BTG/BUSD'\n"
     ]
    }
   ],
   "source": [
    "### sigle Train sample\n",
    "pair=\"BTG/BUSD\"\n",
    "print(f\"working on pair: {pair}\")\n",
    "try:\n",
    "    m,h=One_pair_AI_Gen(pair)\n",
    "    histoplus.update(h)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price_volatility_15m=round((100*(df_list15m[pair][\"high\"]-df_list15m[pair][\"low\"])/df_list15m[pair][\"high\"]).mean()*0.75,2)\n",
    "# print(f\"price_volatility_15m:{price_volatility_15m}%\")\n",
    "# df=mini_expand3(pair=pair,i=0,j=len(df_list1m[pair]),window=WINDOW_SIZE,metadata=MetaData,buy_pourcent=max(price_volatility_15m,BUY_PERCENT),sell_pourcent=SELL_PERCENT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MetaData=get_crypto_metadata(Binance_USDT_HALAL)\n",
    "# MetaData.to_csv(\"../Data/MetaData.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ORN/BUSD'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m pair\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mORN/BUSD\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m buy_function\u001b[39m=\u001b[39mbuy_after_depth\n\u001b[0;32m----> 3\u001b[0m m,h\u001b[39m=\u001b[39mOne_pair_AI_Gen(pair)\n",
      "Cell \u001b[0;32mIn [6], line 3\u001b[0m, in \u001b[0;36mOne_pair_AI_Gen\u001b[0;34m(pair, row_numbers)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mOne_pair_AI_Gen\u001b[39m(pair\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mETH/USDT\u001b[39m\u001b[39m\"\u001b[39m,row_numbers\u001b[39m=\u001b[39m\u001b[39m500000\u001b[39m):\n\u001b[1;32m      2\u001b[0m     ResJS\u001b[39m=\u001b[39m{}\n\u001b[0;32m----> 3\u001b[0m     price_volatility_15m\u001b[39m=\u001b[39m\u001b[39mround\u001b[39m((\u001b[39m100\u001b[39m\u001b[39m*\u001b[39m(df_list15m[pair][\u001b[39m\"\u001b[39m\u001b[39mhigh\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m-\u001b[39mdf_list15m[pair][\u001b[39m\"\u001b[39m\u001b[39mlow\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m/\u001b[39mdf_list15m[pair][\u001b[39m\"\u001b[39m\u001b[39mhigh\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mmean()\u001b[39m*\u001b[39m\u001b[39m0.75\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mprice_volatility_15m:\u001b[39m\u001b[39m{\u001b[39;00mprice_volatility_15m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     df\u001b[39m=\u001b[39mmini_expand3(pair\u001b[39m=\u001b[39mpair,i\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,j\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(df_list1m[pair]),window\u001b[39m=\u001b[39mWINDOW_SIZE,metadata\u001b[39m=\u001b[39mMetaData,buy_pourcent\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(price_volatility_15m,BUY_PERCENT),sell_pourcent\u001b[39m=\u001b[39mSELL_PERCENT)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ORN/BUSD'"
     ]
    }
   ],
   "source": [
    "pair=\"ORN/BUSD\"\n",
    "buy_function=buy_after_depth\n",
    "m,h=One_pair_AI_Gen(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Binance_USDT_HALAL.index(\"LOKA/USDT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BUY_MODE==\"BUY_DIP\":\n",
    "     buy_function=buy_min_up\n",
    "if BUY_MODE==\"BUY_ONLY\":\n",
    "     buy_function=buy_up\n",
    "if BUY_MODE==\"AFTER_DEPTH\":\n",
    "     buy_function=buy_after_depth\n",
    "errorlist={}\n",
    "histoplus={}\n",
    "for pair in Binance_USDT_HALAL[Binance_USDT_HALAL.index(\"STX/USDT\"):]:    # ICX/USDT min\n",
    "#for pair in VOLATILE_BUSD_PAIRS[:]:    # ICX/USDT min\n",
    "     print(f\"working on pair: {pair}\")\n",
    "     try:\n",
    "          m,h=One_pair_AI_Gen(pair)\n",
    "          histoplus.update(h)\n",
    "          \n",
    "     except Exception as e:\n",
    "          errorlist[pair]=e\n",
    "          print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histoplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Binance_USDT_HALAL[13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair=\"GMT/USDT\"\n",
    "price_volatility_15m=(100*(df_list15m[pair][\"high\"]-df_list15m[pair][\"low\"])/df_list15m[pair][\"high\"]).mean()\n",
    "print(f\"price_volatility_15m:{price_volatility_15m}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=mini_expand3(pair=pair,i=0,j=len(df_list1m[pair]),window=WINDOW_SIZE,metadata=MetaData,buy_pourcent=max(price_volatility_15m*0.5,BUY_PERCENT),sell_pourcent=SELL_PERCENT)\n",
    "print(\"df original shape \"+str(df.shape))\n",
    "print(f\"df original shape buy mean : {df.buy.mean()*100}\")\n",
    "df=df.reset_index()\n",
    "try:df.pop(\"num_index\")\n",
    "except: pass\n",
    "try:df.pop(\"index\")\n",
    "except: pass\n",
    "try:df.pop(\"date\")\n",
    "except: pass\n",
    "df=data_shufler(df)            \n",
    "#df=data_chooser(df,weight=50,row_numbers=df.buy.sum()*2)\n",
    "df=data_chooser50(df,row_numbers=500000)\n",
    "gc.collect()\n",
    "df=data_cleanup(df)\n",
    "df=df.dropna()\n",
    "#df.pop(\"price\");print(\"we work with no price\")\n",
    "#df.pop(\"BTC_price\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BTC\n",
    "df=mini_expand4_btc(i=0,j=len(df_list1m[pair]),window=100,metadata=MetaData,buy_pourcent=0.4,sell_pourcent=SELL_PERCENT)\n",
    "print(\"df original shape \"+str(df.shape))\n",
    "print(f\"df original shape buy mean : {df.buy.mean()*100}\")\n",
    "df=df.reset_index()\n",
    "try:df.pop(\"num_index\")\n",
    "except: pass\n",
    "try:df.pop(\"index\")\n",
    "except: pass\n",
    "try:df.pop(\"date\")\n",
    "except: pass\n",
    "df=data_shufler(df)            \n",
    "df=data_chooser50(df,row_numbers=500000)\n",
    "gc.collect()\n",
    "df=data_cleanup(df)\n",
    "df=df.dropna()\n",
    "#df.pop(\"price\");print(\"we work with no price\")\n",
    "#df.pop(\"BTC_price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResJS={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data_shufler(df)            \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df choosen data shape\"+str(df.shape))\n",
    "(df.shape[0]/2)==df.buy.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.buy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=df.to_numpy(dtype=np.float32)\n",
    "#dt=df.to_numpy()\n",
    "dt=np.nan_to_num(dt,nan=0)\n",
    "#dt=dt.astype(np.float32)\n",
    "dt=np.nan_to_num(dt, neginf=0) \n",
    "dt=np.nan_to_num(dt, posinf=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_20percent= int(0.2*len(dt[:,0]))\n",
    "print(index_20percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_20percent= int(0.2*len(df.iloc[:,0]))\n",
    "# print(index_20percent)\n",
    "# XVALIDATION= df.iloc[:index_20percent, :-1]\n",
    "# YVALIDATION= df.iloc[:index_20percent,-1]\n",
    "# XTRAIN= df.iloc[index_20percent:, 0:-1]\n",
    "# YTRAIN= df.iloc[index_20percent:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if True:\n",
    "#     if True:\n",
    "#     #if True:\n",
    "#         print(\"normalizing ...\")\n",
    "#         mean = df.iloc[index_20percent:, 0:-1].mean(axis=0).values\n",
    "#         std = df.iloc[index_20percent:, 0:-1].std(axis=0).values\n",
    "\n",
    "\n",
    "#         # print(mean.values)\n",
    "#         df.iloc[index_20percent:, 0:-1] -= mean\n",
    "#         df.iloc[index_20percent:, 0:-1] /= std\n",
    "\n",
    "#         df.iloc[:index_20percent, :-1] -=mean\n",
    "#         df.iloc[:index_20percent, :-1] /= std\n",
    "#         FIRST_NORM_FLAG=False\n",
    "#         ######################### SAVIN NORM ################\n",
    "#         try:\n",
    "#             Normalization={\"mean\":mean.tolist(),\"std\":std.tolist()}\n",
    "#             with open(Normalization_File.replace(\"/UltimeTradingBot/Data/\", \"/UltimeTradingBot/Data/\"+pair.replace(\"/\", \"-\")+\"-\"), 'w+') as fp:\n",
    "#                         json.dump(Normalization, fp,  indent=4)\n",
    "#                         print(Normalization_File)\n",
    "#         except Exception as e:\n",
    "#             print(\"error Normalization in juppiter\")\n",
    "#             print(e)\n",
    "#     else:print(\"already normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if True:\n",
    "    if True:\n",
    "    #if True:\n",
    "        print(\"normalizing ...\")\n",
    "        mean = dt[index_20percent:, 0:-1].mean(axis=0)\n",
    "        std = dt[index_20percent:, 0:-1].std(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "        dt[index_20percent:, 0:-1] -= mean \n",
    "        dt[index_20percent:, 0:-1] /= std\n",
    "\n",
    "        dt[:index_20percent, :-1] -=mean\n",
    "        dt[:index_20percent, :-1] /= std\n",
    "        FIRST_NORM_FLAG=False\n",
    "        ######################### SAVIN NORM ################\n",
    "        try:\n",
    "            Normalization={\"mean\":mean.tolist(),\"std\":std.tolist()}\n",
    "            with open(f'{DATA_DIR}/{pair}-tp{int(BUY_PERCENT*100)}_w{WINDOW_SIZE}_max{MAX_FORCAST_SIZE}min_Norm_v{VERSION}.json', 'w+') as fp:\n",
    "                        json.dump(Normalization, fp,  indent=4)\n",
    "                        print(fp.name)\n",
    "        except Exception as e:\n",
    "            print(\"error Normalization in juppiter\")\n",
    "            print(e)\n",
    "    else:print(\"already normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=np.nan_to_num(dt,nan=0)\n",
    "dt=np.nan_to_num(dt, neginf=0) \n",
    "dt=np.nan_to_num(dt, posinf=0) \n",
    "dt=dt.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=dt[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt[index_20percent:, 0:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_DIM=dt.shape[1]-1\n",
    "model = Sequential()\n",
    "model.add(Dense(int(250),input_dim=IN_DIM,activation='relu')) #( 100=>66.23)\n",
    "# resultus withe 250 d0.3 50 d 20 d 8 = 65.6% vs  65.49 no droppout vs 65.78 d0.5 vs 65.68 d0.4 # 65.48 # one dropout of   0.5 = 66.11   #tanh 66.33 accuracy #softmax 66.12 #softplus 66.5 # sigmoid 66.21 / \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(int(20),activation='relu')) # best softplus 66.26(69) vs relu 66.65(70)  / -20 => 66.25 /250 ->65.78\n",
    "#model2.add(Dropout(0.1)) #5=> 66.00  66.21 vs no dopout 66.28\n",
    "#model2.add(Dense(int(20),activation='relu')) # disabled 6.24\n",
    "model.add(Dense(int(50),activation='relu')) # -4 -> -> 66.24\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "print(model.summary())\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "callbacks_a = ModelCheckpoint(filepath =MODEL_FILE.replace(\"/UltimeTradingBot/Data/\", \"/UltimeTradingBot/Data/\"+pair.replace(\"/\", \"-\")+\"-\"),monitor ='val_accuracy',save_best_only = True, save_weights = True)\n",
    "callbacks_b = EarlyStopping(monitor ='val_accuracy',mode='auto',patience=15,verbose=1)\n",
    "history = model.fit(dt[index_20percent:, 0:-1],\n",
    "                dt[index_20percent:,-1],\n",
    "                validation_data=(dt[:index_20percent, :-1],dt[:index_20percent,-1]),\n",
    "                epochs=6000,\n",
    "                batch_size=256*10,\n",
    "                callbacks=[callbacks_a,callbacks_b])\n",
    "\n",
    "print('##########################################################################')\n",
    "print(MODEL_FILE.replace(\"/UltimeTradingBot/Data/\", \"/UltimeTradingBot/Data/\"+pair.replace(\"/\", \"-\")+\"-\"))\n",
    "print(f\"------val_accuracy-----> {'{0:.4g}'.format(max(history.history['val_accuracy'])*100)} | {'{0:.4g}'.format(max(history.history['accuracy'])*100)} <----------accuracy----------\")\n",
    "ResJS[pair]='{0:.4g}'.format(max(history.history['val_accuracy'])*100)\n",
    "#94%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Tests and evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_function=buy_min_up\n",
    "df=mini_expand3(pair=pair,i=0,j=len(df_list1m[pair]),window=WINDOW_SIZE,metadata=MetaData,buy_pourcent=BUY_PERCENT,sell_pourcent=SELL_PERCENT)\n",
    "print(\"df original shape \"+str(df.shape))\n",
    "print(f\"df original shape buy mean : {df.buy.mean()*100}\")\n",
    "df=df.reset_index()\n",
    "try:df.pop(\"num_index\")\n",
    "except: pass\n",
    "try:df.pop(\"index\")\n",
    "except: pass\n",
    "try:df.pop(\"date\")\n",
    "except: pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i_start=22500\n",
    "i_end=i_start+1000\n",
    "x = np.linspace(0, 10, 500)\n",
    "dashes = [10, 5, 100, 5]  # 10 points on, 5 off, 100 on, 5 off\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot(df.index[i_start:i_end], df.price[i_start:i_end], '-', linewidth=1,\n",
    "                 label='Dashes set retroactively')\n",
    "line1.set_dashes(dashes)\n",
    "plt.plot(df[i_start:i_end][df.buy[i_start:i_end]==1].index, df[i_start:i_end][df.buy[i_start:i_end]==1].price, 'ro')\n",
    "\n",
    "\n",
    "ax.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=NormalDataTest(pair=\"APE/USDT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i_start=22500\n",
    "i_end=i_start+1000\n",
    "x = np.linspace(0, 10, 500)\n",
    "dashes = [10, 5, 100, 5]  # 10 points on, 5 off, 100 on, 5 off\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot(np.arange(i_start,i_end), dt[i_start:i_end,0], '-', linewidth=1,\n",
    "                 label='Price')\n",
    "# line1.set_dashes(dashes)\n",
    "plt.plot(np.arange(i_start,i_end)[dt[i_start:i_end,-1]==1], dt[i_start:i_end,0][dt[i_start:i_end,-1]==1], 'ro')\n",
    "\n",
    "\n",
    "ax.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_20percent=dt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XVALIDATION= dt[:index_20percent, :-1]\n",
    "YVALIDATION= dt[:index_20percent,-1]\n",
    "XTRAIN= dt[index_20percent:, 0:-1]\n",
    "YTRAIN= dt[index_20percent:,-1]\n",
    "\n",
    "\n",
    "XX0=XVALIDATION[YVALIDATION==0]\n",
    "YY0=YVALIDATION[YVALIDATION==0]\n",
    "\n",
    "INDEX_SEP=int(XX0.shape[0]/4)\n",
    "XX0Train=XX0[INDEX_SEP:]\n",
    "YY0Train=YY0[INDEX_SEP:]\n",
    "\n",
    "XX0Val=XX0[:INDEX_SEP]\n",
    "YY0Val=YY0[:INDEX_SEP]\n",
    "\n",
    "XX1=XVALIDATION[YVALIDATION==1]\n",
    "YY1=YVALIDATION[YVALIDATION==1]\n",
    "\n",
    "INDEX_SEP=int(XX1.shape[0]/4)\n",
    "XX1Train=XX1[INDEX_SEP:]\n",
    "YY1Train=YY1[INDEX_SEP:]\n",
    "\n",
    "XX1Val=XX1[:INDEX_SEP]\n",
    "YY1Val=YY1[:INDEX_SEP]\n",
    "\n",
    "\n",
    "accuracy0 = model.evaluate(XX0, YY0)\n",
    "accuracy1 = model.evaluate(XX1, YY1)\n",
    "accuracy = model.evaluate(XVALIDATION, YVALIDATION)\n",
    "maxaccuracy = model.evaluate(dt[:,:-1], dt[:,-1])\n",
    "\n",
    "print(f\"class 0: {format(accuracy0[1]*100,'0.2f')} %\")\n",
    "print(f\"class 1: {format(accuracy1[1]*100,'0.2f')} %\")\n",
    "print(f\"FULL class : {format(accuracy[1]*100,'0.2f')} %\")\n",
    "print(f\"FULL class with all data: {format(maxaccuracy[1]*100,'0.2f')} %\")\n",
    "\n",
    "#accuracy = model.evaluate(dt[:,0:-1], dt[:,-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dftest=mini_expand3(pair=pair,i=0,j=len(df_list1m[pair]),window=WINDOW_SIZE,metadata=MetaData,buy_pourcent=0.4,sell_pourcent=SELL_PERCENT)\n",
    "dftest=df\n",
    "print(\"df original shape \"+str(dftest.shape))\n",
    "print(f\"df original shape buy mean : {dftest.buy.mean()*100}\")\n",
    "dftest=dftest.reset_index()\n",
    "try:dftest.pop(\"num_index\")\n",
    "except: pass\n",
    "try:dftest.pop(\"index\")\n",
    "except: pass\n",
    "try:dftest.pop(\"date\")\n",
    "except: pass\n",
    "dftest=data_shufler(dftest)            \n",
    "gc.collect()\n",
    "dftest=data_cleanup(dftest)\n",
    "dftest=dftest.dropna()\n",
    "df.pop(\"price\");print(\"we work with no price\")\n",
    "df.pop(\"BTC_price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest.buy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtt=dftest.to_numpy(dtype=np.float32)\n",
    "dtt=dt\n",
    "#dt=df.to_numpy()\n",
    "dtt=np.nan_to_num(dtt,nan=0)\n",
    "#dt=dt.astype(np.float32)\n",
    "dtt=np.nan_to_num(dtt, neginf=0) \n",
    "dtt=np.nan_to_num(dtt, posinf=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stats plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction2=(model.predict( dtt[:, 0:-1])).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ixx=dtt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "False_prediction=dtt[:ixx,-1][(prediction2[:ixx].transpose()[0]!=dtt[:ixx])]\n",
    "True_prediction=dtt[:ixx,-1][(prediction2[:ixx].transpose()[0]==dtt[:ixx])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtt[:,-1].mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp0=False_prediction[False_prediction==0].shape[0]*100/ixx #### it mean that 11.73 of the 0 class are wrong the buyed witch lead the losses\n",
    "print( f\"Prediction mean :{prediction2.mean()*100} %\"+'#### the colose to 50 the better')\n",
    "print( f\"False prediction class 0 :{fp0} %\"+'#### it mean that x of the 0 class are wrong the buyed witch lead the losses')\n",
    "fp1=False_prediction[False_prediction==1].shape[0]*100/ixx   #### we don't buy x % of the correct chanses\n",
    "print( f\"False prediction class 1 :{fp1} %\"+'#### we don\\'t buy x % of the correct chanses')\n",
    "trp0=True_prediction[True_prediction==0].shape[0]*100/ixx   #### it mean that 40 % of class 0 are predicted correctly\n",
    "trp1=True_prediction[True_prediction==1].shape[0]*100/ixx     #### the only buying correct of all\n",
    "print( f\"True prediction class 0 :{trp0} %\"+'#### it mean that 40 % of class 0 are predicted correctly')\n",
    "print( f\"True prediction class 1 :{trp1} %\"+'#### the only buying correct of all')\n",
    "print(f\"successful buy pourcent of unsuccessfull: {100*trp1/(trp1+fp1)}  %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(dt[:index_20percent,:-1], Y[:index_20percent]) #3-> 66.76 / 4 -> 65.75\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

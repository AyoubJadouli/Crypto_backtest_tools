{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the necessary libraries and load the pre-trained models from the H5 files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 06:54:13.189350: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-04 06:54:13.189426: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-04 06:54:13.267432: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-04 06:54:15.297783: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-04 06:54:15.297921: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-04 06:54:15.297944: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/usr/local/lib/python3.9/dist-packages/pandas/core/arrays/masked.py:59: UserWarning: Pandas requires version '1.3.2' or newer of 'bottleneck' (version '1.2.1' currently installed).\n",
      "  from pandas.core import (\n",
      "2023-03-04 06:54:17.643159: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-04 06:54:17.643216: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-04 06:54:17.643266: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: abj-K93SV\n",
      "2023-03-04 06:54:17.643282: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: abj-K93SV\n",
      "2023-03-04 06:54:17.643370: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2023-03-04 06:54:17.643437: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 390.154.0\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Dense\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the pre-trained models\n",
    "model1 = load_model('/UltimeTradingBot/Data/AFTER_DEPTH_CLOSE/tp130_w7_max16min_Model_vInit.h5')\n",
    "model2 = load_model('/UltimeTradingBot/Data/BUY_MIN_CLOSE/tp70_w7_max4min_Model_VeryDeep.h5')\n",
    "model3 = load_model('/UltimeTradingBot/Data/BUY_TEST/tp150_w7_max2min_Model_vInit.h5')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to freeze the layers in each of the pre-trained models to prevent their weights from being updated during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers in each of the pre-trained models\n",
    "for layer in model1.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in model2.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in model3.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can define the input shape for our model and concatenate the outputs from the pre-trained models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape for our model\n",
    "input_shape = (286,)\n",
    "\n",
    "# Define the input layer for our model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Concatenate the outputs from the pre-trained models\n",
    "concat_layer = concatenate([model1.output, model2.output, model3.output])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model\n",
    "Finally, you can train the model on your data. You need to provide the same input data to the new model as the pre-trained models. You can do this by passing the input tensor to the inputs argument of the new model. For example:\n",
    "\n",
    "\n",
    "\n",
    "Here, input_tensor is a tensor of shape (num_samples, input_shape[0], input_shape[1], input_shape[2]) containing your input images, and labels is a tensor of shape (num_samples, 1) containing the binary labels (0 or 1) for each sample. You can adjust the number of epochs and batch size as needed for your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some deep layers on top of the concatenated outputs\n",
    "x = Dense(256, activation='relu')(concat_layer)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "output_layer = Dense(1, activation='sigmoid')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The name \"dense_4\" is used 2 times in the model. All layer names should be unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Define our model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m Model(inputs\u001b[39m=\u001b[39;49m[model1\u001b[39m.\u001b[39;49minput, model2\u001b[39m.\u001b[39;49minput, model3\u001b[39m.\u001b[39;49minput], outputs\u001b[39m=\u001b[39;49moutput_layer)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Compile the model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:165\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m    157\u001b[0m         [\n\u001b[1;32m    158\u001b[0m             functional_utils\u001b[39m.\u001b[39mis_input_keras_tensor(t)\n\u001b[1;32m    159\u001b[0m             \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(inputs)\n\u001b[1;32m    160\u001b[0m         ]\n\u001b[1;32m    161\u001b[0m     ):\n\u001b[1;32m    162\u001b[0m         inputs, outputs \u001b[39m=\u001b[39m functional_utils\u001b[39m.\u001b[39mclone_graph_nodes(\n\u001b[1;32m    163\u001b[0m             inputs, outputs\n\u001b[1;32m    164\u001b[0m         )\n\u001b[0;32m--> 165\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_graph_network(inputs, outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:264\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_coordinates\u001b[39m.\u001b[39mappend((layer, node_index, tensor_index))\n\u001b[1;32m    263\u001b[0m \u001b[39m# Keep track of the network's nodes and layers.\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m nodes, nodes_by_depth, layers, _ \u001b[39m=\u001b[39m _map_graph_network(\n\u001b[1;32m    265\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutputs\n\u001b[1;32m    266\u001b[0m )\n\u001b[1;32m    267\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_network_nodes \u001b[39m=\u001b[39m nodes\n\u001b[1;32m    268\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nodes_by_depth \u001b[39m=\u001b[39m nodes_by_depth\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:1143\u001b[0m, in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m all_names:\n\u001b[1;32m   1142\u001b[0m     \u001b[39mif\u001b[39;00m all_names\u001b[39m.\u001b[39mcount(name) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1143\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1144\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe name \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m is used \u001b[39m\u001b[39m{\u001b[39;00mall_names\u001b[39m.\u001b[39mcount(name)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1145\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtimes in the model. All layer names should be unique.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1146\u001b[0m         )\n\u001b[1;32m   1147\u001b[0m \u001b[39mreturn\u001b[39;00m network_nodes, nodes_by_depth, layers, layers_by_depth\n",
      "\u001b[0;31mValueError\u001b[0m: The name \"dense_4\" is used 2 times in the model. All layer names should be unique."
     ]
    }
   ],
   "source": [
    "# Define our model\n",
    "model = Model(inputs=[model1.input, model2.input, model3.input], outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_data = np.random.rand(100, 1, 286) # example input data\n",
    "labels = np.random.randint(0, 2, size=(100, 1)) # example binary labels\n",
    "\n",
    "binary_model.fit(x=input_data, y=labels, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The name \"dense_5\" is used 2 times in the model. All layer names should be unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m output_layer \u001b[39m=\u001b[39m Dense(\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m)(x)\n\u001b[1;32m     28\u001b[0m \u001b[39m# Define the overall model\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m model \u001b[39m=\u001b[39m Model(inputs\u001b[39m=\u001b[39;49m[model1\u001b[39m.\u001b[39;49minput, model2\u001b[39m.\u001b[39;49minput, model3\u001b[39m.\u001b[39;49minput], outputs\u001b[39m=\u001b[39;49moutput_layer)\n\u001b[1;32m     31\u001b[0m \u001b[39m# Compile the model\u001b[39;00m\n\u001b[1;32m     32\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:165\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m    157\u001b[0m         [\n\u001b[1;32m    158\u001b[0m             functional_utils\u001b[39m.\u001b[39mis_input_keras_tensor(t)\n\u001b[1;32m    159\u001b[0m             \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(inputs)\n\u001b[1;32m    160\u001b[0m         ]\n\u001b[1;32m    161\u001b[0m     ):\n\u001b[1;32m    162\u001b[0m         inputs, outputs \u001b[39m=\u001b[39m functional_utils\u001b[39m.\u001b[39mclone_graph_nodes(\n\u001b[1;32m    163\u001b[0m             inputs, outputs\n\u001b[1;32m    164\u001b[0m         )\n\u001b[0;32m--> 165\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_graph_network(inputs, outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:264\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_coordinates\u001b[39m.\u001b[39mappend((layer, node_index, tensor_index))\n\u001b[1;32m    263\u001b[0m \u001b[39m# Keep track of the network's nodes and layers.\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m nodes, nodes_by_depth, layers, _ \u001b[39m=\u001b[39m _map_graph_network(\n\u001b[1;32m    265\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutputs\n\u001b[1;32m    266\u001b[0m )\n\u001b[1;32m    267\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_network_nodes \u001b[39m=\u001b[39m nodes\n\u001b[1;32m    268\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nodes_by_depth \u001b[39m=\u001b[39m nodes_by_depth\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:1143\u001b[0m, in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m all_names:\n\u001b[1;32m   1142\u001b[0m     \u001b[39mif\u001b[39;00m all_names\u001b[39m.\u001b[39mcount(name) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1143\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1144\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe name \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m is used \u001b[39m\u001b[39m{\u001b[39;00mall_names\u001b[39m.\u001b[39mcount(name)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1145\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtimes in the model. All layer names should be unique.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1146\u001b[0m         )\n\u001b[1;32m   1147\u001b[0m \u001b[39mreturn\u001b[39;00m network_nodes, nodes_by_depth, layers, layers_by_depth\n",
      "\u001b[0;31mValueError\u001b[0m: The name \"dense_5\" is used 2 times in the model. All layer names should be unique."
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the three input models from h5 files\n",
    "model1 = load_model('/UltimeTradingBot/Data/AFTER_DEPTH_CLOSE/tp130_w7_max16min_Model_vInit.h5')\n",
    "model2 = load_model('/UltimeTradingBot/Data/BUY_MIN_CLOSE/tp70_w7_max4min_Model_VeryDeep.h5')\n",
    "model3 = load_model('/UltimeTradingBot/Data/BUY_TEST/tp150_w7_max2min_Model_vInit.h5')\n",
    "\n",
    "# Freeze the weights of the three input models\n",
    "for layer in model1.layers:\n",
    "    layer.trainable = False\n",
    "for layer in model2.layers:\n",
    "    layer.trainable = False\n",
    "for layer in model3.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Get the output tensors of the three input models\n",
    "output1 = model1.output\n",
    "output2 = model2.output\n",
    "output3 = model3.output\n",
    "\n",
    "# Concatenate the output tensors\n",
    "merged = concatenate([output1, output2, output3])\n",
    "\n",
    "# Define the final layers of the model\n",
    "x = Dense(64, activation='relu')(merged)\n",
    "output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Define the overall model\n",
    "model = Model(inputs=[model1.input, model2.input, model3.input], outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't set the attribute \"name\", likely because it conflicts with an existing read-only @property of the object. Please choose a different name.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py:3075\u001b[0m, in \u001b[0;36mLayer.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3075\u001b[0m     \u001b[39msuper\u001b[39;49m(tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49mtracking\u001b[39m.\u001b[39;49mAutoTrackable, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(\n\u001b[1;32m   3076\u001b[0m         name, value\n\u001b[1;32m   3077\u001b[0m     )\n\u001b[1;32m   3078\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m# Add unique names to the layers\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model1\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 17\u001b[0m     layer\u001b[39m.\u001b[39;49mname \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel1_\u001b[39m\u001b[39m{\u001b[39;00mlayer\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model2\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m     19\u001b[0m     layer\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel2_\u001b[39m\u001b[39m{\u001b[39;00mlayer\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py:3079\u001b[0m, in \u001b[0;36mLayer.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   3075\u001b[0m         \u001b[39msuper\u001b[39m(tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mtracking\u001b[39m.\u001b[39mAutoTrackable, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(\n\u001b[1;32m   3076\u001b[0m             name, value\n\u001b[1;32m   3077\u001b[0m         )\n\u001b[1;32m   3078\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m-> 3079\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m   3080\u001b[0m             (\n\u001b[1;32m   3081\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mt set the attribute \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m, likely because it \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   3082\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mconflicts with an existing read-only @property of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3083\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mobject. Please choose a different name.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3084\u001b[0m             )\u001b[39m.\u001b[39mformat(name)\n\u001b[1;32m   3085\u001b[0m         )\n\u001b[1;32m   3086\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   3088\u001b[0m \u001b[39m# Wraps data structures in `Trackable`, unwraps `NoDependency` objects.\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't set the attribute \"name\", likely because it conflicts with an existing read-only @property of the object. Please choose a different name."
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load the models\n",
    "model1 = load_model('/UltimeTradingBot/Data/AFTER_DEPTH_CLOSE/tp130_w7_max16min_Model_vInit.h5')\n",
    "model2 = load_model('/UltimeTradingBot/Data/BUY_MIN_CLOSE/tp70_w7_max4min_Model_VeryDeep.h5')\n",
    "model3 = load_model('/UltimeTradingBot/Data/BUY_TEST/tp150_w7_max2min_Model_vInit.h5')\n",
    "\n",
    "# Define the input shape for our model\n",
    "input_shape = (286,)\n",
    "\n",
    "# Define the input layer for our model\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Add unique names to the layers\n",
    "for layer in model1.layers:\n",
    "    layer.name = f'model1_{layer.name}'\n",
    "for layer in model2.layers:\n",
    "    layer.name = f'model2_{layer.name}'\n",
    "for layer in model3.layers:\n",
    "    layer.name = f'model3_{layer.name}'\n",
    "\n",
    "# Define the input layers\n",
    "input1 = model1.input\n",
    "input2 = model2.input\n",
    "input3 = model3.input\n",
    "\n",
    "# Get the output of each model\n",
    "output1 = model1.output\n",
    "output2 = model2.output\n",
    "output3 = model3.output\n",
    "\n",
    "# Concatenate the outputs\n",
    "merged = concatenate([output1, output2, output3])\n",
    "\n",
    "# Add a dense layer for classification\n",
    "x = Dense(64, activation='relu')(merged)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input1, input2, input3], outputs=x)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Layer model1_dense_3 has no inbound nodes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m input3 \u001b[39m=\u001b[39m model3\u001b[39m.\u001b[39minput\n\u001b[1;32m     19\u001b[0m \u001b[39m# Get the output of each model\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m output1 \u001b[39m=\u001b[39m new_layers1[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49moutput\n\u001b[1;32m     21\u001b[0m output2 \u001b[39m=\u001b[39m new_layers2[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39moutput\n\u001b[1;32m     22\u001b[0m output3 \u001b[39m=\u001b[39m new_layers3[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39moutput\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py:2045\u001b[0m, in \u001b[0;36mLayer.output\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2031\u001b[0m \u001b[39m\"\"\"Retrieves the output tensor(s) of a layer.\u001b[39;00m\n\u001b[1;32m   2032\u001b[0m \n\u001b[1;32m   2033\u001b[0m \u001b[39mOnly applicable if the layer has exactly one output,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2042\u001b[0m \u001b[39m  RuntimeError: if called in Eager mode.\u001b[39;00m\n\u001b[1;32m   2043\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2044\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inbound_nodes:\n\u001b[0;32m-> 2045\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m   2046\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLayer \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m has no inbound nodes.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2047\u001b[0m     )\n\u001b[1;32m   2048\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_node_attribute_at_index(\u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39moutput_tensors\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Layer model1_dense_3 has no inbound nodes."
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load the models\n",
    "model1 = load_model('/UltimeTradingBot/Data/AFTER_DEPTH_CLOSE/tp130_w7_max16min_Model_vInit.h5')\n",
    "model2 = load_model('/UltimeTradingBot/Data/BUY_MIN_CLOSE/tp70_w7_max4min_Model_VeryDeep.h5')\n",
    "model3 = load_model('/UltimeTradingBot/Data/BUY_TEST/tp150_w7_max2min_Model_vInit.h5')\n",
    "\n",
    "# Create new layers with unique names\n",
    "new_layers1 = [Dense(64, activation='relu', name='model1_' + layer.name) for layer in model1.layers]\n",
    "new_layers2 = [Dense(64, activation='relu', name='model2_' + layer.name) for layer in model2.layers]\n",
    "new_layers3 = [Dense(64, activation='relu', name='model3_' + layer.name) for layer in model3.layers]\n",
    "\n",
    "\n",
    "# Define the input layers\n",
    "input1 = model1.input\n",
    "input2 = model2.input\n",
    "input3 = model3.input\n",
    "\n",
    "# Get the output of each model\n",
    "output1 = new_layers1[-1].output\n",
    "output2 = new_layers2[-1].output\n",
    "output3 = new_layers3[-1].output\n",
    "\n",
    "# Concatenate the outputs\n",
    "merged = concatenate([output1, output2, output3])\n",
    "\n",
    "# Add a dense layer for classification\n",
    "x = Dense(64, activation='relu')(merged)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input1, input2, input3], outputs=x)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
